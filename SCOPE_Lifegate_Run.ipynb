{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ek8__7lVidSf"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyOAENXl0lhIiUSADwJA4YE0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajagota7/Shaping/blob/main/SCOPE_Lifegate_Run.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/Shaping\n",
        "# !git pull origin main"
      ],
      "metadata": {
        "id": "wTacK-667akf"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "zZ2S2CI8K_jT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jsHzrhmfpiTr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28ed31b4-5097-4630-dca9-c0b5c877fa39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pygame 2.5.2 (SDL 2.28.2, Python 3.10.12)\n",
            "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from google.colab import drive\n",
        "import pickle\n",
        "# np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)\n",
        "from scipy.optimize import minimize\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.lines import Line2D\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "import sys\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "import copy\n",
        "from copy import deepcopy\n",
        "\n",
        "from typing import List, Union, Callable\n",
        "\n",
        "import pygame\n",
        "import click\n",
        "import random\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lifegate class play"
      ],
      "metadata": {
        "id": "ek8__7lVidSf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# from copy import deepcopy\n",
        "# import pygame\n",
        "# import numpy as np\n",
        "# import click\n"
      ],
      "metadata": {
        "id": "0tbWAPyxi04a"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # RGB colors\n",
        "# WHITE = (255, 255, 255)\n",
        "# BLACK = (0, 0, 0)\n",
        "# RED = (255, 0, 0)\n",
        "# BLUE = (0, 100, 255)\n",
        "# GREEN = (0, 255, 0)\n",
        "# WALL = (80, 80, 80)\n",
        "# YELLOW = (255, 255, 0)\n",
        "\n",
        "\n",
        "\n",
        "# class LifeGate(object):\n",
        "#     def __init__(self, state_mode, rng, death_drag, max_steps=100, fixed_life=True, rendering=False, image_saving=False, render_dir=None):\n",
        "#         self.rng = rng\n",
        "#         self.state_dtype = np.float32\n",
        "#         self.frame_skip = 1  # for env consistency\n",
        "#         self.fixed_life = fixed_life\n",
        "#         self.blue = BLUE\n",
        "#         self.death_drag = death_drag\n",
        "#         self.legal_actions = [0, 1, 2, 3, 4]\n",
        "#         self.action_meanings = ['no-op', 'up', 'down', 'left', 'right']\n",
        "#         self.reward_scheme = {'death': -1.0, 'recovery': +1.0, 'step': 0.0, 'barrier': 0.0}\n",
        "#         self.nb_actions = len(self.legal_actions)\n",
        "#         self.player_pos_x = None\n",
        "#         self.player_pos_y = None\n",
        "#         self.agent_init_pos = None\n",
        "#         self.state_mode = state_mode    # how the returned state look like ('pixel' or '1hot' or 'multi-head')\n",
        "#         # self.scr_w = None\n",
        "#         # self.scr_h = None\n",
        "#         # self.possible_recoveries = []\n",
        "#         self.recovery_observablity = True\n",
        "#         # self.observability_switch_point = None  # where to turn observability off\n",
        "#         # self.rendering_scale = None\n",
        "#         # self.barriers = None\n",
        "#         self.recoveries = None\n",
        "#         self.deaths = None\n",
        "#         # self.dead_ends = None\n",
        "#         self._rendering = rendering\n",
        "#         # self.state_shape = None\n",
        "#         self.init_subclass()\n",
        "#         if rendering:\n",
        "#             self._init_pygame()\n",
        "#         self.image_saving = image_saving\n",
        "#         self.render_dir_main = render_dir\n",
        "#         self.render_dir = None\n",
        "#         self.state = None\n",
        "#         self.step_id = 0\n",
        "#         self.game_over = False\n",
        "\n",
        "#         self.max_steps = max_steps\n",
        "\n",
        "#         self.reset()\n",
        "\n",
        "#     def init_subclass(self):\n",
        "#         # should implement sizes, barriers, recoveries, deaths, init_player(), and rendering_scale\n",
        "#         self.scr_w, self.scr_h = 10, 10\n",
        "#         self.tabular_state_shape = (self.scr_w, self.scr_h)\n",
        "#         self.state_shape = [24]\n",
        "#         self.rendering_scale = 30\n",
        "#         self.barriers = [[0, 0], [1, 0], [2, 0], [3, 0], [4, 0], [1, 5], [2, 5], [3, 5], [4, 5]]\n",
        "#         self.possible_recoveries = [[5, 0], [6, 0], [7, 0]]\n",
        "#         self.main_deaths = [[self.scr_w - 1, k] for k in range(self.scr_h)] + [[8,0]]\n",
        "#         self.dead_ends = [[x, y] for x in range(self.scr_w // 2, self.scr_w - 1) for y in range(self.scr_w // 2, self.scr_w)]\n",
        "#         self.observability_switch_point = [0, 5]\n",
        "\n",
        "#     @property\n",
        "#     def rendering(self):\n",
        "#         return self._rendering\n",
        "\n",
        "#     @rendering.setter\n",
        "#     def rendering(self, flag):\n",
        "#         if flag is True:\n",
        "#             if self._rendering is False:\n",
        "#                 self._init_pygame()\n",
        "#                 self._rendering = True\n",
        "#         else:\n",
        "#             self.close()\n",
        "#             self._rendering = False\n",
        "\n",
        "#     def _init_pygame(self):\n",
        "#         pygame.init()\n",
        "#         size = [self.rendering_scale * self.scr_w, self.rendering_scale * self.scr_h]\n",
        "#         self.screen = pygame.display.set_mode(size)\n",
        "#         pygame.display.set_caption(\"LifeGate\")\n",
        "\n",
        "#     def _init_rendering_folder(self):\n",
        "#         if self.render_dir_main is None:\n",
        "#             self.render_dir_main = 'render'\n",
        "#         if not os.path.exists(os.path.join(os.getcwd(), self.render_dir_main)):\n",
        "#             os.mkdir(os.path.join(os.getcwd(), self.render_dir_main))\n",
        "#         i = 0\n",
        "#         while os.path.exists(os.path.join(os.getcwd(), self.render_dir_main, 'render' + str(i))):\n",
        "#             i += 1\n",
        "#         self.render_dir = os.path.join(os.getcwd(), self.render_dir_main, 'render' + str(i))\n",
        "#         os.mkdir(self.render_dir)\n",
        "\n",
        "#     def reset(self):\n",
        "#         if self.image_saving:\n",
        "#             self._init_rendering_folder()\n",
        "#         self.game_over = False\n",
        "#         self.step_id = 0\n",
        "#         self.recovery_observablity = True\n",
        "#         self.blue = BLUE\n",
        "#         state = self.init_episode()\n",
        "#         return state\n",
        "\n",
        "#     def init_episode(self):\n",
        "#         # should implement reconfigurations at the beginning of each episode\n",
        "#         self.player_pos_x, self.player_pos_y = 2, self.scr_h - 1\n",
        "#         targets = deepcopy(self.possible_recoveries)\n",
        "#         # if self.fixed_life == True:\n",
        "#         #     rec = targets.pop(2)  # fixed life-gate for DQN\n",
        "#         # else:\n",
        "#         #     rec = targets.pop(self.rng.randint(len(targets)))\n",
        "#         self.recoveries = targets #[rec]\n",
        "#         self.deaths = self.main_deaths #+ targets\n",
        "#         return self.get_obs(self.state_mode)\n",
        "\n",
        "#     def render(self):\n",
        "#         if not self.rendering:\n",
        "#             return\n",
        "#         pygame.event.pump()\n",
        "#         self.screen.fill(BLACK)\n",
        "#         size = [self.rendering_scale, self.rendering_scale]\n",
        "#         for pos in self.dead_ends:\n",
        "#             p = [self.rendering_scale * pos[0], self.rendering_scale * pos[1]]\n",
        "#             rec1 = pygame.Rect(p[0], p[1], size[0], size[1])\n",
        "#             pygame.draw.rect(self.screen, YELLOW, rec1)\n",
        "#         player = pygame.Rect(self.rendering_scale * self.player_pos_x, self.rendering_scale * self.player_pos_y,\n",
        "#                              size[0], size[1])\n",
        "#         pygame.draw.rect(self.screen, WHITE, player)\n",
        "#         for pos in self.deaths:\n",
        "#             p = [self.rendering_scale * pos[0], self.rendering_scale * pos[1]]\n",
        "#             rec1 = pygame.Rect(p[0], p[1], size[0], size[1])\n",
        "#             pygame.draw.rect(self.screen, RED, rec1)\n",
        "#         for pos in self.recoveries:\n",
        "#             p = [self.rendering_scale * pos[0], self.rendering_scale * pos[1]]\n",
        "#             rec1 = pygame.Rect(p[0], p[1], size[0], size[1])\n",
        "#             pygame.draw.rect(self.screen, self.blue, rec1)  # self.blue will change if reach obs point\n",
        "#         for pos in self.barriers:\n",
        "#             p = [self.rendering_scale * pos[0], self.rendering_scale * pos[1]]\n",
        "#             rec1 = pygame.Rect(p[0], p[1], size[0], size[1])\n",
        "#             pygame.draw.rect(self.screen, WALL, rec1)\n",
        "#         pygame.display.flip()\n",
        "\n",
        "#         if self.image_saving:\n",
        "#             self.save_image()\n",
        "\n",
        "#     def save_image(self):\n",
        "#         if self.rendering and self.render_dir is not None:\n",
        "#             pygame.image.save(self.screen, self.render_dir + '/render' + str(self.step_id) + '.jpg')\n",
        "#         else:\n",
        "#             raise ValueError('env.rendering is False and/or environment has not been reset.')\n",
        "\n",
        "#     def close(self):\n",
        "#         if self.rendering:\n",
        "#             pygame.quit()\n",
        "\n",
        "#     def _move_player(self, action):\n",
        "#         x, y = (self.player_pos_x, self.player_pos_y)\n",
        "#         # dead-end:\n",
        "#         if [x, y] in self.dead_ends:\n",
        "#             if self.rng.binomial(1, 0.70):\n",
        "#                 action = 4  # forceful right\n",
        "#             else:\n",
        "#                 action = 0  # no-op\n",
        "#         else:\n",
        "#             # natural risk of death\n",
        "#             if self.rng.binomial(1, self.death_drag):  # say with 25% if death_drag==0.25\n",
        "#                 action = 4\n",
        "\n",
        "#         if action == 4:    # right\n",
        "#             x += 1\n",
        "#         elif action == 3:  # left\n",
        "#             x -= 1\n",
        "#         elif action == 2:  # down\n",
        "#             y += 1\n",
        "#         elif action == 1:  # up\n",
        "#             y -= 1\n",
        "#         # updating the position\n",
        "#         if [x, y] in self.barriers or x < 0 or y < 0 or y >= self.scr_h:\n",
        "#             return\n",
        "#         else:\n",
        "#             self.player_pos_x, self.player_pos_y = x, y\n",
        "\n",
        "#     def _get_status(self):\n",
        "#         # check the current situation\n",
        "#         if [self.player_pos_x, self.player_pos_y] in self.deaths:\n",
        "#             return 'death'\n",
        "#         elif [self.player_pos_x, self.player_pos_y] in self.recoveries:\n",
        "#             return 'recovery'\n",
        "\n",
        "#     def step(self, action):\n",
        "#         assert action in self.legal_actions, 'Illegal action.'\n",
        "#         if self.step_id >= self.max_steps - 1:\n",
        "#             self.game_over = True\n",
        "#             return self.get_obs(self.state_mode), 0., self.game_over, {}\n",
        "#         self.step_id += 1\n",
        "#         self._move_player(action)\n",
        "#         if [self.player_pos_x, self.player_pos_y] == self.observability_switch_point and self.recovery_observablity == True:\n",
        "#             self.recovery_observablity = False\n",
        "#             self.blue = BLACK\n",
        "#         status = self._get_status()\n",
        "#         if status == 'death':\n",
        "#             self.game_over = True\n",
        "#             reward = self.reward_scheme['death']\n",
        "#         elif status == 'recovery':\n",
        "#             self.game_over = True\n",
        "#             reward = self.reward_scheme['recovery']\n",
        "#         else:\n",
        "#             reward = self.reward_scheme['step']\n",
        "#         return self.get_obs(self.state_mode), reward, self.game_over, {}\n",
        "\n",
        "#     def get_lives(self):\n",
        "#         if self.game_over == True:\n",
        "#             return 0\n",
        "#         else:\n",
        "#             return 1\n",
        "\n",
        "#     def get_state(self):\n",
        "#         return self.get_obs(self.state_mode)\n",
        "\n",
        "#     def get_obs(self, method):\n",
        "#         if method == 'vector':\n",
        "#             return self._get_vec_obs()\n",
        "#         elif method == 'pixel':\n",
        "#             return self._get_pixel_obs()\n",
        "#         elif method == 'tabular':\n",
        "#             return self._get_tabular_obs()\n",
        "#         else:\n",
        "#             raise ValueError('Unknown observation method.')\n",
        "\n",
        "#     def _get_vec_obs(self):\n",
        "#         x = np.zeros(self.scr_w + self.scr_h + len(self.possible_recoveries), dtype=self.state_dtype)\n",
        "#         x[self.player_pos_x] = 1.0\n",
        "#         x[self.player_pos_y + self.scr_w] = 1.0\n",
        "#         if self.recovery_observablity == True or self.fixed_life == True:\n",
        "#             for k in self.recoveries:\n",
        "#                 x[k[0] - 5 + self.scr_w + self.scr_h] = 1.0\n",
        "#         return x\n",
        "\n",
        "#     def _get_tabular_obs(self):\n",
        "#         return np.array([self.player_pos_x, self.player_pos_y])\n",
        "\n",
        "#     def _get_pixel_obs(self):\n",
        "#         raise NotImplementedError"
      ],
      "metadata": {
        "id": "1p8iyu4BifbS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# shaping dependencies"
      ],
      "metadata": {
        "id": "AsZMw4C0f2K-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ajagota7/Shaping.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wu7X59dK3hqk",
        "outputId": "e502e086-44e9-40d4-af32-236f334527c0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Shaping'...\n",
            "remote: Enumerating objects: 319, done.\u001b[K\n",
            "remote: Counting objects: 100% (107/107), done.\u001b[K\n",
            "remote: Compressing objects: 100% (74/74), done.\u001b[K\n",
            "remote: Total 319 (delta 63), reused 76 (delta 33), pack-reused 212\u001b[K\n",
            "Receiving objects: 100% (319/319), 12.99 MiB | 7.56 MiB/s, done.\n",
            "Resolving deltas: 100% (178/178), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile('/content/Shaping/lifegate_1.zip', 'r') as zip_ref:\n",
        "    # zip_ref.extractall('/content/med-deadend/lifegate/results/lifegate_1')\n",
        "    zip_ref.extractall('/content/Shaping/')"
      ],
      "metadata": {
        "id": "2noY6FOTdsmY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/Shaping/')\n",
        "\n"
      ],
      "metadata": {
        "id": "id2reVHQ3heg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import q_networks"
      ],
      "metadata": {
        "id": "DgppFp3cDm4L"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/med-deadend/lifegate\n",
        "\n",
        "\n",
        "# results_dir = 'results/lifegate_1/'\n",
        "results_dir = '/content/Shaping/'\n",
        "# Load the Q tables from the primary learning agent, Q_D and Q_R value functions\n",
        "with open(results_dir+'tabular_qnet.pkl', 'rb') as fq:\n",
        "    ai = pickle.load(fq)\n",
        "\n",
        "with open(results_dir+'tabular_qd.pkl', 'rb') as fd:\n",
        "    ai_d = pickle.load(fd)\n",
        "\n",
        "with open(results_dir+'tabular_qr.pkl', 'rb') as fr:\n",
        "    ai_r = pickle.load(fr)"
      ],
      "metadata": {
        "id": "7lv4ZIBkeLW3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q_table = np.zeros((10, 10, 5))\n",
        "q_d = np.zeros_like(q_table)\n",
        "q_r = np.zeros_like(q_table)\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    for j in range(10):\n",
        "        for a in range(5):\n",
        "            key = tuple([j, i, a])\n",
        "            try:\n",
        "                q_table[i,j,a] = ai.q[key]\n",
        "                q_d[i,j,a] = ai_d.q[key]\n",
        "                q_r[i,j,a] = ai_r.q[key]\n",
        "            except:\n",
        "                pass"
      ],
      "metadata": {
        "id": "Rk0Z42sNebl4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q_table[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VN6wsQe24GTy",
        "outputId": "5766f8f1-09f7-4289-fd23-35602074499e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import yaml\n",
        "# import random\n",
        "# from lifegate import LifeGate\n",
        "# params = yaml.safe_load(open(results_dir+'config.yaml', 'r'))\n",
        "# np.random.seed(seed=params['random_seed'])\n",
        "# random.seed(params['random_seed'])\n",
        "# random_state = np.random.RandomState(params['random_seed'])"
      ],
      "metadata": {
        "id": "4uTTjsWNfK21"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import Shaping\n",
        "from Shaping import *\n",
        "from shaping_features import *\n",
        "from IS import *\n",
        "from neural_net import *\n",
        "from SCOPE_straight import SCOPE_straight\n",
        "from existing_experiments import existing_experiments\n",
        "from SCOPE_experiment import SCOPE_experiment\n",
        "from multi_experiment_visualisations import *\n",
        "from lifegate import LifeGate"
      ],
      "metadata": {
        "id": "fjtHFmIzWlSn"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount Drive"
      ],
      "metadata": {
        "id": "0cfld7A1b26t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3aWklQ8b4iA",
        "outputId": "2aff7866-78b5-473f-932a-970cd7a4b1c7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Varying Shaping Function Sets"
      ],
      "metadata": {
        "id": "PAfVYVH6ahN3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following experiments are organized by shaping function. Given a chosen shaping function, the number of trajectories, max length of trajectories, neural network architecture, and train set size among other variables are played with"
      ],
      "metadata": {
        "id": "q-4EYv50Jisq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## smallest distance to dead end"
      ],
      "metadata": {
        "id": "7pLq1p90RzqG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    # Parameters related to policy generation\n",
        "    \"pi_b_top_k\": 1,\n",
        "    \"pi_b_epsilon\": 0.4,\n",
        "    \"pi_e_top_k\": 1,\n",
        "    \"pi_e_epsilon\": 0.05,\n",
        "    \"q_table\": q_table,\n",
        "    \"gamma\": 0.99,\n",
        "    \"num_trajectories\": 200,\n",
        "    \"num_bootstraps\": 10000,\n",
        "    \"percent_to_estimate_phi\": 0.3,\n",
        "\n",
        "    # Parameters related to shaping\n",
        "    \"shaping_feature\": smallest_distance_to_deadend,\n",
        "    \"shaping_coefficient\": 0.1,\n",
        "\n",
        "    # Parameters related to neural network architecture and training\n",
        "    \"hidden_dims\": [8, 8],\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"dropout_prob\": 0.2,\n",
        "    \"l1_reg\": 0.00001,\n",
        "    \"l2_reg\": 0.00001,\n",
        "    \"scope_weight\": 1,\n",
        "    \"mse_weight\": 1,\n",
        "    \"num_epochs\": 300,\n",
        "\n",
        "    # Parameters related to environment\n",
        "    \"max_length\": 50,\n",
        "    \"death_drag\": 0.0,\n",
        "    # Other general parameters\n",
        "    \"dtype\": torch.float64,\n",
        "    \"experiment_type\": \"test\",\n",
        "    \"folder_path\": \"/content/drive/MyDrive/Lifegate_experiments\"\n",
        "    # \"folder_path\": \"/content\"\n",
        "}"
      ],
      "metadata": {
        "id": "EhqHlUgzi9SS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the varying trajectory lengths\n",
        "num_trajectories = [200, 400, 600, 800, 1000]\n",
        "# Define hidden_dims\n",
        "hidden_dimens = [[8],[8,8],[32]]\n",
        "# Define trajectory lengths\n",
        "trajectory_length = [30, 50, 70, 100]\n",
        "\n",
        "for num in num_trajectories:\n",
        "  # Modify the base parameters for each experiment\n",
        "  # params = base_params_test.copy()  # Make a copy to avoid modifying the base parameters\n",
        "  params[\"num_trajectories\"] = num  # Update the number of trajectories\n",
        "\n",
        "  for dims in hidden_dimens:\n",
        "    # params = base_params_test.copy()  # Make a copy to avoid modifying the base parameters\n",
        "    params[\"hidden_dims\"] = dims\n",
        "\n",
        "    for len in trajectory_length:\n",
        "      params[\"max_length\"] = len\n",
        "\n",
        "      # Create an instance of SCOPE_experiment with modified parameters\n",
        "      test_experiment = SCOPE_experiment(**params)\n",
        "      test_experiment.run_experiment()"
      ],
      "metadata": {
        "id": "bJY4CTyl3Ld6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the varying trajectory lengths\n",
        "num_trajectories = [200, 400, 600, 800, 1000]\n",
        "# Define hidden_dims\n",
        "hidden_dimens = [[8],[8,8],[32]]\n",
        "# Define trajectory lengths\n",
        "trajectory_length = [30, 50, 70, 100]\n",
        "\n",
        "for num in num_trajectories:\n",
        "  # Modify the base parameters for each experiment\n",
        "  # params = base_params_test.copy()  # Make a copy to avoid modifying the base parameters\n",
        "  params[\"num_trajectories\"] = num  # Update the number of trajectories\n",
        "\n",
        "  for dims in hidden_dimens:\n",
        "    # params = base_params_test.copy()  # Make a copy to avoid modifying the base parameters\n",
        "    params[\"hidden_dims\"] = dims\n",
        "\n",
        "    for len in trajectory_length:\n",
        "      params[\"max_length\"] = len\n",
        "\n",
        "      # Create an instance of SCOPE_experiment with modified parameters\n",
        "      test_experiment = SCOPE_experiment(**params)\n",
        "      # test_experiment.run_experiment()\n",
        "      test_experiment.plot_metrics_save(save= True)"
      ],
      "metadata": {
        "id": "sGYxb-YJImGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## smallest distance to recovery"
      ],
      "metadata": {
        "id": "y-Vp1cTrRtYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    # Parameters related to policy generation\n",
        "    \"pi_b_top_k\": 1,\n",
        "    \"pi_b_epsilon\": 0.4,\n",
        "    \"pi_e_top_k\": 1,\n",
        "    \"pi_e_epsilon\": 0.05,\n",
        "    \"q_table\": q_table,\n",
        "    \"gamma\": 0.99,\n",
        "    \"num_trajectories\": 200,\n",
        "    \"num_bootstraps\": 10000,\n",
        "    \"percent_to_estimate_phi\": 0.3,\n",
        "\n",
        "    # Parameters related to shaping\n",
        "    \"shaping_feature\": smallest_distance_to_recovery,\n",
        "    \"shaping_coefficient\": 0.1,\n",
        "\n",
        "    # Parameters related to neural network architecture and training\n",
        "    \"hidden_dims\": [8],\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"dropout_prob\": 0.2,\n",
        "    \"l1_reg\": 0.00001,\n",
        "    \"l2_reg\": 0.00001,\n",
        "    \"scope_weight\": 1,\n",
        "    \"mse_weight\": 1,\n",
        "    \"num_epochs\": 300,\n",
        "\n",
        "    # Parameters related to environment\n",
        "    \"max_length\": 30,\n",
        "    \"death_drag\": 0.0,\n",
        "    # Other general parameters\n",
        "    \"dtype\": torch.float64,\n",
        "    \"experiment_type\": \"test\",\n",
        "    \"folder_path\": \"/content/drive/MyDrive/Lifegate_experiments\"\n",
        "    # \"folder_path\": \"/content\"\n",
        "}"
      ],
      "metadata": {
        "id": "AN4IdEycRFtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_experiment = SCOPE_experiment(**params)\n",
        "# test_experiment.run_experiment()\n",
        "test_load = existing_experiments(test_experiment)\n",
        "test_load.get_heatmap()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "uthX6ChZJU63",
        "outputId": "2c6938e6-9616-4476-a5df-13f8800631eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"3a51b487-c5e8-481e-adbb-c47061d28783\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"3a51b487-c5e8-481e-adbb-c47061d28783\")) {                    Plotly.newPlot(                        \"3a51b487-c5e8-481e-adbb-c47061d28783\",                        [{\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"z\":[[0.21525313377144034,0.18346766985078272,0.11636995566277952,0.08926190658739122,0.06215385751200292,0.03695526808915467,0.012844032019626472,-0.01126720404990178,-0.03537844011942992,-0.05948967618895812],[0.34949011564369226,0.3612523316279045,0.3084528920608829,0.25127176438700377,0.22716052831747566,0.2030492922479475,0.17893805617841926,0.15482682010889098,0.13071558403936284,0.1066043479698347],[0.4934790049286973,0.5099556701587027,0.508636460324316,0.44351590664188356,0.3932545524762684,0.36914331640674025,0.345032080337212,0.3209208442676838,0.29680960819815566,0.27269837212862746],[0.6059687928945006,0.618493039781908,0.6310172866693153,0.6198646117583957,0.5785789212228842,0.5352373405655331,0.5111261044960048,0.4870148684264766,0.4629036323569485,0.4387923962874203],[0.7184585808603041,0.7309828277477115,0.7435070746351189,0.7560313215225263,0.7055148815500889,0.665166602509762,0.6535170700027799,0.6531088925852695,0.6289976565157411,0.604886420446213],[0.8309483688261075,0.8434726157135148,0.8559968626009222,0.8685211094883296,0.8673256973627508,0.8028888063607302,0.750816872301455,0.7460871133027371,0.7467481518753143,0.7474091904478914],[0.9434381567919108,0.9559624036793182,0.9684866505667256,0.981010897454133,0.9935351443415403,0.968250575340954,0.9025003012799311,0.8382790031558769,0.8386571566026941,0.8393181951752713],[1.0559279447577141,1.0684521916451215,1.080976438532529,1.0935006854199365,1.1060249323073437,1.1108332280105426,1.067862070260155,1.002111796199132,0.9448102715833417,0.9312271999026513],[1.1684177327235175,1.180941979610925,1.1934662264983322,1.2059904733857398,1.2185147202731472,1.2310389671605546,1.219825022385166,1.167473565179356,1.101723291118333,1.0513415400108066],[1.280907520689321,1.2934317675767284,1.3059560144641358,1.3184802613515432,1.3310045082389506,1.343528755126358,1.354340758658335,1.3288168167597898,1.267085060098557,1.201334786037534]],\"type\":\"heatmap\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"Values\"},\"ticks\":\"outside\",\"tickvals\":[-0.05948967618895812,1.354340758658335],\"ticktext\":[-0.05948967618895812,1.354340758658335]}},\"xaxis\":{\"tickvals\":[0,1,2,3,4,5,6,7,8,9],\"ticktext\":[0,1,2,3,4,5,6,7,8,9],\"title\":{\"text\":\"X\"}},\"yaxis\":{\"tickvals\":[9,8,7,6,5,4,3,2,1,0],\"ticktext\":[9,8,7,6,5,4,3,2,1,0],\"title\":{\"text\":\"Y\"},\"autorange\":\"reversed\"},\"title\":{\"text\":\"Heatmap\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('3a51b487-c5e8-481e-adbb-c47061d28783');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the varying trajectory lengths\n",
        "num_trajectories = [200, 400, 600, 800, 1000]\n",
        "# Define hidden_dims\n",
        "hidden_dimens = [[8],[8,8],[32]]\n",
        "# Define trajectory lengths\n",
        "trajectory_length = [30, 50, 70, 100]\n",
        "\n",
        "for num in num_trajectories:\n",
        "  # Modify the base parameters for each experiment\n",
        "  # params = base_params_test.copy()  # Make a copy to avoid modifying the base parameters\n",
        "  params[\"num_trajectories\"] = num  # Update the number of trajectories\n",
        "\n",
        "  for dims in hidden_dimens:\n",
        "    # params = base_params_test.copy()  # Make a copy to avoid modifying the base parameters\n",
        "    params[\"hidden_dims\"] = dims\n",
        "\n",
        "    for len in trajectory_length:\n",
        "      params[\"max_length\"] = len\n",
        "\n",
        "      # Create an instance of SCOPE_experiment with modified parameters\n",
        "      test_experiment = SCOPE_experiment(**params)\n",
        "      test_experiment.run_experiment()"
      ],
      "metadata": {
        "id": "3JB7O1OvRcln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the varying trajectory lengths\n",
        "num_trajectories = [200, 400, 600, 800, 1000]\n",
        "# Define hidden_dims\n",
        "hidden_dimens = [[8],[8,8],[32]]\n",
        "# Define trajectory lengths\n",
        "trajectory_length = [30, 50, 70, 100]\n",
        "\n",
        "for num in num_trajectories:\n",
        "  # Modify the base parameters for each experiment\n",
        "  # params = base_params_test.copy()  # Make a copy to avoid modifying the base parameters\n",
        "  params[\"num_trajectories\"] = num  # Update the number of trajectories\n",
        "\n",
        "  for dims in hidden_dimens:\n",
        "    # params = base_params_test.copy()  # Make a copy to avoid modifying the base parameters\n",
        "    params[\"hidden_dims\"] = dims\n",
        "\n",
        "    for len in trajectory_length:\n",
        "      params[\"max_length\"] = len\n",
        "\n",
        "      # Create an instance of SCOPE_experiment with modified parameters\n",
        "      test_experiment = SCOPE_experiment(**params)\n",
        "      # test_experiment.run_experiment()\n",
        "      test_load = existing_experiments(test_experiment)\n",
        "      test_load.plot_metrics_save(save= True)\n",
        "      print(test_load.experiment_instance.generate_file_name())\n"
      ],
      "metadata": {
        "id": "KQFSG4PeePw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the varying trajectory lengths\n",
        "num_trajectories = [200, 400, 600, 800, 1000]\n",
        "# Define hidden_dims\n",
        "hidden_dimens = [[8],[8,8],[32]]\n",
        "# Define trajectory lengths\n",
        "trajectory_length = [30, 50, 70, 100]\n",
        "\n",
        "for num in num_trajectories:\n",
        "  # Modify the base parameters for each experiment\n",
        "  # params = base_params_test.copy()  # Make a copy to avoid modifying the base parameters\n",
        "  params[\"num_trajectories\"] = num  # Update the number of trajectories\n",
        "\n",
        "  for dims in hidden_dimens:\n",
        "    # params = base_params_test.copy()  # Make a copy to avoid modifying the base parameters\n",
        "    params[\"hidden_dims\"] = dims\n",
        "\n",
        "    for len in trajectory_length:\n",
        "      params[\"max_length\"] = len\n",
        "\n",
        "      # Create an instance of SCOPE_experiment with modified parameters\n",
        "      test_experiment = SCOPE_experiment(**params)\n",
        "      # test_experiment.run_experiment()\n",
        "      test_load = existing_experiments(test_experiment)\n",
        "      test_load.plot_metrics_save(save= True)\n",
        "      print(test_load.experiment_instance.generate_file_name())"
      ],
      "metadata": {
        "id": "jgteQgU2la8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_trajectories = [200, 400, 600, 800, 1000]\n",
        "dims = [[8], [8,8], [32]]\n",
        "trajectory_length = [30, 50, 70, 100]\n",
        "\n",
        "for i in dims:\n",
        "  params[\"hidden_dims\"] = i\n",
        "  for len in trajectory_length:\n",
        "    params[\"max_length\"] = len\n",
        "    save__experiments_over_trajectories(params, num_trajectories)"
      ],
      "metadata": {
        "id": "NN0hlh6BomLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regional Shaping around bottleneck"
      ],
      "metadata": {
        "id": "xc625XVbSY0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    # Parameters related to policy generation\n",
        "    \"pi_b_top_k\": 1,\n",
        "    \"pi_b_epsilon\": 0.7,\n",
        "    \"pi_e_top_k\": 1,\n",
        "    \"pi_e_epsilon\": 0.2,\n",
        "    \"q_table\": q_table,\n",
        "    \"gamma\": 0.99,\n",
        "    \"num_trajectories\": 800,\n",
        "    \"num_bootstraps\": 10000,\n",
        "    \"percent_to_estimate_phi\": 0.3,\n",
        "\n",
        "    # Parameters related to shaping\n",
        "    \"shaping_feature\": bottleneck_four_regions_k_p9_a_1,\n",
        "    \"shaping_coefficient\": 0.1,\n",
        "\n",
        "    # Parameters related to neural network architecture and training\n",
        "    \"hidden_dims\": [8,8],\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"dropout_prob\": 0.2,\n",
        "    \"l1_reg\": 0.00001,\n",
        "    \"l2_reg\": 0.00001,\n",
        "    \"scope_weight\": 1.0,\n",
        "    \"mse_weight\": 1.0,\n",
        "    \"num_epochs\": 500,\n",
        "\n",
        "    # Parameters related to environment\n",
        "    \"max_length\": 50,\n",
        "    \"death_drag\": 0.0,\n",
        "    # Other general parameters\n",
        "    \"dtype\": torch.float32,\n",
        "    \"experiment_type\": \"test\",\n",
        "    \"folder_path\": \"/content/drive/MyDrive/Lifegate_experiments\"\n",
        "    # \"folder_path\": \"/content\"\n",
        "}"
      ],
      "metadata": {
        "id": "xxOfZcRKk3A3"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_trajectories = [200, 400, 600, 800, 1000]\n",
        "\n",
        "for i in list_trajectories:\n",
        "  params[\"num_trajectories\"] = i\n",
        "  test_experiment = SCOPE_experiment(**params)\n",
        "  print(f\"{i} trajectories:\")\n",
        "\n",
        "  test_load = existing_experiments(test_experiment)\n",
        "  test_load.plot_metrics()\n",
        "  test_load.get_heatmap()\n",
        "  test_load.get_state_visitation_heatmap()\n",
        "\n",
        "  # test_experiment.run_experiment()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_e-OZq_iYhVB",
        "outputId": "9e6b4f0b-9b21-47bf-ceff-95f730466857"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200 trajectories:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"8fc7f672-1503-4916-84d8-d9629c72ce75\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"8fc7f672-1503-4916-84d8-d9629c72ce75\")) {                    Plotly.newPlot(                        \"8fc7f672-1503-4916-84d8-d9629c72ce75\",                        [{\"mode\":\"lines\",\"name\":\"IS Estimate\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377,0.029925204813480377],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"Train Estimate\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[-0.2092474102973938,0.5280756950378418,0.5103650093078613,0.49352920055389404,0.47705867886543274,0.4623306691646576,0.4516686499118805,0.44039028882980347,0.42727217078208923,0.4139677882194519,0.4011808931827545,0.3893173336982727,0.3776566684246063,0.36556848883628845,0.3536151349544525,0.3422490656375885,0.33113133907318115,0.3200659453868866,0.30909445881843567,0.29815182089805603,0.28728577494621277,0.2768080532550812,0.26725929975509644,0.2585638761520386,0.25017493963241577,0.24379262328147888,0.2385980486869812,0.23378513753414154,0.22962187230587006,0.225075364112854,0.22049397230148315,0.21603524684906006,0.21173906326293945,0.20800574123859406,0.20451553165912628,0.20089632272720337,0.1973021775484085,0.19376240670681,0.19032804667949677,0.18686462938785553,0.18340666592121124,0.18010924756526947,0.17690995335578918,0.17380432784557343,0.17080539464950562,0.167852520942688,0.16492506861686707,0.1621846705675125,0.1592029631137848,0.15576787292957306,0.15224695205688477,0.14884033799171448,0.1455431580543518,0.14237824082374573,0.13934360444545746,0.1364193856716156,0.1336040496826172,0.1308964043855667,0.12830549478530884,0.12582717835903168,0.12353230267763138,0.12131225317716599,0.1191740483045578,0.11711667478084564,0.1151379868388176,0.11323025077581406,0.11138657480478287,0.10960716754198074,0.10789480060338974,0.10621524602174759,0.10456456243991852,0.10297026485204697,0.10142802447080612,0.09993734955787659,0.0984920859336853,0.09709327667951584,0.09574020653963089,0.09442993253469467,0.09315463900566101,0.09190148860216141,0.09067597985267639,0.08947328478097916,0.08830025047063828,0.08715462684631348,0.08603545278310776,0.08497823029756546,0.08399229496717453,0.08306089788675308,0.08215522021055222,0.08114197105169296,0.08016085624694824,0.07919993251562119,0.07825718075037003,0.07737207412719727,0.0765061005949974,0.07565341889858246,0.07481788098812103,0.07399296760559082,0.07317718863487244,0.07236924767494202,0.07156727463006973,0.07077613472938538,0.06998781859874725,0.06919801980257034,0.06841151416301727,0.06762457638978958,0.06683523952960968,0.06599662452936172,0.06515999883413315,0.06432491540908813,0.06351599842309952,0.06272891908884048,0.061939842998981476,0.06114882975816727,0.06035345420241356,0.05955838784575462,0.05876421555876732,0.05797108635306358,0.05718804895877838,0.05640948563814163,0.055630531162023544,0.05489066615700722,0.05419507995247841,0.05351393297314644,0.05283213034272194,0.05214950069785118,0.05146847665309906,0.050786856561899185,0.05010408163070679,0.04942043125629425,0.0487387590110302,0.04805474355816841,0.04736774414777756,0.046678632497787476,0.0459878034889698,0.04529515653848648,0.04460214078426361,0.043884649872779846,0.04312291741371155,0.04236253350973129,0.04160380735993385,0.040847402065992355,0.0400930717587471,0.03934182599186897,0.038592901080846786,0.03784613683819771,0.03710354119539261,0.03636222705245018,0.03562147915363312,0.034890662878751755,0.03416287526488304,0.03343704715371132,0.03271475434303284,0.03199734911322594,0.031282469630241394,0.03056267648935318,0.029838470742106438,0.029117630794644356,0.028400607407093048,0.02768811583518982,0.026964260265231133,0.026238132268190384,0.025516007095575333,0.02479727938771248,0.024289995431900024,0.02391849085688591,0.02354653738439083,0.023206884041428566,0.02287127450108528,0.02253877930343151,0.022205635905265808,0.02188173308968544,0.021566715091466904,0.021251168102025986,0.020936675369739532,0.020625486969947815,0.02031390182673931,0.020002033561468124,0.01968098059296608,0.019366448745131493,0.019052300602197647,0.018738575279712677,0.018425174057483673,0.018046025186777115,0.017661908641457558,0.017279714345932007,0.01690060645341873,0.016522608697414398,0.01613893359899521,0.01573428511619568,0.015330792404711246,0.014928230084478855,0.01452692225575447,0.0141270337626338,0.01372846681624651,0.013331335037946701,0.012925042770802975,0.012503637000918388,0.012092290446162224,0.011685872450470924,0.0112873874604702,0.010895904153585434,0.010552839376032352,0.010177040472626686,0.009800879284739494,0.009433381259441376,0.009105376899242401,0.00878293439745903,0.008455819450318813,0.00812417920678854,0.007792826741933823,0.007462167181074619,0.007131967227905989,0.006805910263210535,0.006432367023080587,0.006052270531654358,0.005673217121511698,0.0052958144806325436,0.004922074265778065,0.004548980854451656,0.004205907229334116,0.0038983894046396017,0.0036064288578927517,0.0033151984680444,0.003024850506335497,0.0027354166377335787,0.002460181014612317,0.0021914129611104727,0.0019256829982623458,0.0016619705129414797,0.001377656008116901,0.0010947533883154392,0.0008238027803599834,0.0005440242821350694,0.0002663258637767285,-9.907435924105812e-06,-0.0002853844198398292,-0.0005626144120469689,-0.0008387269917875528,-0.001113001024350524,-0.001385550363920629,-0.0016645437572151423,-0.001960515510290861,-0.002254356862977147,-0.0025666423607617617,-0.0028974972665309906,-0.0032261668238788843,-0.0035527432337403297,-0.003877199487760663,-0.00419964361935854,-0.0045188916847109795,-0.004835563246160746,-0.005166629794985056,-0.005509940441697836,-0.005851398222148418,-0.006151032168418169,-0.006376256234943867,-0.0066000414080917835,-0.006822334136813879,-0.007043282967060804,-0.007263577077537775,-0.007482713088393211,-0.007692266721278429,-0.007890742272138596,-0.008088285103440285,-0.008284569717943668,-0.008479414507746696,-0.008654875680804253,-0.008823848329484463,-0.008991099894046783,-0.009156322106719017,-0.009319155476987362,-0.009480166248977184,-0.009639252908527851,-0.009796739555895329,-0.009952588938176632,-0.01010683923959732,-0.010259630158543587,-0.01037103682756424,-0.010478110983967781,-0.010590039193630219,-0.010705327615141869,-0.010821806266903877,-0.010935971513390541,-0.01104861218482256,-0.011161734350025654,-0.01127281691879034,-0.01138297002762556,-0.011492537334561348,-0.011601531878113747,-0.011709965765476227,-0.01181783340871334,-0.011925108730793,-0.01203212607651949,-0.01214631088078022,-0.012259827926754951,-0.012371726334095001,-0.012482843361794949,-0.01255458127707243,-0.012615357525646687,-0.012766953557729721,-0.01292612124234438,-0.013078314252197742,-0.013225244358181953,-0.013370047323405743,-0.013514227233827114,-0.013657818548381329,-0.013800623826682568,-0.013942686840891838,-0.014084170572459698,-0.014225656166672707,-0.01437369268387556,-0.014521928504109383,-0.014665435999631882,-0.014808102510869503,-0.01495012640953064,-0.01509148720651865,-0.015232165344059467,-0.01537234801799059,-0.015511984005570412,-0.015651095658540726,-0.015789657831192017,-0.015927838161587715,-0.01606547087430954,-0.016202647238969803,-0.016342241317033768,-0.01648535765707493,-0.016629068180918694,-0.01677200384438038,-0.01691410318017006,-0.0170554481446743,-0.017196044325828552,-0.017332499846816063,-0.01746544800698757,-0.017597246915102005,-0.017728378996253014,-0.01785903424024582,-0.01798916794359684,-0.01811598613858223,-0.018240980803966522,-0.018364673480391502,-0.018487580120563507,-0.0186099074780941,-0.018731730058789253,-0.018851883709430695,-0.018969671800732613,-0.019090691581368446,-0.019212475046515465,-0.019334986805915833,-0.019456634297966957,-0.019577419385313988,-0.019692540168762207,-0.019803982228040695,-0.0199139267206192,-0.020022820681333542,-0.02013077214360237,-0.020237812772393227,-0.020344000309705734,-0.020449334755539894,-0.02055388316512108,-0.020657652989029884,-0.020760690793395042,-0.020863009616732597,-0.02096462994813919,-0.021065514534711838,-0.021166114136576653,-0.021265925839543343,-0.021364932879805565,-0.02146325819194317,-0.021560806781053543,-0.02165011316537857,-0.021735921502113342,-0.02181985229253769,-0.021904373541474342,-0.021966448053717613,-0.02202838845551014,-0.022090338170528412,-0.022152703255414963,-0.022214693948626518,-0.022278055548667908,-0.022341780364513397,-0.022404221817851067,-0.022465430200099945,-0.022526094689965248,-0.022586582228541374,-0.022646790370345116,-0.022706566378474236,-0.022765636444091797,-0.022824479267001152,-0.022883083671331406,-0.02294149249792099,-0.022999603301286697,-0.023057403042912483,-0.02311490848660469,-0.023172028362751007,-0.023228822275996208,-0.02328820712864399,-0.023379726335406303,-0.023470502346754074,-0.023560751229524612,-0.023650439456105232,-0.02373957820236683,-0.02382788062095642,-0.023915555328130722,-0.024002710357308388,-0.024089301005005836,-0.024175411090254784,-0.02426121011376381,-0.02434755489230156,-0.0244333166629076,-0.024518443271517754,-0.024603059515357018,-0.024687273427844048,-0.024771077558398247,-0.024854974821209908,-0.02493848092854023,-0.025021523237228394,-0.025104980915784836,-0.025189006701111794,-0.025272967293858528,-0.025356533005833626,-0.025439627468585968,-0.02552236244082451,-0.02560475468635559,-0.025686727836728096,-0.02576822228729725,-0.025849172845482826,-0.025929760187864304,-0.026016607880592346,-0.026118958368897438,-0.026220694184303284,-0.026321912184357643,-0.026422543451189995,-0.026522567495703697,-0.026622075587511063,-0.026720678433775902,-0.026817092671990395,-0.026913180947303772,-0.02700967714190483,-0.02710716240108013,-0.027204222977161407,-0.02729853428900242,-0.027391882613301277,-0.027484703809022903,-0.02757721208035946,-0.02766941301524639,-0.027762213721871376,-0.027854440733790398,-0.02794605679810047,-0.028033532202243805,-0.028121858835220337,-0.028211554512381554,-0.0282983910292387,-0.02838430181145668,-0.028468960896134377,-0.028544429689645767,-0.02859189361333847,-0.02863761968910694,-0.028681723400950432,-0.028724100440740585,-0.028764676302671432,-0.028806360438466072,-0.02885352447628975,-0.028899582102894783,-0.02894514799118042,-0.02899433858692646,-0.029032904654741287,-0.02906818315386772,-0.02910221554338932,-0.029134921729564667,-0.029142938554286957,-0.0291480403393507,-0.02915291115641594,-0.02915775403380394,-0.029162107035517693,-0.02916536293923855,-0.029166901484131813,-0.029163990169763565,-0.02916034497320652,-0.029158025979995728,-0.02915540151298046,-0.02915186993777752,-0.029147451743483543,-0.029142217710614204,-0.029136212542653084,-0.02912955917418003,-0.02912229858338833,-0.029114535078406334,-0.029106304049491882,-0.02909829095005989,-0.029093679040670395,-0.0290885828435421,-0.029082970693707466,-0.029077086597681046,-0.029070788994431496,-0.029075033962726593,-0.029082132503390312,-0.02908862940967083,-0.029094964265823364,-0.02910066582262516],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"Test Estimate\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.26338550448417664,0.2453269064426422,0.22748984396457672,0.2098974585533142,0.19221782684326172,0.18246540427207947,0.17731967568397522,0.17271092534065247,0.1679643988609314,0.16326528787612915,0.15861663222312927,0.15458591282367706,0.15089905261993408,0.14669442176818848,0.14251650869846344,0.13837489485740662,0.13436076045036316,0.13037896156311035,0.12643469870090485,0.12251688539981842,0.11860966682434082,0.1147226095199585,0.11087766289710999,0.10718303173780441,0.10352097451686859,0.09988434612751007,0.09628965705633163,0.09259501099586487,0.08894214779138565,0.08533717691898346,0.08178037405014038,0.0782729834318161,0.07481846958398819,0.07142006605863571,0.06808040291070938,0.06480098515748978,0.06158437579870224,0.05843350291252136,0.0553513802587986,0.05234162136912346,0.04944636672735214,0.046692561358213425,0.044013213366270065,0.04140998423099518,0.038885243237018585,0.0364408940076828,0.034071821719408035,0.031781457364559174,0.02957901544868946,0.027465585619211197,0.02545234002172947,0.023622125387191772,0.021897347643971443,0.020272836089134216,0.018739785999059677,0.0172991082072258,0.015950946137309074,0.014695697464048862,0.013533159159123898,0.012463006190955639,0.011458126828074455,0.01053791306912899,0.009708922356367111,0.008970444090664387,0.008321105502545834,0.007759653497487307,0.007284050807356834,0.006892017554491758,0.006581536028534174,0.006349420174956322,0.006194111425429583,0.006112849339842796,0.006102652754634619,0.0061609698459506035,0.006283937953412533,0.006468495819717646,0.006711669731885195,0.007009991444647312,0.007361218333244324,0.007761549204587936,0.008206627331674099,0.00869324803352356,0.009217985905706882,0.009777940809726715,0.010370057076215744,0.010991246439516544,0.011638930067420006,0.012310351245105267,0.01300308108329773,0.013714761473238468,0.014443804509937763,0.015190497040748596,0.015949377790093422,0.0167183056473732,0.017494894564151764,0.01827721670269966,0.01906350627541542,0.019852308556437492,0.02064179629087448,0.02143068239092827,0.022218093276023865,0.023002518340945244,0.02378278784453869,0.02455776184797287,0.02532646618783474,0.026087848469614983,0.026841213926672935,0.027586065232753754,0.028322545811533928,0.029049767181277275,0.029767049476504326,0.030473975464701653,0.03117012418806553,0.03185516223311424,0.03244058042764664,0.033012717962265015,0.03357415646314621,0.034124623984098434,0.034663837403059006,0.03519152104854584,0.0357079915702343,0.036225348711013794,0.03673224523663521,0.037227947264909744,0.03771263360977173,0.038186006247997284,0.03864869102835655,0.03910089656710625,0.03954295814037323,0.039974991232156754,0.040397338569164276,0.04081070423126221,0.041215382516384125,0.04161161184310913,0.04199951887130737,0.04237927496433258,0.042751360684633255,0.04311545565724373,0.04347188025712967,0.043820880353450775,0.044162724167108536,0.04449743777513504,0.04482530429959297,0.04514675587415695,0.045462269335985184,0.04577315226197243,0.04607999324798584,0.04637053608894348,0.04664057120680809,0.04692396894097328,0.04720192402601242,0.0474746972322464,0.047742366790771484,0.048005178570747375,0.04826290160417557,0.048515792936086655,0.0487639382481575,0.04900713637471199,0.0492456778883934,0.04948049783706665,0.04971159249544144,0.04993855580687523,0.05016152188181877,0.05038053169846535,0.05058278888463974,0.05077603459358215,0.05096571519970894,0.05115194618701935,0.051334694027900696,0.05151427164673805,0.05169079452753067,0.051864463835954666,0.052035339176654816,0.052203644067049026,0.05236734449863434,0.052525073289871216,0.052680354565382004,0.05283297225832939,0.05298326537013054,0.05313140153884888,0.053277503699064255,0.05342162400484085,0.05356379970908165,0.053703974932432175,0.05384363234043121,0.053982701152563095,0.05412108078598976,0.054258640855550766,0.05439530685544014,0.054530877619981766,0.054665300995111465,0.054798826575279236,0.054931409657001495,0.055062755942344666,0.05519312247633934,0.05532218515872955,0.05544990301132202,0.0555766224861145,0.055700767785310745,0.05582418292760849,0.05594682693481445,0.05606890842318535,0.05619050934910774,0.0563114732503891,0.05643131211400032,0.05654951184988022,0.05666637420654297,0.05677996203303337,0.05689201503992081,0.05700266733765602,0.057111646980047226,0.05722825229167938,0.05734489858150482,0.05746477097272873,0.057602569460868835,0.057738739997148514,0.05787346139550209,0.05800649896264076,0.05813785269856453,0.0582677498459816,0.05839623510837555,0.05852349102497101,0.05864885821938515,0.058769341558218,0.05897274240851402,0.059206146746873856,0.05943780019879341,0.05966794490814209,0.05989651009440422,0.06012352183461189,0.0603487491607666,0.06057194992899895,0.0607929565012455,0.061007775366306305,0.06122220307588577,0.061434607952833176,0.06164257228374481,0.061848174780607224,0.06205175817012787,0.062253400683403015,0.06245308741927147,0.06265165656805038,0.0628509595990181,0.0630485787987709,0.06324466317892075,0.06343936175107956,0.06363261491060257,0.06382449716329575,0.06401517987251282,0.0642046183347702,0.06439264118671417,0.06457940489053726,0.06476493924856186,0.06494957208633423,0.06513334065675735,0.06531623750925064,0.06550032645463943,0.06568516790866852,0.06586997956037521,0.06605436652898788,0.06623880565166473,0.06642353534698486,0.06660833954811096,0.06679341197013855,0.06697870045900345,0.06707922369241714,0.06717445701360703,0.06726916879415512,0.0673631802201271,0.06745514273643494,0.06754592061042786,0.06763600558042526,0.0677248015999794,0.06781265884637833,0.06790237128734589,0.06799259781837463,0.06808191537857056,0.06817024201154709,0.06825771182775497,0.06834446638822556,0.06843063235282898,0.06851627677679062,0.06860128045082092,0.06868570297956467,0.06876938790082932,0.06885233521461487,0.06893439590930939,0.06901521235704422,0.0690951868891716,0.06917428225278854,0.06925240904092789,0.06932967901229858,0.06940607726573944,0.06948152929544449,0.0695560872554779,0.06962957978248596,0.0697021633386612,0.0697738528251648,0.06984445452690125,0.06991397589445114,0.06998281180858612,0.07005094736814499,0.07011829316616058,0.07018494606018066,0.07025075703859329,0.07031591981649399,0.07038041204214096,0.07044424116611481,0.07050737738609314,0.07056986540555954,0.07063160091638565,0.07069249451160431,0.07075252383947372,0.07081175595521927,0.07087011635303497,0.07092742621898651,0.07098373025655746,0.07103898376226425,0.0710931271314621,0.07114627957344055,0.07119841128587723,0.07124952971935272,0.07129964232444763,0.07134880125522614,0.07139699161052704,0.07144425809383392,0.07149071991443634,0.0715363547205925,0.0715811625123024,0.0716252252459526,0.07166849076747894,0.07171103358268738,0.07175282388925552,0.07179386168718338,0.07183408737182617,0.0718735009431839,0.07191214710474014,0.07195014506578445,0.07198749482631683,0.07202431559562683,0.07206059247255325,0.07209635525941849,0.07213161885738373,0.07216636091470718,0.07220058143138885,0.07223428040742874,0.07226826250553131,0.0723024383187294,0.07233674079179764,0.07237308472394943,0.07241013646125793,0.07244718819856644,0.07248435914516449,0.0725216343998909,0.0725589469075203,0.0725962370634079,0.07263347506523132,0.07267060875892639,0.07270762324333191,0.0727444589138031,0.07278105616569519,0.072817362844944,0.07285336405038834,0.0728890523314476,0.07292437553405762,0.07295935600996017,0.07299399375915527,0.07302837073802948,0.07306237518787384,0.07309604436159134,0.07312937080860138,0.07316230982542038,0.07319487631320953,0.0732269436120987,0.07325569540262222,0.07328367978334427,0.07331090420484543,0.07333767414093018,0.0733640268445015,0.07338989526033401,0.0734153464436531,0.0734403133392334,0.07346484065055847,0.07348890602588654,0.07351250946521759,0.07353570312261581,0.07355838268995285,0.07358061522245407,0.07360242307186127,0.07362380623817444,0.07364477962255478,0.07366535067558289,0.07368553429841995,0.0737052857875824,0.07372473925352097,0.07374382764101028,0.07376261055469513,0.0737810730934143,0.07379918545484543,0.07381699979305267,0.07383446395397186,0.07385162264108658,0.07386843860149384,0.07388491928577423,0.07390104979276657,0.07391684502363205,0.0739322230219841,0.07394718378782272,0.07396169751882553,0.07397585362195969,0.07398960739374161,0.07400298863649368,0.07401597499847412,0.07402865588665009,0.0740409642457962,0.07405295968055725,0.07406461983919144,0.07407592982053757,0.07408690452575684,0.07409749925136566,0.0741078332066536,0.07411787658929825,0.07412753999233246,0.07413686811923981,0.07414581626653671,0.07415442168712616,0.07416271418333054,0.07417075335979462,0.07417825609445572,0.07418537884950638,0.07419207692146301,0.07419838011264801,0.07420433312654495,0.07420989871025085,0.07421508431434631,0.07421989738941193,0.07422433793544769,0.07422828674316406,0.07423176616430283,0.07423486560583115,0.07423757016658783,0.07423990219831467,0.07424198091030121,0.07424383610486984,0.07424550503492355,0.07424700260162354,0.074248306453228,0.07424941658973694,0.07425034046173096,0.07425107806921005,0.07425253838300705,0.07425545901060104,0.07425961643457413,0.07426479458808899,0.07427085936069489,0.0742778331041336,0.07428672164678574,0.07429627329111099,0.07430637627840042,0.07431688159704208,0.07432777434587479,0.07433896511793137,0.07435037940740585,0.07436195760965347,0.07437362521886826,0.0743853971362114,0.07439714670181274,0.07441005110740662,0.07442533224821091,0.07444053888320923,0.0744556188583374,0.07447057962417603,0.07448538392782211,0.07450000941753387,0.07451441884040833,0.0745294913649559,0.07454508543014526,0.07456106692552567,0.07457733899354935,0.07459361851215363,0.07461006194353104,0.07462666928768158,0.07464341074228287,0.07465857267379761,0.07466769218444824,0.07467684149742126,0.07468603551387787,0.07469519972801208,0.07470430433750153,0.07471335679292679,0.07472243905067444,0.07473159581422806,0.07474078238010406,0.07474999129772186,0.07475811243057251,0.07476402819156647,0.07477013021707535,0.07477635890245438,0.07478252053260803,0.07478858530521393],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"On-policy Estimate\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595,0.821009215952595],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"IS Variance\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315,0.0004088816058356315],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"lines\",\"name\":\"Train Variance\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.26679784059524536,0.0812557190656662,0.07890984416007996,0.07653535902500153,0.0742247924208641,0.07199697941541672,0.06988072395324707,0.06764045357704163,0.06502585858106613,0.062482647597789764,0.06007850542664528,0.05783966928720474,0.055601686239242554,0.053177934139966965,0.05086692050099373,0.04871584475040436,0.04666924104094505,0.04469196870923042,0.04279273748397827,0.04098551347851753,0.03926490992307663,0.0376400388777256,0.0362444743514061,0.03504353016614914,0.033918943256139755,0.03316079080104828,0.032493799924850464,0.031897999346256256,0.03135392814874649,0.030952870845794678,0.030598415061831474,0.03028823249042034,0.0300199706107378,0.02976253069937229,0.029522068798542023,0.029318736866116524,0.029151208698749542,0.02901620976626873,0.028909271582961082,0.02882959134876728,0.028745947405695915,0.028623182326555252,0.028518518432974815,0.02843167446553707,0.028358543291687965,0.028298482298851013,0.028253715485334396,0.028227247297763824,0.028101541101932526,0.02782622165977955,0.02751545049250126,0.027218909934163094,0.026934636756777763,0.026665227487683296,0.026407962664961815,0.02615812048316002,0.025914708152413368,0.025676673278212547,0.025442102923989296,0.025208860635757446,0.024973375722765923,0.02474011294543743,0.024508429691195488,0.024277811869978905,0.02404746599495411,0.023816848173737526,0.023585833609104156,0.023354025557637215,0.023121105507016182,0.022886160761117935,0.022649036720395088,0.02241005003452301,0.022169223055243492,0.021927107125520706,0.021683020517230034,0.021437859162688255,0.02119184471666813,0.020945103839039803,0.020697670057415962,0.02044895850121975,0.020199209451675415,0.01994844153523445,0.0196975264698267,0.019446734338998795,0.019196325913071632,0.01894599385559559,0.018692584708333015,0.01843946799635887,0.01818789541721344,0.01795217953622341,0.01771932654082775,0.0174880251288414,0.017258498817682266,0.017033658921718597,0.016811296343803406,0.016591191291809082,0.016372904181480408,0.016156991943717003,0.01594376750290394,0.015733344480395317,0.01552568282932043,0.015321224927902222,0.015119871124625206,0.014921439811587334,0.014726033434271812,0.01453372836112976,0.014344373717904091,0.014157756231725216,0.013974274508655071,0.013793925754725933,0.013617150485515594,0.013443688862025738,0.013273296877741814,0.01310597825795412,0.01294173114001751,0.012780492193996906,0.012622241862118244,0.01246699970215559,0.012314802967011929,0.012165569700300694,0.012019265443086624,0.011875273659825325,0.011737109161913395,0.01160260010510683,0.011470697820186615,0.011341333389282227,0.011214463971555233,0.011090046726167202,0.010967954061925411,0.01084813941270113,0.01073058694601059,0.010614991188049316,0.010501309297978878,0.010389549657702446,0.010279703885316849,0.010171760804951191,0.010065678507089615,0.009961643256247044,0.009859680198132992,0.009759571403265,0.009661302901804447,0.009564846754074097,0.00947023369371891,0.009377450682222843,0.009286307729780674,0.009196783415973186,0.00910906307399273,0.009022931568324566,0.00893839169293642,0.008855508640408516,0.008774164132773876,0.008694261312484741,0.008615856990218163,0.008538949303328991,0.008463469333946705,0.008390652015805244,0.008320123888552189,0.008250948041677475,0.008183108642697334,0.008116574957966805,0.008050240576267242,0.007984757423400879,0.007920551113784313,0.007857609540224075,0.007812224328517914,0.007778013125061989,0.007744182832539082,0.007713089231401682,0.007682354189455509,0.0076520745642483234,0.007622136268764734,0.007592430803924799,0.00756295258179307,0.007533780764788389,0.007505376357585192,0.0074784401804208755,0.007451795507222414,0.007425440009683371,0.0073996963910758495,0.0073742130771279335,0.007349005900323391,0.007324070669710636,0.0072994050569832325,0.007275220938026905,0.007251071743667126,0.007227167021483183,0.007203484885394573,0.007180026266723871,0.007156285922974348,0.007131202612072229,0.007106383331120014,0.007081832271069288,0.007057552225887775,0.007033539470285177,0.007009789813309908,0.006986298598349094,0.006963151041418314,0.006940371822565794,0.006917772348970175,0.006895437836647034,0.006873215548694134,0.006851137150079012,0.006829869467765093,0.006810394115746021,0.006790678948163986,0.00676741125062108,0.006741022225469351,0.006714794784784317,0.006688856054097414,0.006663196720182896,0.0066377813927829266,0.006612810306251049,0.006588282994925976,0.006564232055097818,0.006537382025271654,0.006510383915156126,0.0064837196841835976,0.006457365583628416,0.00643116794526577,0.006405276246368885,0.006380230188369751,0.006355168763548136,0.0063302540220320225,0.0063056256622076035,0.006281273905187845,0.006257188972085714,0.006233386229723692,0.0062098428606987,0.006186553742736578,0.006163517478853464,0.006139995064586401,0.006116796750575304,0.006094485521316528,0.006072819232940674,0.006051450502127409,0.006030372343957424,0.006009609904140234,0.005989240016788244,0.00596912344917655,0.005949246231466532,0.005929610226303339,0.005909694358706474,0.00588885135948658,0.005868263076990843,0.00584710156545043,0.005825132597237825,0.005803416948765516,0.005781959742307663,0.005760757718235254,0.0057398127391934395,0.005719115026295185,0.005698659457266331,0.005678568966686726,0.005658798851072788,0.005639246664941311,0.0056157526560127735,0.005584665574133396,0.0055536022409796715,0.005522593390196562,0.005491667427122593,0.005460820160806179,0.005430039018392563,0.005399307236075401,0.005368600599467754,0.005338036920875311,0.00530762504786253,0.005277409218251705,0.005245477892458439,0.00521299010142684,0.005180511623620987,0.005148088559508324,0.0051157609559595585,0.005083389114588499,0.005051013547927141,0.005018678493797779,0.004986396990716457,0.004954200703650713,0.004922107327729464,0.004886255133897066,0.004850255325436592,0.00481428811326623,0.0047783032059669495,0.004742445424199104,0.004706824664026499,0.00467147771269083,0.004636406432837248,0.00460160244256258,0.0045670741237699986,0.004532836377620697,0.004498897586017847,0.0044652679935097694,0.004431955516338348,0.004398955963551998,0.0043662614189088345,0.004333559423685074,0.0043012043461203575,0.004269213881343603,0.00423749815672636,0.004202574025839567,0.004166698083281517,0.004140692297369242,0.0041160802356898785,0.0040917545557022095,0.004067426081746817,0.004043160937726498,0.004018984269350767,0.003994910512119532,0.003970954567193985,0.003947132732719183,0.00392345804721117,0.003899908158928156,0.00387633522041142,0.0038529180455952883,0.0038296529091894627,0.003806585678830743,0.003783715423196554,0.003761035157367587,0.0037385548930615187,0.0037162264343351126,0.0036940581630915403,0.003672053338959813,0.003650218714028597,0.0036285596434026957,0.0036070721689611673,0.0035857618786394596,0.0035649663768708706,0.003544312436133623,0.0035238065756857395,0.003503494430333376,0.003483380191028118,0.003463453147560358,0.0034437167923897505,0.00342425680719316,0.003405050141736865,0.0033860299736261368,0.0033671939745545387,0.0033485391177237034,0.0033300602808594704,0.003311705309897661,0.003293517976999283,0.0032755036372691393,0.003257645294070244,0.0032399434130638838,0.0032223884481936693,0.003205023007467389,0.003187910420820117,0.003170920768752694,0.003154071979224682,0.0031373691745102406,0.0031207927968353033,0.003104347037151456,0.0030880433041602373,0.003071865998208523,0.003055805806070566,0.0030398706439882517,0.003024061443284154,0.003008382860571146,0.002992836758494377,0.0029774215072393417,0.0029621422290802,0.0029470035806298256,0.0029320023022592068,0.0029171444475650787,0.00290242419578135,0.002887832699343562,0.0028733655344694853,0.0028590252622962,0.002844815840944648,0.0028307344764471054,0.0028167804703116417,0.0028032567352056503,0.0027899681590497494,0.0027767911087721586,0.0027637258172035217,0.0027502274606376886,0.002736826427280903,0.0027235248126089573,0.002710317727178335,0.002697206102311611,0.002684161998331547,0.002671203576028347,0.002658350858837366,0.0026456087362021208,0.002632974646985531,0.0026204485911875963,0.0026080289389938116,0.002595718950033188,0.0025835258420556784,0.0025714407674968243,0.002559464192017913,0.0025475958827883005,0.0025358328130096197,0.0025241770781576633,0.0025126226246356964,0.002501174807548523,0.0024898278061300516,0.0024785881396383047,0.002467521233484149,0.0024565784260630608,0.002445757621899247,0.0024350571911782026,0.002424475969746709,0.0024140109308063984,0.0024036637041717768,0.0023934324271976948,0.002383317332714796,0.0023733058478683233,0.0023633993696421385,0.0023535906802862883,0.002343884203583002,0.002334279241040349,0.0023247769568115473,0.002315378747880459,0.0023060825187712908,0.002296885708346963,0.00228778924793005,0.0022787919733673334,0.0022698878310620785,0.0022610793821513653,0.002252370584756136,0.002243757015094161,0.0022352382075041533,0.002226785756647587,0.002218404319137335,0.0022100943606346846,0.0022018556483089924,0.0021936921402812004,0.0021856038365513086,0.0021780654788017273,0.00217173108831048,0.002165458630770445,0.00215925183147192,0.002153106266632676,0.002147023333236575,0.0021410020999610424,0.0021350460592657328,0.002129156142473221,0.002123326063156128,0.0021175392903387547,0.00211178045719862,0.0021060723811388016,0.002100421814247966,0.002094822470098734,0.002089275512844324,0.0020837823394685984,0.0020783450454473495,0.0020729750394821167,0.0020676548592746258,0.0020623821765184402,0.002056556986644864,0.0020505411084741354,0.002044990425929427,0.002039628801867366,0.0020342629868537188,0.002028906485065818,0.0020234312396496534,0.002017516642808914,0.0020116236992180347,0.0020057549700140953,0.0019999146461486816,0.0019941029604524374,0.0019883557688444853,0.001982735237106681,0.001977146603167057,0.001971597783267498,0.0019660850521177053,0.001960417488589883,0.0019547338597476482,0.0019490686245262623,0.0019434471614658833,0.0019374650437384844,0.0019314782693982124,0.001925530144944787,0.001919624744914472,0.0019139458891004324,0.0019083044026046991,0.0019026645459234715,0.0018969692755490541,0.0018912932137027383,0.0018858612747862935,0.001880504423752427,0.0018751716706901789,0.0018698658095672727,0.001864587771706283,0.001859338954091072,0.0018541193567216396,0.0018489295616745949,0.0018437720136716962,0.0018386434530839324,0.0018335450440645218,0.0018284606048837304,0.0018234034068882465,0.0018183727515861392,0.0018133689882233739,0.0018083939794450998,0.0018035847460851073,0.001798837329261005,0.0017941059777513146,0.0017893287586048245,0.0017845697002485394],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"lines\",\"name\":\"Test Variance\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.008554554544389248,0.00825420767068863,0.007965106517076492,0.0076810275204479694,0.007389388512820005,0.007105590775609016,0.0068463836796581745,0.0066089387983083725,0.006358522921800613,0.00611183000728488,0.005874161142855883,0.005642525386065245,0.0054246606305241585,0.005265410523861647,0.00511139165610075,0.00496099004521966,0.0048047807067632675,0.004654226824641228,0.0045072403736412525,0.004366336390376091,0.004231421276926994,0.004102252423763275,0.003976740408688784,0.003829431952908635,0.0036890855990350246,0.0035592331551015377,0.003435647115111351,0.0033178189769387245,0.0032056663185358047,0.0030989497900009155,0.002997432602569461,0.00290076551027596,0.0028088463004678488,0.002721476601436734,0.0026384475640952587,0.002559568965807557,0.0024846484884619713,0.0024135014973580837,0.0023459652438759804,0.0022818713914602995,0.0022213354241102934,0.0021644255612045527,0.002110523171722889,0.0020594745874404907,0.0020111342892050743,0.001965368166565895,0.0019218603847548366,0.0018804949941113591,0.0018413433572277427,0.001804343773983419,0.001768891466781497,0.0017307106172665954,0.001693452475592494,0.0016575526678934693,0.0016237176023423672,0.0015918362187221646,0.0015618028119206429,0.001533518428914249,0.0015068886568769813,0.0014818195486441255,0.0014579608105123043,0.001435425248928368,0.0014142150757834315,0.0013942541554570198,0.00137547857593745,0.001357822329737246,0.0013412288390100002,0.0013256431557238102,0.0013110128929838538,0.0012972928816452622,0.0012844259617850184,0.0012723918771371245,0.0012611495330929756,0.0012506539933383465,0.0012408734764903784,0.0012317743385210633,0.001223323866724968,0.0012154916767030954,0.001208235858939588,0.0012015358079224825,0.0011953816283494234,0.0011897488730028272,0.0011846148408949375,0.0011799552012234926,0.0011757462052628398,0.00117196561768651,0.0011685921344906092,0.0011656052665784955,0.0011629859218373895,0.0011606900952756405,0.001158356317318976,0.0011562680592760444,0.001154478406533599,0.0011529705952852964,0.001151727163232863,0.0011507332092151046,0.0011499731335788965,0.0011494355276226997,0.0011491000186651945,0.00114895636215806,0.0011489955941215158,0.0011492056073620915,0.0011495756916701794,0.0011500939726829529,0.0011507488088682294,0.0011515314690768719,0.0011524298461154103,0.0011534378863871098,0.001154557103291154,0.0011557744583114982,0.0011570776114240289,0.0011584602762013674,0.001159914769232273,0.001161433756351471,0.0011607811320573092,0.0011601104633882642,0.0011594846146181226,0.001158900442533195,0.001158344093710184,0.0011578182457014918,0.0011573240626603365,0.0011567288311198354,0.0011561543215066195,0.0011556041426956654,0.001155075733549893,0.0011545668821781874,0.0011540754931047559,0.0011535995872691274,0.0011531389318406582,0.0011526907328516245,0.0011522542918100953,0.0011518289102241397,0.0011514133075252175,0.0011510069016367197,0.0011506103910505772,0.0011502228444442153,0.0011498425155878067,0.0011494705686345696,0.0011491061886772513,0.001148749957792461,0.001148400828242302,0.0011480601970106363,0.0011477262014523149,0.0011474022176116705,0.0011470864992588758,0.0011467807926237583,0.0011464852141216397,0.0011457221116870642,0.0011442853137850761,0.0011429288424551487,0.001141591346822679,0.0011402724776417017,0.0011389717692509294,0.0011376901529729366,0.0011364237871021032,0.0011351732537150383,0.001133937737904489,0.0011327179381623864,0.0011315129231661558,0.0011303273495286703,0.0011291604023426771,0.0011280073085799813,0.0011268674861639738,0.0011257409350946546,0.001124618574976921,0.0011235043639317155,0.0011224005138501525,0.0011213067919015884,0.0011202224995940924,0.001119146472774446,0.0011180788278579712,0.001117019448429346,0.0011159677524119616,0.0011149237398058176,0.001113841193728149,0.0011127210455015302,0.001111611956730485,0.0011105118319392204,0.001109421020373702,0.0011083404533565044,0.0011072702473029494,0.0011062105186283588,0.0011051608016714454,0.0011041206307709217,0.001103096641600132,0.0011020884849131107,0.0011010953458026052,0.0011001157108694315,0.0010991488816216588,0.0010981934610754251,0.0010972482850775123,0.0010963128879666328,0.0010953866876661777,0.0010944686364382505,0.0010935597820207477,0.001092660240828991,0.001091768848709762,0.0010908833937719464,0.0010899343760684133,0.0010889957193285227,0.0010880663758143783,0.001087149023078382,0.0010862431954592466,0.0010853473795577884,0.0010844593634828925,0.0010835743742063642,0.0010826935758814216,0.0010817998554557562,0.0010809059021994472,0.0010800163727253675,0.001079130219295621,0.0010783463949337602,0.0010775845730677247,0.0010768347419798374,0.0010761331068351865,0.0010754410177469254,0.0010747590567916632,0.0010740867583081126,0.0010734229581430554,0.001072767423465848,0.0010721220169216394,0.0010714870877563953,0.001070860424079001,0.0010702739236876369,0.001069754594936967,0.0010692658834159374,0.0010687847388908267,0.0010683134896680713,0.0010678519029170275,0.0010673999786376953,0.0010669565526768565,0.0010665199952200055,0.0010660894913598895,0.001065651304088533,0.0010653031058609486,0.0010649600299075246,0.0010646007722243667,0.0010642443085089326,0.001063892967067659,0.0010635467479005456,0.0010632053017616272,0.0010629129828885198,0.0010628076270222664,0.0010627054143697023,0.0010626072762534022,0.0010625136783346534,0.0010624240385368466,0.0010623388225212693,0.0010622587287798524,0.0010621828259900212,0.0010621106484904885,0.0010620434768497944,0.001061981194652617,0.001061926013790071,0.0010618773521855474,0.0010618334636092186,0.001061809714883566,0.001061804941855371,0.0010618169326335192,0.0010618440574035048,0.0010618857340887189,0.0010619440581649542,0.0010620173998177052,0.001062107039615512,0.0010622121626511216,0.001061505638062954,0.0010607573203742504,0.0010600126115605235,0.0010592698818072677,0.0010585245909169316,0.0010577795328572392,0.0010570356389507651,0.0010562898823991418,0.0010555442422628403,0.0010547912679612637,0.001054034917615354,0.0010532792657613754,0.0010525238467380404,0.0010517697082832456,0.001051016733981669,0.0010502658551558852,0.0010495178867131472,0.0010487721301615238,0.0010480282362550497,0.0010472852736711502,0.001046542776748538,0.0010458040051162243,0.0010450781555846334,0.0010443528881296515,0.001043628086335957,0.0010429028188809752,0.001042177900671959,0.00104145344812423,0.001040728995576501,0.0010400060564279556,0.001039284747093916,0.0010385720524936914,0.0010378925362601876,0.0010372139513492584,0.0010365355992689729,0.001035860157571733,0.001035186112858355,0.001034512766636908,0.0010338403517380357,0.0010331689845770597,0.0010325005277991295,0.0010318343993276358,0.0010311708319932222,0.001030509709380567,0.0010298506822437048,0.0010291936341673136,0.001028538215905428,0.0010278838453814387,0.0010272309882566333,0.0010265802266076207,0.0010259303962811828,0.001025281730107963,0.0010246341116726398,0.001023986260406673,0.0010233389912173152,0.0010226924205198884,0.0010220458498224616,0.001021399861201644,0.0010207542218267918,0.001020109630189836,0.001019465853460133,0.0010188238229602575,0.0010181835386902094,0.0010175453498959541,0.0010169093729928136,0.0010162750259041786,0.0010156425414606929,0.001015012152493,0.001014383160509169,0.0010137554490938783,0.0010131290182471275,0.001012503751553595,0.0010118805803358555,0.001011259388178587,0.0010106404079124331,0.0010100234067067504,0.0010094080353155732,0.001008794060908258,0.0010081813670694828,0.001007569837383926,0.0010069608688354492,0.0010063587687909603,0.0010057621402665973,0.0010051713325083256,0.0010046277893707156,0.0010041039204224944,0.0010035850573331118,0.0010030721314251423,0.0010025646770372987,0.0010020628105849028,0.0010015653679147363,0.0010010726982727647,0.0010005838703364134,0.0010000992333516479,0.000999618205241859,0.0009991402039304376,0.0009986652294173837,0.00099819281604141,0.0009977229638025165,0.0009972560219466686,0.00099679094273597,0.0009963284246623516,0.000995868118479848,0.0009954101406037807,0.0009949537925422192,0.0009944995399564505,0.000994047150015831,0.0009935962734743953,0.000993147143162787,0.0009926463244482875,0.000992145505733788,0.0009916444541886449,0.0009911449160426855,0.0009906464256346226,0.0009901495650410652,0.0009896541014313698,0.0009891596855595708,0.0009886667830869555,0.0009881751611828804,0.000987685052677989,0.0009871961083263159,0.0009867087937891483,0.000986222643405199,0.000985737657174468,0.000985254067927599,0.00098477175924927,0.0009842906147241592,0.000983811100013554,0.0009833332151174545,0.0009828567272052169,0.000982381752692163,0.0009819089900702238,0.0009814378572627902,0.0009809683542698622,0.0009805007139220834,0.0009800349362194538,0.0009795703226700425,0.0009791075717657804,0.000978646450676024,0.0009781866101548076,0.0009777285158634186,0.0009772715857252479,0.0009768157033249736,0.0009763611597009003,0.0009759079548530281,0.0009754558559507132,0.0009750050958245993,0.0009745553252287209,0.0009741073590703309,0.0009736602660268545,0.0009732148027978837,0.0009727703873068094,0.0009723269613459706,0.0009718855726532638,0.0009714452316984534,0.0009710068115964532,0.0009705702541396022,0.0009701350354589522,0.0009697013301774859,0.0009692690218798816,0.0009688384016044438,0.0009684094111435115,0.0009679821087047458,0.000967555504757911,0.0009671302977949381,0.0009667067206464708,0.0009662840166129172,0.0009658629423938692,0.0009654432651586831,0.0009650243446230888,0.0009646067628636956,0.0009641905780881643,0.0009637746261432767,0.0009633591980673373,0.0009629446431063116,0.0009625307284295559,0.0009621178614906967,0.0009617062169127166,0.0009612964931875467,0.0009608882246538997,0.0009604819933883846,0.0009600772755220532,0.000959674536716193,0.0009592733113095164,0.0009588738903403282,0.0009584819781593978,0.0009581015328876674,0.0009577351156622171,0.000957380747422576,0.0009570377878844738,0.0009567082161083817,0.0009564287611283362,0.0009561572223901749,0.0009558922029100358,0.0009556334698572755,0.0009553799754939973,0.0009551317198202014,0.0009548880043439567,0.0009546478395350277,0.0009544113418087363,0.000954178161919117,0.0009539472521282732,0.0009537408477626741,0.0009535806020721793,0.0009534215205349028,0.0009532635449431837,0.0009531058021821082,0.0009529484086669981,0.0009527908987365663,0.0009526333888061345,0.000952480360865593,0.0009523311746306717,0.0009521851316094398,0.0009520421153865755,0.0009518907754682004,0.0009517393191345036,0.0009515901328995824,0.0009514431585557759,0.00095129240071401,0.0009511232492513955,0.000950955378357321,0.0009507888462394476,0.0009506238857284188,0.0009504592744633555,0.0009502959437668324,0.0009501338354311883,0.0009499734151177108,0.0009498143335804343,0.0009496566490270197,0.0009494618279859424,0.0009491928503848612,0.0009489265503361821,0.000948662927839905,0.0009484011097811162,0.0009481415036134422],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"lines\",\"name\":\"Train MSE Loss\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[21.162118911743164,20.439157485961914,19.392261505126953,18.387332916259766,17.42348861694336,16.503204345703125,15.63375186920166,14.803616523742676,14.013253211975098,13.25995922088623,12.542505264282227,11.857181549072266,11.204758644104004,10.585650444030762,9.997662544250488,9.440680503845215,8.91199779510498,8.409743309020996,7.932890892028809,7.481101036071777,7.053972244262695,6.651108741760254,6.270710468292236,5.91151762008667,5.572671890258789,5.253403663635254,4.952460765838623,4.669366836547852,4.404025077819824,4.15497350692749,3.9211065769195557,3.7014706134796143,3.4956002235412598,3.3027942180633545,3.122300863265991,2.9535670280456543,2.795945167541504,2.6489105224609375,2.512031316757202,2.384565591812134,2.266014337539673,2.15561842918396,2.053070068359375,1.9579492807388306,1.8698080778121948,1.7882227897644043,1.712638020515442,1.6427055597305298,1.578186273574829,1.5186705589294434,1.463837742805481,1.4133142232894897,1.3667941093444824,1.3239699602127075,1.284554123878479,1.2483046054840088,1.2149698734283447,1.1842936277389526,1.1560395956039429,1.1300251483917236,1.106019377708435,1.0838626623153687,1.0633623600006104,1.044343113899231,1.0266444683074951,1.010132074356079,0.9946914911270142,0.980200469493866,0.9665527939796448,0.9536622166633606,0.9414304494857788,0.9297810196876526,0.9186485409736633,0.9079649448394775,0.8976823091506958,0.8877413272857666,0.8780999779701233,0.8687337636947632,0.8595904111862183,0.8506428599357605,0.8418920040130615,0.8333192467689514,0.8249032497406006,0.8166345953941345,0.8085063099861145,0.8005062937736511,0.7926300168037415,0.784870445728302,0.7772198915481567,0.7696458101272583,0.7621617913246155,0.7547827959060669,0.747503936290741,0.74034583568573,0.7332994341850281,0.7263547778129578,0.719511866569519,0.7127699255943298,0.7061258554458618,0.6995736956596375,0.6931095123291016,0.6867483854293823,0.6804885268211365,0.6743258833885193,0.668260395526886,0.6622886061668396,0.6564083099365234,0.6506079435348511,0.6448971629142761,0.639275848865509,0.6337416172027588,0.6282899379730225,0.6229210495948792,0.6176347732543945,0.6124297380447388,0.6073048710823059,0.602264404296875,0.5973061919212341,0.5924323201179504,0.5876376032829285,0.5829147100448608,0.5782651305198669,0.5736866593360901,0.569176971912384,0.5647319555282593,0.5603501200675964,0.5560390949249268,0.5517865419387817,0.5475874543190002,0.5434446930885315,0.5393348336219788,0.5352716445922852,0.5312597751617432,0.5273009538650513,0.5233938097953796,0.5195371508598328,0.5157364010810852,0.5119866728782654,0.5082848072052002,0.5046309232711792,0.5010307431221008,0.49747854471206665,0.49397337436676025,0.49051257967948914,0.4870833456516266,0.4836970567703247,0.4803539514541626,0.47705554962158203,0.4738030731678009,0.47059473395347595,0.4674271047115326,0.464299738407135,0.4612117409706116,0.4581609070301056,0.4551437795162201,0.45216134190559387,0.4492139518260956,0.44630172848701477,0.44342392683029175,0.44058042764663696,0.4377731382846832,0.4349997341632843,0.43226152658462524,0.4295516908168793,0.42687124013900757,0.4242221713066101,0.4216059148311615,0.4190290570259094,0.4164813756942749,0.4139572083950043,0.411459743976593,0.40898841619491577,0.4065421223640442,0.40412279963493347,0.4017295837402344,0.39936208724975586,0.3970203101634979,0.39470529556274414,0.392412394285202,0.3901428282260895,0.38789814710617065,0.385677307844162,0.38347816467285156,0.3812870979309082,0.37911468744277954,0.376963347196579,0.37483441829681396,0.3727234899997711,0.3706328570842743,0.36856183409690857,0.3665061295032501,0.3644658625125885,0.36244457960128784,0.36044248938560486,0.35846129059791565,0.35650211572647095,0.3545600175857544,0.35263288021087646,0.3507228493690491,0.34881463646888733,0.3469213843345642,0.3450395166873932,0.3431771993637085,0.34133249521255493,0.33949920535087585,0.33767905831336975,0.33587396144866943,0.33408400416374207,0.3323098421096802,0.3305530846118927,0.32881271839141846,0.3270872235298157,0.32537612318992615,0.3236767649650574,0.32199180126190186,0.320320725440979,0.31866055727005005,0.31701475381851196,0.31537917256355286,0.31375715136528015,0.31214597821235657,0.3105440139770508,0.30895376205444336,0.30737733840942383,0.30581480264663696,0.30426445603370667,0.30272504687309265,0.3011977970600128,0.29968196153640747,0.2981800138950348,0.2966938018798828,0.2952217757701874,0.29376280307769775,0.2923186421394348,0.290886789560318,0.2894688546657562,0.2880646586418152,0.28667619824409485,0.285300076007843,0.28393638134002686,0.28258422017097473,0.2812422811985016,0.2799125611782074,0.2785938084125519,0.2772855758666992,0.27598869800567627,0.27470287680625916,0.273427277803421,0.272161602973938,0.27090731263160706,0.2696615159511566,0.2684255838394165,0.2671984136104584,0.26597899198532104,0.26476702094078064,0.2635606825351715,0.262357234954834,0.26116225123405457,0.2599753141403198,0.25879597663879395,0.2576214373111725,0.2564539611339569,0.25529325008392334,0.25413909554481506,0.25299325585365295,0.2518560290336609,0.2507269084453583,0.24959830939769745,0.24847206473350525,0.24735307693481445,0.2462410181760788,0.24513176083564758,0.24402359127998352,0.24292249977588654,0.24182860553264618,0.2407410591840744,0.23966023325920105,0.23858602344989777,0.23751616477966309,0.23645296692848206,0.23539821803569794,0.23434941470623016,0.23330847918987274,0.23227430880069733,0.23124805092811584,0.23022937774658203,0.22921694815158844,0.22821186482906342,0.22721391916275024,0.22622434794902802,0.22524228692054749,0.22426837682724,0.2233022302389145,0.2223438173532486,0.22139538824558258,0.22045476734638214,0.21952062845230103,0.21859076619148254,0.21766063570976257,0.21673204004764557,0.21578814089298248,0.2148451805114746,0.2139044851064682,0.2129610925912857,0.21202071011066437,0.21108455955982208,0.21015314757823944,0.20922662317752838,0.20830513536930084,0.20738846063613892,0.2064753919839859,0.20556838810443878,0.20466682314872742,0.20377178490161896,0.20288266241550446,0.20199966430664062,0.20112308859825134,0.20025081932544708,0.19937588274478912,0.1985062211751938,0.19764229655265808,0.19678393006324768,0.19593089818954468,0.1950828731060028,0.1942417174577713,0.1934061497449875,0.1925767958164215,0.19175352156162262,0.1909361034631729,0.1901244819164276,0.18931785225868225,0.1885170191526413,0.18772181868553162,0.18693138659000397,0.18614760041236877,0.18536952137947083,0.1845966875553131,0.18382909893989563,0.18306657671928406,0.1823083907365799,0.18154995143413544,0.18079550564289093,0.18004530668258667,0.17929881811141968,0.17855697870254517,0.17781896889209747,0.1770814061164856,0.17634829878807068,0.17561955749988556,0.17489519715309143,0.17417560517787933,0.17346081137657166,0.1727505326271057,0.17204532027244568,0.17134486138820648,0.1706491857767105,0.16995833814144135,0.16927236318588257,0.16859126091003418,0.16791532933712006,0.16724464297294617,0.16657884418964386,0.16591788828372955,0.16526179015636444,0.1646111160516739,0.16396468877792358,0.16332291066646576,0.1626858115196228,0.16205336153507233,0.16142545640468597,0.16080079972743988,0.16018041968345642,0.15956513583660126,0.1589554101228714,0.1583433300256729,0.15773501992225647,0.1571301817893982,0.15652784705162048,0.15592901408672333,0.1553342342376709,0.15474344789981842,0.1541566550731659,0.15357382595539093,0.15299485623836517,0.15241974592208862,0.15184852480888367,0.1512811779975891,0.15071718394756317,0.1501566767692566,0.14959989488124847,0.14904706180095673,0.14849834144115448,0.14795345067977905,0.1474122852087021,0.14687497913837433,0.14634156227111816,0.14581142365932465,0.1452844738960266,0.1447611302137375,0.14424146711826324,0.1437254101037979,0.14321298897266388,0.14270424842834473,0.14219911396503448,0.14169760048389435,0.14119862020015717,0.1407025307416916,0.14020968973636627,0.1397201418876648,0.13923387229442596,0.1387508660554886,0.13827137649059296,0.13779520988464355,0.13732220232486725,0.13685256242752075,0.13638611137866974,0.13592283427715302,0.13546279072761536,0.1350060999393463,0.13455241918563843,0.1341015249490738,0.13365036249160767,0.13320045173168182,0.13275320827960968,0.1323087066411972,0.13186682760715485,0.13142767548561096,0.13099177181720734,0.13055935502052307,0.1301298290491104,0.12970320880413055,0.12927943468093872,0.12885841727256775,0.1284400373697281,0.12802454829216003,0.12761177122592926,0.12720130383968353,0.12679404020309448,0.12638837099075317,0.1259838491678238,0.1255818009376526,0.12518180906772614,0.12478400021791458,0.12438856065273285,0.123995341360569,0.12360486388206482,0.12321700155735016,0.1228315457701683,0.12244849652051926,0.12206654250621796,0.1216851994395256,0.12130434811115265,0.12092555314302444,0.12054876983165741,0.12017396837472916,0.11980116367340088,0.11943022161722183,0.11906127631664276,0.11869434267282486,0.11832952499389648,0.11796673387289047,0.11760593950748444,0.11724701523780823,0.11688981205224991,0.11653537303209305,0.11618320643901825,0.11583328992128372,0.11548539996147156,0.11513972282409668,0.11479604244232178,0.11445505172014236,0.11411523818969727,0.11377700418233871,0.11344056576490402,0.11310277879238129,0.11276627331972122,0.11243154853582382,0.11209894716739655,0.11176825314760208,0.11143985390663147,0.11111363023519516,0.11078893393278122,0.11046605557203293,0.11014501750469208,0.10982582718133926,0.10950850695371628,0.10919304937124252,0.10887947678565979,0.1085677444934845,0.10825763642787933,0.10794874280691147,0.10764147341251373,0.10733594000339508,0.1070321723818779,0.10673025250434875,0.10642915219068527,0.10612917691469193,0.10583066195249557,0.10553482174873352,0.10524070262908936],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"mode\":\"lines\",\"name\":\"IS MSE\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865,0.6262227942857865],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"mode\":\"lines\",\"name\":\"Train MSE\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[1.3282265565272544,0.16706576674118034,0.17540966728201596,0.18377851951053495,0.1925267643834115,0.20064727934132334,0.20629317767652247,0.21251122126114652,0.22005471932066703,0.22816537148882532,0.23633432602638266,0.24419755049148442,0.25216316763880003,0.26060419005619695,0.2693241474530919,0.277927126280052,0.2866495752968272,0.295636129034299,0.3048494560557036,0.3143653690417358,0.32412562140276985,0.33379494435905155,0.3428834440401428,0.35138829042951253,0.3597707142781225,0.3663397856559015,0.37169656768054526,0.3767301176206583,0.38109291837427606,0.38609002661434505,0.3912169729191857,0.3962817357833052,0.401230089569214,0.4055357907108111,0.40958653157227715,0.4138587372104825,0.4181616784536709,0.42245476947528693,0.4266680088586435,0.4309689480181317,0.43528295921221916,0.43937595180543015,0.4433823785107239,0.4473058416551594,0.4511235525288278,0.45491215053511574,0.45870012387058356,0.46227702889962446,0.4660890573984797,0.4703722661268535,0.47475841610341685,0.4790299104333522,0.4831890321293706,0.48720522789201615,0.4910759685763616,0.4948213562073002,0.4984405707670692,0.5019323659671613,0.5052805482429947,0.5084869260284959,0.5114474202743371,0.5143159526625976,0.517081032238744,0.5197425213872018,0.522301658085549,0.5247679117204525,0.5271501264387007,0.5294469000404551,0.531653274885855,0.5338165802106192,0.5359419782672942,0.5379899853320983,0.5399663141895944,0.5418717436314834,0.5437140236879922,0.5454921462963127,0.5472069807315304,0.5488625589311094,0.5504699552400162,0.552047036583334,0.5535858452038549,0.5550932601303575,0.556559954567466,0.5579892922913481,0.5593827584605892,0.5606876056999099,0.5618865265271625,0.5630071881325639,0.564093122441196,0.5653557196134747,0.5665756186193751,0.567769038122118,0.5689390846147295,0.5700298576239653,0.5710961851209717,0.5721464554938315,0.5731744125575442,0.57419026723815,0.5751965085850389,0.5761951465831606,0.5771889062425959,0.5781709010895733,0.5791530104079513,0.5801415144681182,0.581129334173226,0.582122143490308,0.5831227604315617,0.5842017694393514,0.5852823135272468,0.5863650564437421,0.5874131250887031,0.5884326974738094,0.5894596098339339,0.590493784765499,0.5915389190237663,0.5925878558185899,0.5936396824875046,0.5946941869249069,0.5957375781148079,0.5967783172972355,0.5978237965748315,0.5988129060007199,0.5997410283315188,0.6006516095008106,0.6015667326762649,0.602486595130888,0.6034074134131701,0.6043325296315374,0.6052626801857739,0.6061973920818156,0.6071322456107439,0.6080736075825958,0.6090224361943031,0.6099774021311651,0.6109378936624296,0.6119040627776663,0.6128736248785326,0.613884234460988,0.614966773652658,0.6160502274825429,0.6171340938452975,0.6182173026009081,0.6193002579563056,0.6203813592102366,0.6214615975072674,0.6225411919039169,0.6236171699905375,0.6246938287583886,0.6257722888071319,0.6268378881273214,0.6279013279864167,0.6289641823790622,0.6300240151945277,0.6310786753166753,0.6321318031908377,0.6331963837652196,0.6342712719654721,0.6353432306856494,0.6364115149831341,0.6374749428494568,0.6385576322288149,0.6396458328842838,0.6407299964514223,0.6418110574686247,0.6425737406756218,0.6431316371586653,0.643690906541714,0.6442016500342966,0.6447065277739091,0.6452071127669542,0.6457092957651946,0.6461971646707346,0.6466712647648879,0.6471467158665415,0.6476214465522901,0.6480925538005885,0.6485647815703252,0.6490379462518554,0.6495266371756527,0.6500053392931675,0.6504838999786478,0.6509622515553878,0.6514405493616771,0.6520251066628502,0.6526179679077223,0.6532082787743781,0.6537941407560933,0.6543787275196751,0.6549724573389378,0.65559891684564,0.6562241055017232,0.6568483880491833,0.6574712422724047,0.6580923954059189,0.658711997739454,0.659329857917126,0.6599631819883188,0.6606216430185516,0.6612643647197499,0.6618997121741041,0.6625226550853242,0.6631347151040383,0.6636694078013763,0.6642592109093242,0.6648496444275929,0.6654227467085101,0.6659288660950416,0.6664263272336673,0.6669318782214827,0.667445279685414,0.6679586770736086,0.6684716108711016,0.6689844589865953,0.6694912550506191,0.6700728248372086,0.6706652068049862,0.6712565106740639,0.6718457189245874,0.6724293907718246,0.6730125917428844,0.6735478753296364,0.674025271625431,0.6744775703722192,0.6749291318922321,0.6753796960197077,0.6758291996172638,0.6762559088276265,0.6766724373565003,0.6770843876996879,0.6774934260884014,0.6779358891216051,0.6783765226726467,0.6787985975018265,0.6792359499757853,0.6796703421334734,0.6801027733136098,0.6805344305050577,0.6809695124654963,0.6814031647710896,0.6818341858785545,0.6822627618910997,0.682701809273781,0.6831680302635811,0.6836311734020517,0.6841242959620327,0.684647404684781,0.6851673831694459,0.6856843842795154,0.6861983560962743,0.6867094746552376,0.6872157715255267,0.687718258787108,0.688245097063416,0.6887927147378063,0.6893377219383753,0.6898098287276289,0.6901513851611301,0.6904906851100872,0.6908276687136301,0.6911626083942092,0.6914966398347434,0.6918289155044505,0.6921454546219515,0.6924437413444329,0.6927407031782378,0.6930358079996359,0.6933287972812251,0.693587982838332,0.6938359046772127,0.6940810359291462,0.6943229091408187,0.6945609653568621,0.6947960030641376,0.695027892369255,0.6952572142021735,0.6954839181780453,0.695708097901882,0.6959300018426733,0.6960793798466985,0.696221430181547,0.6963716092730229,0.6965273851880559,0.6966852949509356,0.6968396196118404,0.6969917070774472,0.697144896960404,0.6972949846830884,0.6974438254047001,0.6975920056038101,0.6977395549892299,0.6978865035947239,0.6980328496642015,0.6981785451993237,0.6983241389485769,0.6984816913166841,0.6986385038337264,0.698793008847995,0.6989465110968689,0.6990311780777817,0.699096627590062,0.699323393140679,0.6995642268581271,0.6997937625988333,0.7000145608517602,0.7002319159227283,0.7004483614970723,0.7006639689947736,0.7008784231594971,0.7010918127111835,0.7013044222650956,0.7015171997630176,0.7017409392623412,0.7019652114027255,0.702181776824665,0.7023971755222872,0.7026117375057142,0.7028254209805319,0.7030382026859981,0.7032503469842178,0.7034617761425406,0.7036725303642026,0.703882573879843,0.7040921921927291,0.7043011034953215,0.7045094657473309,0.7047224293684419,0.7049414732617765,0.7051617016218228,0.7053808666748413,0.7055988689374978,0.7058158343560292,0.7060317751508095,0.7062410892566937,0.7064448122438718,0.7066468295370962,0.7068479471551324,0.7070484802993223,0.7072483484612812,0.7074428100944568,0.7076344107329265,0.7078240298991286,0.7080125159111685,0.7082002158435826,0.7083872448562882,0.7085716897329745,0.7087524422921375,0.7089387754073266,0.7091265620046294,0.7093157482843474,0.7095036382342353,0.7096902385458582,0.7098674860496942,0.7100387002329575,0.7102075376894655,0.710374757288602,0.7105405410177552,0.7107049461991923,0.7108680712734122,0.7110299140670742,0.711190592025695,0.7113501218546282,0.711508578205412,0.7116659886326179,0.7118223813766547,0.7119776844246141,0.7121326521452748,0.712286439743263,0.712439022462056,0.7125906041676666,0.7127410236796927,0.712878001684759,0.713009334862605,0.7131376293877307,0.71326704517098,0.7133581975675214,0.7134492288734378,0.7135403829752185,0.7136323397297131,0.7137237683314149,0.7138175842743762,0.7139121065650877,0.7140045778705995,0.714095087438616,0.7141847949478262,0.7142743193000562,0.7143634859437666,0.7144520403045614,0.7145395273791063,0.7146267459554552,0.7147136775565768,0.7148003941769162,0.7148867197913412,0.7149726343806649,0.7150581600848812,0.7151431480613545,0.7152276929981903,0.715316726761259,0.7154602070917337,0.7156025730450111,0.7157441870879059,0.7158849906663225,0.7160250011960088,0.7161637306776347,0.7163015328279585,0.7164385880331713,0.7165748206966511,0.7167103596374295,0.7168454925520459,0.7169816606935973,0.7171169601588983,0.7172513017540477,0.7173848973788991,0.7175179308982795,0.7176503874103132,0.7177831149417708,0.7179152951064272,0.7180468036274463,0.7181791219732855,0.7183125114044437,0.7184459042651401,0.718578738025056,0.7187108827365591,0.7188424989739017,0.7189736196001872,0.7191041155899273,0.7192338855604236,0.7193628228179576,0.7194912331424008,0.7196308117190915,0.7197978748175754,0.7199639792613473,0.7201292925413129,0.7202936931128272,0.7204571472882905,0.7206198084979093,0.7207810198955933,0.720938605738464,0.7210957172276257,0.7212535823355595,0.7214131716889529,0.7215721103621824,0.7217264609342084,0.7218792465179185,0.7220312073852793,0.7221827081811972,0.7223337603121823,0.7224859148711198,0.7226371625022562,0.7227874373077262,0.7229301451809659,0.7230741232787846,0.7232209074150578,0.7233630400790763,0.7235036110064441,0.723642079427307,0.7237648280636717,0.7238395620184742,0.7239113690151754,0.7239804473895245,0.7240466236349653,0.7241097709191177,0.7241748696457159,0.7242494128064006,0.7243221116152944,0.7243940185703354,0.7244721277819389,0.7245320242952071,0.724586318331356,0.724638514584678,0.7246885019968088,0.7246961508564318,0.7246988386952473,0.7247011725154628,0.724703501600769,0.7247052243204583,0.7247051189965112,0.7247020952057106,0.7246914496839195,0.724679575538473,0.7246702005300546,0.7246603812141407,0.7246490436329875,0.7246362254376678,0.7246220479313163,0.7246065885454601,0.724590056330775,0.7245725215689195,0.7245541640806916,0.7245350408015026,0.724516318336312,0.7245033926808145,0.7244896709249259,0.7244750985486781,0.7244600907718228,0.7244444087901817,0.7244468167001801,0.7244541380489765,0.7244604526673182,0.724466445983434,0.7244713807921274],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"mode\":\"lines\",\"name\":\"Test MSE\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.31949875813620315,0.3396643291534017,0.3602303514421281,0.3811386075520854,0.402767999530865,0.41484379021109075,0.4211826079308853,0.4268996124086751,0.432826056052085,0.43873890492874396,0.44463809612265315,0.4497625443393229,0.45447229163224967,0.4599658521798202,0.46546374545314145,0.47095060638230846,0.47629088215036375,0.48162437510272554,0.4869410003890597,0.4922578722314254,0.4975965478925018,0.5029430228498932,0.5082635630536839,0.5133772532235568,0.5184784621975663,0.5235803110353473,0.5286540861619059,0.533905072959684,0.5391278586046846,0.5443122988058726,0.5494567133030137,0.5545578766094366,0.5596094762666064,0.5646053702401853,0.569540245072758,0.5744104572880707,0.5792107363312275,0.5839352196159349,0.5885778866031846,0.5931317423542005,0.5975305657286851,0.6017307071434393,0.6058333112068511,0.6098344366883492,0.6137290429856008,0.6175128199660214,0.6211923228272732,0.6247609499200063,0.6282031056268799,0.6315158370166696,0.6346796343076601,0.6375568828176252,0.6402732305472915,0.642836302704734,0.6452599558403129,0.6475417735107951,0.6496806206099024,0.6516750085262933,0.6535244709516099,0.6552287928685571,0.6568309267132098,0.6582991580465513,0.659622381465109,0.6608012211624896,0.6618374434428088,0.6627326731631614,0.6634898732296551,0.6641124558833005,0.6646034587194724,0.6649678757381092,0.6652080805274005,0.6653284801958022,0.6653338562762044,0.6652283181764129,0.6650181520873356,0.6647083590931075,0.664303817647794,0.6638102291762433,0.6632312998889185,0.6625733032790001,0.6618434296972194,0.6610469806093008,0.6601896160219346,0.6592761369711476,0.6583115921090665,0.657301076551777,0.6562488518083406,0.6551594590457613,0.6540368999082584,0.6528850263283975,0.6517061192529819,0.6505000758080054,0.6492758214287668,0.6480368389948876,0.6467869918395633,0.6455293958289491,0.6442668944032142,0.643001825796198,0.6417371064746259,0.6404747876947835,0.6392162532610185,0.6379638950404132,0.6367195533656,0.63548501271805,0.6342617870820784,0.6330515119500879,0.6318552452879604,0.630673733984587,0.6295067141226145,0.628355542956481,0.6272212436212017,0.6261044267294528,0.6250057056486491,0.6239255542582406,0.6230012740657362,0.6220985913084124,0.6212134575277699,0.6203462615199605,0.6194973984599232,0.6186672678700148,0.6178553370790952,0.6170424471137717,0.6162465211169091,0.6154686812883732,0.6147086116434972,0.6139667445343868,0.6132420664528347,0.6125342195115087,0.6118426510308785,0.6111671509175077,0.6105071574038944,0.6098615466024069,0.6092298359726662,0.6086116321932437,0.6080067185377301,0.6074148078478293,0.6068351318018755,0.6062681728750761,0.60571341458908,0.6051704589491606,0.6046388726276603,0.6041186018453314,0.6036091909104075,0.6031099591765776,0.6026201529056056,0.6021377352391548,0.6016617854156914,0.6012108064525878,0.6007910832792118,0.6003508984834985,0.599919316385574,0.5994959241295631,0.5990805917819053,0.5986729319616099,0.5982732901261684,0.5978812618574771,0.5974967066747083,0.5971199288107384,0.5967504716085406,0.5963868902265191,0.5960291843529958,0.5956779702461361,0.595333034940397,0.5949943099303457,0.5946814980996723,0.5943826580303577,0.5940893935656102,0.5938015226028079,0.5935190921996009,0.5932416157850483,0.5929689123718109,0.5927006691569975,0.5924367909162308,0.5921769311020673,0.5919241677459751,0.5916805985695631,0.5914408511973017,0.591205253208171,0.5909732817884719,0.590744678322188,0.5905192522470412,0.5902969218307803,0.590077627714851,0.5898614535277811,0.589646129320592,0.5894317628911967,0.589218507205116,0.5890065601225175,0.5887960345028425,0.5885872365941994,0.5883802442774403,0.5881746736777045,0.5879705919863351,0.5877684482386722,0.587567848809254,0.5873692893667549,0.5871728304798237,0.5869779385345943,0.5867869552122853,0.5865971304847782,0.5864085254654082,0.5862208231062662,0.5860338971660904,0.585847985073407,0.5856638304017022,0.5854822135710166,0.5853026733043117,0.5851281524019056,0.5849560026328195,0.5847860226992365,0.584618626101464,0.5844397068457307,0.5842607741989209,0.5840769542015919,0.5838658410145786,0.5836572604830008,0.5834509389402153,0.5832472328923604,0.583046139831206,0.5828473115419319,0.5826506805690275,0.5824559678061607,0.5822641754671867,0.5820799000404433,0.5817693416064358,0.5814131821346727,0.5810598060321406,0.5807088444852512,0.5803604029216939,0.5800144394920427,0.5796713022926392,0.5793313555526615,0.5789948506255614,0.5786678409973227,0.5783416080419737,0.5780185451478994,0.5777023002891188,0.5773897307418455,0.5770803156906931,0.5767739339527168,0.5764706054372257,0.5761691008585716,0.5758667493041183,0.5755670328890007,0.57526972471654,0.57497459767324,0.5746817398444583,0.5743910371905515,0.5741022293895927,0.5738153818014677,0.5735307518589442,0.5732481025402302,0.5729673872422589,0.5726881110969672,0.5724102162064343,0.5721337111321821,0.5718554918253176,0.5715762224953191,0.5712970832716583,0.5710186687256248,0.5707402579999233,0.5704614934331969,0.5701826997196713,0.5699035860165187,0.5696242304581826,0.5694719388674948,0.5693276011049764,0.5691840713019677,0.5690416170570716,0.5689022658515829,0.568764716960735,0.5686282297454203,0.5684936987889623,0.5683605978789211,0.5682247107496089,0.5680880621039136,0.5679527992154487,0.5678190445313479,0.5676865966704924,0.5675552419707767,0.5674247903481859,0.567295141396154,0.5671664735362034,0.5670386964083364,0.5669120441810211,0.5667865160182366,0.5666623389482567,0.5665400595992499,0.5664190599905204,0.5662993956177284,0.5661811995569066,0.5660643041554504,0.5659487315320569,0.5658345928078248,0.565721810685114,0.5656106423982193,0.56550085935993,0.5653924633494621,0.5652857127590687,0.5651805952372697,0.5650765198790519,0.5649735072682134,0.5648716906897,0.5647709246112151,0.5646714326155039,0.564572925391483,0.5644754356593665,0.5643789522082229,0.5642835194010802,0.5641890695317001,0.5640957587815969,0.5640037206898627,0.5639129879059043,0.5638234599747708,0.5637352489746463,0.5636486216862545,0.563563510923685,0.5634799832832913,0.563398126533192,0.5633177623463852,0.5632389352154707,0.5631616329503923,0.5630858446509002,0.5630114915860579,0.5629385965132527,0.5628670919032664,0.5627967997262635,0.5627277532619747,0.562659952633202,0.5625932749004059,0.5625277974468599,0.5624634086443081,0.5624001532002657,0.5623380302275555,0.5622771287331054,0.5622174485209087,0.5621589223080015,0.5621013722581477,0.5620447981071506,0.56198902137065,0.5619340640193561,0.5618798809469528,0.5618264494920059,0.5617738029083645,0.5617219409708972,0.5616708649695034,0.561619374137609,0.5615676010151532,0.5615156463959031,0.5614606847703646,0.5614046857356997,0.5613486944525562,0.5612925333900095,0.5612362244156532,0.5611798680442296,0.5611235523377016,0.5610673222469833,0.5610112548868963,0.5609553728845715,0.5608997648315641,0.560844519302021,0.5607897142860783,0.5607353715515581,0.5606815021803349,0.5606281844859753,0.5605753839029316,0.5605231010577634,0.5604712129263757,0.560419886750531,0.5603690660318563,0.5603187623125604,0.560269042154003,0.5602198828437646,0.560171473969879,0.5601279738193269,0.5600856229453273,0.5600444098446236,0.5600038793510748,0.5599639752221115,0.5599247982373988,0.5598862478287843,0.5598484238401054,0.559811259828799,0.5597747889141051,0.5597390112621544,0.5597038484907154,0.5596694569388072,0.5596357358328217,0.5596026517014385,0.5595702047219199,0.559538372450168,0.559507143581909,0.5594764962611644,0.5594464972551915,0.5594169458426141,0.5593879423211556,0.5593593982687549,0.5593313353380429,0.5593037980307177,0.5592767086033303,0.5592501449604235,0.5592240395657155,0.5591984487525735,0.5591733611205677,0.5591487985528566,0.5591247392161226,0.5591013049519693,0.5590784956054843,0.559056355957754,0.5590347523898673,0.5590137514273733,0.5589933087448594,0.55897345735637,0.5589540644755031,0.5589352293239384,0.5589168635867361,0.5588990000503224,0.55888166089338,0.5588648248798639,0.5588485577772759,0.5588326823593958,0.558817243070039,0.5588023729206696,0.5587880052882859,0.5587742068124968,0.5587609221189203,0.5587481066161315,0.5587356713166824,0.5587240381073876,0.5587129739631757,0.5587025458712916,0.5586927085445732,0.5586833959552242,0.5586746634987901,0.558666499393949,0.558658893082927,0.5586518446131737,0.5586455308570444,0.5586399187103726,0.5586348749789375,0.5586304216783713,0.5586265258265295,0.5586230095496252,0.5586198290323048,0.5586169281681855,0.5586142852822302,0.5586119332318439,0.5586098724811722,0.5586080914356893,0.558606590385401,0.558604017472929,0.5585992750398703,0.5585926994959868,0.5585846115864335,0.5585752109934563,0.5585644663468838,0.5585509122634177,0.5585363759605629,0.558521022980416,0.5585050756552021,0.558488555215384,0.5584715952013197,0.5584543061953595,0.5584367762305663,0.5584191166921099,0.5584013049858791,0.5583835292030632,0.5583640537952955,0.5583410760091935,0.5583182111016678,0.5582955368793183,0.5582730413332775,0.5582507801896184,0.5582287863403431,0.5582071155043709,0.5581844595813031,0.5581610293312675,0.5581370243175474,0.5581125890559905,0.5580881348778393,0.5580634364245809,0.5580384960989012,0.5580133583457934,0.5579905751233887,0.5579767933498105,0.557962968538255,0.5579490785064014,0.5579352346989954,0.5579214803752759,0.5579078053426342,0.5578940872140882,0.5578802597345024,0.5578663892803197,0.5578524870315195,0.5578401713358223,0.5578310731068776,0.5578216996297205,0.5578121398690555,0.5578026820672152,0.5577933711073886],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.45],\"title\":{\"text\":\"Epoch\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.625,1.0],\"title\":{\"text\":\"Estimate\"}},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.55,1.0],\"title\":{\"text\":\"Epoch\"}},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.625,1.0],\"title\":{\"text\":\"Variance\"}},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.0,0.45],\"title\":{\"text\":\"Epoch\"}},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,0.375],\"title\":{\"text\":\"MSE Loss\"}},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.55,1.0],\"title\":{\"text\":\"Epoch\"}},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.0,0.375],\"title\":{\"text\":\"MSE\"}},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Estimate over Epochs\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Variance over Epochs\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Shaping Train MSE Loss over Epochs\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Total MSE over Epochs\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Metrics over Epochs\"},\"showlegend\":true},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('8fc7f672-1503-4916-84d8-d9629c72ce75');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"44337040-0b0b-446c-a43f-d24c31efbc4c\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"44337040-0b0b-446c-a43f-d24c31efbc4c\")) {                    Plotly.newPlot(                        \"44337040-0b0b-446c-a43f-d24c31efbc4c\",                        [{\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"z\":[[0.05482488125562668,0.057785745710134506,0.05325512960553169,0.042639777064323425,0.03202443569898605,0.02140910178422928,0.01079375296831131,0.00017840787768363953,-0.01043693721294403,-0.02029881626367569],[0.050121109932661057,0.05857495218515396,0.05821488797664642,0.05102115124464035,0.04109645634889603,0.03117174655199051,0.02124704048037529,0.011322353035211563,0.001397654414176941,-0.008527033030986786],[0.04648015275597572,0.04799387603998184,0.04956740885972977,0.05100313201546669,0.04631028324365616,0.03869537264108658,0.028770657256245613,0.018845953047275543,0.00892125815153122,-0.0010034404695034027],[0.04331113398075104,0.03881041705608368,0.0443696603178978,0.041809022426605225,0.043304480612277985,0.03909852355718613,0.034405648708343506,0.02636958658695221,0.016444899141788483,0.006520196795463562],[0.037530191242694855,0.03264816105365753,0.03686707094311714,0.036548878997564316,0.03510424867272377,0.03604516386985779,0.031886760145425797,0.027193913236260414,0.022501053288578987,0.014043815433979034],[0.031749241054058075,0.026485899463295937,0.030214177444577217,0.03381277620792389,0.028728116303682327,0.028399469330906868,0.029340367764234543,0.02663118951022625,0.02042578160762787,0.015289291739463806],[0.025968298316001892,0.02032364159822464,0.02405192330479622,0.02778019569814205,0.025992009788751602,0.020907338708639145,0.021694671362638474,0.02263559401035309,0.021431075409054756,0.015225648880004883],[0.019828304648399353,0.014161385595798492,0.017889656126499176,0.021617945283651352,0.024651456624269485,0.018171224743127823,0.014048963785171509,0.014989905059337616,0.015930816531181335,0.01623094081878662],[0.013594098389148712,0.007999122142791748,0.011727400124073029,0.015455678105354309,0.019183959811925888,0.016186345368623734,0.010350443422794342,0.007344193756580353,0.008285105228424072,0.009226024150848389],[0.007897496223449707,0.001836869865655899,0.0055651552975177765,0.009293433278799057,0.013021696358919144,0.01662512868642807,0.007721222937107086,0.0025296956300735474,0.0006393864750862122,0.0015803202986717224]],\"type\":\"heatmap\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"Values\"},\"ticks\":\"outside\",\"tickvals\":[-0.02029881626367569,0.05857495218515396],\"ticktext\":[-0.02029881626367569,0.05857495218515396]}},\"xaxis\":{\"tickvals\":[0,1,2,3,4,5,6,7,8,9],\"ticktext\":[0,1,2,3,4,5,6,7,8,9],\"title\":{\"text\":\"X\"}},\"yaxis\":{\"tickvals\":[9,8,7,6,5,4,3,2,1,0],\"ticktext\":[9,8,7,6,5,4,3,2,1,0],\"title\":{\"text\":\"Y\"},\"autorange\":\"reversed\"},\"title\":{\"text\":\"Heatmap\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('44337040-0b0b-446c-a43f-d24c31efbc4c');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"73be3244-aaef-41a8-aa4f-ce004d54d6c0\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"73be3244-aaef-41a8-aa4f-ce004d54d6c0\")) {                    Plotly.newPlot(                        \"73be3244-aaef-41a8-aa4f-ce004d54d6c0\",                        [{\"colorbar\":{\"title\":{\"text\":\"Visits\"}},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"x\":[0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9],\"y\":[9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0],\"z\":[0,19,72,183,516,541,610,573,450,470,0,52,169,430,454,0,194,299,272,478,0,91,316,409,170,0,64,87,148,456,0,237,251,125,68,0,21,40,72,113,0,195,119,78,40,0,10,9,19,40,47,113,45,21,11,1,1,1,1,9,9,19,7,7,7,1,1,1,1,9,3,5,1,1,2,1,1,1,1,9,0,1,0,0,0,2,1,1,2,7,0,0,0,0,0,0,1,1,1,6],\"zmax\":610,\"zmin\":0,\"type\":\"heatmap\"}],                        {\"title\":{\"text\":\"State Visitations Heatmap\"},\"xaxis\":{\"title\":{\"text\":\"X-axis\"}},\"yaxis\":{\"ticktext\":[9,8,7,6,5,4,3,2,1,0],\"tickvals\":[0,1,2,3,4,5,6,7,8,9],\"title\":{\"text\":\"Y-axis\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('73be3244-aaef-41a8-aa4f-ce004d54d6c0');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "400 trajectories:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"90da71dd-3c8b-4ec6-92c3-f2c0b023c88d\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"90da71dd-3c8b-4ec6-92c3-f2c0b023c88d\")) {                    Plotly.newPlot(                        \"90da71dd-3c8b-4ec6-92c3-f2c0b023c88d\",                        [{\"mode\":\"lines\",\"name\":\"IS Estimate\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753,0.04546554386615753],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"Train Estimate\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.41211971640586853,0.16619418561458588,0.14772804081439972,0.1295323669910431,0.11249857395887375,0.09647157788276672,0.08338629454374313,0.07067964226007462,0.05839549005031586,0.046593163162469864,0.03503923863172531,0.0242693480104208,0.014222783036530018,0.005418749060481787,-0.0031319009140133858,-0.01035679504275322,-0.01709706336259842,-0.022202789783477783,-0.027433227747678757,-0.03272677958011627,-0.037870511412620544,-0.042607322335243225,-0.0477680005133152,-0.05279003456234932,-0.05744146555662155,-0.06185481697320938,-0.066217802464962,-0.07027534395456314,-0.07247813045978546,-0.07385390996932983,-0.07488071918487549,-0.07580238580703735,-0.07663936913013458,-0.07751300185918808,-0.07834798097610474,-0.07911911606788635,-0.07983600348234177,-0.0806247889995575,-0.08142776042222977,-0.08225705474615097,-0.0833841860294342,-0.08442748337984085,-0.08557219803333282,-0.08669918030500412,-0.0877896249294281,-0.0888950526714325,-0.08999612182378769,-0.09135153889656067,-0.09285290539264679,-0.09425005316734314,-0.09561659395694733,-0.09689900279045105,-0.09814963489770889,-0.09941138327121735,-0.10059992969036102,-0.10173354297876358,-0.10270857065916061,-0.10356564074754715,-0.10444454103708267,-0.10534027218818665,-0.10621405392885208,-0.10703171044588089,-0.10786071419715881,-0.10869797319173813,-0.10948267579078674,-0.11021546274423599,-0.11089527606964111,-0.11152637004852295,-0.11211075633764267,-0.11264543235301971,-0.11313178390264511,-0.11357131600379944,-0.11396235227584839,-0.11423077434301376,-0.11445043981075287,-0.11463113129138947,-0.11478911340236664,-0.11491271108388901,-0.11500272154808044,-0.11506040394306183,-0.1150880828499794,-0.11508947610855103,-0.1150619238615036,-0.1150464341044426,-0.11501453816890717,-0.11494868248701096,-0.11484725028276443,-0.11471767723560333,-0.11460601538419724,-0.11450926214456558,-0.11440019309520721,-0.11427994072437286,-0.11413862556219101,-0.11398651450872421,-0.11382728070020676,-0.11367134749889374,-0.1135110855102539,-0.11334499716758728,-0.11317379027605057,-0.11299802362918854,-0.11281793564558029,-0.11263038218021393,-0.11244139075279236,-0.11225778609514236,-0.11207528412342072,-0.11189845204353333,-0.11174064874649048,-0.11157945543527603,-0.11136764287948608,-0.11114831268787384,-0.11092942953109741,-0.1107177734375,-0.1105089858174324,-0.1103014126420021,-0.1100950837135315,-0.10988830775022507,-0.10968092083930969,-0.10947248339653015,-0.10926175862550735,-0.10905211418867111,-0.1088830903172493,-0.10877665877342224,-0.1086750477552414,-0.10857383161783218,-0.10848052054643631,-0.10838721692562103,-0.1082957535982132,-0.10820361226797104,-0.1081104502081871,-0.1080167144536972,-0.10792367160320282,-0.10783100873231888,-0.10773857682943344,-0.10770121216773987,-0.1076631098985672,-0.10762318223714828,-0.10758128762245178,-0.10753775388002396,-0.10749155282974243,-0.10741990059614182,-0.10734586417675018,-0.10726815462112427,-0.10718916356563568,-0.10710872709751129,-0.1070268303155899,-0.10694371163845062,-0.10685937851667404,-0.10677357017993927,-0.10668419301509857,-0.1065889298915863,-0.10648229718208313,-0.1063716933131218,-0.10623449832201004,-0.10610168427228928,-0.10595954954624176,-0.1058168113231659,-0.10565537959337234,-0.10547980666160583,-0.10530264675617218,-0.105124831199646,-0.10494641214609146,-0.10476740449666977,-0.1045868769288063,-0.10440759360790253,-0.10423492640256882,-0.1040617898106575,-0.10388791561126709,-0.10371547937393188,-0.10353906452655792,-0.10342148691415787,-0.10330209881067276,-0.10318146646022797,-0.10306137800216675,-0.1029447540640831,-0.10282663255929947,-0.1027071550488472,-0.10259179770946503,-0.1024705171585083,-0.10230447351932526,-0.10213790088891983,-0.1019701138138771,-0.10180017352104187,-0.10163111984729767,-0.10146044939756393,-0.10128802061080933,-0.10096178948879242,-0.10061836242675781,-0.10026728361845016,-0.0999009907245636,-0.09953466057777405,-0.09916432201862335,-0.09878366440534592,-0.09840322285890579,-0.09802298247814178,-0.09766151010990143,-0.09731591492891312,-0.0969727411866188,-0.09663055092096329,-0.09629370272159576,-0.09596220403909683,-0.09563440084457397,-0.0953018069267273,-0.09496680647134781,-0.0946328341960907,-0.09427142143249512,-0.09389564394950867,-0.0935232937335968,-0.09315193444490433,-0.0927806943655014,-0.09239564836025238,-0.09201499074697495,-0.09163558483123779,-0.09125746786594391,-0.0908806100487709,-0.09050504118204117,-0.09013128280639648,-0.08975142240524292,-0.08937310427427292,-0.08899619430303574,-0.0886206328868866,-0.08824658393859863,-0.08787529170513153,-0.08750582486391068,-0.08714717626571655,-0.08679518103599548,-0.0864449068903923,-0.08609599620103836,-0.0857483297586441,-0.08540166914463043,-0.08505386114120483,-0.08470700681209564,-0.08435192704200745,-0.08399342745542526,-0.08363664895296097,-0.0832812562584877,-0.08292725682258606,-0.08257601410150528,-0.08222320675849915,-0.08185291290283203,-0.08148381114006042,-0.08111600577831268,-0.08074962347745895,-0.0803895890712738,-0.08003111928701401,-0.07967393845319748,-0.0793180838227272,-0.07896358519792557,-0.07861004024744034,-0.078257717192173,-0.07790911942720413,-0.0775638073682785,-0.07722754776477814,-0.07689955085515976,-0.076573945581913,-0.07624920457601547,-0.07592542469501495,-0.07560212910175323,-0.07527918368577957,-0.0749349296092987,-0.07459203898906708,-0.07425057142972946,-0.07390409708023071,-0.07351480424404144,-0.07312589883804321,-0.07273778319358826,-0.07234679162502289,-0.07195274531841278,-0.07155763357877731,-0.07116129249334335,-0.07076653093099594,-0.07038208097219467,-0.06999696046113968,-0.0696123018860817,-0.06923344731330872,-0.06887223571538925,-0.06851574778556824,-0.06816057115793228,-0.06780658662319183,-0.06745436787605286,-0.06710020452737808,-0.06674258410930634,-0.06639185547828674,-0.06604798883199692,-0.06569939106702805,-0.0653575211763382,-0.06501363217830658,-0.06467147171497345,-0.06433279067277908,-0.06399555504322052,-0.06366091966629028,-0.06333060562610626,-0.06300231069326401,-0.06267927587032318,-0.06235693395137787,-0.06203541159629822,-0.0617145337164402,-0.061395250260829926,-0.061068084090948105,-0.060733649879693985,-0.060398515313863754,-0.06006363406777382,-0.05973029136657715,-0.05939749628305435,-0.05906543508172035,-0.05865781381726265,-0.0582447312772274,-0.057832811027765274,-0.05742090940475464,-0.05700917914509773,-0.05659718066453934,-0.05618123710155487,-0.05576547980308533,-0.05534995719790459,-0.05493530258536339,-0.05452146753668785,-0.054108526557683945,-0.05369643494486809,-0.05328549072146416,-0.0528758242726326,-0.05246695503592491,-0.052059099078178406,-0.05164894834160805,-0.05123906210064888,-0.050833191722631454,-0.05045326426625252,-0.05007705092430115,-0.04970211908221245,-0.04932234063744545,-0.04894017428159714,-0.04855897277593613,-0.04817872866988182,-0.047799672931432724,-0.04742295667529106,-0.04705008864402771,-0.04667845368385315,-0.04630798473954201,-0.04592229798436165,-0.04553478583693504,-0.04514874517917633,-0.0447639524936676,-0.044380489736795425,-0.04399840533733368,-0.043617844581604004,-0.04323872923851013,-0.042861007153987885,-0.04248471185564995,-0.04210956394672394,-0.041735537350177765,-0.04136292636394501,-0.04099182039499283,-0.0406198687851429,-0.040248844772577286,-0.03987918049097061,-0.0395115464925766,-0.03914782032370567,-0.038785919547080994,-0.03839055076241493,-0.03798561543226242,-0.03758213669061661,-0.037179309874773026,-0.03677721694111824,-0.0363759808242321,-0.035975705832242966,-0.03557609021663666,-0.035177137702703476,-0.03477901220321655,-0.034381765872240067,-0.03398549184203148,-0.03359023854136467,-0.03319566324353218,-0.03280201554298401,-0.0324096754193306,-0.0320185124874115,-0.03162860497832298,-0.031239135190844536,-0.030849451199173927,-0.030461156740784645,-0.030072730034589767,-0.029683636501431465,-0.02929595112800598,-0.028909659013152122,-0.028524823486804962,-0.02814042940735817,-0.02774845063686371,-0.0273579154163599,-0.02696819230914116,-0.02656991221010685,-0.026173129677772522,-0.025777770206332207,-0.025383993983268738,-0.02499239332973957,-0.024602364748716354,-0.02421403117477894,-0.023827284574508667,-0.023442422971129417,-0.02305918000638485,-0.022677529603242874,-0.022297481074929237,-0.02191900461912155,-0.02154216542840004,-0.021166842430830002,-0.020793011412024498,-0.0204208642244339,-0.02005026862025261,-0.019682200625538826,-0.019318224862217903,-0.018958160653710365,-0.01859932765364647,-0.01824144273996353,-0.01788465864956379,-0.017530864104628563,-0.017190849408507347,-0.016853518784046173,-0.016517452895641327,-0.01618248224258423,-0.0158480703830719,-0.015532013028860092,-0.015238284133374691,-0.014948355033993721,-0.0146627277135849,-0.01437786128371954,-0.014094114303588867,-0.013811404816806316,-0.013528860174119473,-0.01323146652430296,-0.01295621320605278,-0.01268061064183712,-0.012405761517584324,-0.01213157083839178,-0.011857964098453522,-0.011585107073187828,-0.011328689754009247,-0.011078152805566788,-0.010828486643731594,-0.010578685440123081,-0.010328667238354683,-0.010076434351503849,-0.009823115542531013,-0.009569835849106312,-0.009316734038293362,-0.009063896723091602,-0.008811390958726406,-0.008559305220842361,-0.008302969858050346,-0.008032606914639473,-0.007774854078888893,-0.007523077540099621,-0.0072719259187579155,-0.007021436933428049,-0.006771744694560766,-0.006506979465484619,-0.006239676382392645,-0.005972557235509157,-0.0057057542726397514,-0.0054393792524933815,-0.00517354067414999,-0.004920248407870531,-0.004669076297432184,-0.0044196476228535175,-0.004171396140009165,-0.003923872951418161,-0.0036771197337657213,-0.0034311714116483927,-0.0031860703602433205,-0.0029380936175584793,-0.002689080312848091,-0.0024409324396401644,-0.0021912960801273584,-0.0019427394727244973,-0.0016949819400906563,-0.001450286596082151,-0.001205956912599504,-0.0009623703081160784,-0.0007195401121862233,-0.00047754563274793327,-0.0002364549582125619,3.7295581023499835e-06,0.00024297232448589057,0.00048164502368308604,0.0007192660705186427,0.0009559633326716721,0.0011925239814445376,0.0014299615286290646,0.001666690455749631,0.0019027000525966287,0.002137662610039115,0.0023715621791779995,0.00260434509254992,0.0028359682764858007,0.003066663397476077,0.0032970940228551626,0.003528306260704994,0.003758738748729229,0.0039886352606117725,0.00421784957870841,0.004446214530616999,0.004673723131418228,0.004899490159004927,0.0051243421621620655,0.005348159000277519],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"Test Estimate\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[-0.3043034076690674,-0.30969753861427307,-0.3138801157474518,-0.3177066147327423,-0.3212697207927704,-0.3185144364833832,-0.311815470457077,-0.30513763427734375,-0.298274964094162,-0.29146963357925415,-0.2848311960697174,-0.27923864126205444,-0.27355921268463135,-0.26807764172554016,-0.26277363300323486,-0.2576274275779724,-0.2526363432407379,-0.2477704882621765,-0.2429303526878357,-0.23826327919960022,-0.2337072789669037,-0.22928406298160553,-0.22501781582832336,-0.21939508616924286,-0.21397282183170319,-0.20874850451946259,-0.2037137746810913,-0.19885365664958954,-0.19419212639331818,-0.18981745839118958,-0.1856154501438141,-0.1815786510705948,-0.17769981920719147,-0.17397186160087585,-0.1703873574733734,-0.1669386625289917,-0.16361021995544434,-0.16040408611297607,-0.15731367468833923,-0.1543290615081787,-0.15144604444503784,-0.14837756752967834,-0.145330011844635,-0.14237108826637268,-0.13949604332447052,-0.1366986632347107,-0.1339733749628067,-0.13131335377693176,-0.12871284782886505,-0.12616746127605438,-0.12363449484109879,-0.12113185971975327,-0.11876621097326279,-0.1164805144071579,-0.11422380059957504,-0.11199308186769485,-0.10978400707244873,-0.1075933501124382,-0.10541844367980957,-0.10325566679239273,-0.10110224038362503,-0.09906481206417084,-0.09703311324119568,-0.09500051289796829,-0.09296615421772003,-0.0909295529127121,-0.08888988196849823,-0.0868467390537262,-0.08479883521795273,-0.0827464610338211,-0.08068982511758804,-0.07862955331802368,-0.07656597346067429,-0.07450000196695328,-0.07243230938911438,-0.07036396116018295,-0.06829564273357391,-0.06622754782438278,-0.06416036933660507,-0.06209554895758629,-0.060034479945898056,-0.05797847732901573,-0.05592872202396393,-0.05388656631112099,-0.05185285583138466,-0.049828268587589264,-0.0478125624358654,-0.045806560665369034,-0.043811846524477005,-0.04183095693588257,-0.0398685447871685,-0.037920545786619186,-0.03598831593990326,-0.034072600305080414,-0.03217563033103943,-0.030297191813588142,-0.02843751758337021,-0.0265972837805748,-0.024777323007583618,-0.022977987304329872,-0.021200181916356087,-0.019443945959210396,-0.017709871754050255,-0.015998253598809242,-0.014309518039226532,-0.012643735855817795,-0.011000948958098888,-0.009381519630551338,-0.007785395253449678,-0.006212138570845127,-0.004661313723772764,-0.003132406622171402,-0.0016255498630926013,-0.00014068173186387867,0.0013221410335972905,0.002763468772172928,0.004182988777756691,0.005581143777817488,0.006957444828003645,0.00831222627311945,0.009645337238907814,0.010956925339996815,0.012246167287230492,0.013513694517314434,0.014760222285985947,0.015984291210770607,0.017180193215608597,0.018355662003159523,0.01951100118458271,0.02064615860581398,0.021747907623648643,0.02259623073041439,0.02342788130044937,0.024242911487817764,0.02504141628742218,0.025823941454291344,0.026590509340167046,0.02734174206852913,0.02807793952524662,0.02879929170012474,0.029506100341677666,0.030198581516742706,0.03087719716131687,0.031541988253593445,0.03219335153698921,0.032831523567438126,0.03345654532313347,0.03406880050897598,0.03466935455799103,0.0352574959397316,0.03583243861794472,0.036377180367708206,0.03689539059996605,0.037404995411634445,0.03790602460503578,0.03839830681681633,0.03888067230582237,0.03935582563281059,0.03982940688729286,0.04029318317770958,0.040747277438640594,0.04119252413511276,0.041628845036029816,0.04205682501196861,0.04249448701739311,0.04293222725391388,0.043361078947782516,0.043781232088804245,0.04419275000691414,0.04459545388817787,0.044989459216594696,0.04537533223628998,0.04575306549668312,0.046122726052999496,0.04648446664214134,0.04683856666088104,0.047185223549604416,0.04752447083592415,0.047857411205768585,0.048184338957071304,0.04850514978170395,0.04882010072469711,0.049129098653793335,0.04943247511982918,0.04973030462861061,0.05002272129058838,0.05031067878007889,0.050594303756952286,0.050874944776296616,0.05115238577127457,0.0514269657433033,0.051698777824640274,0.05196718871593475,0.052232250571250916,0.052493780851364136,0.0527413934469223,0.052972082048654556,0.05319943279027939,0.05342300236225128,0.05363868549466133,0.05384782701730728,0.05405277758836746,0.0542534738779068,0.05445011705160141,0.054642584174871445,0.05483065918087959,0.055014465004205704,0.055302269756793976,0.055595070123672485,0.055884260684251785,0.05617024376988411,0.056452855467796326,0.056731902062892914,0.05700485780835152,0.057269591838121414,0.05753077566623688,0.05778828263282776,0.058042094111442566,0.05829230323433876,0.058539390563964844,0.0587831549346447,0.05902363359928131,0.05926233530044556,0.05949952453374863,0.059733521193265915,0.059964533895254135,0.06023797020316124,0.06055547669529915,0.06086983159184456,0.061180729418992996,0.06148794665932655,0.06179125979542732,0.06209097430109978,0.062387000769376755,0.0626792460680008,0.06315906345844269,0.0637022852897644,0.06423967331647873,0.06477219611406326,0.06529991328716278,0.0658220574259758,0.06613137573003769,0.06602298468351364,0.06591594219207764,0.06580976396799088,0.06570430845022202,0.06559677422046661,0.06548533588647842,0.06537466496229172,0.06526466459035873,0.06515602767467499,0.0650484710931778,0.06494181603193283,0.06483615934848785,0.06473138183355331,0.06462851911783218,0.06452689319849014,0.06442593038082123,0.06432493031024933,0.06422358006238937,0.06412232667207718,0.06402123719453812,0.06394098699092865,0.06387799233198166,0.06381373852491379,0.06374844163656235,0.06368205696344376,0.06361407786607742,0.06354396045207977,0.06347253918647766,0.06339852511882782,0.0633220449090004,0.06328510493040085,0.06325647979974747,0.0632202997803688,0.06318327784538269,0.06314436346292496,0.06310371309518814,0.06305951625108719,0.06301362067461014,0.06296706944704056,0.06291965395212173,0.06287132203578949,0.06282173842191696,0.06277099996805191,0.06271927803754807,0.06266660988330841,0.06261317431926727,0.06255940347909927,0.06250536441802979,0.06245056167244911,0.0623951219022274,0.06233898922801018,0.062282342463731766,0.062225114554166794,0.0621674507856369,0.06210922822356224,0.06205049529671669,0.06199107691645622,0.06193128600716591,0.0618710033595562,0.06180979683995247,0.06174780800938606,0.06168494373559952,0.06162138655781746,0.06155615299940109,0.0614895261824131,0.06142158806324005,0.06135242432355881,0.06128222122788429,0.06121087074279785,0.061138544231653214,0.06106527894735336,0.06099121645092964,0.06091652810573578,0.06084129586815834,0.06076555699110031,0.06068931892514229,0.06061265245079994,0.06053560972213745,0.060458142310380936,0.060380369424819946,0.06030232086777687,0.06022415682673454,0.06014639139175415,0.06006898358464241,0.05999187007546425,0.05991510674357414,0.05983841419219971,0.05976191908121109,0.05968547239899635,0.05960915610194206,0.05953292176127434,0.05945688486099243,0.05938104912638664,0.0593053363263607,0.05922972410917282,0.05915427207946777,0.05907908454537392,0.05900406464934349,0.05892914906144142,0.05885450541973114,0.05878002941608429,0.05870571359992027,0.05863155424594879,0.05855761095881462,0.05848386138677597,0.058410197496414185,0.058336786925792694,0.058263666927814484,0.05819078907370567,0.05811825022101402,0.05804586037993431,0.05797380208969116,0.057901978492736816,0.05783037841320038,0.05774787440896034,0.05766121298074722,0.05757416412234306,0.05748674273490906,0.05739906430244446,0.057310864329338074,0.05723663419485092,0.05716367065906525,0.05709077790379524,0.05701795592904091,0.05694493278861046,0.0568719357252121,0.056799110025167465,0.056726451963186264,0.0566539540886879,0.056581635028123856,0.056509532034397125,0.056437596678733826,0.05636584386229515,0.05629432201385498,0.056223127990961075,0.05615224689245224,0.05608164146542549,0.056011371314525604,0.05594141408801079,0.05587168410420418,0.055802300572395325,0.05573311075568199,0.055664196610450745,0.055595532059669495,0.055527087301015854,0.05545894801616669,0.055391084402799606,0.055323515087366104,0.05525607988238335,0.05518887937068939,0.05512189492583275,0.05505508556962013,0.05498848855495453,0.054922107607126236,0.054855912923812866,0.05478988587856293,0.05472410097718239,0.054658472537994385,0.05459307134151459,0.054527830332517624,0.05446285381913185,0.05439811944961548,0.05433366075158119,0.05426938459277153,0.054205529391765594,0.054142024368047714,0.054078929126262665,0.05401647463440895,0.05395463854074478,0.05389344319701195,0.05383320152759552,0.053773894906044006,0.053715404123067856,0.05365767702460289,0.053600676357746124,0.053544383496046066,0.05348902568221092,0.05343468114733696,0.05338107794523239,0.053328435868024826,0.053276512771844864,0.053225379437208176,0.05317484587430954,0.053125232458114624,0.0530763678252697,0.05302821099758148,0.0529807023704052,0.05293385684490204,0.05288759618997574,0.052841875702142715,0.05279672145843506,0.052752092480659485,0.052707988768815994,0.052664466202259064,0.05262482166290283,0.052587103098630905,0.052550170570611954,0.05251395329833031,0.05247840657830238,0.05244341492652893,0.05240900442004204,0.05237489193677902,0.052341215312480927,0.05230794847011566,0.052275169640779495,0.05224280431866646,0.05221080407500267,0.05217919871211052,0.05215063318610191,0.05212440341711044,0.052099473774433136,0.052075691521167755,0.052052970975637436,0.052031196653842926,0.05201030150055885,0.05199018493294716,0.05197077617049217,0.05195195972919464,0.051933806389570236,0.051916174590587616,0.05189904943108559,0.051882341504096985,0.05186603218317032,0.05185021460056305,0.0518348403275013,0.05181986093521118,0.0518052913248539,0.05178770795464516,0.051763683557510376,0.051739998161792755,0.051716603338718414,0.05169343203306198,0.05167049542069435,0.051647789776325226,0.05162420496344566,0.051600318402051926,0.051576610654592514,0.05155310779809952,0.05152961611747742,0.05150628089904785,0.051483154296875,0.051461461931467056,0.051441919058561325,0.05142250284552574,0.0514032244682312,0.05138413608074188,0.051365166902542114,0.051346294581890106,0.05132708698511124,0.05130505934357643,0.05128319188952446,0.05126143619418144,0.05123978853225708,0.05121803656220436,0.051196251064538956,0.0511767640709877,0.05115751922130585,0.05113820731639862],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"On-policy Estimate\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964,0.8209239287512964],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"IS Variance\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333,0.0005283948848955333],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"lines\",\"name\":\"Train Variance\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.11333893984556198,0.042688727378845215,0.04143621027469635,0.0402701199054718,0.03917427733540535,0.03816210478544235,0.03715905547142029,0.03617198392748833,0.03523246943950653,0.03435535356402397,0.03357860818505287,0.03281673416495323,0.03208203241229057,0.031312331557273865,0.030581435188651085,0.029897214844822884,0.029286295175552368,0.028609026223421097,0.02798432484269142,0.02741558477282524,0.026897476986050606,0.026423141360282898,0.026044059544801712,0.025718340650200844,0.025430239737033844,0.025216614827513695,0.025039464235305786,0.024873150512576103,0.02453809604048729,0.024233011528849602,0.0239565372467041,0.023706555366516113,0.023482859134674072,0.023282645270228386,0.023106373846530914,0.022952435538172722,0.022817349061369896,0.022697478532791138,0.022596051916480064,0.022511271759867668,0.022446954622864723,0.022401751950383186,0.022398438304662704,0.022408444434404373,0.02242899313569069,0.022457731887698174,0.02249276451766491,0.022544171661138535,0.022601159289479256,0.02266073040664196,0.022721726447343826,0.022775301709771156,0.022829068824648857,0.022880444303154945,0.02293073572218418,0.022979089990258217,0.02301982045173645,0.02305411361157894,0.02308550849556923,0.023111987859010696,0.02313133515417576,0.02314637415111065,0.02316221594810486,0.023178668692708015,0.023188892751932144,0.02319265529513359,0.023189669474959373,0.023179881274700165,0.02316328138113022,0.02313993126153946,0.023109864443540573,0.02307317964732647,0.023030027747154236,0.022983282804489136,0.02293088473379612,0.022872410714626312,0.022811196744441986,0.022744424641132355,0.022672293707728386,0.022595088928937912,0.0225131306797266,0.02242668904364109,0.02233622595667839,0.022245610132813454,0.022151805460453033,0.022055547684431076,0.02195698954164982,0.021855738013982773,0.021750740706920624,0.021642496809363365,0.02153260074555874,0.02142133004963398,0.02130899578332901,0.02119581215083599,0.021083034574985504,0.02097051404416561,0.020857738330960274,0.020744826644659042,0.020631959661841393,0.02051929198205471,0.020406942814588547,0.020294787362217903,0.02018328383564949,0.020073072984814644,0.019963670521974564,0.019855089485645294,0.019747065380215645,0.019639907404780388,0.019532708451151848,0.01942647621035576,0.019321460276842117,0.019217683002352715,0.019115224480628967,0.01901409588754177,0.018914317712187767,0.018815934658050537,0.01871895045042038,0.01862347684800625,0.018529372289776802,0.01843659207224846,0.0183480903506279,0.018263526260852814,0.018180323764681816,0.01809833198785782,0.018017226830124855,0.017936989665031433,0.01785682886838913,0.01777779497206211,0.017699873074889183,0.01762302778661251,0.017547212541103363,0.01747237890958786,0.017396701499819756,0.017319703474640846,0.017243631184101105,0.0171684380620718,0.01709410920739174,0.017020640894770622,0.01694798469543457,0.016876107081770897,0.016805002465844154,0.016734644770622253,0.016665026545524597,0.016596123576164246,0.01652790978550911,0.016460366547107697,0.016393465921282768,0.01632719859480858,0.016261082142591476,0.01619463600218296,0.01612633652985096,0.016058078035712242,0.01598702184855938,0.01591641828417778,0.015846895053982735,0.015777984634041786,0.01570991799235344,0.01564277708530426,0.015576406382024288,0.01551063358783722,0.015445448458194733,0.01538083702325821,0.015316784381866455,0.015253527089953423,0.015191227197647095,0.01512946281582117,0.015068194828927517,0.015007443726062775,0.014945694245398045,0.01488838717341423,0.01483146846294403,0.014774921350181103,0.014718753285706043,0.014662977308034897,0.014607559889554977,0.014552498236298561,0.014497755095362663,0.01444332767277956,0.014389459043741226,0.014335840940475464,0.014282463118433952,0.01422934141010046,0.014176418073475361,0.01412375271320343,0.014071369543671608,0.014005717821419239,0.013938997872173786,0.013871677219867706,0.013802321627736092,0.013733364641666412,0.01366445142775774,0.013595214113593102,0.013526407070457935,0.013458051718771458,0.013391701504588127,0.013326150365173817,0.01326078362762928,0.013195921666920185,0.013131801038980484,0.013068736530840397,0.01300650741904974,0.012944879941642284,0.012883806601166725,0.012823234312236309,0.01276312954723835,0.01270347647368908,0.012644264847040176,0.012585516087710857,0.012527242302894592,0.01246968749910593,0.012412503361701965,0.01235569454729557,0.012299271300435066,0.012243232689797878,0.01218758150935173,0.012132285162806511,0.012077339924871922,0.012022756040096283,0.011968564242124557,0.011914766393601894,0.011861378327012062,0.011808445677161217,0.011755959130823612,0.011703915894031525,0.011652275919914246,0.011601048521697521,0.01155024766921997,0.011499852873384953,0.011449861340224743,0.011400291696190834,0.011351118795573711,0.011302337981760502,0.01125393621623516,0.011205915361642838,0.01115827914327383,0.011111019179224968,0.011064103804528713,0.011016788892447948,0.010966690257191658,0.010916906408965588,0.010867437347769737,0.010818296112120152,0.010769122280180454,0.01072026789188385,0.010671754367649555,0.01062357984483242,0.010575739666819572,0.010528205893933773,0.010480991564691067,0.010434100404381752,0.010387464426457882,0.010342284105718136,0.010297668166458607,0.01025325246155262,0.010209111496806145,0.01016524899750948,0.010121670551598072,0.010078337043523788,0.010031946934759617,0.009985877200961113,0.00994012039154768,0.009893499314785004,0.00983846839517355,0.0097837895154953,0.009729480370879173,0.009675351902842522,0.009621532633900642,0.009568139910697937,0.009515085257589817,0.009462477639317513,0.009411933831870556,0.009361706674098969,0.009311802685260773,0.009261859580874443,0.009211866185069084,0.0091620571911335,0.009112552739679813,0.009063400328159332,0.009014628827571869,0.00896662287414074,0.008919385261833668,0.008872434496879578,0.008825613185763359,0.008779013529419899,0.008732753805816174,0.008686860091984272,0.008641273714601994,0.008595972321927547,0.008550940081477165,0.008506190031766891,0.008461683988571167,0.008417503908276558,0.008374215103685856,0.00833121221512556,0.00828850083053112,0.008246083743870258,0.008203938603401184,0.008162149228155613,0.008120753802359104,0.008079529739916325,0.008038521744310856,0.007997811771929264,0.00795739982277155,0.00791728775948286,0.007867646403610706,0.007816976867616177,0.007766414433717728,0.007716015912592411,0.007665807381272316,0.007615730166435242,0.0075655728578567505,0.0075156232342123985,0.007465905509889126,0.007416450884193182,0.007367273326963186,0.007318391930311918,0.007269817870110273,0.007221561390906572,0.007173637859523296,0.007126046344637871,0.007078797090798616,0.00703192176297307,0.006985390093177557,0.00693920161575079,0.006893646903336048,0.006848757620900869,0.006804171018302441,0.0067599196918308735,0.006715964060276747,0.006672299932688475,0.0066289291717112064,0.006585847586393356,0.006543046794831753,0.006500516552478075,0.0064583043567836285,0.006416406482458115,0.006375942379236221,0.0063360342755913734,0.006296455394476652,0.006257201079279184,0.006218277849256992,0.006179678253829479,0.006141408812254667,0.006103464402258396,0.006065844092518091,0.006028544157743454,0.005991564132273197,0.00595490075647831,0.005918555893003941,0.005882533732801676,0.005846684332937002,0.00581112178042531,0.005775879602879286,0.005740961991250515,0.005706366151571274,0.005672096740454435,0.005636056885123253,0.005599566735327244,0.005563283339142799,0.00552722904831171,0.005491411779075861,0.005455837119370699,0.005420488305389881,0.005385374650359154,0.005350502673536539,0.005315882153809071,0.0052815149538218975,0.005247407592833042,0.005213563330471516,0.005179984960705042,0.005146675743162632,0.00511363847181201,0.005080869887024164,0.005048372782766819,0.005016150884330273,0.0049842046573758125,0.004952539224177599,0.004921140149235725,0.004890012089163065,0.0048591517843306065,0.0048285601660609245,0.004798238165676594,0.004768136888742447,0.00473783491179347,0.004707795567810535,0.004678027238696814,0.004648539703339338,0.004619310609996319,0.004590335767716169,0.004561618901789188,0.004533159546554089,0.004504958167672157,0.004477012436836958,0.004449312575161457,0.004421863704919815,0.004394667688757181,0.004367718938738108,0.004341016989201307,0.0043145581148564816,0.004288341850042343,0.00426236679777503,0.004236632026731968,0.00421114219352603,0.004185888916254044,0.004160906653851271,0.0041362992487847805,0.004112116992473602,0.004088148474693298,0.004064391832798719,0.004040831699967384,0.00401754816994071,0.003994479309767485,0.0039715999737381935,0.003948912490159273,0.003926417790353298,0.00390411214902997,0.003883360419422388,0.0038644399028271437,0.0038456348702311516,0.0038269280921667814,0.003808358684182167,0.0037899299059063196,0.003771643852815032,0.0037535286974161863,0.003735312959179282,0.0037161188665777445,0.0036969748325645924,0.0036779518704861403,0.00365905137732625,0.003640277311205864,0.003621631534770131,0.0036026244051754475,0.003583587473258376,0.0035646879114210606,0.003545929677784443,0.003527309512719512,0.0035085685085505247,0.0034898342564702034,0.003471194999292493,0.003452662378549576,0.0034342403523623943,0.0034159310162067413,0.0033977420534938574,0.0033796632196754217,0.003362056566402316,0.0033448475878685713,0.0033277806360274553,0.0033108340576291084,0.0032940064556896687,0.0032773034181445837,0.003260604804381728,0.003243982093408704,0.0032274529803544283,0.0032110228203237057,0.0031946960370987654,0.003178474958986044,0.003162391483783722,0.0031464239582419395,0.0031305670272558928,0.0031148241832852364,0.003099198453128338,0.00308369193226099,0.0030683039221912622,0.0030530367512255907,0.003037902992218733,0.003022894263267517,0.00300800078548491,0.0029932211618870497,0.002978523261845112,0.0029639198910444975,0.002949564019218087,0.00293532432988286,0.0029211940709501505,0.002907173940911889,0.0028932634741067886,0.0028794643003493547,0.0028657743241637945,0.0028521958738565445,0.002838742220774293,0.0028254042845219374,0.002812172519043088,0.002799027366563678,0.0027860708069056273,0.0027732285670936108,0.0027604943607002497,0.0027478619012981653,0.002735330257564783,0.002722900127992034,0.002710572211071849,0.002698370022699237,0.002686311025172472,0.0026744550559669733,0.002662695711478591,0.0026510173920542,0.0026394259184598923,0.0026279299054294825,0.0026165256276726723,0.002605210989713669,0.0025939878541976213,0.0025828590150922537],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"lines\",\"name\":\"Test Variance\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.2910063862800598,0.28331175446510315,0.2745833694934845,0.26590433716773987,0.25722426176071167,0.24935045838356018,0.24150243401527405,0.23382960259914398,0.2258424460887909,0.21784092485904694,0.21011126041412354,0.202006995677948,0.19294539093971252,0.1841713935136795,0.1757620871067047,0.16770696640014648,0.16000120341777802,0.1526229977607727,0.14550922811031342,0.13872064650058746,0.13224638998508453,0.12607450783252716,0.1201874241232872,0.11393219977617264,0.10799605399370193,0.1023678258061409,0.09703175723552704,0.09197396039962769,0.0871829241514206,0.08264646679162979,0.0783519297838211,0.07428684085607529,0.0704396665096283,0.06679914891719818,0.06335470825433731,0.06009577587246895,0.05700839310884476,0.0540880411863327,0.051325928419828415,0.048713747411966324,0.046243514865636826,0.043819062411785126,0.041505374014377594,0.039319299161434174,0.03725438937544823,0.03530421108007431,0.033462464809417725,0.03172312304377556,0.03008045256137848,0.028529353439807892,0.027052544057369232,0.025653555989265442,0.024329671636223793,0.0230783149600029,0.021897083148360252,0.020782148465514183,0.01972959190607071,0.018735909834504128,0.017797840759158134,0.0169120691716671,0.016075437888503075,0.015305081382393837,0.014577335678040981,0.013888868503272533,0.01323753222823143,0.01262133102864027,0.012038259766995907,0.011486433446407318,0.010963927023112774,0.01046910509467125,0.010000414215028286,0.009556381963193417,0.009135584346950054,0.008736710995435715,0.0083585474640131,0.007999878376722336,0.007659530267119408,0.007336325477808714,0.007029242813587189,0.006737411953508854,0.006459975615143776,0.006196100264787674,0.0059449938125908375,0.005705912597477436,0.005478166975080967,0.005261052865535021,0.0050538391806185246,0.0048559741117060184,0.004666989669203758,0.004486320540308952,0.0043134246952831745,0.004148028790950775,0.003989757504314184,0.003838206175714731,0.003693035338073969,0.003553894581273198,0.0034204721450805664,0.0032924930565059185,0.003169690491631627,0.0030517936684191227,0.0029385918751358986,0.0028298357501626015,0.0027253187727183104,0.002624872140586376,0.0025283098220825195,0.0024354588240385056,0.002346174791455269,0.002260316628962755,0.0021777451038360596,0.0020983058493584394,0.0020218556746840477,0.0019482524367049336,0.0018773966003209352,0.0018091838574036956,0.001743547385558486,0.001680367044173181,0.0016195890493690968,0.0015611160779371858,0.0015049079665914178,0.0014508907916024327,0.0013990128645673394,0.0013491945574060082,0.001301426556892693,0.0012556227156892419,0.0012117100413888693,0.0011695879511535168,0.0011291493428871036,0.001090436358936131,0.0010534044122323394,0.0010180106619372964,0.0009846030734479427,0.0009597295429557562,0.00093580357497558,0.0009127865196205676,0.0008906612056307495,0.0008693907293491066,0.0008489573956467211,0.0008293263963423669,0.0008104733424261212,0.0007923783850856125,0.0007750170188955963,0.0007583622937090695,0.0007423878414556384,0.0007270773057825863,0.0007124025141820312,0.0006983443745411932,0.0006848801858723164,0.0006719863158650696,0.0006596434977836907,0.0006478439318016171,0.0006365449517033994,0.0006255423068068922,0.0006153541035018861,0.0006055488483980298,0.0005961110582575202,0.0005870613967999816,0.0005783888045698404,0.0005700044566765428,0.0005617740098387003,0.0005538962432183325,0.000546362076420337,0.0005391485174186528,0.000532248115632683,0.0005256443400867283,0.0005191806703805923,0.0005129459896124899,0.0005070095066912472,0.000501357251778245,0.0004959800862707198,0.0004908650298602879,0.00048600329319015145,0.0004813807609025389,0.0004769886436406523,0.0004728148633148521,0.00046884999028407037,0.0004650848568417132,0.00046150985872372985,0.00045811673044227064,0.0004548321303445846,0.00045170672819949687,0.00044874203740619123,0.0004459287447389215,0.00044326146598905325,0.0004407305386848748,0.00043833383824676275,0.00043606184772215784,0.00043390574865043163,0.00043186050606891513,0.00042992777889594436,0.00042810029117390513,0.0004263725131750107,0.0004247405449859798,0.0004232000501360744,0.00042174605187028646,0.0004203751450404525,0.0004189198953099549,0.00041733201942406595,0.0004158297961112112,0.00041440955828875303,0.000413041387218982,0.0004117338976357132,0.00041049846913665533,0.000409331260016188,0.000408229127060622,0.00040718872332945466,0.00040620530489832163,0.0004052756994497031,0.0004044282541144639,0.0004036327882204205,0.00040288851596415043,0.0004021938075311482,0.0004015456943307072,0.00040094173164106905,0.0004003728972747922,0.00039983069291338325,0.00039932606159709394,0.0003988570242654532,0.0003984220093116164,0.0003980193578172475,0.0003976496518589556,0.0003973106504417956,0.0003970010147895664,0.00039674408617429435,0.000396542513044551,0.0003963690251111984,0.00039622350595891476,0.0003965378855355084,0.00039739086059853435,0.00039835082134231925,0.00039941276190802455,0.0004005712107755244,0.00040181996882893145,0.0004031573480460793,0.00040457831346429884,0.00040607890696264803,0.0004100500955246389,0.0004152758920099586,0.00042092730291187763,0.00042699315235950053,0.00043346176971681416,0.0004403144121170044,0.00044383853673934937,0.0004400130419526249,0.00043627977720461786,0.0004326342314016074,0.00042907404713332653,0.0004255530657246709,0.0004220450937282294,0.0004186248406767845,0.00041528919246047735,0.000412040768424049,0.0004088746209163219,0.0004057908372487873,0.0004027886316180229,0.00039986567571759224,0.0003970226680394262,0.0003942567273043096,0.0003915653796866536,0.0003889438521582633,0.00038638844853267074,0.0003838999255094677,0.0003814789524767548,0.0003793463110923767,0.0003774472279474139,0.0003755766083486378,0.00037373616942204535,0.0003719244559761137,0.00037013887776993215,0.0003683785907924175,0.0003666480188257992,0.00036493854713626206,0.000363252212991938,0.000361929414793849,0.000360700098099187,0.00035944805131293833,0.00035820287303067744,0.0003569633117876947,0.0003557302989065647,0.00035456253681331873,0.0003534108982421458,0.000352270930306986,0.0003511407703626901,0.0003500208258628845,0.00034890923416242003,0.000347807421348989,0.00034671553294174373,0.0003456337726674974,0.00034456350840628147,0.0003435058461036533,0.00034246101859025657,0.0003414263774175197,0.0003404025628697127,0.0003393908264115453,0.00033839160460047424,0.0003374046937096864,0.0003364305885042995,0.0003354684740770608,0.0003345182922203094,0.0003335794317536056,0.00033265232923440635,0.0003317371883895248,0.00033083156449720263,0.00032993615604937077,0.00032905078842304647,0.0003281758981756866,0.0003273067995905876,0.0003264452680014074,0.0003255920310039073,0.00032474746694788337,0.00032391230342909694,0.00032308604568243027,0.0003222692757844925,0.00032146216835826635,0.00032066524727270007,0.000319879298331216,0.00031910446705296636,0.0003183407534379512,0.000317588186590001,0.000316846912028268,0.0003161168424412608,0.0003153979196213186,0.0003146901144646108,0.0003139932523481548,0.00031330814817920327,0.00031263602431863546,0.0003119780740235001,0.000311333715217188,0.00031070271506905556,0.0003100837056990713,0.00030947657069191337,0.00030888093169778585,0.0003082968760281801,0.0003077241126447916,0.00030716287437826395,0.00030661284108646214,0.00030607383814640343,0.0003055455454159528,0.0003050279919989407,0.00030452097416855395,0.0003040243173018098,0.0003035375848412514,0.000303060922306031,0.0003025938640348613,0.0003021362063009292,0.00030168777448125184,0.0003012483939528465,0.00030081780278123915,0.0003003958845511079,0.00029998240643180907,0.0002995774557348341,0.0002991806250065565,0.00029879185603931546,0.00029841065406799316,0.000298037106404081,0.00029767214437015355,0.000297315651550889,0.00029695467674173415,0.00029659856227226555,0.00029625179013237357,0.0002959145058412105,0.00029558633104898036,0.00029526776052080095,0.0002949654881376773,0.00029467028798535466,0.0002943816944025457,0.000294099299935624,0.00029382179491221905,0.00029355011065490544,0.000293284363579005,0.00029302420443855226,0.0002927697205450386,0.0002925208827946335,0.00029227702179923654,0.0002920385159086436,0.0002918047830462456,0.0002915759396273643,0.0002913516073022038,0.0002911316987592727,0.0002909163013100624,0.00029070497839711607,0.00029049802105873823,0.00029029505094513297,0.0002900958643294871,0.0002899007231462747,0.0002897094818763435,0.00028952176216989756,0.0002893378841690719,0.0002891574113164097,0.00028898066375404596,0.000288807088509202,0.00028863694751635194,0.0002884700079448521,0.0002883062406908721,0.00028814576216973364,0.00028798854327760637,0.0002878342929761857,0.00028768289485014975,0.0002875342615880072,0.0002873883058782667,0.00028724499861709774,0.00028710425249300897,0.00028696595109067857,0.0002868295705411583,0.0002866949653252959,0.00028656251379288733,0.00028643201221711934,0.00028630299493670464,0.0002861761022359133,0.00028605072293430567,0.00028592810849659145,0.0002858078514691442,0.00028568966081365943,0.00028557429322972894,0.0002854611084330827,0.0002853503974620253,0.0002852419565897435,0.0002851352619472891,0.00028503002249635756,0.00028492684941738844,0.00028482498601078987,0.0002847251307684928,0.00028462629416026175,0.0002845289127435535,0.00028443249175325036,0.000284337205812335,0.00028424288029782474,0.00028414977714419365,0.0002840575762093067,0.0002839664230123162,0.0002838755026459694,0.0002837850188370794,0.00028369491337798536,0.00028360498254187405,0.00028351577930152416,0.00028342651785351336,0.0002833371690940112,0.00028321161516942084,0.0002830727316904813,0.00028293192735873163,0.00028278943500481546,0.0002826451091095805,0.0002824992989189923,0.000282351829810068,0.00028220436070114374,0.00028205636772327125,0.00028190846205689013,0.0002817604108713567,0.0002816123014781624,0.00028146422118879855,0.00028131561703048646,0.00028117935289628804,0.000281049229670316,0.00028091942658647895,0.0002807902928907424,0.00028066153754480183,0.0002805330150295049,0.00028040449251420796,0.0002802759117912501,0.00028014706913381815,0.0002800178190227598,0.000279887521173805,0.0002797661582008004,0.00027965460321865976,0.0002795419713947922,0.00027942858287133276,0.00027931371005252004,0.00027919799322262406,0.00027908096672035754,0.00027896257233805954,0.00027882581343874335,0.0002786577388178557,0.000278489722404629,0.00027832179330289364,0.0002781541843432933,0.0002779863716568798,0.00027781855897046626,0.00027765470440499485,0.0002774923632387072,0.00027732946909964085,0.00027716613840311766,0.0002770034479908645,0.00027684008819051087,0.00027667684480547905,0.00027648749528452754,0.0002762555959634483,0.00027602381305769086,0.0002757924667093903,0.00027556048007681966,0.00027532887179404497,0.00027509735082276165,0.0002748670522123575,0.0002746465615928173,0.0002744266530498862,0.000274207501206547,0.0002739726332947612,0.0002737040922511369,0.0002734368899837136,0.0002731902350205928,0.0002729457919485867,0.00027270239661447704],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"lines\",\"name\":\"Train MSE Loss\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[21.067392349243164,19.93779754638672,18.907894134521484,17.921037673950195,16.97486686706543,16.07196617126465,15.217756271362305,14.402987480163574,13.626797676086426,12.886913299560547,12.182252883911133,11.509116172790527,10.86888599395752,10.261460304260254,9.685117721557617,9.140917778015137,8.624642372131348,8.134598731994629,7.669031143188477,7.228386402130127,6.812310695648193,6.42027473449707,6.050488471984863,5.701742172241211,5.373015880584717,5.063284873962402,4.771932125091553,4.498387813568115,4.242960453033447,4.003480434417725,3.7789056301116943,3.5682480335235596,3.3708102703094482,3.186095952987671,3.013347625732422,2.852001428604126,2.7013468742370605,2.5608396530151367,2.4299700260162354,2.3082008361816406,2.19500470161438,2.0896174907684326,1.9916901588439941,1.9009495973587036,1.816965937614441,1.7392997741699219,1.6675260066986084,1.6012320518493652,1.5401057004928589,1.4838076829910278,1.431978702545166,1.384300947189331,1.3404613733291626,1.3001208305358887,1.2630220651626587,1.228933572769165,1.1975517272949219,1.1686872243881226,1.1421173810958862,1.1176069974899292,1.0949403047561646,1.073960542678833,1.0545048713684082,1.036454677581787,1.019671082496643,1.0040242671966553,0.9893767833709717,0.9756078124046326,0.9626185297966003,0.9503318667411804,0.9386647343635559,0.9275445342063904,0.9169077277183533,0.9066964983940125,0.8968564867973328,0.8873392343521118,0.8780737519264221,0.8690441250801086,0.8602359294891357,0.8516232967376709,0.8431897759437561,0.834913969039917,0.8267825841903687,0.8187780976295471,0.8108794093132019,0.8030503392219543,0.7953195571899414,0.7876929044723511,0.7801662087440491,0.7727370858192444,0.765401303768158,0.7581599950790405,0.7510110139846802,0.7439565658569336,0.736986517906189,0.7301028966903687,0.7233104705810547,0.7166067957878113,0.7099932432174683,0.7034727334976196,0.6970453262329102,0.6907058954238892,0.6844533085823059,0.6782912015914917,0.6722176671028137,0.6662322878837585,0.6603319048881531,0.6545182466506958,0.6487860083580017,0.6431329250335693,0.6375445127487183,0.6320302486419678,0.6265940070152283,0.6212370991706848,0.6159483194351196,0.6107337474822998,0.6055943369865417,0.6005277037620544,0.595534086227417,0.590610146522522,0.585755467414856,0.5809699892997742,0.5762531757354736,0.5716002583503723,0.5670024752616882,0.5624678730964661,0.5579976439476013,0.5535866022109985,0.5492374300956726,0.5449479222297668,0.5407193303108215,0.5365488529205322,0.5324341654777527,0.5283734202384949,0.5243658423423767,0.520409345626831,0.5165035724639893,0.5126479268074036,0.5088430047035217,0.5050904154777527,0.5013864040374756,0.4977271258831024,0.49411335587501526,0.49054545164108276,0.48702213168144226,0.4835401475429535,0.4800969660282135,0.4766956865787506,0.47333529591560364,0.47001415491104126,0.4667309522628784,0.4634838402271271,0.46025529503822327,0.45706480741500854,0.4539109170436859,0.45079341530799866,0.44771525263786316,0.44466665387153625,0.4416496455669403,0.43866539001464844,0.4357123076915741,0.43278998136520386,0.4298999011516571,0.42703935503959656,0.4242058992385864,0.421407014131546,0.41863715648651123,0.415896475315094,0.4131852984428406,0.4105040431022644,0.4078512191772461,0.4052259027957916,0.40262967348098755,0.4000621736049652,0.39752185344696045,0.3950093686580658,0.3925267159938812,0.3900713324546814,0.3876318633556366,0.3852177560329437,0.3828287720680237,0.3804648518562317,0.37812569737434387,0.3758123517036438,0.37352439761161804,0.37125644087791443,0.36900994181632996,0.36678487062454224,0.3645736277103424,0.36237412691116333,0.3601880371570587,0.35801786184310913,0.35586631298065186,0.35373303294181824,0.3516211211681366,0.3495309054851532,0.3474592864513397,0.3454078733921051,0.3433765470981598,0.34136763215065,0.3393805921077728,0.33741506934165955,0.33546942472457886,0.333541601896286,0.3316313922405243,0.32973945140838623,0.32786571979522705,0.326009601354599,0.32417044043540955,0.32233965396881104,0.3205306828022003,0.3187394440174103,0.3169657588005066,0.31520920991897583,0.3134695887565613,0.3117469251155853,0.31004080176353455,0.30835139751434326,0.3066774010658264,0.3050191104412079,0.30337777733802795,0.30174925923347473,0.3001324236392975,0.29853206872940063,0.29694631695747375,0.2953743040561676,0.29381629824638367,0.29227155447006226,0.2907397449016571,0.2892233431339264,0.28772062063217163,0.2862335741519928,0.28476008772850037,0.2833000719547272,0.28185275197029114,0.28041842579841614,0.2789991796016693,0.2775932550430298,0.2761957049369812,0.27481064200401306,0.27343806624412537,0.2720783054828644,0.27073386311531067,0.26940059661865234,0.2680789530277252,0.266769140958786,0.2654709815979004,0.2641841173171997,0.26290827989578247,0.2616402208805084,0.26037850975990295,0.25912752747535706,0.2578882575035095,0.256658673286438,0.2554391622543335,0.2542298436164856,0.25303107500076294,0.2518431842327118,0.2506641447544098,0.24949465692043304,0.24833640456199646,0.2471870630979538,0.24603761732578278,0.24489624798297882,0.24376262724399567,0.24263520538806915,0.2415129393339157,0.24039354920387268,0.2392822653055191,0.23817314207553864,0.23706741631031036,0.23596695065498352,0.23486772179603577,0.23377305269241333,0.23268307745456696,0.23160192370414734,0.2305285483598709,0.22946247458457947,0.22840313613414764,0.2273487001657486,0.2262987643480301,0.22525541484355927,0.22421404719352722,0.2231781929731369,0.2221488356590271,0.22112630307674408,0.2201121300458908,0.21910201013088226,0.2180982530117035,0.21709609031677246,0.21609759330749512,0.21510399878025055,0.214118093252182,0.21313905715942383,0.21216700971126556,0.21120169758796692,0.21024374663829803,0.20929381251335144,0.20834973454475403,0.20741303265094757,0.2064802497625351,0.2055494487285614,0.2046254277229309,0.20370794832706451,0.20278272032737732,0.2018592208623886,0.2009401172399521,0.2000257521867752,0.19911620020866394,0.19820566475391388,0.1972985565662384,0.19639621675014496,0.19549860060214996,0.19460682570934296,0.19372078776359558,0.19284041225910187,0.19196538627147675,0.19109606742858887,0.19023266434669495,0.1893749237060547,0.1885214000940323,0.18767356872558594,0.18683117628097534,0.18599353730678558,0.18515720963478088,0.1843256950378418,0.1834985613822937,0.18267400562763214,0.18185298144817352,0.18103711307048798,0.1802264004945755,0.17942103743553162,0.17862080037593842,0.17782555520534515,0.17703576385974884,0.17625120282173157,0.17547129094600677,0.1746978461742401,0.17392998933792114,0.1731676608324051,0.17241087555885315,0.17165973782539368,0.1709142029285431,0.17017368972301483,0.1694386750459671,0.16870863735675812,0.16798409819602966,0.16726499795913696,0.16655142605304718,0.1658439040184021,0.16514189541339874,0.1644454151391983,0.16375474631786346,0.1630704253911972,0.1623930037021637,0.16172049939632416,0.16104687750339508,0.1603754311800003,0.15970760583877563,0.15904410183429718,0.15838482975959778,0.15772925317287445,0.15707740187644958,0.1564294695854187,0.15578584372997284,0.15514659881591797,0.15451174974441528,0.15388107299804688,0.15325473248958588,0.1526329666376114,0.15201550722122192,0.1514023095369339,0.15079350769519806,0.15018917620182037,0.14958934485912323,0.14899420738220215,0.14840324223041534,0.14781562983989716,0.14723224937915802,0.14665314555168152,0.14607833325862885,0.14550775289535522,0.14494141936302185,0.14437922835350037,0.14382116496562958,0.14326713979244232,0.14271622896194458,0.1421692967414856,0.14162619411945343,0.14108705520629883,0.1405520886182785,0.14002107083797455,0.13949352502822876,0.1389697641134262,0.13845008611679077,0.13793423771858215,0.13742206990718842,0.13691334426403046,0.13640835881233215,0.13590706884860992,0.13540934026241302,0.13491539657115936,0.1344252973794937,0.1339387744665146,0.13345572352409363,0.132975772023201,0.13249820470809937,0.13202358782291412,0.13155050575733185,0.1310804784297943,0.13061407208442688,0.130149707198143,0.12968838214874268,0.1292300969362259,0.1287749707698822,0.12832291424274445,0.12787269055843353,0.12742358446121216,0.12697675824165344,0.1265323907136917,0.12609072029590607,0.12565216422080994,0.12521633505821228,0.12478193640708923,0.12434986233711243,0.12391963601112366,0.12349191308021545,0.12306662648916245,0.12264391034841537,0.12222383916378021,0.12180642783641815,0.12139186263084412,0.12097994983196259,0.12057068943977356,0.12016402930021286,0.11975988000631332,0.119356669485569,0.1189555823802948,0.11855700612068176,0.11816100776195526,0.11776765435934067,0.11737669259309769,0.1169881820678711,0.11660143733024597,0.11621694266796112,0.1158348023891449,0.11545480042695999,0.11507727205753326,0.11470221728086472,0.11432968080043793,0.11395668983459473,0.11358519643545151,0.11321568489074707,0.11284832656383514,0.11248326301574707,0.1121203824877739,0.11175988614559174,0.11140179634094238,0.11104600131511688,0.1106925830245018,0.11034148186445236,0.1099926084280014,0.10964607447385788,0.10930181294679642,0.10895957052707672,0.10861940681934357,0.10828162729740143,0.10794618725776672,0.10761237144470215,0.10728009790182114,0.10694965720176697,0.10662137717008591,0.10629522055387497,0.10597116500139236,0.10564923286437988,0.10532943904399872,0.10501173138618469,0.10469617694616318,0.10438276082277298,0.10407145321369171,0.10376221686601639,0.1034550666809082,0.10314931720495224,0.10284549742937088,0.10254330933094025,0.10224279761314392,0.10194424539804459,0.10164760053157806,0.10135280340909958,0.10106052458286285,0.10077078640460968,0.10048320144414902,0.10019668191671371,0.09991207718849182,0.09962939471006393,0.09934820234775543,0.0990687757730484,0.09879101067781448,0.09851523488759995,0.09824134409427643],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"mode\":\"lines\",\"name\":\"IS MSE\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636,0.6018641015735636],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"mode\":\"lines\",\"name\":\"Train MSE\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.28045982387692764,0.47135976392670814,0.4946289138098431,0.5182924115787539,0.5410407606481752,0.5629933134643815,0.5811208173438949,0.5990384733402108,0.6166820892672615,0.6339434881014022,0.6511933543493871,0.6674752551803735,0.6828487709098073,0.6963610296598217,0.7096494455940331,0.7209248565963818,0.7315654783991089,0.7394716897306374,0.747694189825718,0.7561351166075478,0.7644253674425061,0.7721093629633672,0.7806697275142747,0.7890944303394395,0.796956005654738,0.8045149287304453,0.8120599155006858,0.8191092941840291,0.8227053354430887,0.8248603921944045,0.8264225045107529,0.8278246385878878,0.8291027328384645,0.8304715635550168,0.831796341471298,0.8330299180655582,0.8341858045789183,0.835487569011,0.836834622870796,0.8382471607112839,0.8402201210811437,0.8420629313982275,0.8441336661801973,0.8461881525274295,0.8481893157787417,0.85022831084479,0.8522681030573787,0.8547907005332548,0.8575892619076066,0.8602041475874603,0.8627682562136444,0.8651742353736583,0.867525284223131,0.8698975308587327,0.872136957399384,0.8742759001295646,0.8761168144189443,0.8777350777237359,0.8793923133740554,0.8810773578010697,0.882716174082391,0.8842480424689525,0.8858031289249942,0.8873755492648929,0.8888453425274604,0.8902132216898039,0.8914766999480837,0.8926434410065726,0.8937170049601458,0.8946916832542604,0.8955699387850031,0.8963545421172129,0.8970423861999197,0.8974976015238965,0.8978560940966485,0.8981356810860999,0.8983700940009047,0.8985346410991428,0.8986309884483404,0.8986617599782409,0.8986316165415934,0.8985477831209657,0.8984057422479885,0.8982861302771171,0.898132619321394,0.897913092150439,0.8976246890524461,0.8972809528677277,0.8969670170810804,0.8966777514389775,0.8963638136534918,0.8960276075318986,0.8956509762625926,0.8952533490674842,0.8948428581460334,0.8944388444333348,0.894026534208944,0.8936032525822836,0.8931705083539339,0.8927295051202314,0.8922808121419438,0.891818438821025,0.8913541034886191,0.8909011859085547,0.8904512017468162,0.8900126835973796,0.8896102794993409,0.8892024689241906,0.8887002829849463,0.8881851394717946,0.8876721416190175,0.8871739442595907,0.8866824988226257,0.8861947323406071,0.8857107192831711,0.8852273542790149,0.8847443365319749,0.8842609605855546,0.8837747852904336,0.8832920325145287,0.8828891830597627,0.8826067087046598,0.8823345808866844,0.8820644185190838,0.8818098572045466,0.8815561951443762,0.8813060469341126,0.8810557824525725,0.8808047503635223,0.8805537463847197,0.8803050772254148,0.880058112809782,0.8798107507712988,0.8796643558215408,0.8795175195326244,0.8793681753870588,0.8792160460406526,0.8790617370093532,0.8789032911347868,0.8786983725692363,0.8784898109285226,0.8782751884058569,0.8780589386756227,0.8778407338979558,0.8776205210383196,0.8773987246295446,0.877175331166376,0.8769498481180785,0.8767179097095705,0.876474738950075,0.8762086444298455,0.8759352487355485,0.8756097707416071,0.8752929054859325,0.8749598773949256,0.8746263839478038,0.8742591326448381,0.8738666580722828,0.8734720755583166,0.8730769393945154,0.8726813366116399,0.8722852814736554,0.8718870358124993,0.8714919533615461,0.8711101344672576,0.8707280423593954,0.8703451423022138,0.8699654787842352,0.8695775201856482,0.8693028346351557,0.8690252184859217,0.8687457028092287,0.8684676003819974,0.8681963203950591,0.8679226594111958,0.8676468771981264,0.8673790521157105,0.8671006304098547,0.866740141802906,0.8663789822792191,0.8660158769207222,0.865649110324393,0.8652842357682295,0.8649166937662631,0.8645462490899266,0.8638789953164636,0.8631791923018715,0.8624649269671112,0.8617208539554602,0.8609773793113288,0.8602268406326085,0.8594572710235769,0.8586888187581856,0.8579214773768964,0.8571909099924075,0.8564905608870294,0.8557950803107433,0.8551021448335514,0.8544199845237227,0.853748917034163,0.8530856789706218,0.852414478660378,0.8517396454678424,0.8510674204909342,0.8503456585452711,0.8495983270701726,0.848857987557376,0.8481201997655903,0.8473833806079041,0.8466223374343242,0.8458699740963731,0.845120560377287,0.8443741716350142,0.8436307496662013,0.8428903487430964,0.842153883669239,0.8414069351289581,0.8406634443752506,0.8399231945813355,0.8391860759991964,0.8384523994718186,0.8377244687793722,0.8370005763842094,0.8362970476608504,0.8356062581929479,0.8349192524154514,0.8342353919297589,0.8335544372249013,0.832875950741634,0.8321960474746919,0.8315185102449985,0.8308267130640591,0.8301293577803979,0.8294357540983026,0.8287452957418517,0.8280579848425379,0.8273762505395446,0.826691537271997,0.8259727160841949,0.8252566354247923,0.8245434808339511,0.8238334909009422,0.823135179689877,0.822440266477598,0.8217482727809328,0.8210592610481608,0.8203732774285307,0.8196895672765541,0.8190086239662978,0.8183349489022363,0.8176676763837367,0.8170183588737229,0.8163846686991032,0.8157556868941819,0.8151287426611526,0.8145040117745762,0.8138806429611277,0.813258355785426,0.8125950410379084,0.8119347256789208,0.8112775061658971,0.8106106951283332,0.8098591154774788,0.8091088837280231,0.8083607357671412,0.8076079317844709,0.8068502877316863,0.8060914790098271,0.8053311272206877,0.8045743535277353,0.8038383368010825,0.8031017375091768,0.8023665807630902,0.8016420137430972,0.8009490804846942,0.8002649953891359,0.7995838007185231,0.7989053292859628,0.7982306267460824,0.7975534841594817,0.7968712233159363,0.7962017354398397,0.7955447957671478,0.7948799247750867,0.7942275622916464,0.7935722219578782,0.7929204870416149,0.7922754316074038,0.7916334328806315,0.7909965440817317,0.7903677655555683,0.7897431006868789,0.7891288383212816,0.7885162946319061,0.7879056975375905,0.7872967391712803,0.7866910722560337,0.7860720599456695,0.78544083975982,0.7848087801529037,0.784177607586196,0.7835496671833493,0.7829232111972816,0.7822985682187203,0.7815316882635536,0.7807545096439662,0.7799798221408432,0.7792056706279719,0.7784323493218939,0.7776590276368344,0.7768790448236145,0.776099942305644,0.7753218287064024,0.7745458440018377,0.773771915208789,0.7730001897743746,0.7722305984621213,0.7714636704858076,0.7706996462442026,0.7699376822272613,0.7691781639691162,0.7684153476011619,0.767653672704988,0.7668996787127451,0.7661918594144788,0.7654914642167515,0.7647938861844976,0.7640884890768534,0.7633795218054972,0.7626728159809035,0.761968358308265,0.7612665437070063,0.7605693602248867,0.7598794114258565,0.7591921983639311,0.7585075982594391,0.7577983231850841,0.7570867383614817,0.7563783319235555,0.7556727088136741,0.7549700145042717,0.7542703222591532,0.7535738866498508,0.7528805638662657,0.7521902595894141,0.7515030248324784,0.750818373650817,0.7501362552109587,0.7494571763975373,0.7487812923592106,0.7481043994064461,0.7474296676392264,0.7467578724840336,0.7460901690494001,0.7454297797085045,0.7447731200016735,0.7440574315870438,0.743325171824936,0.742595947739697,0.7418683971888608,0.7411426671011565,0.74041897207758,0.7396974720547932,0.7389776571424288,0.7382595386572124,0.7375434053120117,0.7368293462092721,0.7361175250120526,0.7354080254343415,0.7347002623901174,0.7339946637043234,0.7332918784786443,0.7325916779532708,0.7318941955515605,0.7311980384315876,0.7305020954496241,0.7298091030225358,0.7291164534139777,0.7284232421543367,0.7277329959263059,0.7270456870586556,0.7263614208445439,0.7256784211841104,0.7249826424481546,0.7242898827122904,0.7235990761950645,0.7228943501708516,0.7221927370091777,0.7214941027854509,0.7207987189850839,0.7201075835096611,0.7194196711675418,0.7187351837448455,0.7180539249905813,0.7173763996259591,0.7167021555570372,0.7160311394766435,0.7153633629785289,0.7146987684473073,0.7140374616924354,0.7133792337078834,0.7127240393846355,0.7120722028609004,0.7114234895609751,0.7107795713997559,0.7101431759578614,0.7095140410957933,0.7088874465194527,0.708262912542863,0.7076406779973938,0.7070239878330127,0.7064308606796245,0.7058426515725719,0.7052569801848912,0.7046735611174091,0.7040914906843572,0.7035419029587509,0.7030316861590171,0.7025281096706677,0.7020319885543264,0.701537439119884,0.7010450621331166,0.7005547209598667,0.7000649856428208,0.6995505364265706,0.6990722100173865,0.6985935029294028,0.6981163245541148,0.6976405167739512,0.6971659583696181,0.6966929262641824,0.6962470454141132,0.6958110511882116,0.6953767684268842,0.694942527084949,0.6945081878522535,0.6940701719855363,0.6936304858594006,0.6931910880394416,0.6927522205278468,0.6923140307880655,0.6918766317905005,0.6914401774943717,0.6909969125969512,0.6905309945896723,0.6900865202520992,0.6896522228692038,0.6892192077502908,0.6887875350145017,0.6883574312591356,0.6879025126768288,0.6874436117511701,0.6869852515176817,0.6865276556765768,0.6860710128520651,0.6856155039501124,0.6851809964314852,0.6847502339436319,0.684322586089328,0.6838971193407742,0.683473094426929,0.6830505810949248,0.6826296350868499,0.6822103273868476,0.6817865348939183,0.6813612829629621,0.6809376954294551,0.6805118945111723,0.680088076935946,0.6796657921181287,0.6792489140874346,0.6788328732316133,0.6784182826525281,0.6780051638669286,0.6775936455943886,0.6771838400742973,0.6767757477675571,0.676369428115481,0.6759642831489558,0.6755610929678103,0.675159636831802,0.6747586033325184,0.6743564331212518,0.6739556510667399,0.6735562674198281,0.67315881152284,0.6727633070783805,0.6723698411274162,0.6719784832849071,0.6715888765147284,0.6711999518932222,0.6708100587227483,0.6704216434634103,0.6700342911427652,0.6696482456759214,0.6692637877244548,0.668880923802166,0.6685010953695781,0.6681229533332,0.6677466952200591],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"mode\":\"lines\",\"name\":\"Test MSE\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[1.5571429449077263,1.5616166569329766,1.5623635889042014,1.5623838517224973,1.5618305948195061,1.5476702465522392,1.5246009805342209,1.501844246329648,1.4784486078352908,1.4552603623734994,1.4328056564820593,1.412364676136329,1.3908387378271696,1.370095814014696,1.3501624924594209,1.3309799946398517,1.3125328610173888,1.2947307547165394,1.2772951602466855,1.2605981879874033,1.2444933742782338,1.2290113337321822,1.2141815571775456,1.1961958525814138,1.1790073383609532,1.1625931456438665,1.1469141805307248,1.1319202840856888,1.1176435295637848,1.1042446184743464,1.0914734510503759,1.0792982634056225,1.0676890564962858,1.0566167825776716,1.0460527744507466,1.0359682751234744,1.0263158830785515,1.0170927139437864,1.0082747372031502,0.9998321424220141,0.9917468796394766,0.9833644531043216,0.9751520517315433,0.9672565889725055,0.9596609121374651,0.9523452397620729,0.9452913254498817,0.9384789652805201,0.9318904599949379,0.9255114545037474,0.9192431596367199,0.9131226645810765,0.9073472303317853,0.9018054050132146,0.896398358858451,0.8911162971677892,0.8859468537113672,0.8808802469830184,0.875908031720448,0.8710199939909639,0.8662076944581217,0.8616843646096227,0.8572224666216468,0.8528064513137897,0.8484326159773471,0.8440981030514145,0.8397994299434701,0.835534018773584,0.8312976521952089,0.8270892784690574,0.8229077753805696,0.8187528490662319,0.8146237089194027,0.8105207266983565,0.8064439156883995,0.8023939810795796,0.7983709765788558,0.7943740678682165,0.7904034575353404,0.7864608099667768,0.7825476934694369,0.7786655396785496,0.7748155649841915,0.7709993148688292,0.7672174826815646,0.7634704420360326,0.7597569303008002,0.7560777153961584,0.7524349507109966,0.7488323133174062,0.7452771071957519,0.741761860235259,0.7382883526060245,0.7348572708741665,0.7314718930445497,0.7281312906770109,0.7248353386647973,0.7215846987479991,0.7183802977181681,0.7152222375907764,0.7121116096429205,0.7090480005956166,0.7060319701227599,0.7030636114502499,0.7001432204596598,0.6972705103025969,0.6944451769432476,0.691667454241544,0.6889368887962393,0.6862523797144967,0.6836128482673027,0.6810170963058542,0.6784650413691241,0.6759562784452674,0.6734906378156068,0.6710669053174241,0.6686853520782302,0.6663449730862459,0.6640463449170394,0.6617886697960835,0.6595719659108924,0.6573957411724862,0.6552611484434253,0.6531669090614628,0.6511116316632761,0.6490974080350266,0.6471331417557488,0.6452062591500447,0.643316084883283,0.6414625200509628,0.6396669158188664,0.6382868429702763,0.6369357492746992,0.6356134297875917,0.6343196348514396,0.6330533805290467,0.6318145385890238,0.6306020134165449,0.6294152359742595,0.628253819008536,0.6271171961434923,0.6260049370529146,0.6249162259374648,0.6238509252897017,0.6228083259469962,0.6217879834830198,0.6207897601490696,0.6198129791571035,0.6188558989376796,0.6179195875786506,0.61700519283151,0.6161391427060681,0.6153161027392139,0.6145074677501197,0.61371314927186,0.6129334103807448,0.6121700437564113,0.6114187042689045,0.610670426095795,0.6099382571779923,0.6092219693298496,0.6085202118621453,0.607833075618417,0.6071596096273755,0.6064715764285369,0.6057840335884048,0.6051109949012531,0.6044521282276285,0.6038073041199082,0.6031767659131559,0.6025603043052891,0.6019570063172988,0.601366855882543,0.6007897185660422,0.6002253304622015,0.5996732326594911,0.5991330937859145,0.5986048382342339,0.5980866726803145,0.5975781803635467,0.5970795121422823,0.5965902499980673,0.5961105212312227,0.5956397935650792,0.5951779397257291,0.5947247335120998,0.5942786867798526,0.5938395916499957,0.5934053654998254,0.5929763286730175,0.5925519485916997,0.5921320733631229,0.5917176680959468,0.5913086421551249,0.5909052673465522,0.5905233274419659,0.590167370873422,0.5898167314947088,0.5894720815663311,0.5891396859066126,0.588817479749049,0.5885018609550924,0.5881929176357863,0.5878903331485201,0.5875942877691831,0.5873051029859896,0.5870225823568057,0.5865809529756086,0.586131894636482,0.585688582232098,0.5852503925001803,0.5848175675815572,0.5843903953857706,0.5839727198476068,0.5835677769792144,0.5831684322387461,0.582774871400918,0.5823871156327809,0.5820050155964543,0.5816278337189698,0.5812558697642864,0.5808890607675172,0.5805251270242635,0.5801636658510921,0.5798072055834718,0.5794554241256329,0.5790396654178307,0.578557573742632,0.5780805814302118,0.5776091416935921,0.5771435821067702,0.57668422904489,0.5762306101076602,0.5757828494257122,0.5753410777244543,0.5746176411678213,0.5737998932185934,0.5729919897258563,0.5721924359226492,0.5714011145158581,0.570619150491118,0.570155636633089,0.5703154483963823,0.57047333954541,0.5706300360877907,0.5707857489348322,0.5709446634373647,0.5711095126833045,0.5712733148527838,0.5714362127047102,0.5715971610661859,0.5717565821107865,0.5719147455888813,0.5720715036721326,0.5722270336896607,0.5723797693006888,0.5725307321203775,0.5726807869182221,0.5728309882941538,0.5729818061544462,0.5731325648351823,0.5732831634383418,0.5734025204272727,0.5734959970769445,0.5735914167529779,0.5736884544568568,0.5737871768447468,0.5738883491255625,0.5739927949717147,0.5740992555725005,0.5742096756956707,0.5743238666143877,0.5743785167755038,0.5744206632988472,0.574474237407026,0.5745290969083484,0.5745868328804209,0.5746472095559769,0.5747130302711005,0.5747814459871396,0.5748508714966785,0.5749216213841853,0.5749937753740378,0.575067840216365,0.5751436708439603,0.5752210078968988,0.5752997953895371,0.5753797637956795,0.5754602590374286,0.5755411797439235,0.5756232749453413,0.5757063533827419,0.5757905012979594,0.5758754480495129,0.5759612953578402,0.5760478234433566,0.5761352182110719,0.5762234062953627,0.576312653025917,0.5764024840689537,0.5764930807341482,0.5765850968320104,0.576678318460785,0.5767728871560887,0.5768685264796555,0.5769667256499713,0.5770670570731581,0.5771693975416403,0.5772736178055644,0.5773794361125143,0.5774870165543067,0.5775960998054466,0.5777066298502296,0.5778183924714647,0.5779311283343529,0.5780447132776162,0.5781590909105504,0.5782742501641147,0.5783900837817181,0.5785065125584312,0.5786236102668213,0.5787411957474502,0.5788592236316586,0.5789774511542596,0.5790950973751683,0.5792122256585756,0.5793289316358572,0.5794451298886502,0.5795612441773841,0.579677081535695,0.5797928683613304,0.5799084799301663,0.5800239896379246,0.5801392218054163,0.5802541703484863,0.5803689541654867,0.5804836069308131,0.5805980378179145,0.5807120876173149,0.5808259036304402,0.5809395818594318,0.5810528668992104,0.5811659171579168,0.5812787437148504,0.5813913520034824,0.5815036508984202,0.5816156741255957,0.5817275862367938,0.5818391312840226,0.5819502524203968,0.5820610229874417,0.5821712950540838,0.5822813578560886,0.5823909328793635,0.582500168720746,0.5826090822191512,0.582734644598278,0.5828665718477064,0.5829991149492109,0.5831322514984612,0.5832658049626867,0.5834001799164147,0.5835132493550808,0.5836244021290968,0.583735464028024,0.5838464346134521,0.5839577280670659,0.5840689981577865,0.5841800229568184,0.5842908077337526,0.5844013638913292,0.5845116628567952,0.5846216469298603,0.584731390441669,0.5848408699521834,0.5849500114390817,0.5850586662908003,0.5851668570719644,0.5852746407219928,0.5853819255028583,0.5854887457616227,0.5855952320904994,0.585701201771462,0.5858068886679437,0.5859121671181552,0.5860170765447461,0.5861216627862349,0.5862257941431489,0.5863295164400538,0.5864328004908904,0.586535891739065,0.5866386358578655,0.5867410612519074,0.5868432307186088,0.5869450870920416,0.5870466242891614,0.5871478877687076,0.5872489059101074,0.5873495643869602,0.5874499943843969,0.5875500872709043,0.5876499456226171,0.5877494089567102,0.5878485112909222,0.587947201505668,0.5880456220911326,0.5881434069113777,0.5882406649918375,0.5883373041728522,0.5884329712885424,0.5885276999775465,0.588621455430455,0.5887137580858159,0.588804635537205,0.5888942706596851,0.5889827429953195,0.5890701089257633,0.5891563964986511,0.589241257298074,0.5893245701737025,0.5894067529542683,0.5894874669888729,0.5895670841726727,0.5896454951107087,0.5897229914642668,0.5897990809098074,0.5898740265971925,0.5899478909207023,0.590020765367305,0.5900926260494347,0.5901635931530806,0.5902337351295809,0.5903030115660722,0.5903714858187037,0.5904391569610195,0.5905059389652297,0.5905667295679923,0.5906245503857049,0.5906811641880676,0.5907366798106327,0.590791165656835,0.5908447994272976,0.5908975407496837,0.5909498263492236,0.5910014437646955,0.5910524336056573,0.5911026752930088,0.5911522833604904,0.5912013322707799,0.5912497755800512,0.5912935593270662,0.5913337593837399,0.5913719619970573,0.5914084021847669,0.5914432112484039,0.5914765664873158,0.5915085706644003,0.5915393782942939,0.5915690979330914,0.591597906960751,0.5916256958110764,0.5916526921174979,0.5916789196166834,0.5917045048870866,0.5917294768566618,0.5917536915076564,0.5917772239257667,0.5918001480979698,0.5918224410090456,0.5918493519547938,0.5918861405253829,0.591922408799523,0.5919582312616745,0.591993711265725,0.5920288310625759,0.5920635965552096,0.5920997197244684,0.5921363098040349,0.5921726253316905,0.5922086262725992,0.5922446117612576,0.5922803569146773,0.5923157822378252,0.5923489753397415,0.5923788188367338,0.5924084682840719,0.592437906787014,0.5924670529835169,0.5924960168099818,0.5925248323646033,0.592554165908699,0.59258785071001,0.5926212904901811,0.5926545599504376,0.5926876483380166,0.5927208645628573,0.5927541346870324,0.5927838877683949,0.5928132710326417,0.5928427593216605],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.45],\"title\":{\"text\":\"Epoch\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.625,1.0],\"title\":{\"text\":\"Estimate\"}},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.55,1.0],\"title\":{\"text\":\"Epoch\"}},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.625,1.0],\"title\":{\"text\":\"Variance\"}},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.0,0.45],\"title\":{\"text\":\"Epoch\"}},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,0.375],\"title\":{\"text\":\"MSE Loss\"}},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.55,1.0],\"title\":{\"text\":\"Epoch\"}},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.0,0.375],\"title\":{\"text\":\"MSE\"}},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Estimate over Epochs\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Variance over Epochs\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Shaping Train MSE Loss over Epochs\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Total MSE over Epochs\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Metrics over Epochs\"},\"showlegend\":true},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('90da71dd-3c8b-4ec6-92c3-f2c0b023c88d');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"ea17aa12-db7f-49d7-a4de-33266df739d1\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"ea17aa12-db7f-49d7-a4de-33266df739d1\")) {                    Plotly.newPlot(                        \"ea17aa12-db7f-49d7-a4de-33266df739d1\",                        [{\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"z\":[[0.05654081329703331,0.05842781066894531,0.053071409463882446,0.041838712990283966,0.03060600534081459,0.019373301416635513,0.008140608668327332,-0.002819698303937912,-0.010644126683473587,-0.018468577414751053],[0.05166570469737053,0.059375833719968796,0.0579986646771431,0.05018920078873634,0.03966769948601723,0.029146205633878708,0.01862473040819168,0.008103225380182266,-0.00241827592253685,-0.012939777225255966],[0.04802319034934044,0.04738873988389969,0.04752755165100098,0.04898928850889206,0.045093003660440445,0.036731407046318054,0.026209920644760132,0.015688423067331314,0.005166918039321899,-0.00535457581281662],[0.043550316244363785,0.03810964897274971,0.041840698570013046,0.03751617297530174,0.03897790610790253,0.037435587495565414,0.032187361270189285,0.023273635655641556,0.01275213435292244,0.0022306405007839203],[0.037654925137758255,0.03187841176986694,0.035396307706832886,0.03259497135877609,0.029246671125292778,0.028966501355171204,0.029778167605400085,0.02452992834150791,0.01928168162703514,0.009815838187932968],[0.03175953030586243,0.025647180154919624,0.0285665150731802,0.02984188310801983,0.023349255323410034,0.021004825830459595,0.020665399730205536,0.02041686698794365,0.016872495412826538,0.011624250560998917],[0.025797512382268906,0.019415944814682007,0.02233528345823288,0.025254620239138603,0.02059616521000862,0.01410352811217308,0.012762997299432755,0.012423574924468994,0.012084130197763443,0.009215079247951508],[0.019439466297626495,0.01318470761179924,0.016104046255350113,0.019023384898900986,0.019024092704057693,0.011350441724061966,0.0048606134951114655,0.004521165043115616,0.004181716591119766,0.0038422755897045135],[0.013523593544960022,0.006953474134206772,0.009872820228338242,0.012792155146598816,0.015711486339569092,0.00910865142941475,0.0021047182381153107,-0.0033812299370765686,-0.003720693290233612,-0.004060141742229462],[0.009305495768785477,0.0025999732315540314,0.0036415867507457733,0.006560910493135452,0.009480256587266922,0.009474571794271469,-0.0006483718752861023,-0.0071410126984119415,-0.011623088270425797,-0.01196252927184105]],\"type\":\"heatmap\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"Values\"},\"ticks\":\"outside\",\"tickvals\":[-0.018468577414751053,0.059375833719968796],\"ticktext\":[-0.018468577414751053,0.059375833719968796]}},\"xaxis\":{\"tickvals\":[0,1,2,3,4,5,6,7,8,9],\"ticktext\":[0,1,2,3,4,5,6,7,8,9],\"title\":{\"text\":\"X\"}},\"yaxis\":{\"tickvals\":[9,8,7,6,5,4,3,2,1,0],\"ticktext\":[9,8,7,6,5,4,3,2,1,0],\"title\":{\"text\":\"Y\"},\"autorange\":\"reversed\"},\"title\":{\"text\":\"Heatmap\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('ea17aa12-db7f-49d7-a4de-33266df739d1');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"5cd3e5ab-b6ea-4f18-ba82-c176551df4ef\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"5cd3e5ab-b6ea-4f18-ba82-c176551df4ef\")) {                    Plotly.newPlot(                        \"5cd3e5ab-b6ea-4f18-ba82-c176551df4ef\",                        [{\"colorbar\":{\"title\":{\"text\":\"Visits\"}},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"x\":[0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9],\"y\":[9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0],\"z\":[0,52,173,458,1126,1157,1211,1110,815,842,0,111,305,823,905,0,423,616,533,923,0,180,548,771,347,0,161,199,329,907,0,432,490,250,134,0,42,83,141,219,0,362,223,127,67,0,15,20,41,59,101,243,102,42,19,1,1,2,8,11,19,48,25,8,7,1,1,2,9,13,7,14,7,1,2,1,1,2,9,13,0,3,5,1,2,2,1,2,9,9,0,0,1,0,0,0,1,2,6,8],\"zmax\":1211,\"zmin\":0,\"type\":\"heatmap\"}],                        {\"title\":{\"text\":\"State Visitations Heatmap\"},\"xaxis\":{\"title\":{\"text\":\"X-axis\"}},\"yaxis\":{\"ticktext\":[9,8,7,6,5,4,3,2,1,0],\"tickvals\":[0,1,2,3,4,5,6,7,8,9],\"title\":{\"text\":\"Y-axis\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('5cd3e5ab-b6ea-4f18-ba82-c176551df4ef');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "600 trajectories:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"10a14bd6-f0aa-45ed-a77d-bbeecc077380\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"10a14bd6-f0aa-45ed-a77d-bbeecc077380\")) {                    Plotly.newPlot(                        \"10a14bd6-f0aa-45ed-a77d-bbeecc077380\",                        [{\"mode\":\"lines\",\"name\":\"IS Estimate\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195,0.03304338455200195],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"Train Estimate\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[-0.11290107667446136,0.17658573389053345,0.16436466574668884,0.1521286964416504,0.1403607875108719,0.12963342666625977,0.12288787961006165,0.11633214354515076,0.11027675867080688,0.10414523631334305,0.09774786233901978,0.09102900326251984,0.08550755679607391,0.08189908415079117,0.07838502526283264,0.07510267198085785,0.07188943773508072,0.06871502846479416,0.0654212236404419,0.0622125044465065,0.05879669263958931,0.05557895451784134,0.052824415266513824,0.04990191012620926,0.04712701216340065,0.043249696493148804,0.039198681712150574,0.03519723191857338,0.031517792493104935,0.028306076303124428,0.025195760652422905,0.022165685892105103,0.019096767529845238,0.016105663031339645,0.013276182115077972,0.010596323758363724,0.007973487488925457,0.005388747435063124,0.0028731331694871187,0.0003700880624819547,-0.0021696011535823345,-0.004355912562459707,-0.006495379842817783,-0.008592410013079643,-0.010521706193685532,-0.012287481687963009,-0.013992507942020893,-0.015477134846150875,-0.016811678186058998,-0.018059024587273598,-0.019214892759919167,-0.020207839086651802,-0.021099593490362167,-0.021907351911067963,-0.02270662970840931,-0.023550502955913544,-0.024382097646594048,-0.02514602616429329,-0.02582671120762825,-0.026513800024986267,-0.027231168001890182,-0.027880217880010605,-0.02844822034239769,-0.028924237936735153,-0.029302727431058884,-0.029586443677544594,-0.029783736914396286,-0.029868358746170998,-0.029870785772800446,-0.029789645224809647,-0.029618453234434128,-0.029359230771660805,-0.02902628481388092,-0.028623804450035095,-0.028153808787465096,-0.027626290917396545,-0.02704666182398796,-0.02640877105295658,-0.025716058909893036,-0.02497115544974804,-0.02418426424264908,-0.02337590418756008,-0.02249930426478386,-0.021546578034758568,-0.020558493211865425,-0.019592439755797386,-0.01858961209654808,-0.017622530460357666,-0.016639582812786102,-0.01562594063580036,-0.014583867974579334,-0.013555062934756279,-0.012516488321125507,-0.011474202387034893,-0.010429750196635723,-0.00937990378588438,-0.008322007954120636,-0.007264174520969391,-0.006207009311765432,-0.005151631776243448,-0.004108321387320757,-0.003070867620408535,-0.002040596678853035,-0.0010205383878201246,-9.63234924711287e-06,0.0009924410842359066,0.0019690918270498514,0.0029310635291039944,0.0038755489513278008,0.004789425525814295,0.005669423379004002,0.006548800505697727,0.007414103485643864,0.008270837366580963,0.009126337245106697,0.009964779019355774,0.010789507068693638,0.011600177735090256,0.012396866455674171,0.013169527985155582,0.013914825394749641,0.014639130793511868,0.015349673107266426,0.016048705205321312,0.01673601195216179,0.01741708628833294,0.018086513504385948,0.018738968297839165,0.01939614862203598,0.02004062570631504,0.020670922473073006,0.021305743604898453,0.021928688511252403,0.022540148347616196,0.023140402510762215,0.02372986264526844,0.024310177192091942,0.024852998554706573,0.025374989956617355,0.025887731462717056,0.026317449286580086,0.026696091517806053,0.02706846036016941,0.02743312157690525,0.027791332453489304,0.028142299503087997,0.028487421572208405,0.028836779296398163,0.02918151207268238,0.029519405215978622,0.029851354658603668,0.030172601342201233,0.03048018179833889,0.030786212533712387,0.031090548262000084,0.0313907191157341,0.03168674185872078,0.03197861090302467,0.03227109834551811,0.03254862502217293,0.0328138992190361,0.033078357577323914,0.03334907814860344,0.03361733257770538,0.03387998417019844,0.03413787856698036,0.03437770903110504,0.034612540155649185,0.03484434634447098,0.03507230430841446,0.03529878705739975,0.03550737351179123,0.03568525239825249,0.03586069121956825,0.03603460639715195,0.03621016815304756,0.03638347610831261,0.036544956266880035,0.03670354187488556,0.03685997799038887,0.03701436147093773,0.03717009723186493,0.037332646548748016,0.03749288246035576,0.03765270113945007,0.037811279296875,0.03796887770295143,0.03812279924750328,0.03827452287077904,0.03842199221253395,0.03856353834271431,0.03870384022593498,0.038845185190439224,0.038987286388874054,0.03912920877337456,0.03927118703722954,0.03941192477941513,0.03955146670341492,0.039689742028713226,0.03982838988304138,0.039968341588974,0.04010699689388275,0.04024425521492958,0.04037989675998688,0.04051049053668976,0.04063395783305168,0.040755949914455414,0.040874920785427094,0.04099230468273163,0.041108064353466034,0.04126306623220444,0.041465796530246735,0.041650280356407166,0.041810717433691025,0.04189341142773628,0.04199672117829323,0.042100608348846436,0.042205601930618286,0.04230814054608345,0.04241422563791275,0.04251658171415329,0.04261760413646698,0.042716529220342636,0.042813900858163834,0.042908016592264175,0.042998023331165314,0.04308677464723587,0.04317322373390198,0.04325750097632408,0.043337974697351456,0.04341806471347809,0.04349749907851219,0.043589089065790176,0.0437089167535305,0.04383054003119469,0.043950702995061874,0.04406759887933731,0.04418328404426575,0.0442977249622345,0.04441095516085625,0.044517189264297485,0.044600266963243484,0.04467815160751343,0.04475778341293335,0.044835176318883896,0.04490724578499794,0.044977813959121704,0.045094288885593414,0.04525146633386612,0.04540511965751648,0.04555831477046013,0.045711152255535126,0.04586343839764595,0.046015165746212006,0.04616666957736015,0.046317413449287415,0.04646769165992737,0.04662548750638962,0.046794772148132324,0.0469646155834198,0.04713403433561325,0.047302890568971634,0.04747118428349495,0.04763875901699066,0.047806017100811005,0.047971904277801514,0.048132408410310745,0.04828953370451927,0.048454444855451584,0.048618823289871216,0.048782967031002045,0.04894837364554405,0.04911339655518532,0.0492781400680542,0.04944368824362755,0.049611516296863556,0.04977915808558464,0.04994572326540947,0.05011219158768654,0.050278257578611374,0.05044354125857353,0.05060814693570137,0.05076998844742775,0.05092965066432953,0.05108855664730072,0.05124654620885849,0.05140365660190582,0.05155787989497185,0.05171683430671692,0.05187523365020752,0.05203003063797951,0.05218420922756195,0.05233690142631531,0.05248870700597763,0.05263950303196907,0.052795134484767914,0.05295489355921745,0.05311369150876999,0.05327073857188225,0.05342668294906616,0.053582243621349335,0.05371518433094025,0.05381903797388077,0.05391069874167442,0.05399660766124725,0.05408179759979248,0.05416649952530861,0.05425061658024788,0.05432969331741333,0.054397955536842346,0.05446554720401764,0.054532330483198166,0.054598383605480194,0.054667651653289795,0.054737742990255356,0.054807115346193314,0.054875507950782776,0.05494216829538345,0.05500798299908638,0.05507303401827812,0.055139921605587006,0.05520676448941231,0.05526962876319885,0.05532458424568176,0.05537768080830574,0.055432360619306564,0.05548672378063202,0.05553892254829407,0.05559009313583374,0.05564061179757118,0.055681224912405014,0.0557074174284935,0.05573455989360809,0.05576126649975777,0.055787645280361176,0.05581042543053627,0.05582260712981224,0.055832695215940475,0.05584288388490677,0.055853068828582764,0.05586326867341995,0.055873412638902664,0.055883366614580154,0.055897582322359085,0.055918071419000626,0.055938415229320526,0.055958494544029236,0.05597824603319168,0.05600357800722122,0.05602942034602165,0.05605534091591835,0.05608094483613968,0.056106097996234894,0.05613088980317116,0.056154683232307434,0.05617736652493477,0.05619730055332184,0.05621674656867981,0.056235674768686295,0.056254249066114426,0.05627235025167465,0.05629640445113182,0.056322552263736725,0.05634765699505806,0.05637094005942345,0.05640013888478279,0.0564296618103981,0.056458473205566406,0.05648642033338547,0.056512150913476944,0.05653693154454231,0.05656127259135246,0.056576360017061234,0.056590691208839417,0.05660465732216835,0.05661832168698311,0.056631267070770264,0.056643884629011154,0.056656211614608765,0.056668248027563095,0.05667969956994057,0.056690942496061325,0.056702665984630585,0.056714076548814774,0.05672651529312134,0.05673639476299286,0.056745946407318115,0.056754980236291885,0.056762974709272385,0.05676985904574394,0.05677635967731476,0.05678076669573784,0.05678517371416092,0.056789446622133255,0.05679348111152649,0.05679609254002571,0.056801654398441315,0.05680743232369423,0.05681300163269043,0.05681789666414261,0.05682260915637016,0.056826408952474594,0.056827545166015625,0.05682819336652756,0.05682923644781113,0.05684295669198036,0.056856751441955566,0.056872688233852386,0.056890662759542465,0.0569087415933609,0.05692695453763008,0.056925538927316666,0.056903570890426636,0.05689621716737747,0.05688953772187233,0.05688317120075226,0.05687706917524338,0.05687130242586136,0.05686570331454277,0.05686023086309433,0.0568549670279026,0.056849487125873566,0.05684364587068558,0.056830033659935,0.05680840462446213,0.05678728595376015,0.05676640570163727,0.05674585700035095,0.05672595649957657,0.056706227362155914,0.0566866509616375,0.05666780844330788,0.05665048956871033,0.05663313716650009,0.05661585181951523,0.0565987192094326,0.056581929326057434,0.05656411871314049,0.056546587496995926,0.056528881192207336,0.056511249393224716,0.05648809298872948,0.05645918473601341,0.05642891302704811,0.056398700922727585,0.05637239292263985,0.05634790658950806,0.05632352828979492,0.056299470365047455,0.05627638101577759,0.05625449866056442,0.056232910603284836,0.05621098726987839,0.056189123541116714,0.056167375296354294,0.05614569038152695,0.05612407252192497,0.05610159784555435,0.05607912689447403,0.056057002395391464,0.05603458732366562,0.056011609733104706,0.05598951503634453,0.055968206375837326,0.05594687536358833,0.055925775319337845,0.05591117590665817,0.05590108782052994,0.05588394030928612,0.05586223676800728,0.05584152787923813,0.05582011863589287,0.055797167122364044,0.05577448010444641,0.05575165897607803,0.055727604776620865,0.05570372939109802,0.05568001791834831,0.05565644055604935,0.05563301220536232,0.055609721690416336,0.055586524307727814,0.05556343495845795,0.05554058775305748,0.055518846958875656,0.05549870431423187,0.05547873675823212,0.05545822158455849,0.05543765425682068,0.05541783943772316,0.055398523807525635,0.055379949510097504,0.055361632257699966,0.05534357950091362,0.0553257130086422,0.05530808866024017,0.05529065057635307,0.05527333915233612,0.05525616556406021,0.05523913726210594],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"Test Estimate\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[-0.07985490560531616,-0.0892162024974823,-0.09766227006912231,-0.10591555386781693,-0.1141088604927063,-0.11541418731212616,-0.11281381547451019,-0.1102084368467331,-0.10731159895658493,-0.10441528260707855,-0.10161567479372025,-0.09985984861850739,-0.09818218648433685,-0.09641891717910767,-0.09474068880081177,-0.09317541867494583,-0.09170866757631302,-0.09029305726289749,-0.08891686797142029,-0.08762648701667786,-0.08634835481643677,-0.08512545377016068,-0.08390341699123383,-0.08227992802858353,-0.0807497575879097,-0.0792948380112648,-0.07792668789625168,-0.07664567232131958,-0.07551363855600357,-0.07451599836349487,-0.07359030842781067,-0.07273876667022705,-0.07194868475198746,-0.07121575623750687,-0.07053502649068832,-0.06990012526512146,-0.06930415332317352,-0.06874597817659378,-0.06822100281715393,-0.06772298365831375,-0.06722782552242279,-0.06658162921667099,-0.0659557580947876,-0.06534593552350998,-0.06474822014570236,-0.06415873765945435,-0.06357309222221375,-0.06298594921827316,-0.06239616125822067,-0.061800163239240646,-0.06118385121226311,-0.06062152609229088,-0.06013114005327225,-0.059622351080179214,-0.059100743383169174,-0.058552149683237076,-0.05797458440065384,-0.057366471737623215,-0.05672638118267059,-0.05605345591902733,-0.055346351116895676,-0.054605238139629364,-0.05386356636881828,-0.05310645326972008,-0.05231258645653725,-0.05148172006011009,-0.05061432346701622,-0.049710750579833984,-0.048771750181913376,-0.047798603773117065,-0.04679238423705101,-0.04575509950518608,-0.044688332825899124,-0.04359389841556549,-0.04247254505753517,-0.04132631793618202,-0.04015687108039856,-0.03896605968475342,-0.037755902856588364,-0.03652806580066681,-0.03528470918536186,-0.03402771055698395,-0.03275894373655319,-0.031480442732572556,-0.030194193124771118,-0.028901517391204834,-0.027604175731539726,-0.026303894817829132,-0.02500251680612564,-0.02370109222829342,-0.022401241585612297,-0.021104298532009125,-0.019811861217021942,-0.01852462813258171,-0.017244264483451843,-0.015971919521689415,-0.014708640985190868,-0.01346056628972292,-0.012223474681377411,-0.010997975245118141,-0.009787471033632755,-0.008593098260462284,-0.007413010578602552,-0.006248201709240675,-0.005097812041640282,-0.003962452989071608,-0.0028422812465578318,-0.0017376409377902746,-0.0006488725775852799,0.0004238220280967653,0.0014803778612986207,0.0025204746052622795,0.0035440383944660425,0.004550946410745382,0.00554114393889904,0.0065147727727890015,0.007471688091754913,0.008412188850343227,0.009336373768746853,0.010244193486869335,0.01113533042371273,0.012009927071630955,0.012743109837174416,0.013433681800961494,0.014109539799392223,0.01477090734988451,0.015417983755469322,0.016050951555371284,0.01667020656168461,0.017275772988796234,0.0178673192858696,0.018434301018714905,0.018988577648997307,0.019530685618519783,0.020060695707798004,0.020579105243086815,0.021086078137159348,0.021581783890724182,0.022066619247198105,0.022540628910064697,0.02300429902970791,0.02345822937786579,0.02390279248356819,0.024337925016880035,0.024763567373156548,0.025180121883749962,0.025587640702724457,0.02598647214472294,0.026377230882644653,0.026759933680295944,0.027134619653224945,0.027494177222251892,0.027831189334392548,0.028160259127616882,0.02848196029663086,0.028796685859560966,0.029103664681315422,0.02940276451408863,0.029694603756070137,0.029979418963193893,0.030257532373070717,0.030530933290719986,0.03080032579600811,0.031063184142112732,0.03132002428174019,0.03157052770256996,0.03181453421711922,0.03205353766679764,0.03228642791509628,0.032523199915885925,0.03275549039244652,0.03298500180244446,0.03321124613285065,0.03343243896961212,0.03364861011505127,0.03385988622903824,0.03406643494963646,0.034268345683813095,0.03446546196937561,0.034657903015613556,0.034845784306526184,0.035029057413339615,0.035208601504564285,0.03538460657000542,0.03555747866630554,0.035733092576265335,0.035907082259655,0.03607771545648575,0.036246296018362045,0.03641578555107117,0.036582961678504944,0.03674771264195442,0.0369100384414196,0.037069957703351974,0.03722713142633438,0.037381358444690704,0.03753272816538811,0.0376809760928154,0.037826377898454666,0.037968818098306656,0.03810824826359749,0.03824486583471298,0.038378819823265076,0.03851008787751198,0.03863881155848503,0.03876451775431633,0.03888774290680885,0.03900735825300217,0.03912418708205223,0.03923872858285904,0.039335306733846664,0.03942852467298508,0.039517417550086975,0.03960445895791054,0.03969041630625725,0.03977533429861069,0.03985900804400444,0.03994136303663254,0.04002195596694946,0.040100887417793274,0.04017866030335426,0.04024603217840195,0.040341466665267944,0.0404563769698143,0.04056929796934128,0.04068003222346306,0.04078860208392143,0.040894877165555954,0.0409989058971405,0.04110066592693329,0.04120022431015968,0.04129742830991745,0.04139242321252823,0.041601620614528656,0.04185236990451813,0.042111415416002274,0.042451683431863785,0.04278764873743057,0.04311934858560562,0.043446850031614304,0.043770670890808105,0.044017449021339417,0.043956149369478226,0.043895456939935684,0.04383503273129463,0.04377476125955582,0.04372531920671463,0.043690573424100876,0.04365958645939827,0.04362516477704048,0.04358982294797897,0.04355360195040703,0.04351653903722763,0.04347868636250496,0.04344022646546364,0.043401118367910385,0.04336145892739296,0.043321285396814346,0.04328123852610588,0.043240997940301895,0.043200597167015076,0.04316001012921333,0.04311923682689667,0.04307832196354866,0.04303722456097603,0.043034859001636505,0.04305131360888481,0.04306714981794357,0.04308236390352249,0.0430954284965992,0.04310470074415207,0.04311328008770943,0.0431213453412056,0.043129339814186096,0.04313671961426735,0.04314389079809189,0.043150775134563446,0.04315723106265068,0.04316328838467598,0.04316902905702591,0.04317427799105644,0.043179139494895935,0.043183647096157074,0.04318768158555031,0.043191343545913696,0.043194569647312164,0.043197449296712875,0.04319990798830986,0.04320289567112923,0.04320627078413963,0.04321013018488884,0.04321445897221565,0.04321897402405739,0.04322351515293121,0.0432281568646431,0.04323282092809677,0.0432373583316803,0.04324159398674965,0.04324573650956154,0.04324975982308388,0.04325343668460846,0.04325661435723305,0.043258894234895706,0.0432603545486927,0.04326099157333374,0.04326046630740166,0.043259069323539734,0.04325703904032707,0.043254319578409195,0.043250877410173416,0.04324657469987869,0.04324148967862129,0.0432356633245945,0.04322917014360428,0.04322202131152153,0.04321429505944252,0.04320427402853966,0.04319220781326294,0.04317941516637802,0.04316594824194908,0.04315178096294403,0.04313697665929794,0.04312148690223694,0.043105289340019226,0.043088532984256744,0.043070994317531586,0.04305276274681091,0.043033841997385025,0.0430142842233181,0.04299412667751312,0.04297341778874397,0.042952317744493484,0.042930833995342255,0.04290900006890297,0.042886778712272644,0.04286433383822441,0.042842037975788116,0.04281988367438316,0.042797863483428955,0.04277591407299042,0.04275405406951904,0.04273219779133797,0.04271040856838226,0.04268856346607208,0.04266679286956787,0.04264502227306366,0.042623307555913925,0.0426015630364418,0.04257984459400177,0.04255823791027069,0.04253682121634483,0.042517829686403275,0.042501650750637054,0.04248557612299919,0.04246950522065163,0.04245353117585182,0.04243753105401993,0.042421650141477585,0.04240580275654793,0.04239005222916603,0.04237429052591324,0.042358726263046265,0.0423431396484375,0.042327526956796646,0.04231196269392967,0.0422963984310627,0.04228094965219498,0.04226548597216606,0.04225005581974983,0.0422346331179142,0.04221944138407707,0.04220438748598099,0.04218952730298042,0.0421748124063015,0.042160212993621826,0.04214569181203842,0.042131274938583374,0.042116884142160416,0.04210246726870537,0.04208797216415405,0.042073436081409454,0.04205865040421486,0.04203835874795914,0.04201751947402954,0.04199615865945816,0.04197440668940544,0.041952263563871384,0.04192943871021271,0.04190593585371971,0.04188191518187523,0.04185732826590538,0.04183231666684151,0.041806917637586594,0.041781265288591385,0.04175524413585663,0.04172895848751068,0.04170241951942444,0.04167580604553223,0.04164914786815643,0.04162243381142616,0.04159567132592201,0.041568901389837265,0.041541796177625656,0.04151460528373718,0.04148747771978378,0.041460372507572174,0.041433386504650116,0.04140642285346985,0.041379448026418686,0.04135255888104439,0.04132567718625069,0.041298869997262955,0.04127601161599159,0.041254203766584396,0.041232701390981674,0.04121139645576477,0.0411902479827404,0.041169315576553345,0.04114848002791405,0.041127730160951614,0.04110701009631157,0.04108637198805809,0.041065722703933716,0.04104509949684143,0.04102444648742676,0.04100390523672104,0.04098351299762726,0.040963273495435715,0.04094312712550163,0.040923163294792175,0.040903300046920776,0.04088353365659714,0.040863923728466034,0.0408443808555603,0.04082493856549263,0.040805570781230927,0.04078631475567818,0.04076707735657692,0.040747854858636856,0.04072868824005127,0.040709588676691055,0.04069044813513756,0.04067208617925644,0.04065432399511337,0.040637142956256866,0.040620457381010056,0.040604233741760254,0.040588464587926865,0.04057302698493004,0.04055801406502724,0.0405433364212513,0.040529072284698486,0.040515147149562836,0.04050156846642494,0.04048822075128555,0.040475133806467056,0.04046226665377617,0.04044945165514946,0.040436699986457825,0.04042401909828186,0.0404113233089447,0.04039866477251053,0.04038598760962486,0.040373608469963074,0.04036152735352516,0.04034971445798874,0.04033805802464485,0.04032665491104126,0.04031546041369438,0.04030478373169899,0.04029466211795807,0.040284935384988785,0.04027564078569412,0.040266670286655426,0.040258027613162994,0.04024956002831459,0.0402413010597229,0.04023314639925957,0.040225181728601456,0.040217265486717224,0.04020944982767105,0.04020177200436592,0.040194109082221985,0.04018644243478775,0.04017902910709381,0.04017175734043121,0.040164701640605927,0.04015762358903885,0.04015059396624565,0.04014350473880768,0.04013202339410782,0.040120817720890045,0.04010987654328346,0.04009919986128807,0.04008874297142029,0.040078479796648026,0.040068406611680984,0.04005851224064827,0.040048714727163315,0.04003903269767761],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"On-policy Estimate\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529,0.8209130223363529],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"IS Variance\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885,0.000233165206736885],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"lines\",\"name\":\"Train Variance\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.06804997473955154,0.07789440453052521,0.0750570073723793,0.07224643230438232,0.06927661597728729,0.06633690744638443,0.06357066333293915,0.060967642813920975,0.058571696281433105,0.05621824041008949,0.053873199969530106,0.05164076387882233,0.04947716370224953,0.04735209047794342,0.04528940096497536,0.043348200619220734,0.04163555055856705,0.03999154642224312,0.038416583091020584,0.036916036158800125,0.0354897677898407,0.0341346375644207,0.032903868705034256,0.03171107918024063,0.030571026727557182,0.02952876314520836,0.0285273939371109,0.027574576437473297,0.02663601189851761,0.025778668001294136,0.02495788037776947,0.02418403886258602,0.023456204682588577,0.022770261391997337,0.022121664136648178,0.021504532545804977,0.020924435928463936,0.02037965878844261,0.019867166876792908,0.019382890313863754,0.0189194418489933,0.018467292189598083,0.018043071031570435,0.01764710433781147,0.017249051481485367,0.016847753897309303,0.016472822055220604,0.01611574925482273,0.01578010432422161,0.015464277938008308,0.015172244049608707,0.014914222992956638,0.014671324752271175,0.014441855251789093,0.014228268526494503,0.014020726084709167,0.013814262114465237,0.013613609597086906,0.01342236902564764,0.013231762684881687,0.013049126602709293,0.012873725965619087,0.012704214081168175,0.012540535070002079,0.012382249347865582,0.012228578329086304,0.012079253792762756,0.011934529058635235,0.011793826706707478,0.01165609247982502,0.011521639302372932,0.011390523985028267,0.011261641047894955,0.011134863831102848,0.011009973473846912,0.010887213982641697,0.01076631247997284,0.010646972805261612,0.01052912324666977,0.010412665084004402,0.010297548957169056,0.010183734819293022,0.010071969591081142,0.009962484240531921,0.009854503907263279,0.009748762473464012,0.009645504876971245,0.009549287147819996,0.009454913437366486,0.009362149983644485,0.009270991198718548,0.00918138399720192,0.009093206375837326,0.009006011299788952,0.00892018061131239,0.008835665881633759,0.008752275258302689,0.008670812472701073,0.008590636774897575,0.00851170439273119,0.00843406468629837,0.008357681334018707,0.008282491937279701,0.0082084396854043,0.008135528303682804,0.008063781075179577,0.007988635450601578,0.007912558503448963,0.00783738773316145,0.007763142231851816,0.007689354475587606,0.007616684306412935,0.007544991094619036,0.0074743046425282955,0.007404644507914782,0.007335943169891834,0.007268162444233894,0.007201295346021652,0.007135233376175165,0.007069915067404509,0.007006017491221428,0.006943337619304657,0.006881520617753267,0.006820546928793192,0.006760406773537397,0.006701005157083273,0.006642389576882124,0.006584705784916878,0.006528342608362436,0.0064727445133030415,0.00641782907769084,0.00636307941749692,0.006309101823717356,0.006255862768739462,0.006203353404998779,0.006151560693979263,0.006100469268858433,0.006050190422683954,0.0060006421990692616,0.0059517668560147285,0.005904753692448139,0.00585900479927659,0.005813799798488617,0.005769137293100357,0.005725025665014982,0.005681452341377735,0.005638412199914455,0.005596220958977938,0.005554573144763708,0.005513431970030069,0.005472797900438309,0.005432761739939451,0.005393375642597675,0.005354426335543394,0.005315958522260189,0.005277973134070635,0.005240468308329582,0.005203444045037031,0.005166927818208933,0.005130634643137455,0.005094909109175205,0.0050595467910170555,0.0050244941376149654,0.004989859648048878,0.004955391399562359,0.004921272862702608,0.004887174349278212,0.004853480029851198,0.004820215981453657,0.004787402227520943,0.00475501362234354,0.004721901845186949,0.004687381908297539,0.004653321113437414,0.004619697108864784,0.004586363211274147,0.004553473088890314,0.004520813003182411,0.004488580394536257,0.004456772468984127,0.00442538782954216,0.00439442228525877,0.0043638660572469234,0.004333727993071079,0.004303973168134689,0.004274602979421616,0.004245585296303034,0.0042169359512627125,0.004188556224107742,0.004159870557487011,0.00413099117577076,0.004102495964616537,0.0040743607096374035,0.004046581219881773,0.0040191649459302425,0.003992109559476376,0.003965415060520172,0.0039390758611261845,0.003913085907697678,0.0038874843157827854,0.0038623064756393433,0.003837462980300188,0.0038129419554024935,0.003788744332268834,0.0037649222649633884,0.0037416010163724422,0.003718571737408638,0.0036958050914108753,0.003673355095088482,0.0036512049846351147,0.003629296086728573,0.0036075867246836424,0.003586250590160489,0.003564485814422369,0.0035401727072894573,0.003516658442094922,0.0034935022704303265,0.003470701863989234,0.0034480898175388575,0.0034256973303854465,0.0034035874996334314,0.0033817696385085583,0.003360243048518896,0.003338984912261367,0.0033179689198732376,0.0032971857581287622,0.0032766838558018208,0.003256509779021144,0.0032366549130529165,0.003217054530978203,0.0031977177131921053,0.0031786425970494747,0.00315987435169518,0.003141292603686452,0.003122854745015502,0.0031046648509800434,0.003086608601734042,0.003068760270252824,0.0030511568766087294,0.0030337919015437365,0.003016555914655328,0.0029991408810019493,0.002981995465233922,0.002965001156553626,0.0029482950922101736,0.002931822557002306,0.002915505087003112,0.002900731284171343,0.0028873183764517307,0.002874170895665884,0.0028611619491130114,0.0028482903726398945,0.0028355526737868786,0.002822949318215251,0.002810470759868622,0.002798123052343726,0.0027859010733664036,0.002773758489638567,0.0027616051957011223,0.0027495399117469788,0.0027375989593565464,0.002725782571360469,0.0027140958700329065,0.0027025400195270777,0.0026911101303994656,0.0026797924656420946,0.0026684878394007683,0.0026571748312562704,0.002646142616868019,0.002635217271745205,0.002624410204589367,0.0026137344539165497,0.0026031751185655594,0.002592731500044465,0.0025823796167969704,0.0025721534620970488,0.002562035107985139,0.0025520017370581627,0.0025420880410820246,0.002532285638153553,0.002522591734305024,0.0025130065623670816,0.0025034798309206963,0.002494026441127062,0.002484677592292428,0.0024754328187555075,0.0024662918876856565,0.0024573146365582943,0.0024486789479851723,0.0024401408154517412,0.0024316904600709677,0.002423252910375595,0.0024148200172930956,0.0024064816534519196,0.002398249227553606,0.0023902084212750196,0.002382311038672924,0.0023744695354253054,0.0023666974157094955,0.002359012607485056,0.002351408125832677,0.0023432532325387,0.0023343393113464117,0.002324918983504176,0.0023152902722358704,0.0023056978825479746,0.0022961450740695,0.0022866339422762394,0.0022772469092160463,0.0022680938709527254,0.002258987631648779,0.0022499309852719307,0.0022409269586205482,0.0022320179268717766,0.0022231810726225376,0.002214401727542281,0.0022056784946471453,0.0021970593370497227,0.002188505604863167,0.0021799977403134108,0.0021715215407311916,0.002163100056350231,0.0021546806674450636,0.0021461157593876123,0.002137561794370413,0.002129065804183483,0.002120629185810685,0.002112237038090825,0.0021038942504674196,0.0020955977961421013,0.0020874610636383295,0.0020796540193259716,0.00207193149253726,0.0020642525050789118,0.0020566200837492943,0.0020490246824920177,0.00204123230651021,0.0020334310829639435,0.0020256766583770514,0.002017969498410821,0.0020103103015571833,0.0020027004648,0.0019951388239860535,0.0019875913858413696,0.001980048371478915,0.001972557045519352,0.001965113915503025,0.0019577147904783487,0.001950364443473518,0.0019430620595812798,0.0019358090357854962,0.0019286081660538912,0.001921457820571959,0.0019143597455695271,0.001907315687276423,0.0019002995686605573,0.0018932612147182226,0.001886268611997366,0.0018793231574818492,0.0018724262481555343,0.0018655756721273065,0.0018587572267279029,0.0018519817385822535,0.0018452453659847379,0.0018385550938546658,0.001832102658227086,0.0018256916664540768,0.0018193190917372704,0.0018129884265363216,0.0018067191122099757,0.0018004955491051078,0.0017943173879757524,0.0017879885854199529,0.0017816991312429309,0.0017754565924406052,0.001769260736182332,0.0017631712835282087,0.0017571334028616548,0.0017511401092633605,0.0017451898893341422,0.0017392919398844242,0.0017334336880594492,0.0017274938290938735,0.0017215694533661008,0.001715630292892456,0.0017096293158829212,0.0017036518547683954,0.001697697676718235,0.0016917450120672584,0.0016857252921909094,0.0016797099960967898,0.001673651859164238,0.0016676237573847175,0.0016616258071735501,0.0016556581249460578,0.0016497330507263541,0.001643878291361034,0.0016380551969632506,0.0016322642331942916,0.001626497250981629,0.0016207632143050432,0.0016150479204952717,0.0016093034064397216,0.0016035960288718343,0.0015979273011907935,0.0015921650920063257,0.0015864414162933826,0.001580799464136362,0.001575219095684588,0.0015696760965511203,0.0015641794307157397,0.001558469026349485,0.0015524756163358688,0.0015466294717043638,0.0015408284962177277,0.001535070245154202,0.0015293541364371777,0.001523680635727942,0.0015180471818894148,0.0015124541241675615,0.001506899599917233,0.0015013840747997165,0.001495902892202139,0.0014904618728905916,0.0014850976876914501,0.0014797794865444303,0.0014745029620826244,0.001469265203922987,0.0014640684239566326,0.0014589106431230903,0.0014537923270836473,0.0014487089356407523,0.0014436570927500725,0.0014386430848389864,0.001433666329830885,0.0014287253143265843,0.0014238186413422227,0.001418957021087408,0.001414129394106567,0.0014093304052948952,0.001404565991833806,0.0013998006470501423,0.0013950369320809841,0.0013902720529586077,0.0013855431461706758,0.0013809290248900652,0.0013763904571533203,0.001371883787214756,0.0013674127403646708,0.0013629751047119498,0.0013585713459178805,0.0013542014639824629,0.0013498462503775954,0.0013455204898491502,0.0013412273256108165,0.001336966292001307,0.001332736574113369,0.0013285231543704867,0.0013243386056274176,0.0013201759429648519,0.001316036214120686,0.0013119104551151395,0.0013077552430331707,0.001303612720221281,0.0012995072174817324,0.0012954316334798932,0.001291530905291438,0.0012877604458481073,0.0012840400449931622,0.0012803712161257863,0.001276742434129119,0.0012731439201161265,0.0012695769546553493,0.001266037579625845,0.0012625266099348664,0.0012590447440743446,0.001255588373169303,0.0012521576136350632,0.0012487511849030852,0.0012453697854653,0.0012420121347531676,0.0012386783491820097,0.0012353680795058608,0.0012320657260715961,0.0012287795543670654,0.0012255512410774827,0.001222346443682909,0.001219152589328587,0.0012158688623458147,0.001212294795550406,0.00120874447748065,0.0012052125530317426,0.0012017077533528209,0.0011982296127825975,0.0011947781313210726,0.001191353308968246,0.0011879552621394396,0.001184582943096757,0.0011812355369329453,0.0011779131600633264],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"lines\",\"name\":\"Test Variance\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.12879881262779236,0.1253916323184967,0.12152504920959473,0.11768554896116257,0.11384213715791702,0.11035525053739548,0.10688923299312592,0.10349705815315247,0.09997998923063278,0.09644198417663574,0.09302462637424469,0.08942289650440216,0.08542700111865997,0.0815381333231926,0.07781074941158295,0.07424129545688629,0.07082771509885788,0.06755512952804565,0.06440380215644836,0.06139678508043289,0.05852967128157616,0.05579729750752449,0.05315056070685387,0.05037837475538254,0.047748345881700516,0.045255742967128754,0.04289298132061958,0.04065399244427681,0.038533564656972885,0.0365259051322937,0.03462528809905052,0.03282628580927849,0.03112371452152729,0.029512720182538033,0.027988560497760773,0.02654602751135826,0.025180090218782425,0.023888057097792625,0.02266605570912361,0.021510396152734756,0.020411642268300056,0.019328072667121887,0.01830415055155754,0.017336664721369743,0.016422679647803307,0.015559321269392967,0.014743720181286335,0.013973196968436241,0.01324539165943861,0.012558011338114738,0.011906139552593231,0.011284857988357544,0.010697228834033012,0.010142608545720577,0.00961911678314209,0.009124868549406528,0.008658190257847309,0.008217521011829376,0.0078013865277171135,0.007408440578728914,0.007037260569632053,0.006686673499643803,0.006360399536788464,0.00605487497523427,0.005765896290540695,0.005492483731359243,0.0052337562665343285,0.00498884217813611,0.0047569372691214085,0.004537345841526985,0.004329340066760778,0.004132323898375034,0.003945653326809406,0.003768742084503174,0.003600991563871503,0.0034418923314660788,0.0032909326255321503,0.003147637005895376,0.0030115805566310883,0.002882330911234021,0.0027595062274485826,0.0026427372358739376,0.002531656762585044,0.0024259500205516815,0.0023253171239048243,0.0022294605150818825,0.0021381087135523558,0.0020510125905275345,0.0019679327961057425,0.0018886446487158537,0.0018129362724721432,0.001740604522638023,0.001671478385105729,0.001605351222679019,0.0015420737909153104,0.0014815020840615034,0.0014234896516427398,0.001367904362268746,0.0013146382989361882,0.001263576908968389,0.00121458456851542,0.0011675470741465688,0.0011224179761484265,0.0010791064705699682,0.0010375287383794785,0.0009976144647225738,0.0009592860005795956,0.0009224778623320162,0.0008871285826899111,0.000853183853905648,0.000820591754745692,0.0007893015281297266,0.0007592705078423023,0.0007304541068151593,0.0007028091931715608,0.0006762922857888043,0.000650869042146951,0.0006264930707402527,0.000603139924351126,0.0005807738634757698,0.0005593710811808705,0.0005389007856138051,0.0005232752300798893,0.0005091055063530803,0.0004954769392497838,0.0004823676426894963,0.00046976152225397527,0.0004576436767820269,0.0004459942865651101,0.0004348022339399904,0.0004240458074491471,0.00041363603668287396,0.0004036382888443768,0.000394038506783545,0.00038482656236737967,0.0003759838582482189,0.0003675032057799399,0.00035936737549491227,0.0003515658318065107,0.00034409158979542553,0.0003369262267369777,0.00033005455043166876,0.00032346451189368963,0.000317149591865018,0.0003111042024102062,0.00030531606171280146,0.0002997773699462414,0.0002944780280813575,0.0002894091885536909,0.00028456258587539196,0.0002799296926241368,0.0002753982844296843,0.0002712144050747156,0.00026721623726189137,0.0002633926342241466,0.0002597360289655626,0.00025625553098507226,0.0002529427583795041,0.0002497826935723424,0.00024676742032170296,0.00024388809106312692,0.0002411168097751215,0.0002384408435318619,0.0002358847123105079,0.0002334422606509179,0.00023111089831218123,0.0002288881514687091,0.00022676671505905688,0.0002247418451588601,0.00022275901574175805,0.00022086135868448764,0.00021906629262957722,0.00021736303460784256,0.00021573789126705378,0.00021418694814201444,0.00021270685829222202,0.0002112936053890735,0.0002099439298035577,0.00020865393162239343,0.00020742071501445025,0.0002062411658698693,0.00020511298498604447,0.00020403489179443568,0.0002030040486715734,0.00020201707957312465,0.00020103054703213274,0.00020007710554637015,0.00019916538440156728,0.00019828887889161706,0.00019743191660381854,0.0001966130075743422,0.00019582992536015809,0.00019508079276420176,0.00019436348520684987,0.00019367667846381664,0.0001930186990648508,0.0001923877134686336,0.00019178212096448988,0.00019120030628982931,0.0001906408288050443,0.00019010205869562924,0.00018958293367177248,0.00018908207130152732,0.00018859839474316686,0.00018813095812220126,0.00018767821893561631,0.00018723959510680288,0.0001868095714598894,0.00018639038898982108,0.00018598335736896843,0.00018555845599621534,0.00018514248949941248,0.00018472604278940707,0.00018431931675877422,0.0001839248725445941,0.0001835418224800378,0.00018316916248295456,0.00018280657241120934,0.00018245370301883668,0.00018210882262792438,0.00018177303718402982,0.000181384282768704,0.00018108193762600422,0.00018089287914335728,0.00018074372201226652,0.00018063218158204108,0.00018055648251902312,0.00018051474762614816,0.000180505434400402,0.00018052657833322883,0.00018057732086163014,0.00018065549375023693,0.0001807603402994573,0.00018163050117436796,0.00018292658205609769,0.00018437161634210497,0.0001859660551417619,0.00018769594316836447,0.00018955499399453402,0.00019153802713844925,0.000193645159015432,0.00019509167759679258,0.0001933448511408642,0.00019163406977895647,0.00018995653954334557,0.00018831172201316804,0.00018681709480006248,0.00018549349624663591,0.0001841933117248118,0.00018288659339305013,0.00018159704632125795,0.00018032458319794387,0.0001790699316188693,0.00017783354269340634,0.00017661653691902757,0.00017541853594593704,0.00017424042744096369,0.0001730822114041075,0.00017194503743667156,0.00017082727572415024,0.00016972896992228925,0.0001686502218944952,0.0001675912062637508,0.00016655238869134337,0.0001655330997891724,0.00016474885342177004,0.00016407985822297633,0.0001634166983421892,0.00016275941743515432,0.00016210450849030167,0.0001614481589058414,0.00016079719353001565,0.0001601521362317726,0.0001595134672243148,0.00015888088091742247,0.00015825529408175498,0.0001576368376845494,0.0001570249442011118,0.00015641970094293356,0.00015582131163682789,0.00015522936882916838,0.00015464411990251392,0.00015406591410283,0.00015349402383435518,0.00015292879834305495,0.00015237000479828566,0.00015181787603069097,0.00015127226652111858,0.00015073509712237865,0.00015020603314042091,0.00014968536561354995,0.00014917396765667945,0.00014867042773403227,0.00014817409100942314,0.00014768495748285204,0.00014720301260240376,0.00014672765973955393,0.00014625843323301524,0.0001457955950172618,0.00014533927605953068,0.00014488876331597567,0.00014444331463892013,0.00014400131476577371,0.00014356327301356941,0.000143129174830392,0.0001426982635166496,0.0001422712521161884,0.00014184870815370232,0.00014143054431769997,0.00014101668784860522,0.00014060699322726578,0.00014020162052474916,0.00013980065705254674,0.00013940443750470877,0.00013901313650421798,0.00013862688501831144,0.00013825642236042768,0.00013790147204417735,0.0001375509746139869,0.00013720488641411066,0.00013686316378880292,0.00013652631605509669,0.00013619425590150058,0.00013586679415311664,0.0001355441054329276,0.00013522598601412028,0.0001349123485852033,0.00013460309128277004,0.00013429833052214235,0.00013399802264757454,0.00013370219676289707,0.0001334110856987536,0.00013312502414919436,0.00013284386659506708,0.00013256756938062608,0.00013229591422714293,0.0001320294541073963,0.00013176805805414915,0.00013151171151548624,0.00013126023986842483,0.00013101358490530401,0.00013077168841846287,0.00013053437578491867,0.00013030153058934957,0.00013007334200665355,0.00012984959175810218,0.00012963022163603455,0.00012941534805577248,0.00012920486915390939,0.00012899882858619094,0.000128797153593041,0.00012859932030551136,0.0001284045574720949,0.000128213272546418,0.00012802524724975228,0.00012784043792635202,0.0001276587281608954,0.0001274801470572129,0.0001273044035769999,0.00012713149772025645,0.00012696140038315207,0.00012679395149461925,0.00012662909284699708,0.0001264667371287942,0.00012630685523618013,0.0001261495053768158,0.00012599467299878597,0.00012584179057739675,0.00012569081445690244,0.00012554231216199696,0.0001253962836926803,0.00012525267084129155,0.0001251113717444241,0.00012497222633101046,0.00012483519094530493,0.00012470013462007046,0.00012456705735530704,0.00012443587183952332,0.00012430672359187156,0.0001241794670931995,0.00012405402958393097,0.00012393064389470965,0.00012381772103253752,0.00012370737385936081,0.00012359966058284044,0.0001234942756127566,0.0001233914226759225,0.00012329134915489703,0.00012319415691308677,0.00012309967132750899,0.00012300786329433322,0.0001229185436386615,0.00012283171236049384,0.00012274707842152566,0.00012266484554857016,0.0001225848391186446,0.00012250705913174897,0.0001224315637955442,0.00012235816393513232,0.00012228699051775038,0.00012221788347233087,0.0001221507554873824,0.00012208553380332887,0.00012202259676996619,0.00012196197349112481,0.00012190351117169484,0.00012184701336082071,0.0001217926328536123,0.00012174019502708688,0.00012168933608336374,0.00012164025974925607,0.00012159305333625525,0.00012153956777183339,0.00012148537643952295,0.00012143201456638053,0.0001213794166687876,0.000121327604574617,0.00012127678201068193,0.0001212268034578301,0.00012117778533138335,0.00012112958211218938,0.00012108213559258729,0.00012103554036002606,0.00012098978913854808,0.00012094456178601831,0.00012090001109754667,0.00012085620983270928,0.00012081304157618433,0.00012077076826244593,0.00012072880053892732,0.00012068740034010261,0.00012064639304298908,0.00012060558219673112,0.00012056493869749829,0.00012052451347699389,0.00012048415374010801,0.00012044380127917975,0.00012040373985655606,0.00012036361295031384,0.00012032350059598684,0.00012028338824165985,0.0001202436033054255,0.00012020417489111423,0.00012016555410809815,0.00012012738443445414,0.00012008978228550404,0.00012005245662294328,0.00012001562572550029,0.0001199793623527512,0.0001199430989800021,0.00011990717030130327,0.00011987139441771433,0.00011983559670625255,0.00011979977716691792,0.00011976388486800715,0.00011972786160185933,0.00011969165643677115,0.00011965583689743653,0.00011962021380895749,0.00011958464892813936,0.00011954938236158341,0.00011951426131417975,0.00011947920575039461,0.00011944451398449019,0.00011941006960114464,0.0001193756761495024,0.0001193415155285038,0.00011930716573260725,0.00011927275772904977,0.0001192386043840088,0.00011920461838599294,0.00011917068331968039,0.00011913670459762216,0.00011910261673619971,0.00011906831787200645,0.00011903404811164364,0.00011899968376383185,0.00011896529758814722,0.0001189304530271329,0.00011889568122569472,0.00011886057473020628,0.00011882482067449018,0.0001187888701679185,0.00011875261407112703,0.00011871598690049723,0.00011867943976540118,0.00011864237603731453,0.00011860601807711646,0.00011856968922074884,0.00011853248724946752,0.00011847973655676469,0.0001184273132821545,0.00011837523925350979,0.00011832320888061076,0.00011827123671537265,0.00011821928637800738,0.00011816727055702358,0.00011811510194092989,0.00011806285328930244,0.00011801052460214123],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"lines\",\"name\":\"Train MSE Loss\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[21.629838943481445,20.56914520263672,19.509557723999023,18.49232292175293,17.515745162963867,16.58300018310547,15.699235916137695,14.855639457702637,14.0519380569458,13.28598403930664,12.555097579956055,11.857328414916992,11.19363784790039,10.563984870910645,9.966349601745605,9.401222229003906,8.864977836608887,8.356103897094727,7.873030662536621,7.416566848754883,6.985763072967529,6.5806708335876465,6.1987128257751465,5.83865213394165,5.499581813812256,5.180490970611572,4.880232334136963,4.598487377166748,4.335167407989502,4.088137626647949,3.856560707092285,3.63936185836792,3.4360220432281494,3.2459001541137695,3.068232536315918,2.9023597240448,2.7475874423980713,2.6032824516296387,2.468979835510254,2.344080924987793,2.2279720306396484,2.1198177337646484,2.0194568634033203,1.9265316724777222,1.8405417203903198,1.7610429525375366,1.687576413154602,1.6197943687438965,1.557315707206726,1.4998096227645874,1.4468936920166016,1.398267388343811,1.3536053895950317,1.3125447034835815,1.2747794389724731,1.2400364875793457,1.20810866355896,1.1787586212158203,1.151753306388855,1.1268705129623413,1.1039048433303833,1.082703709602356,1.0630873441696167,1.0449055433273315,1.0279793739318848,1.0121928453445435,0.9973951578140259,0.9835002422332764,0.9703999757766724,0.958001971244812,0.9462464451789856,0.9350684881210327,0.9243720769882202,0.9140867590904236,0.9041532874107361,0.8945410251617432,0.8852099776268005,0.8761269450187683,0.8672638535499573,0.8585994243621826,0.8501097559928894,0.841769814491272,0.8335698246955872,0.8255074620246887,0.817570686340332,0.8097419142723083,0.8020197749137878,0.7943964600563049,0.7868695855140686,0.77944016456604,0.7721081972122192,0.7648659348487854,0.757712721824646,0.7506440281867981,0.7436696290969849,0.7367848753929138,0.7299913167953491,0.7232842445373535,0.716670572757721,0.7101510167121887,0.7037254571914673,0.697391927242279,0.691148042678833,0.6849916577339172,0.6789230108261108,0.6729437708854675,0.6670493483543396,0.6612426042556763,0.655521810054779,0.6498845815658569,0.6443295478820801,0.6388581991195679,0.6334694623947144,0.6281612515449524,0.6229320168495178,0.6177762150764465,0.6126939058303833,0.6076859831809998,0.6027535200119019,0.5978960394859314,0.5931128859519958,0.5883994102478027,0.5837545394897461,0.5791751742362976,0.5746620297431946,0.5702142715454102,0.5658307075500488,0.5615085363388062,0.5572474598884583,0.5530478358268738,0.5489068627357483,0.5448261499404907,0.5408024191856384,0.5368331670761108,0.5329174995422363,0.5290541648864746,0.5252418518066406,0.5214779376983643,0.5177614688873291,0.5140931606292725,0.510448157787323,0.5068336725234985,0.5032642483711243,0.4997369945049286,0.49625176191329956,0.4928070604801178,0.4894021451473236,0.4860345125198364,0.48269781470298767,0.47939902544021606,0.476138174533844,0.47291597723960876,0.46973347663879395,0.4665876626968384,0.4634808897972107,0.46041107177734375,0.45737677812576294,0.4543749988079071,0.45140448212623596,0.44846755266189575,0.44556015729904175,0.4426877200603485,0.43984872102737427,0.4370427131652832,0.4342713952064514,0.4315336048603058,0.42882996797561646,0.4261566698551178,0.4235110878944397,0.4208948016166687,0.41830646991729736,0.4157446622848511,0.4132083058357239,0.41069886088371277,0.40821537375450134,0.4057575762271881,0.4033253490924835,0.4009162187576294,0.3985326588153839,0.39617428183555603,0.39384031295776367,0.3915271461009979,0.3892291188240051,0.38695117831230164,0.3846917748451233,0.3824542164802551,0.3802366852760315,0.3780358135700226,0.3758552670478821,0.3736937642097473,0.37154898047447205,0.36942434310913086,0.3673194944858551,0.36523565649986267,0.36317265033721924,0.3611302673816681,0.35910898447036743,0.3571074604988098,0.35512539744377136,0.3531608283519745,0.35121554136276245,0.3492876887321472,0.34737589955329895,0.3454812169075012,0.3436068892478943,0.3417520523071289,0.3399146497249603,0.33809319138526917,0.33628785610198975,0.3344998061656952,0.33273398876190186,0.3309827148914337,0.3292446434497833,0.32752105593681335,0.32581138610839844,0.32411521673202515,0.32243430614471436,0.32076895236968994,0.3191182315349579,0.3174818754196167,0.31586042046546936,0.31425368785858154,0.31266069412231445,0.3110819458961487,0.3095173239707947,0.3079661726951599,0.3064288794994354,0.30490562319755554,0.30339595675468445,0.30189913511276245,0.3004152178764343,0.2989450693130493,0.29748672246932983,0.29603904485702515,0.2946038246154785,0.29318004846572876,0.2917671501636505,0.29036659002304077,0.28897807002067566,0.28760024905204773,0.28623226284980774,0.28487294912338257,0.2835253179073334,0.28218066692352295,0.2808447778224945,0.27951711416244507,0.27819496393203735,0.276875764131546,0.2755616009235382,0.2742564380168915,0.2729606330394745,0.2716735303401947,0.27039530873298645,0.2691265344619751,0.26786744594573975,0.26661765575408936,0.26537758111953735,0.26414430141448975,0.2629144489765167,0.26169297099113464,0.260481059551239,0.259278267621994,0.2580850422382355,0.25690126419067383,0.25572627782821655,0.25455889105796814,0.2533913254737854,0.2522317171096802,0.2510814368724823,0.24993951618671417,0.2488051801919937,0.24767525494098663,0.2465532124042511,0.2454383373260498,0.24432975053787231,0.24322247505187988,0.24212321639060974,0.24103069305419922,0.23994487524032593,0.23886710405349731,0.23779763281345367,0.23673613369464874,0.23568232357501984,0.2346360981464386,0.23359769582748413,0.2325672209262848,0.231544628739357,0.23052701354026794,0.22951100766658783,0.22850236296653748,0.22750025987625122,0.22650612890720367,0.2255205363035202,0.2245425134897232,0.22357164323329926,0.22260943055152893,0.22165483236312866,0.2207067310810089,0.21976622939109802,0.21883130073547363,0.21789655089378357,0.21695968508720398,0.21602024137973785,0.21508358418941498,0.21415087580680847,0.21322280168533325,0.2122991979122162,0.2113802582025528,0.21046584844589233,0.20955784618854523,0.20865605771541595,0.20776015520095825,0.20687037706375122,0.20598697662353516,0.20510999858379364,0.2042364925146103,0.20336733758449554,0.2025037705898285,0.20164267718791962,0.20078644156455994,0.19993670284748077,0.19908931851387024,0.1982458531856537,0.19740772247314453,0.19657543301582336,0.19574786722660065,0.1949242651462555,0.1941061019897461,0.1932927519083023,0.19248318672180176,0.19167795777320862,0.19087734818458557,0.1900804340839386,0.1892884522676468,0.18849679827690125,0.18770499527454376,0.18691690266132355,0.1861329823732376,0.18535354733467102,0.1845787912607193,0.18380886316299438,0.18304334580898285,0.18228255212306976,0.1815265268087387,0.18077515065670013,0.18002881109714508,0.17928725481033325,0.17855070531368256,0.17781780660152435,0.17709136009216309,0.17636935412883759,0.17565223574638367,0.1749400943517685,0.17423264682292938,0.17352968454360962,0.17283101379871368,0.17213697731494904,0.1714479625225067,0.17076453566551208,0.1700860559940338,0.16941259801387787,0.16874413192272186,0.1680804193019867,0.16742080450057983,0.16676512360572815,0.1661134511232376,0.16546592116355896,0.1648228019475937,0.16418392956256866,0.1635502278804779,0.1629212647676468,0.16229678690433502,0.16167742013931274,0.16106253862380981,0.16045208275318146,0.15984602272510529,0.15924400091171265,0.15864568948745728,0.1580517292022705,0.15746194124221802,0.15687638521194458,0.15629439055919647,0.15570880472660065,0.15512648224830627,0.15454770624637604,0.15397273004055023,0.15340007841587067,0.15283066034317017,0.15226472914218903,0.1517018973827362,0.1511421650648117,0.1505846381187439,0.1500304490327835,0.1494797319173813,0.14893250167369843,0.14838877320289612,0.14784766733646393,0.14730961620807648,0.1467750072479248,0.14624391496181488,0.14571651816368103,0.14519235491752625,0.14467237889766693,0.14415545761585236,0.14364135265350342,0.14313070476055145,0.1426234394311905,0.14211955666542053,0.14161904156208038,0.14112013578414917,0.14062419533729553,0.1401306837797165,0.13963767886161804,0.13914752006530762,0.13866034150123596,0.13817612826824188,0.13769479095935822,0.13721591234207153,0.13673803210258484,0.13626302778720856,0.13579073548316956,0.13532112538814545,0.1348544806241989,0.13439035415649414,0.13392874598503113,0.13346996903419495,0.13301411271095276,0.13256090879440308,0.1321103870868683,0.1316627413034439,0.13121826946735382,0.1307767778635025,0.13033810257911682,0.1299021989107132,0.12946905195713043,0.12903879582881927,0.12861135601997375,0.1281866878271103,0.12776434421539307,0.12734447419643402,0.12692728638648987,0.126511812210083,0.1260978728532791,0.12568651139736176,0.12527768313884735,0.12487142533063889,0.12446703016757965,0.12406467646360397,0.1236647516489029,0.12326744198799133,0.12287227064371109,0.12247893959283829,0.12208802998065948,0.12169963866472244,0.12131370604038239,0.12093031406402588,0.12054909765720367,0.12017019093036652,0.11979318410158157,0.11941766738891602,0.11904440075159073,0.11867349594831467,0.11830418556928635,0.11793681234121323,0.117571622133255,0.1172085851430893,0.11684787273406982,0.1164894551038742,0.11613234132528305,0.11577671021223068,0.11542320996522903,0.11507131904363632,0.11472061276435852,0.1143718957901001,0.11402509361505508,0.11367975920438766,0.1133364662528038,0.11299522966146469,0.11265599727630615,0.11231884360313416,0.1119837835431099,0.11165080964565277,0.11131991446018219,0.11099009215831757,0.11066164076328278,0.1103351041674614,0.11001040041446686,0.10968653112649918,0.10936415940523148,0.10904299467802048,0.10872353613376617,0.10840586572885513,0.10809004306793213,0.1077759861946106,0.10746375471353531,0.10715323686599731,0.10684458166360855,0.10653771460056305,0.10623230040073395,0.10592872649431229],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"mode\":\"lines\",\"name\":\"IS MSE\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813,0.6209717313491813],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"mode\":\"lines\",\"name\":\"Train MSE\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.9400587462509303,0.4930520591664674,0.506112751912968,0.519518906866814,0.5324279603032439,0.5442043868361919,0.5508097632109984,0.5574018575721036,0.5635755955179605,0.5699742994904167,0.5768410486034985,0.5843714451781938,0.590298362448764,0.5934936913104767,0.5966372274029891,0.599581279316607,0.6026718808475061,0.6057933684066407,0.6091844409878034,0.6125425120051212,0.6163110677803068,0.6198708729280508,0.6228639770155199,0.6261692143317633,0.6293158162669333,0.6342890115067218,0.6396047042746423,0.6449238797493093,0.6497808407977919,0.6540044389014152,0.6581238409195413,0.6621813463393664,0.6663655111545229,0.670485146983506,0.6743989298192533,0.6781176845401368,0.6817951232464156,0.685459501741717,0.689056427144931,0.6926735973006378,0.6963844469400677,0.6995361070986187,0.7026477350282586,0.7057263666350304,0.7085327592873041,0.7110708338036833,0.7135400665446331,0.715664244286596,0.7175627781895862,0.7193383734572281,0.7209871577736175,0.7223985265139341,0.7236565699636184,0.7247880384983516,0.7259223858426201,0.7271393716337514,0.7283381019814499,0.7294295231469057,0.7303905453877798,0.7313639819423183,0.7323976942072232,0.7333236906026124,0.7341187346459596,0.7347639040184705,0.7352490705004278,0.735577920019011,0.7357642299924898,0.7357634874553219,0.7356269148474202,0.7353511210755028,0.7349254302389931,0.7343534283904064,0.7336584668869144,0.7328476838973882,0.731924457188489,0.7309061801197864,0.7298019384412778,0.7286011943577373,0.7273099244585323,0.7259327073128724,0.7244869727403608,0.7230075262701944,0.7214163222538237,0.7197006624979847,0.7179288153862787,0.716198194280203,0.7144101780967522,0.712691160451905,0.710949279829476,0.7091595865541701,0.7073260449179565,0.705518369333233,0.7036979556106012,0.7018745031824926,0.7000509860541488,0.6982220090502607,0.6963830107191452,0.694548281867153,0.6927181835284818,0.6908945171668947,0.6890942822859144,0.687307132242295,0.6855351509875044,0.6837832179301221,0.6820495332797356,0.6803335406359889,0.6786577967686277,0.6770070434375928,0.6753876206485471,0.6738208675028223,0.6723114801165183,0.6708057701042615,0.6693254820658915,0.6678616254349733,0.6664022665993489,0.6649729965088154,0.6635682724338632,0.6621885757826091,0.6608336076962451,0.6595194677340872,0.65825210735822,0.6570209258029416,0.6558138302389364,0.654627115919595,0.6534610708039927,0.652306724402767,0.6511727928602064,0.6500679187575013,0.6489576414571346,0.6478693401972437,0.6468052474712824,0.6457348796178187,0.644685067521657,0.6436551086897747,0.6426445063483852,0.6416525507890403,0.6406765621607898,0.6397617518859192,0.6388814031616904,0.638016979984724,0.637286878402745,0.636639537998109,0.6360029883776472,0.6353794902023232,0.6347670406276642,0.634166871322955,0.6335767449463298,0.6329809957472674,0.6323933574891563,0.6318172891888996,0.6312513599695401,0.6307031751339477,0.6301774510435911,0.6296548019044415,0.6291354990751918,0.6286234404168614,0.6281185901048876,0.627620949588689,0.6271230120941745,0.6266490575956877,0.6261951369674589,0.6257430057869886,0.6252814603221795,0.6248243627605934,0.6243763945646099,0.6239363997160194,0.6235249734254626,0.6231219283074584,0.6227241793570839,0.6223330363381868,0.6219447402952779,0.6215839350507176,0.6212700325902598,0.6209604837053351,0.6206538249160941,0.6203449325746999,0.6200400819936651,0.6197540760727474,0.6194730896401808,0.6191959488171583,0.6189224983361333,0.6186473949365978,0.618362071376691,0.618080843556398,0.6178007039296101,0.61752294293089,0.6172471189120317,0.6169774693147536,0.6167115770698328,0.6164520827817224,0.6162017062808833,0.6159537005424655,0.6157044626077247,0.6154544377568881,0.6152050960950038,0.6149560682492582,0.6147093805432186,0.614464956482251,0.6142228996023266,0.6139806873705075,0.6137369008632648,0.6134955123475675,0.6132566659142855,0.61302070445428,0.6127930339042876,0.6125770195185193,0.6123636293873144,0.6121552449625833,0.6119496809204281,0.611746977479327,0.6114833501399292,0.6111455645415187,0.6108366716282639,0.6105648873190627,0.6104117268875019,0.610227262651848,0.6100422784514774,0.6098559484589428,0.6096736517651783,0.6094860737913047,0.6093046062729429,0.6091255276294438,0.6089500249465755,0.608777227757391,0.6086097578827327,0.6084489314353697,0.6082903554499334,0.608135704109202,0.6079847648147911,0.6078400092417735,0.607696126842188,0.6075535383993117,0.6073923715869134,0.6071875143384814,0.606980039050562,0.6067751105271784,0.6065754205478439,0.606377846617547,0.606182476992099,0.6059892522293632,0.6058070455263063,0.6056606350359911,0.605522570000652,0.605381956064824,0.6052451181713244,0.6051167877980738,0.6049909526864203,0.6047954384573119,0.6045381678366506,0.6042866780129935,0.604036084493704,0.603786229749437,0.6035374102373496,0.6032896374662098,0.6030423818732302,0.6027964803594674,0.6025514712798845,0.6022949450827001,0.6020206704701736,0.6017456762271506,0.6014715212308053,0.6011984185445054,0.6009263727206162,0.6006556263316294,0.6003855516746677,0.6001177644512455,0.5998583650993113,0.5996042300168813,0.5993383965406857,0.5990735471525919,0.5988092325104335,0.5985431532822404,0.5982778374745159,0.5980131230332556,0.59774731306227,0.5974781666808814,0.5972094717023074,0.5969425779738037,0.5966760087239162,0.5964102262913732,0.5961458130065677,0.5958826076283803,0.5956237724785588,0.5953684190925443,0.595114385565727,0.5948619172932704,0.5946109558407167,0.594364649837556,0.5941114546273083,0.5938592612427281,0.5936127453831118,0.593367241014026,0.5931240736504138,0.5928824100444079,0.592642449691897,0.592395298058855,0.5921419985935522,0.5918902819547094,0.5916413732388416,0.5913942937535825,0.5911479320892065,0.5909357758727181,0.5907675201564391,0.59061748338314,0.5904760773703545,0.5903358251135212,0.5901963753168967,0.5900578783420148,0.5899272472389758,0.5898134415016109,0.5897007197683805,0.589589295830592,0.5894790524918485,0.5893639860200965,0.5892477397536932,0.5891326624527573,0.5890191519406697,0.5889084085773019,0.588799034887083,0.5886908854473423,0.5885799633435429,0.5884691733623156,0.5883644867896607,0.5882717722975009,0.5881819209228342,0.5880897092669506,0.5879980477065222,0.5879097496644723,0.5878230802105302,0.5877374601279798,0.5876671648523243,0.587619271801729,0.5875700108787802,0.5875214619649034,0.5874734626988227,0.5874310084745166,0.587404575747427,0.5873813380296412,0.5873579934084919,0.5873347019597221,0.5873114358812715,0.587288304870827,0.5872655129577602,0.5872362148456459,0.5871973233005211,0.5871587065640779,0.5871205435054799,0.5870829267884456,0.5870368224673744,0.5869899866532847,0.5869430818636284,0.586896714939346,0.586851089339163,0.5868060699875707,0.5867626329164546,0.5867209228379803,0.5866833963568604,0.5866466627849465,0.5866107690406038,0.5865754657873015,0.5865409330782357,0.5864973295729621,0.5864505686644464,0.5864054432454524,0.5863631506661978,0.5863120516216611,0.5862605001875111,0.5862100767784914,0.5861610182763395,0.586115411344262,0.5860713037232753,0.5860279147262195,0.5859985219508148,0.5859703249914393,0.5859427334230966,0.5859156501768921,0.5858897727153681,0.5858644482547853,0.5858396128438351,0.5858152649476271,0.5857918635664757,0.5857688210034804,0.5857449625843203,0.5857215981961507,0.5856966478398274,0.5856755474452767,0.5856549717886996,0.5856352109829168,0.5856170403005366,0.5856004992959691,0.5855845492157894,0.5855717559695784,0.5855589927973642,0.5855464647694583,0.5855343314065852,0.5855244154520916,0.5855100609033075,0.5854954078855564,0.5854811058725317,0.5854678583270124,0.5854549227278617,0.5854434006729395,0.5854359198290617,0.585429221890719,0.5854219591589577,0.5853952303058021,0.5853684265093461,0.585338431599597,0.5853053850290015,0.5852722170901676,0.5852388912212704,0.5852353438320219,0.585262917515041,0.5852683080523124,0.5852727135386712,0.5852766836714423,0.5852802918592422,0.5852834303995099,0.585286352886305,0.5852891222822463,0.5852916114816481,0.585294469913135,0.5852979149448357,0.5853132754575775,0.5853409644963261,0.585367920488784,0.5853945546763657,0.5854207217815834,0.5854459400161781,0.5854709361278574,0.5854957390316481,0.5855194558940668,0.585540876085162,0.5855623859600824,0.5855838311898749,0.5856050792787164,0.5856258383836551,0.5856482034910943,0.5856701761031355,0.585692445637968,0.5857146364704314,0.5857452732551692,0.5857847067539672,0.5858262254393997,0.5858676907927066,0.5859033030492066,0.5859362066741396,0.5859689781935863,0.5860012965985408,0.586032168354722,0.5860612291759543,0.5860898747440799,0.5861190486851852,0.5861481618784358,0.5861771319922369,0.5862060383173042,0.5862348743323689,0.5862650381860149,0.5862952262224262,0.5863249071828932,0.5863550565615784,0.5863860814575597,0.5864157272631791,0.5864441841850883,0.5864727132318389,0.5865009197321515,0.5865193559461337,0.5865310203974898,0.5865535363921696,0.5865830757148686,0.5866111340649721,0.5866402952129175,0.5866718488544889,0.5867030263883928,0.5867344385892894,0.5867677679901357,0.5868008503829462,0.5868337086642409,0.5868663871429775,0.5868988636915543,0.586931154114318,0.586963326933941,0.5869953589790199,0.5870270293460323,0.5870570232561354,0.587084629474346,0.587111991982171,0.5871402045832979,0.5871684079988411,0.587195169836557,0.5872211919353225,0.5872460981438405,0.5872706386047106,0.5872948014161475,0.5873187063349649,0.5873422677781732,0.5873655714015468,0.5873887074092183,0.58741165785936,0.5874344114447544],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"mode\":\"lines\",\"name\":\"Test MSE\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.9401816726361202,0.9537268382151344,0.965305617027399,0.9766967586298112,0.9881080585271159,0.9870638940655023,0.9787350406413997,0.9704842299043918,0.9615809368050506,0.9526744561061198,0.9440838234027549,0.9372455763908579,0.9301630039958072,0.9230360205783892,0.9162324681308451,0.9097989734473528,0.903706063997908,0.897851649026681,0.892194231453903,0.8868408251358787,0.8816528777547525,0.8767030176929378,0.8718433495843063,0.866135880344301,0.8607441145824497,0.8556299347987647,0.8508058060116521,0.8462656027998617,0.8421143230155927,0.8383190362437821,0.8347614968472331,0.8314398058039394,0.8283257425062326,0.8254064777422249,0.8226681842552996,0.8200940914510044,0.8176667100580065,0.8153811942914878,0.8132253703948005,0.8111843473028879,0.809205807903605,0.8069748292023452,0.804840384254976,0.8027916051082199,0.8008185160826612,0.7989113416114687,0.7970594070281962,0.7952505888837619,0.7934805054819507,0.7917405793271269,0.7900010338768363,0.7883880180616504,0.7869360449148691,0.7854851523835122,0.7840433446389959,0.7825838573448535,0.7811016155337507,0.7795923907226688,0.7780523091369445,0.7764786445623731,0.7748677501343118,0.7732188979265336,0.7715944796834446,0.769964918713949,0.7682888601422543,0.7665650702923502,0.7647936707495996,0.7629745961449522,0.7611085408192699,0.7591972351792865,0.7572420126634769,0.7552459573147157,0.7532113593855365,0.7511409581124668,0.7490356295479376,0.7468985722450823,0.7447322939742679,0.7425396727033559,0.740323903648632,0.7380875505368304,0.7358340616903789,0.7335663939960698,0.731287482421366,0.7290005693127611,0.7267088093338929,0.7244142124474426,0.7221195441305397,0.7198275173027636,0.7175410321588158,0.7152616471705373,0.7129918840067181,0.7107337731649721,0.7084898082109414,0.7062609202474842,0.7040497112400517,0.7018579079928003,0.6996870538639062,0.6975471897590247,0.6954310609619107,0.6933394848059666,0.6912778942536529,0.6892479511817247,0.6872464347807763,0.6852747970351746,0.683331427248208,0.6814171642580675,0.679532086181553,0.6776765916477197,0.6758510757572707,0.6740557116763872,0.6722904505861264,0.6705556637099152,0.6688513264180348,0.6671774931163825,0.6655341092745638,0.6639208011779857,0.6623376732997787,0.6607840974862006,0.6592597964245787,0.6577647239316691,0.6562992814005436,0.6548631183144616,0.6536618826990097,0.6525319908978237,0.6514273363730175,0.6503474771975459,0.6492920187006731,0.6482605966586319,0.6472525010117322,0.6462676307728469,0.6453064469952942,0.6443857342042741,0.643486453275968,0.6426076881101179,0.641749275628737,0.6409103627080991,0.6400906438727998,0.6392897961305174,0.6385071415602869,0.6377425701750153,0.6369952569555771,0.6362642013628952,0.6355487710018823,0.6348490352613927,0.6341650588406048,0.6334961649244248,0.632842240040623,0.6322026982276473,0.6315765330895242,0.6309636908078304,0.6303640822588021,0.6297888620666234,0.6292500082428241,0.6287241598123482,0.6282103807196259,0.6277080265423798,0.6272183144010681,0.6267414309962467,0.6262763685942558,0.6258227323651713,0.6253799919001409,0.6249449634939139,0.6245165140777869,0.6240986516077779,0.6236905448375225,0.6232926847329958,0.6229053121035291,0.6225260532681753,0.622156647273628,0.6217812711119172,0.6214131565185943,0.6210496318351127,0.6206914512687601,0.6203414070708894,0.6199994416982936,0.6196653459146514,0.6193388456875106,0.6190197912355825,0.6187084191387927,0.6184045333730844,0.6181079438697101,0.617818719308102,0.6175354718064108,0.6172578960250592,0.6169853470528488,0.6167085526450882,0.6164344030612465,0.6161656243096167,0.6159001602694844,0.6156333464403462,0.6153702570591177,0.6151110628534721,0.6148557595489232,0.6146043134584617,0.6143572522898932,0.6141148870199015,0.613877073008856,0.6136442203838033,0.613415893003297,0.6131922677787525,0.6129734163697932,0.6127590261353473,0.6125488601740958,0.6123429502445484,0.6121410718062582,0.6119439614388517,0.6117507772619633,0.6115632770970856,0.6113801733172659,0.6112006848723923,0.6110492839824283,0.6109031625776657,0.6107638172220836,0.6106273905252443,0.6104926850449987,0.6103596294954291,0.610228542404675,0.6100995392017696,0.6099733112385628,0.6098496988587069,0.6097279170962574,0.6096223338050429,0.6094730354604037,0.6092934681759343,0.6091170718809908,0.6089441510420829,0.6087746675567113,0.6086088215433165,0.6084465344555577,0.6082878377871449,0.6081326247266968,0.6079811299429421,0.607833124798666,0.6075078913548089,0.6071184267495722,0.6067163145580624,0.6061880222241116,0.6056667929816307,0.6051525539206783,0.6046451871053199,0.604143879569326,0.6037618235140603,0.6038553273016051,0.6039479310043544,0.6040401584681824,0.6041321885514812,0.6042075429907228,0.6042602285894049,0.604307096894256,0.604359300102539,0.6044129533536989,0.6044679930459717,0.604524362177466,0.6045819802937913,0.6046405648562164,0.6047001793485784,0.6047606741871588,0.6048219915680526,0.6048831362293434,0.6049446048039763,0.6050063452326951,0.6050683982191735,0.6051307639833937,0.6051933734927415,0.6052562898644681,0.6052591858464135,0.6052329177626393,0.6052076180922676,0.6051832926154856,0.6051623137951543,0.6051472332969823,0.6051332362355862,0.6051200449391553,0.6051069702649671,0.6050948579569546,0.6050830772678625,0.605071750010062,0.6050610958039837,0.6050510683628472,0.6050415403937106,0.6050327838246276,0.6050246366395516,0.6050170470256081,0.6050101996697863,0.6050039384589622,0.6049983616578339,0.6049933304244063,0.6049889604954534,0.6049837762147606,0.6049779974430364,0.6049714738263653,0.6049642294262997,0.604956703208101,0.6049491436742027,0.6049414349412342,0.6049336986749881,0.604926166044848,0.6049191089045451,0.6049122030402256,0.6049054891388411,0.6048993199193587,0.6048939321856261,0.6048899442680034,0.6048872349902785,0.604885810124678,0.6048861961618778,0.6048879418885708,0.6048906770642625,0.6048944885194855,0.6048994283390348,0.6049057107727603,0.60491321432675,0.6049218753765558,0.6049315783988576,0.6049423062115085,0.6049539372931445,0.604969153616866,0.6049875668145026,0.6050071146962348,0.6050277161488201,0.6050494117464947,0.6050721035450913,0.6050958668488612,0.605120736303049,0.605146480341282,0.6051734465384468,0.6052014957972949,0.6052306222961072,0.605260745088374,0.6052918062457164,0.6053237305204531,0.605356268974761,0.6053894104000169,0.6054231025309258,0.6054574033371772,0.6054920575878849,0.6055264861579256,0.6055607004908894,0.6055947121482266,0.6056286194963363,0.6056623934790086,0.6056961673779777,0.6057298424510862,0.6057636099145307,0.6057972670212745,0.6058309295142701,0.605864510354653,0.605898143025613,0.6059317404436603,0.6059651692675591,0.6059983076236083,0.6060276752608577,0.6060526679714274,0.60607750229079,0.6061023345867128,0.6061270198157925,0.6061517492554306,0.606176296728917,0.6062007953414557,0.606225146482236,0.6062495183293908,0.6062735858856966,0.6062976913215213,0.6063218403525578,0.6063459169315405,0.6063699965270489,0.6063938992854265,0.606417827676595,0.6064417062388934,0.6064655761479842,0.6064890892999713,0.6065123906613711,0.6065353930887353,0.6065581718313918,0.6065807732501414,0.6066032552265869,0.6066255771372786,0.6066478607380272,0.6066701874083691,0.6066926382428213,0.6067151551473554,0.6067380633216999,0.6067695593009661,0.6068019117530109,0.606835080180833,0.6068688612215957,0.606903255130076,0.6069387149081786,0.6069752349470738,0.6070125655856587,0.607050782326881,0.6070896644901425,0.6071291540912455,0.6071690419187535,0.6072095081758823,0.6072503901951153,0.6072916706014527,0.6073330708164627,0.6073745442151202,0.6074161083540444,0.6074577514693874,0.6074994096093845,0.6075415936979612,0.607583915100893,0.6076261415743265,0.6076683368362795,0.6077103496896847,0.6077523312702214,0.6077943336714487,0.6078362055187387,0.6078780689779338,0.6079198195807339,0.6079554080527526,0.6079893587500467,0.6080228348840434,0.6080560048175013,0.6080889324502691,0.6081215250135229,0.6081539682449469,0.6081862796784073,0.6082185463078277,0.6082506867290343,0.6082828462843362,0.6083149668631528,0.6083471353014522,0.6083791309462248,0.608410895747178,0.6084424237585859,0.6084738082034887,0.6085049090082126,0.6085358542663771,0.6085666496030442,0.6085972018211735,0.6086276503603868,0.6086579429547697,0.6086881201255671,0.6087181236819427,0.6087480992082441,0.608778052158483,0.6088079186698856,0.608837681282568,0.6088675088964763,0.6088961226301933,0.6089238018912735,0.6089505753268166,0.6089765767068734,0.6090018580145836,0.6090264310510022,0.6090504877074113,0.6090738820331207,0.6090967538655356,0.6091189808926407,0.6091406791927629,0.6091618371085415,0.6091826348139597,0.6092030257145884,0.6092230737019418,0.6092430409973513,0.6092629099626262,0.6092826688244858,0.6093024515670324,0.6093221766246117,0.6093419311450493,0.6093612211128718,0.6093800463895285,0.6093984532821634,0.6094166164257527,0.6094343841759762,0.6094518264373278,0.6094684607818442,0.6094842289284416,0.6094993808206661,0.6095138581788664,0.6095278295852363,0.6095412891041356,0.6095544754308856,0.6095673360847801,0.6095800339907436,0.609592434925821,0.6096047604442512,0.6096169287025488,0.6096288812156089,0.6096408103828791,0.6096527451788661,0.6096642841706053,0.6096756023071974,0.6096865826452662,0.6096975986911545,0.6097085392436076,0.6097195720967529,0.6097374480458069,0.6097548941015569,0.6097719277196068,0.6097885485770026,0.6098048264824817,0.6098208021095681,0.6098364811767676,0.6098518810387438,0.6098671297512683,0.6098821982188241],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.45],\"title\":{\"text\":\"Epoch\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.625,1.0],\"title\":{\"text\":\"Estimate\"}},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.55,1.0],\"title\":{\"text\":\"Epoch\"}},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.625,1.0],\"title\":{\"text\":\"Variance\"}},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.0,0.45],\"title\":{\"text\":\"Epoch\"}},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,0.375],\"title\":{\"text\":\"MSE Loss\"}},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.55,1.0],\"title\":{\"text\":\"Epoch\"}},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.0,0.375],\"title\":{\"text\":\"MSE\"}},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Estimate over Epochs\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Variance over Epochs\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Shaping Train MSE Loss over Epochs\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Total MSE over Epochs\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Metrics over Epochs\"},\"showlegend\":true},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('10a14bd6-f0aa-45ed-a77d-bbeecc077380');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"dc32c609-4774-4230-ac7c-0cd01d465111\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"dc32c609-4774-4230-ac7c-0cd01d465111\")) {                    Plotly.newPlot(                        \"dc32c609-4774-4230-ac7c-0cd01d465111\",                        [{\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"z\":[[0.05757277458906174,0.05933089181780815,0.05447155982255936,0.04319530725479126,0.0318736732006073,0.020552027970552444,0.00923037901520729,-0.0020912587642669678,-0.012127812951803207,-0.020222801715135574],[0.052125945687294006,0.0607469379901886,0.060065995901823044,0.05159791558980942,0.04088107496500015,0.030164236202836037,0.019447367638349533,0.00873052328824997,-0.0019863061606884003,-0.012703139334917068],[0.04774107784032822,0.048890236765146255,0.04965272173285484,0.050849393010139465,0.047290459275245667,0.038007430732250214,0.027290578931570053,0.016573738306760788,0.005856890231370926,-0.004859942942857742],[0.044168490916490555,0.03943528234958649,0.04415695369243622,0.03985365852713585,0.04091988876461983,0.03985293582081795,0.03451491892337799,0.02441694214940071,0.013700094074010849,0.0029832646250724792],[0.038100194185972214,0.03322853520512581,0.03689010441303253,0.035119231790304184,0.031843990087509155,0.03107094019651413,0.03218705952167511,0.027077380567789078,0.021543297916650772,0.010826453566551208],[0.03203190490603447,0.027053164318203926,0.029942700639367104,0.03263054043054581,0.026081519201397896,0.023834308609366417,0.02306126430630684,0.02228822186589241,0.019639845937490463,0.014301858842372894],[0.02596360631287098,0.020877789705991745,0.023767326027154922,0.026656856760382652,0.023592816665768623,0.017043795436620712,0.015824638307094574,0.015051610767841339,0.014278572052717209,0.012202337384223938],[0.019895315170288086,0.014702416956424713,0.01759195700287819,0.020481493324041367,0.02213035151362419,0.01455511525273323,0.008588019758462906,0.007814988493919373,0.007041942328214645,0.0062689147889614105],[0.013827025890350342,0.008527044206857681,0.01141657680273056,0.01430610939860344,0.017195645719766617,0.012351974844932556,0.005517397075891495,0.0005783513188362122,-0.0001946873962879181,-0.0009677223861217499],[0.008660536259412766,0.002351675182580948,0.005241207778453827,0.008130732923746109,0.011020287871360779,0.013142857700586319,0.0030286982655525208,-0.0035203173756599426,-0.007431309670209885,-0.00820435956120491]],\"type\":\"heatmap\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"Values\"},\"ticks\":\"outside\",\"tickvals\":[-0.020222801715135574,0.0607469379901886],\"ticktext\":[-0.020222801715135574,0.0607469379901886]}},\"xaxis\":{\"tickvals\":[0,1,2,3,4,5,6,7,8,9],\"ticktext\":[0,1,2,3,4,5,6,7,8,9],\"title\":{\"text\":\"X\"}},\"yaxis\":{\"tickvals\":[9,8,7,6,5,4,3,2,1,0],\"ticktext\":[9,8,7,6,5,4,3,2,1,0],\"title\":{\"text\":\"Y\"},\"autorange\":\"reversed\"},\"title\":{\"text\":\"Heatmap\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('dc32c609-4774-4230-ac7c-0cd01d465111');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"49eb695f-0b8e-4d8f-8d5f-598b621de2fe\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"49eb695f-0b8e-4d8f-8d5f-598b621de2fe\")) {                    Plotly.newPlot(                        \"49eb695f-0b8e-4d8f-8d5f-598b621de2fe\",                        [{\"colorbar\":{\"title\":{\"text\":\"Visits\"}},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"x\":[0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9],\"y\":[9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0],\"z\":[0,81,268,698,1731,1791,1828,1627,1224,1250,0,160,468,1233,1389,0,701,946,810,1377,0,303,914,1228,542,0,262,304,469,1392,0,644,742,390,198,0,62,123,207,342,0,517,317,158,77,0,24,40,57,84,143,352,148,57,26,2,2,3,9,14,26,67,32,15,8,2,2,3,10,15,9,17,11,5,3,5,8,7,10,15,0,3,5,1,2,4,2,6,10,11,0,0,1,0,0,1,2,2,7,10],\"zmax\":1828,\"zmin\":0,\"type\":\"heatmap\"}],                        {\"title\":{\"text\":\"State Visitations Heatmap\"},\"xaxis\":{\"title\":{\"text\":\"X-axis\"}},\"yaxis\":{\"ticktext\":[9,8,7,6,5,4,3,2,1,0],\"tickvals\":[0,1,2,3,4,5,6,7,8,9],\"title\":{\"text\":\"Y-axis\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('49eb695f-0b8e-4d8f-8d5f-598b621de2fe');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "800 trajectories:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"8970c92f-3429-47cd-a963-e242f1e1deb0\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"8970c92f-3429-47cd-a963-e242f1e1deb0\")) {                    Plotly.newPlot(                        \"8970c92f-3429-47cd-a963-e242f1e1deb0\",                        [{\"mode\":\"lines\",\"name\":\"IS Estimate\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876,0.08668600767850876],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"Train Estimate\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[-0.5445098876953125,-1.2774921655654907,-1.254064679145813,-1.2274771928787231,-1.2011748552322388,-1.1731499433517456,-1.1428180932998657,-1.112951636314392,-1.0835802555084229,-1.0539644956588745,-1.0241332054138184,-0.9938308596611023,-0.9623088836669922,-0.9326035380363464,-0.9029458165168762,-0.8728294968605042,-0.8429633975028992,-0.8137218952178955,-0.7855969667434692,-0.7580599784851074,-0.7309558391571045,-0.7041711807250977,-0.6786743998527527,-0.6544458270072937,-0.6313480734825134,-0.6101018786430359,-0.5898243188858032,-0.5701838135719299,-0.5511744022369385,-0.5326504111289978,-0.5149582028388977,-0.49782851338386536,-0.48040780425071716,-0.4633694887161255,-0.44685664772987366,-0.430418998003006,-0.41391822695732117,-0.39758220314979553,-0.38157907128334045,-0.3663196861743927,-0.3514961302280426,-0.3349425196647644,-0.31871047616004944,-0.3030533492565155,-0.28761234879493713,-0.27227911353111267,-0.25732794404029846,-0.24273227155208588,-0.2284502238035202,-0.21445462107658386,-0.20018717646598816,-0.18544530868530273,-0.17083893716335297,-0.1564180552959442,-0.14212749898433685,-0.12817533314228058,-0.11475712805986404,-0.10139436274766922,-0.08837376534938812,-0.07574215531349182,-0.06349208950996399,-0.05185501649975777,-0.04059873893857002,-0.02971586212515831,-0.019211947917938232,-0.009062794037163258,0.0007183332345448434,0.0101309297606349,0.019169161096215248,0.027822375297546387,0.03496178984642029,0.041433174163103104,0.04785165563225746,0.054203785955905914,0.06047144904732704,0.06664130836725235,0.07270170748233795,0.07864131778478622,0.0844285860657692,0.0900719091296196,0.09500808268785477,0.09919609129428864,0.10319352149963379,0.10701745748519897,0.11068414151668549,0.1141769289970398,0.11746131628751755,0.12050100415945053,0.12336494028568268,0.12608927488327026,0.1286771297454834,0.13112252950668335,0.1334385871887207,0.13563714921474457,0.13771158456802368,0.13966593146324158,0.1414734125137329,0.14309169352054596,0.1445970982313156,0.14601287245750427,0.14734052121639252,0.14858636260032654,0.14972344040870667,0.1507692188024521,0.151731476187706,0.15261584520339966,0.15341728925704956,0.15414151549339294,0.15479686856269836,0.1553574651479721,0.1558581441640854,0.15628132224082947,0.15662729740142822,0.15689216554164886,0.1570717990398407,0.15720880031585693,0.15730831027030945,0.15737232565879822,0.15740835666656494,0.15741726756095886,0.15724079310894012,0.1568295806646347,0.15640789270401,0.15598097443580627,0.15555258095264435,0.15539734065532684,0.1553003191947937,0.1552242934703827,0.1551547646522522,0.15508320927619934,0.1550063043832779,0.15492752194404602,0.15484441816806793,0.15474297106266022,0.15463320910930634,0.15451863408088684,0.1543724536895752,0.15419861674308777,0.15400829911231995,0.15373413264751434,0.15346351265907288,0.15317882597446442,0.15289340913295746,0.1526096910238266,0.1523221731185913,0.1520313322544098,0.15173549950122833,0.15143419802188873,0.15112847089767456,0.15081487596035004,0.15048936009407043,0.1501660794019699,0.14984089136123657,0.1494854986667633,0.14912055432796478,0.1487509310245514,0.14833879470825195,0.1479065716266632,0.1474505066871643,0.14698801934719086,0.1465231031179428,0.14605799317359924,0.1455947309732437,0.1451365053653717,0.14467251300811768,0.14420340955257416,0.14373399317264557,0.14329884946346283,0.14287319779396057,0.14244484901428223,0.14201466739177704,0.1415833979845047,0.14114950597286224,0.14069651067256927,0.14023549854755402,0.13977108895778656,0.13930583000183105,0.13883894681930542,0.13837219774723053,0.13790695369243622,0.13740280270576477,0.13689351081848145,0.13638567924499512,0.13587917387485504,0.13537423312664032,0.13487060368061066,0.13436782360076904,0.13386709988117218,0.13336731493473053,0.13286729156970978,0.13236305117607117,0.13186945021152496,0.13138578832149506,0.13090839982032776,0.13043121993541718,0.1299564391374588,0.12949314713478088,0.1290469914674759,0.12860408425331116,0.1281633824110031,0.12759104371070862,0.1268625259399414,0.12607260048389435,0.12529271841049194,0.12452506273984909,0.12376774847507477,0.12302012741565704,0.12228284031152725,0.12155556678771973,0.12083454430103302,0.12012435495853424,0.11942706257104874,0.11874502152204514,0.11806075274944305,0.11739049106836319,0.11673448234796524,0.11609198153018951,0.11546222120523453,0.11484324932098389,0.11423379182815552,0.11363875865936279,0.11305565387010574,0.11252341419458389,0.11200148612260818,0.11148889362812042,0.11098600178956985,0.11049249023199081,0.1100044697523117,0.10952456295490265,0.10908307880163193,0.10865606367588043,0.10823709517717361,0.10782569646835327,0.10742192715406418,0.10702589154243469,0.10663378983736038,0.1062377542257309,0.10584738850593567,0.10546363890171051,0.10508561879396439,0.1047108918428421,0.1043417751789093,0.10398174077272415,0.10362878441810608,0.10328276455402374,0.10294374078512192,0.10261446237564087,0.1022900715470314,0.10197440534830093,0.10166281461715698,0.10135456919670105,0.10104618966579437,0.10073921829462051,0.10043521970510483,0.10013460367918015,0.09983659535646439,0.09953778237104416,0.09923972934484482,0.09894435107707977,0.09865151345729828,0.09836076945066452,0.09807129204273224,0.09778241813182831,0.097495436668396,0.09721193462610245,0.09693021327257156,0.09665320813655853,0.0963853970170021,0.09607192873954773,0.0957641452550888,0.09543946385383606,0.09507789462804794,0.09472671896219254,0.09439031779766083,0.09406072646379471,0.09373711049556732,0.09341965615749359,0.09310805797576904,0.0928025096654892,0.09249994158744812,0.09219469875097275,0.09187416732311249,0.09154609590768814,0.09120156615972519,0.09086336940526962,0.09053412824869156,0.09021519124507904,0.08990544080734253,0.08960513025522232,0.0893137976527214,0.08902967721223831,0.08873654156923294,0.08845718950033188,0.08819378912448883,0.08793816715478897,0.08772144466638565,0.08752762526273727,0.08734448254108429,0.087159164249897,0.08697313070297241,0.0867917612195015,0.0866137221455574,0.08643999695777893,0.0862695649266243,0.0861029326915741,0.08593957871198654,0.08577857911586761,0.08561984449625015,0.08546178042888641,0.08530396223068237,0.08514870703220367,0.0849948450922966,0.08484650403261185,0.08470062166452408,0.0845562145113945,0.08441363275051117,0.08427128940820694,0.08413287252187729,0.0839991495013237,0.08386977761983871,0.08374395966529846,0.08362135291099548,0.083499014377594,0.0833764374256134,0.08325806260108948,0.0831351950764656,0.08300813287496567,0.08289463073015213,0.08278518170118332,0.08268339186906815,0.08258665353059769,0.08247438073158264,0.08235923200845718,0.08224508166313171,0.08213111758232117,0.08201677352190018,0.08190266042947769,0.08178732544183731,0.08167190104722977,0.08155601471662521,0.08141423016786575,0.08126542717218399,0.08111882209777832,0.08097437769174576,0.08083119988441467,0.0806887298822403,0.08054782450199127,0.08040841668844223,0.08027107268571854,0.08013515174388885,0.07998883724212646,0.07983127236366272,0.07967449724674225,0.07951755076646805,0.0793614611029625,0.07920611649751663,0.07905124127864838,0.07889679074287415,0.0787428617477417,0.07858919352293015,0.07843524217605591,0.07828128337860107,0.07812771201133728,0.07797475904226303,0.07782238721847534,0.07767116278409958,0.0775206983089447,0.07737164944410324,0.07722382992506027,0.07708752155303955,0.07721367478370667,0.07735025882720947,0.07749498635530472,0.07764537632465363,0.07779958099126816,0.07789617031812668,0.07799205183982849,0.07810012996196747,0.07821245491504669,0.07832644879817963,0.07843784242868423,0.07854816317558289,0.07865645736455917,0.07877150923013687,0.07888397574424744,0.0789916142821312,0.07909408956766129,0.07919260859489441,0.07928667962551117,0.07937830686569214,0.07946943491697311,0.07956013083457947,0.07964394986629486,0.07972700148820877,0.07981055974960327,0.07989201694726944,0.0799713283777237,0.08004739880561829,0.08011206984519958,0.08016788214445114,0.08021998405456543,0.0802781879901886,0.07970165461301804,0.0787978544831276,0.07788536697626114,0.07696673274040222,0.0760454460978508,0.07512764632701874,0.0742141529917717,0.07330182939767838,0.07239329069852829,0.0714910700917244,0.07059658318758011,0.06971143931150436,0.06883763521909714,0.0679774135351181,0.06758204102516174,0.06736432760953903,0.06715355068445206,0.06694848090410233,0.06676030904054642,0.06659514456987381,0.06644245237112045,0.06630527973175049,0.06617802381515503,0.0660599023103714,0.0659499242901802,0.06584764271974564,0.06575273722410202,0.06566444039344788,0.06558206677436829,0.0655050203204155,0.06543278694152832,0.06536626070737839,0.06530634313821793,0.06525061279535294,0.06520240753889084,0.06515590846538544,0.06511148065328598,0.06506901234388351,0.06502790749073029,0.06498775631189346,0.06494706124067307,0.06490680575370789,0.06486755609512329,0.06482883542776108,0.06479032337665558,0.06475112587213516,0.06471054255962372,0.06466853618621826,0.06462425738573074,0.06457658112049103,0.06452754884958267,0.06447794288396835,0.06442775577306747,0.06437461078166962,0.06431801617145538,0.06425853073596954,0.0641976073384285,0.06413326412439346,0.06406240165233612,0.0639905110001564,0.06391805410385132,0.06384635716676712,0.06377441436052322,0.06370165199041367,0.06362740695476532,0.06356137245893478,0.06350061297416687,0.06343825161457062,0.0633641853928566,0.06329017132520676,0.06323830038309097,0.06316198408603668,0.06307144463062286,0.06297339498996735,0.06288404762744904,0.06279587000608444,0.0627075657248497,0.06261952221393585,0.06253374367952347,0.062447961419820786,0.06236225739121437,0.06227647140622139,0.06219044700264931,0.06210436299443245,0.06201910972595215,0.06195025146007538,0.06189151108264923,0.061835791915655136,0.06178133562207222,0.06172236427664757,0.06166010722517967,0.06159300357103348,0.06152528524398804,0.061461932957172394,0.061395857483148575,0.06133044511079788,0.061265893280506134,0.06120164692401886],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"Test Estimate\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.21600820124149323,0.20057927072048187,0.1859653741121292,0.17163944244384766,0.15729452669620514,0.15079325437545776,0.148359477519989,0.1460474282503128,0.14399896562099457,0.14192405343055725,0.13985732197761536,0.1376040130853653,0.1352432668209076,0.1328536570072174,0.13045625388622284,0.12805412709712982,0.12566542625427246,0.12328732758760452,0.12091528624296188,0.11853744834661484,0.11621835827827454,0.11390257626771927,0.11166900396347046,0.10953492671251297,0.1074003204703331,0.10528066754341125,0.10305281728506088,0.10076963901519775,0.0984916239976883,0.09622345119714737,0.09396688640117645,0.09171786904335022,0.08948331326246262,0.08727164566516876,0.08508571237325668,0.0829271748661995,0.08079792559146881,0.07870228588581085,0.07664403319358826,0.07462481409311295,0.07264605164527893,0.07071784138679504,0.0688413679599762,0.06701910495758057,0.06529355049133301,0.06364000588655472,0.06204615905880928,0.06051381304860115,0.05904509127140045,0.05756522715091705,0.056085534393787384,0.05465900897979736,0.05329170450568199,0.05198892951011658,0.050754353404045105,0.04958910495042801,0.04849907383322716,0.0474877655506134,0.046556152403354645,0.04570016637444496,0.044870078563690186,0.04411257058382034,0.04344380646944046,0.04286165162920952,0.04236571490764618,0.04195716604590416,0.041634511202573776,0.04139319434762001,0.04123317077755928,0.04115485027432442,0.041156187653541565,0.041263796389102936,0.04147154092788696,0.04177150875329971,0.04215611144900322,0.042618148028850555,0.04315083101391792,0.04374752938747406,0.044402118772268295,0.04510902240872383,0.04586097598075867,0.04664646089076996,0.047462474554777145,0.04830753803253174,0.04917819797992706,0.050072383135557175,0.05098865181207657,0.05192510411143303,0.05287689343094826,0.05384354293346405,0.05482446402311325,0.05581720545887947,0.05681958049535751,0.05783172696828842,0.05884972959756851,0.059870459139347076,0.060891032218933105,0.06191113963723183,0.06293094158172607,0.06394738703966141,0.06495890766382217,0.06596404314041138,0.06696140766143799,0.06794942915439606,0.06890442222356796,0.06984299421310425,0.07077135145664215,0.07168900966644287,0.07259535789489746,0.07349014282226562,0.07437290996313095,0.07524313032627106,0.07610079646110535,0.07694533467292786,0.07777676731348038,0.0785943940281868,0.07939814776182175,0.08018603175878525,0.08095911890268326,0.08171830326318741,0.08246313780546188,0.08319486677646637,0.08391354233026505,0.08461921662092209,0.08531202375888824,0.0859759971499443,0.08660614490509033,0.08721043169498444,0.08780206739902496,0.08838112652301788,0.0889483392238617,0.08950453251600266,0.09005029499530792,0.09058506786823273,0.09110905230045319,0.09162262827157974,0.09212592989206314,0.0926194116473198,0.09310337156057358,0.09357920289039612,0.09404690563678741,0.09450666606426239,0.09495867788791656,0.09540309011936188,0.09584023803472519,0.09627015143632889,0.09669546782970428,0.09712590277194977,0.09755904972553253,0.09798547625541687,0.09840753674507141,0.09882494807243347,0.09923609346151352,0.09964735805988312,0.10005412250757217,0.1004549041390419,0.10084995627403259,0.10123947262763977,0.10162343829870224,0.10200171917676926,0.10237431526184082,0.10274142026901245,0.10310295224189758,0.10345912724733353,0.10381068289279938,0.10415742546319962,0.1044992208480835,0.10483615845441818,0.10516858100891113,0.10549670457839966,0.10582050681114197,0.10613998025655746,0.10645512491464615,0.10676611214876175,0.10707280039787292,0.10737542808055878,0.10769371688365936,0.10801459848880768,0.10833124816417694,0.1086430698633194,0.1089501827955246,0.10925634950399399,0.10955914109945297,0.1098586693406105,0.11015486717224121,0.11044787615537643,0.11073771864175797,0.11102446168661118,0.11130806803703308,0.11158905923366547,0.11186910420656204,0.11214617639780045,0.11242088675498962,0.11269349604845047,0.1129639521241188,0.11323201656341553,0.11349675059318542,0.11372077465057373,0.11394277215003967,0.11416260898113251,0.11438028514385223,0.11459608376026154,0.11481077969074249,0.11502427607774734,0.11523649841547012,0.11544717848300934,0.11565636843442917,0.11586378514766693,0.11606944352388382,0.11627353727817535,0.11647597700357437,0.11667684465646744,0.11686553806066513,0.11703720688819885,0.11720797419548035,0.11737771332263947,0.11754424124956131,0.1177080050110817,0.11787037551403046,0.11803120374679565,0.11819028109312057,0.11834795773029327,0.1185041293501854,0.11865867674350739,0.11881475895643234,0.11907496303319931,0.11933310329914093,0.11958906054496765,0.11984281241893768,0.12009438127279282,0.1203436553478241,0.12059051543474197,0.12083500623703003,0.12107709050178528,0.12131678313016891,0.12155594676733017,0.12179410457611084,0.12203879654407501,0.12228337675333023,0.12252572923898697,0.12276581674814224,0.12300362437963486,0.12323971092700958,0.12347433716058731,0.1237073615193367,0.12393878400325775,0.1241685077548027,0.12439627945423126,0.12462176382541656,0.12484493106603622,0.12506572902202606,0.12528426945209503,0.12550127506256104,0.12571680545806885,0.12593084573745728,0.1261431872844696,0.12635378539562225,0.1265626847743988,0.12676984071731567,0.1269751638174057,0.12717868387699127,0.12738025188446045,0.1275799572467804,0.12777765095233917,0.12797336280345917,0.12816710770130157,0.12835898995399475,0.12854906916618347,0.12873759865760803,0.12892505526542664,0.1291176974773407,0.12931706011295319,0.12951503694057465,0.12971080839633942,0.12990494072437286,0.1300973892211914,0.13028821349143982,0.13047736883163452,0.13066475093364716,0.13085049390792847,0.13103452324867249,0.1312166452407837,0.13139808177947998,0.1315809041261673,0.13176371157169342,0.13194644451141357,0.13212840259075165,0.1323097199201584,0.13249029219150543,0.13267041742801666,0.1328500509262085,0.1330289989709854,0.13320712745189667,0.13338437676429749,0.13356056809425354,0.1337312012910843,0.13389761745929718,0.13406017422676086,0.13422155380249023,0.13438162207603455,0.13454028964042664,0.13469752669334412,0.13485318422317505,0.13500717282295227,0.13515928387641907,0.1353098303079605,0.13545872271060944,0.13560576736927032,0.13561853766441345,0.13562892377376556,0.13563835620880127,0.13564683496952057,0.13565438985824585,0.13566088676452637,0.1356663554906845,0.13567082583904266,0.13567429780960083,0.13567663729190826,0.13567794859409332,0.13567818701267242,0.13567747175693512,0.13567586243152618,0.13567335903644562,0.13566984236240387,0.13566529750823975,0.13565996289253235,0.13565462827682495,0.135649174451828,0.13564352691173553,0.13563770055770874,0.13563157618045807,0.1356251984834671,0.13561853766441345,0.13565172255039215,0.13570374250411987,0.13574005663394928,0.13577590882778168,0.13581117987632751,0.13584588468074799,0.13588005304336548,0.13591362535953522,0.13594657182693481,0.13597886264324188,0.1360103338956833,0.1360410898923874,0.136071115732193,0.1361003816127777,0.13612885773181915,0.1361566185951233,0.13618367910385132,0.13620999455451965,0.13623550534248352,0.1362602561712265,0.13628439605236053,0.13630786538124084,0.1363281011581421,0.13634780049324036,0.13636691868305206,0.1363855004310608,0.13640351593494415,0.13642095029354095,0.13643783330917358,0.13645412027835846,0.13646981120109558,0.13648317754268646,0.13649500906467438,0.13650628924369812,0.13651704788208008,0.13652724027633667,0.13653695583343506,0.13654588162899017,0.13655449450016022,0.13656309247016907,0.1365710347890854,0.1365784853696823,0.13658541440963745,0.13659213483333588,0.13659872114658356,0.13660505414009094,0.13661125302314758,0.1366177797317505,0.13662412762641907,0.13663040101528168,0.13663655519485474,0.13664260506629944,0.13664844632148743,0.13665416836738586,0.13665977120399475,0.13666528463363647,0.1366707682609558,0.13667616248130798,0.13668157160282135,0.13668698072433472,0.13669244945049286,0.136697918176651,0.13670341670513153,0.13670891523361206,0.13671432435512543,0.1367197036743164,0.13672541081905365,0.1367313414812088,0.13673746585845947,0.13674378395080566,0.13674978911876678,0.13675539195537567,0.13676053285598755,0.13676516711711884,0.13676947355270386,0.13677339255809784,0.1367768496274948,0.1367798149585724,0.1367814689874649,0.13678237795829773,0.13678275048732758,0.13678216934204102,0.13678090274333954,0.13677895069122314,0.13677605986595154,0.13677231967449188,0.1367683708667755,0.13676422834396362,0.1367599070072174,0.1367553174495697,0.1367507129907608,0.13674600422382355,0.13674110174179077,0.13673600554466248,0.1367308646440506,0.13672566413879395,0.13672035932540894,0.13671492040157318,0.13670934736728668,0.1367035061120987,0.13669736683368683,0.1366909146308899,0.13668414950370789,0.13667753338813782,0.13667167723178864,0.13666653633117676,0.13666194677352905,0.13665789365768433,0.13665418326854706,0.13665077090263367,0.13664762675762177,0.136644646525383,0.1366419643163681,0.13663947582244873,0.13663716614246368,0.13663499057292938,0.13663290441036224,0.13663099706172943,0.13662919402122498,0.13662737607955933,0.1366255134344101,0.1366235911846161,0.13662153482437134,0.13661931455135345,0.1366170346736908,0.13661494851112366,0.13661198318004608,0.13660907745361328,0.136606365442276,0.13660377264022827,0.1366012990474701,0.13659898936748505,0.1365969330072403,0.13659881055355072,0.13660363852977753,0.13660861551761627,0.13661372661590576,0.136618971824646,0.1366243213415146,0.13662979006767273,0.13663530349731445,0.13664090633392334,0.1366465538740158,0.13665223121643066,0.1366579532623291,0.13666369020938873,0.13666945695877075,0.1366751492023468,0.13668599724769592,0.1367022544145584,0.13671875,0.13673503696918488,0.13675124943256378,0.13676750659942627,0.13678456842899323,0.13680227100849152,0.13682058453559875,0.13683940470218658,0.13685870170593262,0.13687832653522491,0.13689777255058289,0.13691793382167816,0.13693861663341522,0.1369599550962448,0.13698168098926544,0.1370038092136383,0.13702352344989777],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"On-policy Estimate\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231,0.8184521978583231],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"IS Variance\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063,0.0015626709209755063],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"lines\",\"name\":\"Train Variance\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[1.8789981603622437,1.612288236618042,1.564954400062561,1.5140098333358765,1.4617159366607666,1.4076383113861084,1.3540985584259033,1.302145004272461,1.2508128881454468,1.200320839881897,1.150794506072998,1.1018033027648926,1.0490162372589111,0.9970830082893372,0.9464114904403687,0.8969748616218567,0.8492975234985352,0.803435206413269,0.7597569227218628,0.7178567051887512,0.67755526304245,0.6389592885971069,0.6026153564453125,0.5690990686416626,0.5383352041244507,0.5112970471382141,0.48536038398742676,0.460537850856781,0.4365940988063812,0.41362136602401733,0.3920769989490509,0.37169501185417175,0.3516012132167816,0.33233770728111267,0.3139752149581909,0.2962552309036255,0.27917852997779846,0.2629391551017761,0.24751977622509003,0.23328520357608795,0.21973295509815216,0.20510998368263245,0.1912858635187149,0.17824292182922363,0.165974423289299,0.15444014966487885,0.14361101388931274,0.13345856964588165,0.12395814806222916,0.11507456749677658,0.10647635906934738,0.09804745018482208,0.09013456851243973,0.08273478597402573,0.07584871351718903,0.06947062909603119,0.06359937787055969,0.05820267274975777,0.05327477678656578,0.048789385706186295,0.04471922665834427,0.04100513830780983,0.03767251968383789,0.03469507768750191,0.032046686857938766,0.029702290892601013,0.027638042345643044,0.02583194337785244,0.02425970695912838,0.022895464673638344,0.021866941824555397,0.02101958729326725,0.02026033028960228,0.019585086032748222,0.01898936554789543,0.018468359485268593,0.01801728829741478,0.01763128489255905,0.017306149005889893,0.017036180943250656,0.016829408705234528,0.01666858419775963,0.016532178968191147,0.016416579484939575,0.016318440437316895,0.016234755516052246,0.016156237572431564,0.016079142689704895,0.016010673716664314,0.015948591753840446,0.01589132659137249,0.015837665647268295,0.01578621193766594,0.01573532074689865,0.015684401616454124,0.015632955357432365,0.015579474158585072,0.015525251626968384,0.015469125472009182,0.01541120558977127,0.015351335518062115,0.015289484523236752,0.015226616524159908,0.015161451883614063,0.015093604102730751,0.01502323243767023,0.014950203709304333,0.014874553307890892,0.014796421863138676,0.014716333709657192,0.014634118415415287,0.014550409279763699,0.014463654719293118,0.01437461469322443,0.014283832162618637,0.0141919469460845,0.014099187217652798,0.01400567963719368,0.013911872170865536,0.013817811384797096,0.013714377768337727,0.013599014841020107,0.013484894298017025,0.013372175395488739,0.013260862790048122,0.013166064396500587,0.013075579889118671,0.01298546977341175,0.012896750122308731,0.0128092085942626,0.012722736224532127,0.01263736467808485,0.012553058564662933,0.012469762936234474,0.012387366965413094,0.012305806390941143,0.012224996462464333,0.012144843116402626,0.012064136564731598,0.011977150104939938,0.01189110241830349,0.011805733665823936,0.011721226386725903,0.011637557297945023,0.011554619297385216,0.011472394689917564,0.01139084529131651,0.0113099105656147,0.011229596100747585,0.011149805039167404,0.011070475913584232,0.01099174004048109,0.010913574136793613,0.010836530476808548,0.010760186240077019,0.010684384033083916,0.010607548989355564,0.010531002655625343,0.010455140843987465,0.010379787534475327,0.010305022820830345,0.010230817832052708,0.010157174430787563,0.010084247216582298,0.010011978447437286,0.009940244257450104,0.009869021363556385,0.0097983218729496,0.009728195145726204,0.009658572264015675,0.009589477442204952,0.009520923718810081,0.00945286639034748,0.009384448640048504,0.009316342882812023,0.009248748421669006,0.00918149296194315,0.009114702232182026,0.009048458188772202,0.008982904255390167,0.008917919360101223,0.00885348953306675,0.008789648301899433,0.008726377971470356,0.00866368692368269,0.008601563982665539,0.008539979346096516,0.008478946052491665,0.008418461307883263,0.008358514867722988,0.008299113251268864,0.008239847607910633,0.008181026205420494,0.00812266580760479,0.008064699359238148,0.008007186464965343,0.007950248196721077,0.007893910631537437,0.007838449440896511,0.0077835326083004475,0.007724716793745756,0.007661316078156233,0.007596755865961313,0.007533447816967964,0.00747137563303113,0.007410487160086632,0.007349216379225254,0.007288556080311537,0.007228971924632788,0.007170416880398989,0.007112869992852211,0.007056339178234339,0.0070009250193834305,0.00694693299010396,0.0068938699550926685,0.006841709837317467,0.00679041538387537,0.006739943753927946,0.006690274924039841,0.006641409359872341,0.006593260448426008,0.006545813754200935,0.0064990627579391,0.00645297858864069,0.006407511420547962,0.006362668704241514,0.006318439729511738,0.006274808663874865,0.006231734529137611,0.006189226172864437,0.0061472756788134575,0.006105848588049412,0.006064933259040117,0.006024514324963093,0.005984586197882891,0.005945146083831787,0.005906286649405956,0.005867807660251856,0.00582980178296566,0.005792220588773489,0.00575504032894969,0.005718311294913292,0.005682102870196104,0.005646285135298967,0.005610852036625147,0.00557578494772315,0.005541164427995682,0.005507012363523245,0.005473943892866373,0.005441212095320225,0.0054088071919977665,0.005376486573368311,0.005344281904399395,0.005312374792993069,0.005280767101794481,0.0052494569681584835,0.005218472331762314,0.005187800154089928,0.005157411098480225,0.005127305630594492,0.005097480956465006,0.005067935213446617,0.005038669798523188,0.005009664222598076,0.0049808938056230545,0.004952420014888048,0.004924195818603039,0.004896228667348623,0.004868238233029842,0.004840873647481203,0.004814208019524813,0.004787858575582504,0.0047619035467505455,0.004736369010061026,0.004711126442998648,0.0046861786395311356,0.004661514423787594,0.0046371230855584145,0.004612995311617851,0.004589101765304804,0.00456538051366806,0.0045416755601763725,0.0045180050656199455,0.004492737352848053,0.004467458929866552,0.004442395642399788,0.004417537245899439,0.004392979200929403,0.004368635360151529,0.00434449315071106,0.004320549312978983,0.004296864848583937,0.004273491911590099,0.004250282887369394,0.004227214492857456,0.004204203374683857,0.004181309137493372,0.004158625844866037,0.004136195871978998,0.004113988950848579,0.004091959446668625,0.004070091526955366,0.0040484024211764336,0.0040268986485898495,0.004005568102002144,0.00398441543802619,0.003963443450629711,0.00394265353679657,0.003922067116945982,0.0039016518276184797,0.003881406970322132,0.003861335339024663,0.0038417032919824123,0.003822237951681018,0.003802933031693101,0.003783782944083214,0.0037647520657628775,0.0037458278238773346,0.0037270381581038237,0.0037083819042891264,0.0036898599937558174,0.003671475686132908,0.003653306746855378,0.0036352493334561586,0.003617326496168971,0.0035995393991470337,0.003581877565011382,0.0035642979200929403,0.0035468433052301407,0.003529502544552088,0.0035122972913086414,0.003494775155559182,0.0034773116931319237,0.0034599818754941225,0.0034427864011377096,0.003425725270062685,0.0034087991807609797,0.003392023965716362,0.0033753830939531326,0.0033588754013180733,0.0033425549045205116,0.003326377598568797,0.0033102978486567736,0.0032943319529294968,0.0032784698996692896,0.0032627019099891186,0.0032470496371388435,0.0032315377611666918,0.0032161157578229904,0.0032007715199142694,0.0031853497494012117,0.0031699466053396463,0.0031546535901725292,0.003139475593343377,0.0031244135461747646,0.003109461860731244,0.0030946219339966774,0.0030798937659710646,0.0030652775894850492,0.003050772473216057,0.003036393551155925,0.0030221338383853436,0.0030079828575253487,0.002993939444422722,0.0029800033662468195,0.002966169500723481,0.0029524373821914196,0.0029388119000941515,0.002925294218584895,0.0029118438251316547,0.0028976474422961473,0.0028836606070399284,0.002869898686185479,0.0028563756495714188,0.002843102440237999,0.0028287002351135015,0.0028143119998276234,0.0028004078194499016,0.0027867795433849096,0.002773420652374625,0.0027603604830801487,0.002747555263340473,0.0027349968440830708,0.002722365316003561,0.0027099009603261948,0.00269763614051044,0.002685567131265998,0.002673690440133214,0.0026619951240718365,0.002650536596775055,0.002639265265315771,0.002628179034218192,0.002617284655570984,0.002606577705591917,0.002596043748781085,0.002585664624348283,0.002575430553406477,0.0025653273332864046,0.0025553544983267784,0.00254553509876132,0.002535845385864377,0.0025264318101108074,0.002508175326511264,0.0024862682912498713,0.0024654464796185493,0.002445786725729704,0.0024273511953651905,0.0024101657327264547,0.0023942592088133097,0.0023794767912477255,0.002365809865295887,0.002353345276787877,0.002342046005651355,0.002331871073693037,0.0023227701894938946,0.0023146828170865774,0.002304387278854847,0.002293025143444538,0.002281550085172057,0.0022699362598359585,0.002258227439597249,0.002246368210762739,0.0022345243487507105,0.0022228697780519724,0.002211197279393673,0.002199516398832202,0.002187839476391673,0.0021761900279670954,0.002164561301469803,0.002152959583327174,0.002141394652426243,0.002129877684637904,0.00211840751580894,0.0021069978829473257,0.0020956459920853376,0.002084322040900588,0.002072648610919714,0.002061109058558941,0.0020496451761573553,0.0020382595248520374,0.002026960253715515,0.002015758538618684,0.0020046140998601913,0.001993556274101138,0.0019825980998575687,0.001971744466573,0.001960985129699111,0.0019503217190504074,0.0019397600553929806,0.0019293008372187614,0.001918930560350418,0.0019086248939856887,0.0018983912887051702,0.0018882417352870107,0.0018781751859933138,0.0018682299414649606,0.001858406700193882,0.0018484019674360752,0.0018382150446996093,0.00182806805241853,0.001817901385948062,0.001807825407013297,0.0017978395335376263,0.0017879412043839693,0.0017781213391572237,0.0017683496698737144,0.0017586402827873826,0.0017492427723482251,0.001740097301080823,0.0017310259863734245,0.0017220228910446167,0.001713091041892767,0.0017041616374626756,0.001695377053692937,0.001686709001660347,0.0016781396698206663,0.0016696039820089936,0.0016611221944913268,0.0016527038533240557,0.001644348376430571,0.0016360507579520345,0.001627816935069859,0.0016196488868445158,0.00161154440138489,0.001603502780199051,0.001595527515746653,0.0015876216348260641,0.0015798872336745262,0.0015722200041636825,0.0015645960811525583,0.0015570252435281873,0.0015495253028348088,0.0015421867137774825,0.001534959301352501,0.0015277864877134562,0.001520624035038054,0.0015135483117774129,0.0015065169427543879,0.0014995295787230134,0.0014925855211913586],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"lines\",\"name\":\"Test Variance\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.0043923440389335155,0.00430825911462307,0.004211084451526403,0.004117240663617849,0.004012491088360548,0.00391171732917428,0.0038106623105704784,0.0037095060106366873,0.003607950871810317,0.003509077476337552,0.0034134353045374155,0.003298026043921709,0.0031766805332154036,0.0030650109983980656,0.0029588222969323397,0.00285808346234262,0.0027630820404738188,0.0026721127796918154,0.002584556583315134,0.0025019387248903513,0.0024242557119578123,0.0023510961327701807,0.0022719467524439096,0.0021858050022274256,0.002105466555804014,0.002030720701441169,0.001961272209882736,0.0018976079300045967,0.0018388640601187944,0.0017845062538981438,0.0017342641949653625,0.001687862677499652,0.0016450616531074047,0.0016056306194514036,0.0015693627065047622,0.0015360559336841106,0.0015055137919262052,0.001477559912018478,0.00145202677231282,0.0014287589583545923,0.0014076250372454524,0.0013865234795957804,0.0013660158729180694,0.0013472102582454681,0.0013292328221723437,0.0013125435216352344,0.0012973565608263016,0.0012835869565606117,0.0012711352901533246,0.0012595717562362552,0.001247884938493371,0.0012370831100270152,0.0012271839659661055,0.0012178412871435285,0.0012090742820873857,0.0012011511716991663,0.001194036565721035,0.001187665038742125,0.0011821307707577944,0.001178455539047718,0.0011737900786101818,0.001169500988908112,0.0011666209902614355,0.001164796412922442,0.0011636409908533096,0.0011631661327555776,0.0011633591493591666,0.0011641863966360688,0.0011656529968604445,0.0011677730362862349,0.0011705439537763596,0.001174367731437087,0.0011792118893936276,0.0011850137962028384,0.001191711868159473,0.001199247082695365,0.0012075621634721756,0.001216597855091095,0.0012262988602742553,0.001236615120433271,0.0012474622344598174,0.0012586720986291766,0.001270221546292305,0.0012820912525057793,0.0012942685279995203,0.0013067414984107018,0.0013194880448281765,0.0013324603205546737,0.0013456630986183882,0.0013591019669547677,0.0013727782061323524,0.0013866759836673737,0.0014007812133058906,0.0014150802744552493,0.001429565018042922,0.0014442024985328317,0.001458932412788272,0.0014737538294866681,0.0014887145953252912,0.0015037599951028824,0.0015188754769042134,0.0015340420650318265,0.0015492560341954231,0.0015645090024918318,0.0015788606833666563,0.0015935194678604603,0.0016081850044429302,0.001622853334993124,0.0016375137493014336,0.0016521606594324112,0.0016667896416038275,0.0016813742695376277,0.0016959152417257428,0.001710409764200449,0.0017248608637601137,0.0017392539884895086,0.0017567015020176768,0.0017749385442584753,0.0017931157490238547,0.001811230555176735,0.0018292648019269109,0.0018472366500645876,0.0018651444697752595,0.0018829811597242951,0.0019007411319762468,0.0019175532506778836,0.0019331807270646095,0.0019485709490254521,0.0019638403318822384,0.001978993183001876,0.0019940296187996864,0.002008940791711211,0.0020237290300428867,0.002038396429270506,0.0020529422909021378,0.0020673677790910006,0.002081673126667738,0.002095859730616212,0.0021099322475492954,0.0021239232737571,0.002137829316779971,0.002151652704924345,0.002165392506867647,0.0021790473256260157,0.002192619489505887,0.0022061059717088938,0.002219417365267873,0.00223309057764709,0.0022471570409834385,0.002261139452457428,0.002275031292811036,0.0022888341918587685,0.0023025490809231997,0.0023161261342465878,0.002329602837562561,0.002342988969758153,0.002356286160647869,0.002369496040046215,0.0023826109245419502,0.0023956298828125,0.0024085466284304857,0.0024213625583797693,0.002434077672660351,0.0024466942995786667,0.0024592133704572916,0.002471637213602662,0.002483962569385767,0.0024961919989436865,0.0025083322543650866,0.002520384732633829,0.002532348735257983,0.0025442177429795265,0.0025559915229678154,0.002567668678238988,0.002579252701252699,0.002590744523331523,0.0026029327418655157,0.0026153060607612133,0.0026275815907865763,0.0026397323235869408,0.0026517806109040976,0.0026639902498573065,0.0026760941836982965,0.002688096836209297,0.0026999989058822393,0.002711803885176778,0.0027235120069235563,0.0027351281605660915,0.002746651414781809,0.002758084563538432,0.0027694283053278923,0.002780682174488902,0.002791850594803691,0.002802942181006074,0.0028139560017734766,0.0028248929884284735,0.0028356853872537613,0.002844569506123662,0.0028533935546875,0.0028621514793485403,0.0028708460740745068,0.002879483625292778,0.0028880981262773275,0.0028966881800442934,0.0029052498284727335,0.0029137812089174986,0.002922284649685025,0.0029307680670171976,0.002939222613349557,0.002947654342278838,0.0029560590628534555,0.0029644332826137543,0.0029724305495619774,0.002979443408548832,0.0029864381067454815,0.0029934102203696966,0.0030003334395587444,0.0030072093941271305,0.0030140550807118416,0.0030208672396838665,0.003027641214430332,0.003034381428733468,0.003041087184101343,0.003047756850719452,0.003054389264434576,0.0030609997920691967,0.003067574929445982,0.003074112581089139,0.003080610418692231,0.003087069606408477,0.003093489445745945,0.0030998659785836935,0.0031062010675668716,0.0031124933157116175,0.003118739230558276,0.00312513904646039,0.0031316063832491636,0.003137682331725955,0.003143629524856806,0.003149532014504075,0.0031553914304822683,0.0031612031161785126,0.0031669801101088524,0.0031727286987006664,0.0031784470193088055,0.0031841357704252005,0.0031897909939289093,0.0031954082660377026,0.0032009724527597427,0.0032064865808933973,0.003211947623640299,0.0032173586077988148,0.003222724189981818,0.0032280460000038147,0.003233326366171241,0.0032385613303631544,0.003243749961256981,0.0032488959841430187,0.003253996605053544,0.003259051591157913,0.003264061640948057,0.0032690248917788267,0.0032739443704485893,0.00327881658449769,0.0032836399041116238,0.0032884208485484123,0.003293157322332263,0.0032978514209389687,0.0033025057055056095,0.0033070817589759827,0.0033122494351118803,0.0033182711340487003,0.0033242658246308565,0.00333023676648736,0.0033361800014972687,0.0033420901745557785,0.003347970312461257,0.003353820415213704,0.003359634429216385,0.0033654181752353907,0.0033711690921336412,0.003376883454620838,0.0033826071303337812,0.0033883850555866957,0.003394178580492735,0.00339998840354383,0.0034058026503771544,0.003411616664379835,0.003417429281398654,0.003423248650506139,0.003429077798500657,0.003434907179325819,0.0034407307393848896,0.0034465461503714323,0.003452344099059701,0.0034578240010887384,0.003463149070739746,0.0034684783313423395,0.003473784541711211,0.003479063743725419,0.00348431384190917,0.00348953390493989,0.003494719974696636,0.0034998732153326273,0.003504987573251128,0.003510065143927932,0.0035151063930243254,0.0035200989805161953,0.0035176770761609077,0.0035151722840964794,0.00351266423240304,0.0035101536195725203,0.0035076397471129894,0.003505116794258356,0.003502586157992482,0.0035000501666218042,0.003497508354485035,0.00349494069814682,0.0034923506900668144,0.0034897401928901672,0.0034871140960603952,0.0034844735637307167,0.003481821855530143,0.0034791540820151567,0.003476472804322839,0.0034737808164209127,0.0034710909239947796,0.0034684028942137957,0.003465713234618306,0.0034630270674824715,0.003460339270532131,0.0034576524049043655,0.0034549657721072435,0.003454924561083317,0.0034558644983917475,0.0034554824233055115,0.003455091966316104,0.003454692428931594,0.003454283345490694,0.0034538679756224155,0.003453443991020322,0.0034530104603618383,0.0034525631926953793,0.003452099161222577,0.0034516204614192247,0.0034511275589466095,0.0034506223164498806,0.0034500996116548777,0.0034495654981583357,0.003448743838816881,0.003447906346991658,0.003447054885327816,0.0034461875911802053,0.0034453098196536303,0.0034444353077560663,0.003444009693339467,0.0034435729030519724,0.003443121677264571,0.0034426578786224127,0.003442181972786784,0.003441693726927042,0.0034411957021802664,0.0034406823106110096,0.0034401577431708574,0.003439615247771144,0.0034390618093311787,0.003438494633883238,0.0034379162825644016,0.0034373244270682335,0.00343672139570117,0.003436097176745534,0.0034354578237980604,0.003434807527810335,0.003434138372540474,0.0034334585070610046,0.0034327644389122725,0.0034320647828280926,0.003431362332776189,0.003430658020079136,0.003429950913414359,0.0034292456693947315,0.0034285387955605984,0.0034278319217264652,0.0034271276090294123,0.0034264191053807735,0.0034257075749337673,0.0034249925520271063,0.003424277761951089,0.0034235611092299223,0.0034228491131216288,0.0034221347887068987,0.003421422326937318,0.0034207142889499664,0.0034200127702206373,0.0034193177707493305,0.003418626496568322,0.0034179401118308306,0.003417257685214281,0.003416578285396099,0.003415909595787525,0.0034152481239289045,0.00341459340415895,0.0034139479976147413,0.003413287689909339,0.003412611084058881,0.0034119170159101486,0.003411204321309924,0.0034104804508388042,0.0034097370225936174,0.0034089763648808002,0.0034081987105309963,0.003407323732972145,0.0034064159262925386,0.0034054939169436693,0.0034045528154820204,0.0034035933203995228,0.003402619855478406,0.0034016179852187634,0.00340059376321733,0.0033995534759014845,0.0033985027112066746,0.003397442400455475,0.0033963711466640234,0.003395296400412917,0.003394218161702156,0.0033931334037333727,0.0033920444548130035,0.003390953643247485,0.0033898630645126104,0.00338877085596323,0.0033876767847687006,0.0033865831792354584,0.0033854783978313208,0.0033843647688627243,0.003383240895345807,0.0033821086399257183,0.0033809782471507788,0.003379863454028964,0.0033787651918828487,0.0033776815980672836,0.003376613138243556,0.0033755565527826548,0.003374512307345867,0.0033734797034412622,0.0033724575769156218,0.0033714459277689457,0.0033704466186463833,0.0033694556914269924,0.0033684736117720604,0.0033674987498670816,0.003366534598171711,0.003365578828379512,0.003364628180861473,0.0033636814914643764,0.0033627389930188656,0.0033617985900491476,0.003360862610861659,0.003359932452440262,0.0033590139355510473,0.003358024638146162,0.003357039066031575,0.003356063272804022,0.003355100518092513,0.0033541477750986814,0.003353206906467676,0.003352280706167221,0.0033513307571411133,0.0033503668382763863,0.0033494168892502785,0.003348481608554721,0.003347562626004219,0.0033466580789536238,0.0033457684330642223,0.003344892058521509,0.003344031050801277,0.0033431826159358025,0.003342347452417016,0.003341526025906205,0.0033407171722501516,0.0033399206586182117,0.0033391346223652363,0.0033383765257894993,0.0033376466017216444,0.00333692436106503,0.0033362102694809437,0.0033355129417032003,0.0033348402939736843,0.003334189299494028,0.003333555068820715,0.0033329378347843885,0.0033323378302156925,0.003331753658130765,0.003331181826069951,0.0033306232653558254,0.003330094274133444,0.003329590894281864,0.0033291156869381666,0.0033286619000136852,0.0033282318618148565,0.0033278153277933598],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"lines\",\"name\":\"Train MSE Loss\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[21.177663803100586,20.35664939880371,19.323644638061523,18.331470489501953,17.37758445739746,16.466289520263672,15.601984977722168,14.774876594543457,13.98455810546875,13.230624198913574,12.511210441589355,11.823622703552246,11.169021606445312,10.546805381774902,9.956208229064941,9.397549629211426,8.867410659790039,8.363706588745117,7.884999752044678,7.432069778442383,7.00447416305542,6.601593971252441,6.221529960632324,5.862966537475586,5.525067329406738,5.207157611846924,4.9080491065979,4.627638816833496,4.365356922149658,4.119194030761719,3.8881616592407227,3.6713342666625977,3.4680416584014893,3.27778959274292,3.100050210952759,2.933856964111328,2.7786850929260254,2.6338226795196533,2.498767137527466,2.3730268478393555,2.2560551166534424,2.1470680236816406,2.0457236766815186,1.9516868591308594,1.8644806146621704,1.7837191820144653,1.7089650630950928,1.6398541927337646,1.5760551691055298,1.5172107219696045,1.4630138874053955,1.4131590127944946,1.3672964572906494,1.3251087665557861,1.286313772201538,1.2506500482559204,1.21785306930542,1.1877318620681763,1.1599819660186768,1.1344068050384521,1.1107971668243408,1.0890082120895386,1.068879246711731,1.0502262115478516,1.0329142808914185,1.0168145895004272,1.0018080472946167,0.9877578616142273,0.9745558500289917,0.9621409177780151,0.9504204392433167,0.9392716884613037,0.9286280274391174,0.9184239506721497,0.9086080193519592,0.8991463780403137,0.8900013566017151,0.8811401128768921,0.8725287318229675,0.8641600012779236,0.8560135364532471,0.8480657339096069,0.8402891755104065,0.8326666355133057,0.8251855373382568,0.8178336024284363,0.8105982542037964,0.8034707903862,0.7964456677436829,0.789509117603302,0.7826615571975708,0.7759035229682922,0.7692330479621887,0.7626498937606812,0.7561543583869934,0.7497443556785583,0.7434067130088806,0.7371415495872498,0.7309558987617493,0.7248573303222656,0.7188395857810974,0.712902843952179,0.7070463299751282,0.701269805431366,0.6955726742744446,0.689956784248352,0.6844145655632019,0.6789436340332031,0.6735477447509766,0.6682228446006775,0.6629712581634521,0.6577857732772827,0.6526703238487244,0.647622287273407,0.6426405310630798,0.6377227306365967,0.6328656673431396,0.6280747652053833,0.6233444213867188,0.6186732649803162,0.6140604019165039,0.6095000505447388,0.6049915552139282,0.6005343794822693,0.5961288213729858,0.5917719006538391,0.5874656438827515,0.583209753036499,0.5790040493011475,0.5748483538627625,0.5707415342330933,0.5666816830635071,0.5626733899116516,0.5587128400802612,0.5547974705696106,0.5509264469146729,0.5470974445343018,0.5433101654052734,0.5395610332489014,0.5358248353004456,0.5321248769760132,0.5284604430198669,0.5248323082923889,0.5212408900260925,0.5176855325698853,0.5141655802726746,0.5106820464134216,0.5072359442710876,0.5038260221481323,0.5004509687423706,0.49711135029792786,0.49380677938461304,0.490537166595459,0.48730334639549255,0.484104186296463,0.48093900084495544,0.4778079688549042,0.47471097111701965,0.47165000438690186,0.46862098574638367,0.465625137090683,0.46265971660614014,0.4597245752811432,0.45681941509246826,0.4539435803890228,0.45109719038009644,0.4482806622982025,0.4454905390739441,0.4427284300327301,0.439993679523468,0.437286376953125,0.4346085786819458,0.4319588840007782,0.429334819316864,0.4267362654209137,0.42416349053382874,0.4216196835041046,0.4191025197505951,0.41661185026168823,0.41414743661880493,0.411700040102005,0.40927281975746155,0.40686920285224915,0.40448883175849915,0.4021313488483429,0.39979687333106995,0.3974849283695221,0.3951960802078247,0.3929295837879181,0.3906857371330261,0.3884647488594055,0.3862619996070862,0.3840765655040741,0.38191017508506775,0.3797634541988373,0.37763816118240356,0.3755340874195099,0.37345021963119507,0.371385782957077,0.36934077739715576,0.36731836199760437,0.36531397700309753,0.3633279800415039,0.3613608777523041,0.3594112694263458,0.35747912526130676,0.35556095838546753,0.3536592423915863,0.3517764210700989,0.3499084711074829,0.34805724024772644,0.3462228775024414,0.34440183639526367,0.3425903618335724,0.3407961130142212,0.3390182554721832,0.3372565507888794,0.3355104625225067,0.33378079533576965,0.3320690095424652,0.33037126064300537,0.3286886513233185,0.32701969146728516,0.3253660500049591,0.32372698187828064,0.32210302352905273,0.32049426436424255,0.31890085339546204,0.31732168793678284,0.3157539963722229,0.31419986486434937,0.3126596212387085,0.31113365292549133,0.3096212148666382,0.3081218898296356,0.3066357970237732,0.30516016483306885,0.30369725823402405,0.30224642157554626,0.3008083403110504,0.29938411712646484,0.2979711592197418,0.2965623438358307,0.29516351222991943,0.2937760055065155,0.292399525642395,0.29103508591651917,0.28968411684036255,0.28834623098373413,0.28702038526535034,0.28570613265037537,0.2843984067440033,0.2830964922904968,0.2818048298358917,0.28052377700805664,0.279253751039505,0.2779935300350189,0.2767431139945984,0.2755032777786255,0.2742742598056793,0.2730550467967987,0.271846204996109,0.27064767479896545,0.2694593667984009,0.26828110218048096,0.2671126425266266,0.2659550905227661,0.26480600237846375,0.2636656165122986,0.2625327706336975,0.26140791177749634,0.2602902352809906,0.2591804265975952,0.2580784857273102,0.2569856345653534,0.2559017539024353,0.2548266053199768,0.2537599503993988,0.25270187854766846,0.25165238976478577,0.2506128251552582,0.24957707524299622,0.24854519963264465,0.24751617014408112,0.2464921623468399,0.24547500908374786,0.24446582794189453,0.24346370995044708,0.2424669861793518,0.24147586524486542,0.2404918521642685,0.23951512575149536,0.23854587972164154,0.23758374154567719,0.23662908375263214,0.23568083345890045,0.23473875224590302,0.23380479216575623,0.23287786543369293,0.23195841908454895,0.23104624450206757,0.23014135658740997,0.22924351692199707,0.2283526211977005,0.227468341588974,0.22659118473529816,0.2257213294506073,0.22485844790935516,0.2240029275417328,0.22315411269664764,0.22231195867061615,0.221476212143898,0.22064609825611115,0.21982219815254211,0.21900463104248047,0.21819277107715607,0.21738380193710327,0.21657714247703552,0.21577595174312592,0.21498042345046997,0.21419037878513336,0.21340586245059967,0.21262675523757935,0.21185387670993805,0.21108539402484894,0.21031898260116577,0.20955495536327362,0.2087957113981247,0.20804138481616974,0.2072920948266983,0.20654739439487457,0.2058064341545105,0.2050701230764389,0.20433856546878815,0.20361165702342987,0.20288978517055511,0.2021729201078415,0.20146073400974274,0.20075339078903198,0.20005100965499878,0.19935360550880432,0.19865919649600983,0.19796784222126007,0.1972808986902237,0.19659866392612457,0.19592128694057465,0.19524841010570526,0.19457998871803284,0.19391585886478424,0.1932562291622162,0.19260074198246002,0.1919497400522232,0.19130262732505798,0.19065925478935242,0.19002003967761993,0.18938502669334412,0.18875417113304138,0.18812738358974457,0.18750491738319397,0.1868867129087448,0.1862727701663971,0.18566298484802246,0.1850574016571045,0.184456005692482,0.18385817110538483,0.18326431512832642,0.1826736181974411,0.1820860058069229,0.18150223791599274,0.18092182278633118,0.1803378164768219,0.17975668609142303,0.17917856574058533,0.17860369384288788,0.17803210020065308,0.17745783925056458,0.176884725689888,0.1763152927160263,0.17574851214885712,0.1751842498779297,0.17462261021137238,0.17406396567821503,0.1735084056854248,0.17295221984386444,0.17239829897880554,0.171847403049469,0.17129941284656525,0.17075394093990326,0.17021097242832184,0.16966767609119415,0.16912667453289032,0.16858839988708496,0.16805295646190643,0.16751807928085327,0.16698585450649261,0.1664564162492752,0.16592948138713837,0.16540545225143433,0.1648835390806198,0.16436322033405304,0.16384537518024445,0.16333064436912537,0.16281822323799133,0.16230687499046326,0.16179688274860382,0.16128818690776825,0.1607811599969864,0.16027513146400452,0.15976864099502563,0.15926454961299896,0.1587611585855484,0.15825578570365906,0.15775249898433685,0.15725158154964447,0.1567533165216446,0.1562577784061432,0.155765101313591,0.15527473390102386,0.15478229522705078,0.15428726375102997,0.15379364788532257,0.15330234169960022,0.15281322598457336,0.15232624113559723,0.15184007585048676,0.15135566890239716,0.15087340772151947,0.1503905951976776,0.14990948140621185,0.14943048357963562,0.14895333349704742,0.14847786724567413,0.14800332486629486,0.14752914011478424,0.14705699682235718,0.14658717811107635,0.14611701667308807,0.14564712345600128,0.14517898857593536,0.14471298456192017,0.14424929022789001,0.14378824830055237,0.1433294713497162,0.14287294447422028,0.14241865277290344,0.14196662604808807,0.14151731133460999,0.14107029139995575,0.14062580466270447,0.14018358290195465,0.139743834733963,0.13930465281009674,0.13886715471744537,0.1384320706129074,0.13799943029880524,0.13756918907165527,0.1371411681175232,0.1367153525352478,0.13629163801670074,0.13587042689323425,0.1354518085718155,0.1350356787443161,0.1346217840909958,0.134210005402565,0.13380040228366852,0.13339169323444366,0.13298457860946655,0.13257938623428345,0.13217636942863464,0.13177582621574402,0.13137772679328918,0.13098189234733582,0.1305921971797943,0.13020260632038116,0.12981347739696503,0.12942631542682648,0.12904368340969086,0.12866352498531342,0.1282854974269867,0.12790964543819427,0.12753614783287048,0.127164825797081,0.1267956793308258,0.12642881274223328,0.1260642409324646,0.12570138275623322,0.12534059584140778,0.12497898936271667,0.12461873888969421,0.1242607906460762,0.12390526384115219,0.12355121970176697,0.12319878488779068,0.1228453740477562,0.12249331921339035,0.12214244157075882,0.12179319560527802,0.12144573032855988,0.12110010534524918,0.12075633555650711],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"mode\":\"lines\",\"name\":\"IS MSE\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557,0.5370444280112557],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"mode\":\"lines\",\"name\":\"Train MSE\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[3.73666380701896,6.005271011186099,5.860280605529539,5.699836905217539,5.540609370236035,5.37411740025864,5.200679713405631,5.032465774929527,4.86854034180577,4.706265114043773,4.545915474424559,4.38617318333685,4.220126266734122,4.063279198498961,3.909622614335248,3.7574086325128455,3.6095993040080203,3.467427476522446,3.332730645181571,3.2032473473478515,3.078220528210451,2.9573412416058984,2.844003406019254,2.738527660294698,2.6402560309044145,2.5520637966268653,2.4686031316003967,2.388847823097703,2.3124711224948875,2.239099626036363,2.170060295636574,2.1042899226424137,2.0386385182954783,1.9754045434536769,1.9149816896819265,1.855934494755732,1.7979153939380903,1.7416788195369504,1.6875948231428421,1.6369696207705193,1.5885120454902348,1.5354293580927956,1.4844248106993305,1.4360176140385774,1.3893532046525814,1.3441349433101974,1.3009139275927313,1.2595710477637332,1.2199628285436614,1.1819710640990055,1.144102533993172,1.1058576538293317,1.0688315183449157,1.033106796459091,0.9985620675035256,0.9655743115443302,0.9344790238512369,0.9043203678084313,0.875608104334159,0.8483729269505468,0.8225449526799,0.7984397856715324,0.7756410316954576,0.7540841356636445,0.7337279079770124,0.7144833527043879,0.6963267156981828,0.6792152158369072,0.6631130798147855,0.6479909809961236,0.6357241612712133,0.6247781504775402,0.6140855259687087,0.603660721128115,0.5935241811159738,0.5836879730426237,0.5741610821934371,0.5649514231677403,0.5560968116748758,0.5475740259517602,0.5402007964800164,0.5339979310274133,0.5281271530745755,0.5225559692947142,0.5172540620149364,0.5122384098456851,0.5075444536178467,0.503215011475386,0.49915696935651854,0.49531500886439944,0.49168097118144516,0.4882597386436434,0.4850298587402716,0.4819717114010312,0.47909218419930716,0.47638375080400697,0.4738797499652218,0.4716370624463451,0.4695498207653334,0.46758585193527963,0.46574221804320537,0.4640097217691302,0.46242476756426787,0.46096201240453677,0.4596101248077193,0.45836128095448186,0.4572216333676086,0.4561832360120501,0.4552348179656228,0.45441095825786904,0.4536649984063777,0.45302067779580196,0.45247585358407194,0.4520362910520635,0.4517078641039135,0.4514347777395885,0.4512104273126449,0.45103227706453386,0.45089083214841996,0.4507849904580383,0.4509148995389901,0.45134350242324606,0.4517875562852743,0.45224029725841497,0.45269676488374383,0.4528078080569864,0.4528459940640871,0.45285672293223084,0.45286023502007083,0.4528676236067325,0.45288318979343317,0.45290236022523134,0.4529283438300932,0.4529797006699312,0.45304301678918035,0.4531135835011482,0.45322690307769403,0.4533776631408172,0.4535498311455205,0.45382725632254095,0.45410105386133104,0.4543943930035429,0.45468972763630183,0.45498380120559156,0.45528382915714094,0.4555891648021867,0.45590200115950186,0.4562229226714123,0.45655055266539785,0.4568893986302651,0.4572448285476576,0.45759807616194004,0.45795465331253465,0.4583529751040594,0.4587650352711277,0.45918417083184265,0.45965952207072536,0.4601624395140343,0.46069841039854265,0.46124393055810503,0.4617937311794573,0.46234478432565507,0.4628943451737933,0.46343826897384505,0.46399104216427944,0.46455167278922077,0.46511367709782026,0.4656303657217412,0.4661351804736902,0.4666445079551645,0.4671572100658844,0.46767229596143334,0.46819180282563905,0.46873722015268193,0.4692942341068062,0.46985679600013097,0.4704212819346088,0.47098887322000493,0.4715572647398759,0.4721247336121968,0.4727461979977668,0.47337573341253963,0.47400438411520474,0.47463231104140646,0.4752591928256608,0.47588535988120834,0.47651141044944584,0.477135702424877,0.47775975811831584,0.4783851785984897,0.4790174304464495,0.47963571697413754,0.48024127731924887,0.48083914002811656,0.48143756542123,0.482033596241584,0.48261482177060555,0.4831734492303441,0.48372886928529,0.4842821813399647,0.48501385110391976,0.4859575903823311,0.48698626272633744,0.4880035117653563,0.48900624448676405,0.4899969713749936,0.4909749809793985,0.4919403304674301,0.4928938863221895,0.4938408074351782,0.49477464616192446,0.4956924789416266,0.49659105763587064,0.49749510937180935,0.49838138668234444,0.49924946209839305,0.500100288864378,0.500934851028638,0.50175582738586,0.5025649727515423,0.5033552445238926,0.5041300980247221,0.5048345103629055,0.5055255867005388,0.506204624948634,0.5068710872842331,0.5075253873518737,0.5081729921224439,0.5088101260588951,0.5093937732441306,0.5099578277791537,0.5105113406644451,0.511054957736789,0.5115885601827349,0.5121119755161512,0.5126305920813296,0.5131557003682888,0.5136734219724043,0.5141824869859927,0.5146840967147595,0.5151816922416342,0.5156720070742844,0.5161501369183008,0.5166187975376224,0.5170781703694178,0.5175281370909962,0.5179648279689703,0.5183952035262338,0.5188143710529007,0.5192282320225716,0.5196378162241194,0.5200478671641069,0.5204562029386072,0.5208607557092723,0.5212609332091064,0.521657841127268,0.5220564091271783,0.522454375019341,0.5228489526782614,0.5232403308947783,0.5236291462226471,0.5240165846771379,0.5244036012095578,0.5247883157280677,0.525168411112906,0.5255463942554496,0.5259179773819631,0.5262766935445686,0.5267014914451442,0.5271188950229364,0.527561621552168,0.5280582411494686,0.5285404723501841,0.529001975167042,0.5294541302721285,0.5298981364907379,0.5303337009489527,0.5307612443475206,0.531180465285975,0.531595780150079,0.5320153355233311,0.5324573100166019,0.5329104861186869,0.5333862186588578,0.5338529622195535,0.5343071117066123,0.5347466750469175,0.53517335641043,0.5355866833137906,0.5359872998050953,0.536377762938667,0.5367818038820016,0.5371662041391738,0.5375276264138412,0.5378779635475816,0.5381716370351401,0.5384320399615332,0.5386771172412588,0.5389256968761936,0.5391756146373107,0.5394189539891797,0.5396576460605398,0.5398902646884352,0.5401183066153846,0.5403410142922794,0.5405591526466521,0.5407740750517948,0.5409859116709907,0.5411970191603258,0.5414079872315412,0.5416154166280948,0.5418210236655722,0.5420190173054856,0.5422136135185656,0.5424062474044484,0.5425963980096187,0.5427863583984007,0.5429706993864504,0.5431483183989928,0.5433197140277184,0.5434860552624541,0.5436478463721364,0.5438094886553136,0.5439716229091827,0.5441277430128005,0.5442906339792413,0.5444598502842563,0.5446092324796067,0.5447528019667796,0.544885238411406,0.5450103966200482,0.545158122458201,0.5453101660667838,0.5454608998119342,0.5456115196599562,0.54576285948763,0.5459140202674072,0.5460671582181137,0.546220588862996,0.5463748601301208,0.5465675207218001,0.5467707124732271,0.5469708048590975,0.5471678671905761,0.5473632065516939,0.5475576365900857,0.5477499138555396,0.5479401606847017,0.5481274893189155,0.5483128321030579,0.5485134847219681,0.5487308181839283,0.5489471445111072,0.5491638882661077,0.5493795307037566,0.5495942306680394,0.5498083965249347,0.5500220939596685,0.5502351795186422,0.5504480376574098,0.5506614882484065,0.5508751164801333,0.5510883272021293,0.5513007768400148,0.5515125197746636,0.5517227114263615,0.5519319244066819,0.552139191138015,0.5523447876475934,0.5525334270983695,0.5523321955321349,0.5521157446427164,0.5518874879645143,0.5516511224803895,0.5514094013122545,0.5512519301612298,0.551095539841558,0.55092159225786,0.5507416565761128,0.5505595450742131,0.5503816067250241,0.5502055358031381,0.5500327344967996,0.5498498864454714,0.549671056121301,0.5494995908033528,0.549335979426412,0.5491784307580665,0.5490276584684533,0.5488807529437625,0.5487347891897473,0.5485896657448387,0.5484549119566213,0.5483214934576559,0.5481875132967141,0.5480568054517166,0.5479294251422286,0.5478069745973518,0.5477014991327624,0.5476092659278615,0.5475226468834614,0.5474273006549116,0.5482605404717447,0.5495748159650415,0.5509046774823192,0.5522464817068692,0.5535951362549008,0.5549415546419413,0.5562845266356004,0.5576285484082824,0.5589697028177633,0.5603042716711369,0.5616300664002062,0.5629445945829586,0.564244762710292,0.5655270847220477,0.5661103797015112,0.5664260139782988,0.5667312073304609,0.5670277728558456,0.5672989231540341,0.5675353967903528,0.567753181656478,0.5679478562253532,0.5681276302117244,0.5682936827987486,0.5684475112016159,0.5685898064433033,0.5687210393405172,0.568842367372323,0.5689548289307976,0.5690593298469393,0.5691566407332856,0.569245426617464,0.5693243244741631,0.5693969497822713,0.5694578952271884,0.5695164086717275,0.5695718813751571,0.5696244837407366,0.5696751215696264,0.5697244232134918,0.5697746050090436,0.5698242142361994,0.5698724104012278,0.5699199168677193,0.5699672061769199,0.5700156276321793,0.5700662429878164,0.5701191094410251,0.5701754943975007,0.5702370704058324,0.5703007676716577,0.5703654188994204,0.5704310344479744,0.5705012372728129,0.5705767706887155,0.5706564894948996,0.5707382023650336,0.5708251218419111,0.5709218660056586,0.5710202623438837,0.5711196136248315,0.571217916010194,0.5713166782443093,0.571416736157781,0.5715191052453872,0.5716094010445181,0.5716919928201802,0.5717770850089374,0.5718799294600931,0.5719827773594959,0.5720521925771931,0.572158684073879,0.5722867913485081,0.5724263612532247,0.5725528336253137,0.5726776080176214,0.5728026528518831,0.5729273819481842,0.573048760126018,0.5731702224480328,0.5732916469624005,0.5734132736767487,0.5735353385874883,0.5736575748190419,0.5737786384563014,0.5738750821380119,0.573956292778643,0.5740329818227528,0.5741078190008796,0.5741895663353852,0.5742764551586615,0.5743707992785577,0.5744661375275827,0.5745548851901524,0.5746478508140296,0.5747398654262391,0.5748306294189337,0.5749209824114987],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"mode\":\"lines\",\"name\":\"Test MSE\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.36733111309859245,0.38607521320450716,0.4042506666640754,0.4224839812304839,0.44114195722487587,0.4496801821418303,0.45283491616099936,0.45583768020223814,0.4584951133471902,0.4611994076792136,0.4639044408760906,0.4668522767525534,0.46995112398250344,0.47311037021556335,0.4762972412189937,0.4795075795731203,0.4827165929500369,0.48592630963819683,0.4891422996492114,0.4923825953089277,0.49555662116329524,0.49874126541623326,0.5018144299246527,0.5047495023310495,0.5077002388927893,0.5106443523531544,0.5137575459344901,0.5169658631976207,0.5201820919738535,0.5233988687576709,0.5266132307121242,0.5298306473556488,0.5330406963620404,0.5362306305249376,0.5393957647392229,0.5425331153812482,0.5456393391854687,0.5487074921753582,0.5517313799355752,0.5547079357973519,0.5576344327663981,0.560493191327486,0.5632824121738065,0.5659989033646214,0.5685771809258465,0.571053988670861,0.5734474520931979,0.5757541821245308,0.5779702888248751,0.5802085539485293,0.582450814500542,0.5846171184872544,0.5866977645536233,0.5886837830141585,0.5905690546618323,0.5923516068075937,0.5940218497617259,0.5955738209222913,0.5970056357597766,0.5983241577015084,0.5996030853709859,0.600771359356524,0.601804627713445,0.6027054918128972,0.6034738700096047,0.6041077005621251,0.6046090774505491,0.604984881333683,0.6052350690532295,0.6053589395974059,0.6053596314340483,0.6051961791097189,0.6048781531334457,0.6044179066248568,0.6038273256425858,0.6031177199574959,0.6022997715942752,0.6013839212056192,0.600379823793402,0.5992962821349029,0.5981446583567278,0.596942767714657,0.5956953749859707,0.5944048883106897,0.5930767554169061,0.5917142811718028,0.5903197825547074,0.5888962457686083,0.5874512098476861,0.585985497152957,0.5845000940884305,0.5829988076157668,0.5814850250444675,0.5799585810114334,0.5784254748058737,0.5768904568164377,0.5753578520976996,0.5738281266037754,0.5723010832810927,0.5707812695436074,0.5692710138450386,0.5677724650557997,0.5662876637849342,0.5648189148347521,0.5634007286423759,0.5620092592501893,0.560634833080377,0.5592781125734947,0.5579399394695286,0.5566206241029784,0.5553207763162201,0.5540410923314,0.5527815183981389,0.5515428379152449,0.5503249542765483,0.549128823876842,0.5479575904660596,0.5468118705515689,0.5456891572564935,0.5445880620004933,0.5435091613194211,0.5424505795596797,0.5414121809347424,0.5403938255114961,0.539395256010526,0.5384389378548592,0.5375318259502906,0.5366630915307044,0.5358134534720717,0.5349827623836823,0.534169909381368,0.5333736395997308,0.5325930611245043,0.5318289553492817,0.5310809936809189,0.5303485910047416,0.5296315206644631,0.5289290932694443,0.5282408520590721,0.5275647821075294,0.5269008567153485,0.5262487857095097,0.5256082659460367,0.524979059527734,0.524360663969607,0.5237530141459683,0.5231521947068725,0.5225447145606809,0.521934088065789,0.5213334363896971,0.5207393452905086,0.520152212826262,0.5195743539046458,0.5189965238519076,0.5184253975052258,0.51786310275797,0.5173092632874463,0.5167635892728699,0.5162260814563268,0.5156969182858402,0.515176080572292,0.5146632797158756,0.5141586208766494,0.5136617853213102,0.5131717082826762,0.5126886590846039,0.5122128159511695,0.5117440436934593,0.5112818503201438,0.5108259201306529,0.5103762758200231,0.5099329130877247,0.5094958234033314,0.5090647532708361,0.5086398998324458,0.5082209170409112,0.507780551019277,0.5073368886586813,0.5068993447853026,0.5064687305086145,0.5060448899890757,0.5056227415728739,0.505205460104633,0.5047928854933917,0.5043851075629111,0.5039819234352264,0.5035832960996977,0.5031891300655994,0.5027994717554913,0.5024135813098405,0.5020290965398213,0.5016488781258812,0.5012720628530958,0.5008982873613628,0.5005276208708985,0.5001603970940508,0.4997978680160441,0.49949094836254365,0.49918692446650287,0.4988859764801507,0.498588104347488,0.4982929129785163,0.4979993434871614,0.49770752932058415,0.4974175697713737,0.49712983847580283,0.49684426250530406,0.49656124574229654,0.4962807561997829,0.49600252571640924,0.4957266737083685,0.49545307964420304,0.49519627175559666,0.4949624329661684,0.49472989932724853,0.49449884308734426,0.4942722970770287,0.494049633203259,0.4938289448799619,0.4936104362318643,0.4933943932861058,0.4931803284739796,0.492968385792374,0.4927587290449915,0.49254693517763154,0.49218951638370556,0.49183508330669673,0.4914837972765551,0.491135683842688,0.4907907095925177,0.49044902657187917,0.4901107937736549,0.48977594711314687,0.4894445336762543,0.48911652569875386,0.4887895238311407,0.48846410531885676,0.48812930786180597,0.4877946570035724,0.48746318173948394,0.48713493229266214,0.48680992146972096,0.48648738209533066,0.48616695555870215,0.48584883463899387,0.4855330177950425,0.4852196333376901,0.48490902613778514,0.48460164364305125,0.48429752712796004,0.4839967427889095,0.4836991355787806,0.48340370559348006,0.4831103698839381,0.4828191495094835,0.48253032745211116,0.4822439624946478,0.4819599942996529,0.48167847978519374,0.481399540197182,0.4811231327730467,0.4808494594038802,0.480578397218062,0.4803101463282839,0.48004466156283365,0.47978192654163576,0.47952179291801883,0.47926417840014196,0.47900873405610866,0.4787547621313006,0.47849430285061056,0.47822550920937873,0.4779586775180385,0.47769493832451126,0.4774335053081835,0.47717443274841803,0.4769176396921653,0.4766631857895151,0.47641120657638036,0.47616152145072155,0.4759142284578732,0.4756695882361556,0.47542596555121425,0.4751805592088722,0.47493525577911555,0.4746901377819516,0.47444615460086054,0.47420311669550474,0.47396116530745075,0.4737198990206672,0.47347938167642556,0.47323986875227675,0.47300153725569327,0.47276446564888736,0.4725288886199431,0.47230066714112146,0.4720781226160262,0.47186092034184723,0.4716453588067711,0.4714316163948372,0.47121981204415364,0.47100998424486845,0.470802331417644,0.4705969754609313,0.47039419387113285,0.47019355948624264,0.46999519348737495,0.469799346612157,0.4697794845699726,0.4697627959156513,0.46974740658058134,0.46973331720928185,0.4697204863568234,0.4697090912994443,0.46969909269567833,0.46969045214315286,0.46968316914942804,0.46967740680492887,0.46967302614839945,0.4696700900791469,0.4696684406988858,0.4696679977825767,0.4696687645984815,0.469670899058571,0.4696744240939975,0.46967901694600056,0.4696836119503956,0.4696883716672645,0.4696933943544636,0.4696986647913732,0.46970434065907823,0.469710363480174,0.46971677326591893,0.4696714136418198,0.4696013177869422,0.4695513501984749,0.4695020075708275,0.46945345186042686,0.4694056621353725,0.4693586008529139,0.4693123469397035,0.46926694002485914,0.469222416472292,0.4691789968500248,0.46913654073671524,0.46909506880257495,0.46905462345004445,0.4690152400930437,0.4689768229802637,0.46893907552223796,0.46890233031581996,0.46886667043257946,0.4688320328939912,0.46879821964043267,0.46876532563836026,0.4687372929923774,0.4687099818078347,0.468683449744872,0.46865763761795504,0.46863258648620537,0.46860831638170025,0.4685847891535605,0.46856206013337853,0.4685401334538591,0.4685213599180404,0.46850466915666744,0.46848871691010974,0.4684734650556855,0.4684589722002623,0.46844511870156286,0.46843232129020457,0.4684199356689352,0.4684075595748674,0.46839605892119685,0.4683852182901026,0.4683750748095691,0.46836521033126766,0.468355526036663,0.46834618541679074,0.46833702496713925,0.4683274194113966,0.4683180561517229,0.46830879457200014,0.46829969818962786,0.4682907399286059,0.46828206318463694,0.46827354556975204,0.46826519080514883,0.46825695615367635,0.46824876685695155,0.4682406972031079,0.4682326091517564,0.46822452558270433,0.46821636731932864,0.46820821563502496,0.4682000271004306,0.4681918435157475,0.46818378585387627,0.46817577191174287,0.468167321762673,0.46815857414347506,0.4681495692298049,0.46814030958991787,0.4681314617712225,0.4681231462623397,0.46811544314956666,0.4681084122020695,0.46810181706756976,0.4680957306181361,0.46809025675050187,0.4680854363187554,0.46808230633229925,0.4680801592888256,0.46807872939602213,0.4680785805928709,0.4680793479041386,0.4680810357588166,0.4680839750934136,0.46808805008394033,0.4680923934577437,0.468096990491817,0.468101821806284,0.4681070079056903,0.4681122108710522,0.46811755260133997,0.4681231519721374,0.46812901131744894,0.46813492980269267,0.468140929841757,0.46814707052543064,0.46815339225891034,0.4681598973748791,0.46816675709551986,0.4681740143942931,0.4681816882032622,0.46818978039718673,0.46819767136058454,0.4682045417598174,0.46821045345589146,0.46821562807233386,0.46822008637867674,0.4682240892513432,0.4682276981061602,0.4682309528772526,0.4682339946315354,0.4682366404903042,0.46823903454861493,0.4682411931651254,0.4682431777622256,0.46824504766774366,0.4682466844538806,0.46824818738982305,0.46824971577450447,0.46825130908397067,0.46825298787162756,0.46825485164336744,0.46825694336955737,0.46825912220745447,0.4682610485329061,0.46826410299066507,0.46826707990926325,0.46826980245593625,0.4682723754904884,0.4682747959842668,0.468277004835718,0.46827888291130754,0.4682753725361331,0.46826782469668954,0.46826008766845856,0.46825218247475153,0.4682441107494957,0.4682359112743739,0.4682275641985042,0.4682191694946124,0.46821066830097136,0.46820211878479184,0.4681935419653027,0.46818491799012835,0.4681762863344112,0.4681676264471244,0.46815907869641876,0.4681435288208395,0.46812063198729803,0.468097418289862,0.46807449772022813,0.468051696026283,0.4680288585907112,0.46800494631129624,0.4679801778432015,0.46795459411572443,0.4679283376243259,0.46790144765536956,0.4678741238964252,0.4678470579219199,0.46781904733010476,0.46779035228828103,0.46776079263182563,0.4677307272617943,0.46770013824825224,0.46767285363381716],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.45],\"title\":{\"text\":\"Epoch\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.625,1.0],\"title\":{\"text\":\"Estimate\"}},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.55,1.0],\"title\":{\"text\":\"Epoch\"}},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.625,1.0],\"title\":{\"text\":\"Variance\"}},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.0,0.45],\"title\":{\"text\":\"Epoch\"}},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,0.375],\"title\":{\"text\":\"MSE Loss\"}},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.55,1.0],\"title\":{\"text\":\"Epoch\"}},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.0,0.375],\"title\":{\"text\":\"MSE\"}},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Estimate over Epochs\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Variance over Epochs\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Shaping Train MSE Loss over Epochs\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Total MSE over Epochs\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Metrics over Epochs\"},\"showlegend\":true},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('8970c92f-3429-47cd-a963-e242f1e1deb0');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"5069988b-e498-4a52-b006-31732bedaac0\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"5069988b-e498-4a52-b006-31732bedaac0\")) {                    Plotly.newPlot(                        \"5069988b-e498-4a52-b006-31732bedaac0\",                        [{\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"z\":[[0.05598258599638939,0.05535392090678215,0.05435295030474663,0.05221900716423988,0.043486110866069794,0.0347532220184803,0.02602034993469715,0.01728745922446251,0.008554574102163315,-0.00017831847071647644],[0.05131860449910164,0.060534194111824036,0.061612632125616074,0.0618019737303257,0.05388031527400017,0.045958660542964935,0.038037002086639404,0.030115347355604172,0.022193673998117447,0.014272019267082214],[0.04698013514280319,0.04903603345155716,0.05370791628956795,0.05602504685521126,0.058342184871435165,0.05463048815727234,0.046708837151527405,0.03878719359636307,0.030865531414747238,0.02294386923313141],[0.04447087273001671,0.039345815777778625,0.04660928249359131,0.04544564336538315,0.04776277765631676,0.05007991939783096,0.05116323381662369,0.047459036111831665,0.03953738883137703,0.03161570802330971],[0.03840417414903641,0.032151881605386734,0.03691905736923218,0.03992980718612671,0.03873053938150406,0.03950050473213196,0.04181763529777527,0.044134773313999176,0.043652668595314026,0.04028754681348801],[0.03233747184276581,0.025768980383872986,0.028583375737071037,0.03449229523539543,0.032133594155311584,0.03210986778140068,0.03265836834907532,0.03355538845062256,0.03587252274155617,0.03818967938423157],[0.026270771399140358,0.01938607543706894,0.02220047637820244,0.02501486800611019,0.02991541475057602,0.02494068630039692,0.02548917755484581,0.02603769674897194,0.026586193591356277,0.027610260993242264],[0.020204074680805206,0.013003170490264893,0.015817563980817795,0.018631968647241592,0.022375304251909256,0.022119194269180298,0.01832001283764839,0.01886848732829094,0.01941700652241707,0.019965507090091705],[0.01566767692565918,0.008621461689472198,0.00943465530872345,0.012249063700437546,0.015063468366861343,0.019901029765605927,0.014322996139526367,0.011699318885803223,0.012247826904058456,0.012796338647603989],[0.011524733155965805,0.004478964954614639,0.0030517540872097015,0.005866151303052902,0.008680541068315506,0.0114949531853199,0.012104813009500504,0.006526775658130646,0.005078654736280441,0.00562715157866478]],\"type\":\"heatmap\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"Values\"},\"ticks\":\"outside\",\"tickvals\":[-0.00017831847071647644,0.0618019737303257],\"ticktext\":[-0.00017831847071647644,0.0618019737303257]}},\"xaxis\":{\"tickvals\":[0,1,2,3,4,5,6,7,8,9],\"ticktext\":[0,1,2,3,4,5,6,7,8,9],\"title\":{\"text\":\"X\"}},\"yaxis\":{\"tickvals\":[9,8,7,6,5,4,3,2,1,0],\"ticktext\":[9,8,7,6,5,4,3,2,1,0],\"title\":{\"text\":\"Y\"},\"autorange\":\"reversed\"},\"title\":{\"text\":\"Heatmap\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('5069988b-e498-4a52-b006-31732bedaac0');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"a9bb3fd9-f071-4d39-813f-438a73c947a5\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a9bb3fd9-f071-4d39-813f-438a73c947a5\")) {                    Plotly.newPlot(                        \"a9bb3fd9-f071-4d39-813f-438a73c947a5\",                        [{\"colorbar\":{\"title\":{\"text\":\"Visits\"}},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"x\":[0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9],\"y\":[9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0],\"z\":[0,120,361,880,2275,2317,2369,2199,1680,1696,0,229,594,1589,1836,0,874,1236,1097,1822,0,437,1216,1554,712,0,330,411,621,1832,0,879,1023,522,244,0,89,164,262,451,0,750,427,192,83,0,30,52,77,109,188,486,185,81,30,4,3,8,12,19,44,97,46,24,8,6,3,6,14,21,10,21,14,6,3,7,10,11,13,18,0,3,5,1,2,6,4,11,13,16,0,0,1,0,0,3,3,5,10,13],\"zmax\":2369,\"zmin\":0,\"type\":\"heatmap\"}],                        {\"title\":{\"text\":\"State Visitations Heatmap\"},\"xaxis\":{\"title\":{\"text\":\"X-axis\"}},\"yaxis\":{\"ticktext\":[9,8,7,6,5,4,3,2,1,0],\"tickvals\":[0,1,2,3,4,5,6,7,8,9],\"title\":{\"text\":\"Y-axis\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('a9bb3fd9-f071-4d39-813f-438a73c947a5');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000 trajectories:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"588787dd-8b73-4a62-baf3-072f9086af03\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"588787dd-8b73-4a62-baf3-072f9086af03\")) {                    Plotly.newPlot(                        \"588787dd-8b73-4a62-baf3-072f9086af03\",                        [{\"mode\":\"lines\",\"name\":\"IS Estimate\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653,0.24946586787700653],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"Train Estimate\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[1.8140969276428223,-2.2111804485321045,-2.1750316619873047,-2.1375417709350586,-2.0989933013916016,-2.059734344482422,-2.0188400745391846,-1.9782140254974365,-1.938026785850525,-1.8959697484970093,-1.8527936935424805,-1.8104079961776733,-1.7685798406600952,-1.7264649868011475,-1.6839648485183716,-1.641515851020813,-1.5994025468826294,-1.5584081411361694,-1.5180257558822632,-1.478352427482605,-1.4385367631912231,-1.3981530666351318,-1.3582987785339355,-1.3188506364822388,-1.2800004482269287,-1.2387564182281494,-1.1986689567565918,-1.15952730178833,-1.1210254430770874,-1.0815064907073975,-1.0424875020980835,-1.0042113065719604,-0.9665166735649109,-0.9293673634529114,-0.8930261731147766,-0.8576394319534302,-0.8230829834938049,-0.7893670201301575,-0.7565714716911316,-0.7244195342063904,-0.6930657029151917,-0.6630442142486572,-0.6336790323257446,-0.6053978800773621,-0.5780695080757141,-0.5515276789665222,-0.5256966948509216,-0.5005763173103333,-0.4761843681335449,-0.4524417519569397,-0.42949581146240234,-0.4073042571544647,-0.3857945203781128,-0.36492642760276794,-0.3447250425815582,-0.3251992166042328,-0.30624204874038696,-0.2879311442375183,-0.2702665328979492,-0.25319111347198486,-0.23670408129692078,-0.22086267173290253,-0.2056914120912552,-0.19115741550922394,-0.17717206478118896,-0.16371923685073853,-0.15079918503761292,-0.13843591511249542,-0.12658539414405823,-0.11523915827274323,-0.10438873618841171,-0.09401534497737885,-0.08411639928817749,-0.07467832416296005,-0.0656801238656044,-0.05711917579174042,-0.04898073151707649,-0.041241955012083054,-0.03382835537195206,-0.026788219809532166,-0.02017221599817276,-0.01391654834151268,-0.008006038144230843,-0.0024232768919318914,0.0028485762886703014,0.007822263054549694,0.012502983212471008,0.016953203827142715,0.021857155486941338,0.026510091498494148,0.03091495670378208,0.035096801817417145,0.039065178483724594,0.042859289795160294,0.046399932354688644,0.049677491188049316,0.05255777761340141,0.05526703968644142,0.05784032493829727,0.0602494515478611,0.06249365955591202,0.06458593159914017,0.06652326881885529,0.0683351531624794,0.07002642005681992,0.07160312682390213,0.07306808233261108,0.07441382855176926,0.07564505934715271,0.07677832990884781,0.07782767713069916,0.07879719883203506,0.07969040423631668,0.08051232993602753,0.08126592636108398,0.08195469528436661,0.08259262144565582,0.0831734910607338,0.08370241522789001,0.08418130874633789,0.08461574465036392,0.08500786125659943,0.08537033945322037,0.08568338304758072,0.08594633638858795,0.08614648878574371,0.08630723506212234,0.08644357323646545,0.08655361086130142,0.08663517981767654,0.0866820216178894,0.08671101927757263,0.08672807365655899,0.08672420680522919,0.08669747412204742,0.08666253089904785,0.08664796501398087,0.08663277328014374,0.08660417795181274,0.08658713102340698,0.08654850721359253,0.08652190864086151,0.0865006074309349,0.08650054037570953,0.08648114651441574,0.08645772933959961,0.08643057197332382,0.08640696108341217,0.08637958765029907,0.08635634928941727,0.08632639050483704,0.08628937602043152,0.08624635636806488,0.08622129261493683,0.08620066940784454,0.08616705238819122,0.08611340820789337,0.08602333813905716,0.08592038601636887,0.0858149379491806,0.08569801598787308,0.08557248115539551,0.08544372767210007,0.08531138300895691,0.08516445010900497,0.0850023552775383,0.08483587950468063,0.08466195315122604,0.08447887003421783,0.08429283648729324,0.08408060669898987,0.08385729789733887,0.08362524956464767,0.0833980068564415,0.08318432420492172,0.08296974748373032,0.082754947245121,0.08253726363182068,0.08232472091913223,0.08211853355169296,0.08191711455583572,0.08170697093009949,0.08149020373821259,0.08127467334270477,0.08106810599565506,0.08086307346820831,0.0806579738855362,0.08045392483472824,0.08025067299604416,0.08005364239215851,0.07985346764326096,0.0796518549323082,0.07944538444280624,0.07923417538404465,0.079037606716156,0.07884041219949722,0.07864031940698624,0.07843782007694244,0.07823269069194794,0.07803234457969666,0.07782833278179169,0.07762925326824188,0.07744213938713074,0.07725325226783752,0.07706258445978165,0.0768599733710289,0.07665203511714935,0.07644104212522507,0.0762285441160202,0.076017364859581,0.0758056789636612,0.07559046894311905,0.07536836713552475,0.07514584809541702,0.07492338865995407,0.07470198720693588,0.07447289675474167,0.07423486560583115,0.07399757951498032,0.07376086711883545,0.07349709421396255,0.07325101643800735,0.07303019613027573,0.07282309234142303,0.07265987247228622,0.07284156233072281,0.07302901893854141,0.07321841269731522,0.07341114431619644,0.07363156229257584,0.0738459900021553,0.07404562830924988,0.0742158442735672,0.07437250763177872,0.07451394945383072,0.07461405545473099,0.07470893859863281,0.07479752600193024,0.0748792216181755,0.0749518945813179,0.07501542568206787,0.07507099956274033,0.07512232661247253,0.07516396045684814,0.07519401609897614,0.07521505653858185,0.07522742450237274,0.07523100078105927,0.07522536814212799,0.07521194219589233,0.07518957555294037,0.07515032589435577,0.07510391622781754,0.07504527270793915,0.0749548077583313,0.07485947757959366,0.0747593492269516,0.07465610653162003,0.07454829663038254,0.07443587481975555,0.07431971281766891,0.07420042902231216,0.07407840341329575,0.0739549770951271,0.07383161783218384,0.07362452894449234,0.07339020073413849,0.07315732538700104,0.07293141633272171,0.07271292805671692,0.07250120490789413,0.07229622453451157,0.07207337766885757,0.07184744626283646,0.07162769138813019,0.07141420245170593,0.07120708376169205,0.07100662589073181,0.07085287570953369,0.0707099512219429,0.07057107239961624,0.07043728977441788,0.07030927389860153,0.07018566876649857,0.07006619870662689,0.0699329599738121,0.06980165094137192,0.0698041319847107,0.0698368102312088,0.06989430636167526,0.06995982676744461,0.07003183662891388,0.07010899484157562,0.07017920911312103,0.07021981477737427,0.07026192545890808,0.0703049898147583,0.07034624367952347,0.07038767635822296,0.07042872160673141,0.07046950608491898,0.07052197307348251,0.07057998329401016,0.07065242528915405,0.07072993367910385,0.0708109512925148,0.07089676707983017,0.07094793021678925,0.07095630466938019,0.07097166031599045,0.07099176943302155,0.0710151344537735,0.07101158797740936,0.07099642604589462,0.07098202407360077,0.07096654176712036,0.07094857096672058,0.07093578577041626,0.07092830538749695,0.07092088460922241,0.07085719704627991,0.07076574862003326,0.07067570835351944,0.07058578729629517,0.07049713283777237,0.07040975987911224,0.07031626254320145,0.07021874934434891,0.07012014091014862,0.07002004235982895,0.06990738958120346,0.06977839767932892,0.06964761763811111,0.06951439380645752,0.06937966495752335,0.06924450397491455,0.06910721957683563,0.06896811723709106,0.0688263326883316,0.06868241727352142,0.06853191554546356,0.06836485862731934,0.06819739937782288,0.06802607327699661,0.06784775853157043,0.06767208874225616,0.06749823689460754,0.06732092797756195,0.06714081019163132,0.06696172803640366,0.06678105890750885,0.06659543514251709,0.06640548259019852,0.06621122360229492,0.06601102650165558,0.06581706553697586,0.06563752144575119,0.06545566767454147,0.06527021527290344,0.0650712251663208,0.06486450135707855,0.06465427577495575,0.06443943083286285,0.06422051787376404,0.06399936974048615,0.0637751892209053,0.06354845315217972,0.06331916153430939,0.06296207755804062,0.06256834417581558,0.06218580901622772,0.061801664531230927,0.06142019107937813,0.06103937327861786,0.060659654438495636,0.06028606742620468,0.05991722270846367,0.059552498161792755,0.05919435992836952,0.05884196609258652,0.058494195342063904,0.05815086513757706,0.05781005695462227,0.05747257545590401,0.057141050696372986,0.05681513622403145,0.05649544671177864,0.05618174374103546,0.05587043613195419,0.055565979331731796,0.055268775671720505,0.05490236356854439,0.05452448129653931,0.05415277183055878,0.05378737300634384,0.05343172699213028,0.05308433994650841,0.0527452751994133,0.05244769901037216,0.0521601065993309,0.051880113780498505,0.0516086183488369,0.05134490877389908,0.051098402589559555,0.050866566598415375,0.05040910467505455,0.04995216056704521,0.0495016984641552,0.049060575664043427,0.04862811043858528,0.04819778725504875,0.047777123749256134,0.0473695769906044,0.046975523233413696,0.046610668301582336,0.046272728592157364,0.04594432935118675,0.04562205821275711,0.04531165957450867,0.04501223936676979,0.04472450166940689,0.04444882646203041,0.044185224920511246,0.043932799249887466,0.043690189719200134,0.04345712810754776,0.043238312005996704,0.043036408722400665,0.04284970462322235,0.042675696313381195,0.04251212626695633,0.04235756769776344,0.042208097875118256,0.04205893725156784,0.041860245168209076,0.04166793078184128,0.04147995635867119,0.0412963330745697,0.040809109807014465,0.04026032239198685,0.03972169756889343,0.0391901470720768,0.03867053613066673,0.0381711944937706,0.03768298774957657,0.037214245647192,0.03675923869013786,0.036321625113487244,0.0358995646238327,0.03549692779779434,0.03511655703186989,0.03475438803434372,0.03441768139600754,0.03410875052213669,0.033815186470746994,0.033546824008226395,0.03329665958881378,0.03305421024560928,0.03282005339860916,0.032596711069345474,0.03237529844045639,0.032154668122529984,0.03195032849907875,0.03175659105181694,0.031571488827466965,0.03139519691467285,0.031227609142661095,0.031068960204720497,0.030918627977371216,0.030775317922234535,0.030637383460998535,0.0305067989975214,0.03037680685520172,0.030253296718001366,0.03013623133301735,0.03002558834850788,0.029920440167188644,0.0298217311501503,0.02972668781876564,0.029634393751621246,0.029546193778514862,0.0294659361243248,0.029389647766947746,0.029315130785107613,0.029243694618344307,0.029173657298088074,0.02910086140036583,0.029032297432422638,0.028965771198272705,0.02889990247786045,0.028831442818045616,0.028763648122549057,0.028696496039628983,0.02862890064716339,0.028561584651470184,0.028495684266090393,0.028427734971046448,0.02835867367684841,0.028288012370467186,0.028217440471053123],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"Test Estimate\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.4266586899757385,0.41093188524246216,0.39616140723228455,0.3819095194339752,0.3677693009376526,0.36074721813201904,0.3583914041519165,0.3562352955341339,0.3542972207069397,0.352343887090683,0.35040801763534546,0.3485490679740906,0.3466246724128723,0.3444938063621521,0.34237977862358093,0.34029847383499146,0.33825647830963135,0.3362405598163605,0.3342368006706238,0.33224743604660034,0.33029815554618835,0.3283837139606476,0.3264847993850708,0.32454466819763184,0.32269996404647827,0.3209105432033539,0.3191389739513397,0.3172606825828552,0.31537970900535583,0.3135323226451874,0.31170859932899475,0.309908002614975,0.30812954902648926,0.30637845396995544,0.30465811491012573,0.30296623706817627,0.30130696296691895,0.2996826171875,0.29809582233428955,0.29654720425605774,0.2950381934642792,0.2935555875301361,0.29204851388931274,0.29058948159217834,0.28919053077697754,0.2878342270851135,0.2865237593650818,0.28526240587234497,0.284004807472229,0.2827954590320587,0.2816450893878937,0.2805570662021637,0.2795308232307434,0.27856504917144775,0.27766722440719604,0.27683910727500916,0.27608245611190796,0.27539896965026855,0.2747892141342163,0.2742539048194885,0.27379363775253296,0.2734106779098511,0.2731150686740875,0.2728919982910156,0.2727406620979309,0.2726602256298065,0.2726495563983917,0.27270764112472534,0.2728327512741089,0.27302342653274536,0.27327778935432434,0.2735939025878906,0.2739696800708771,0.27440282702445984,0.2748909294605255,0.27543142437934875,0.27602192759513855,0.27665960788726807,0.2773423194885254,0.2780681252479553,0.27883413434028625,0.27963751554489136,0.280475914478302,0.28134647011756897,0.28224751353263855,0.2831752896308899,0.2841266393661499,0.2850988805294037,0.2860932946205139,0.2871067523956299,0.28813624382019043,0.2891789674758911,0.2902325987815857,0.29129424691200256,0.29235973954200745,0.2934284210205078,0.29449886083602905,0.2955687642097473,0.29663652181625366,0.2977004647254944,0.2987586259841919,0.299809068441391,0.30085137486457825,0.301884263753891,0.30290669202804565,0.3039177358150482,0.30491557717323303,0.30590030550956726,0.3068712651729584,0.3078630864620209,0.3088456690311432,0.3098125457763672,0.3107633590698242,0.311697781085968,0.31261566281318665,0.31351709365844727,0.3144018054008484,0.31526970863342285,0.3161207437515259,0.3169550895690918,0.3177729845046997,0.31857430934906006,0.3193545937538147,0.32010865211486816,0.3208464980125427,0.32156869769096375,0.32227542996406555,0.322966992855072,0.3236364722251892,0.32429057359695435,0.3249303102493286,0.32555583119392395,0.3261682987213135,0.3267678916454315,0.32735514640808105,0.327930212020874,0.3284982442855835,0.3290562629699707,0.32960397005081177,0.3301409184932709,0.33066731691360474,0.33118364214897156,0.33168938755989075,0.3321848213672638,0.332670658826828,0.3331472873687744,0.333619624376297,0.3340916931629181,0.33455508947372437,0.33500972390174866,0.3354560434818268,0.3358941972255707,0.33632442355155945,0.33674678206443787,0.3371628224849701,0.3375726044178009,0.33797603845596313,0.338373601436615,0.33876529335975647,0.3391515910625458,0.33953362703323364,0.3399123549461365,0.3402876853942871,0.34065935015678406,0.3410273492336273,0.34139156341552734,0.34175166487693787,0.3421134054660797,0.3424757421016693,0.3428334593772888,0.34318670630455017,0.3435356914997101,0.34388020634651184,0.3442229628562927,0.34457433223724365,0.3449229598045349,0.34526899456977844,0.3456125855445862,0.3459535837173462,0.34629154205322266,0.3466266095638275,0.3469584286212921,0.3472873866558075,0.34761330485343933,0.3479364812374115,0.34825602173805237,0.34857094287872314,0.34876748919487,0.3489493429660797,0.3491286337375641,0.3493031859397888,0.34947359561920166,0.34964144229888916,0.34980711340904236,0.34997227787971497,0.3501390218734741,0.3503034710884094,0.3504655659198761,0.3506261706352234,0.3507798910140991,0.35092517733573914,0.3510689437389374,0.3512108623981476,0.3513508439064026,0.35148894786834717,0.3516249358654022,0.35175877809524536,0.3518904149532318,0.35201990604400635,0.3521472215652466,0.3522726595401764,0.35239607095718384,0.3525172472000122,0.3526364266872406,0.3527536690235138,0.35286885499954224,0.35298243165016174,0.3531048595905304,0.35323068499565125,0.3533557057380676,0.3534800112247467,0.35360342264175415,0.3537258803844452,0.3538469672203064,0.3539665937423706,0.35408511757850647,0.3542802631855011,0.354518324136734,0.35475417971611023,0.354987770318985,0.35521891713142395,0.35544735193252563,0.3556757867336273,0.3559040427207947,0.3561321198940277,0.35635972023010254,0.35658448934555054,0.3568069636821747,0.35702815651893616,0.35724765062332153,0.35746532678604126,0.35768118500709534,0.35789525508880615,0.3581073582172394,0.35831737518310547,0.3584353029727936,0.3585282266139984,0.3586198389530182,0.3587099611759186,0.358798623085022,0.3588860332965851,0.35897183418273926,0.3590559959411621,0.3591383397579193,0.3592189848423004,0.35929784178733826,0.3593749403953552,0.3594500422477722,0.35952329635620117,0.3595944941043854,0.3596637547016144,0.35973110795021057,0.3597964644432068,0.3598598539829254,0.35992133617401123,0.35998043417930603,0.35997167229652405,0.3599376082420349,0.3599011301994324,0.35986220836639404,0.3598209619522095,0.3598279058933258,0.3598727583885193,0.3599158823490143,0.3599573075771332,0.35999736189842224,0.3600359857082367,0.3600733280181885,0.36010926961898804,0.36014407873153687,0.3601774275302887,0.3602096140384674,0.3602660596370697,0.36032435297966003,0.3603818118572235,0.36043840646743774,0.36049461364746094,0.3605499863624573,0.3606025278568268,0.3606528341770172,0.3607020676136017,0.3607504367828369,0.36079782247543335,0.36084413528442383,0.3608887195587158,0.36093178391456604,0.3609738349914551,0.3610147535800934,0.3610546290874481,0.3610934317111969,0.361131489276886,0.3611696660518646,0.36120638251304626,0.36124110221862793,0.3612741231918335,0.3613055646419525,0.3613353967666626,0.3613643944263458,0.36139145493507385,0.3614167869091034,0.3614402115345001,0.36146238446235657,0.36148321628570557,0.36150267720222473,0.3615207076072693,0.36153745651245117,0.36155375838279724,0.36156851053237915,0.3615817427635193,0.36159342527389526,0.3616029918193817,0.36161014437675476,0.3616158068180084,0.3616201877593994,0.36162325739860535,0.36162498593330383,0.3616253435611725,0.3616243302822113,0.36162203550338745,0.36161860823631287,0.3616170287132263,0.3616192638874054,0.36162108182907104,0.3616223931312561,0.3616231679916382,0.3616233468055725,0.36162295937538147,0.3616219758987427,0.36162036657333374,0.36161816120147705,0.3616153597831726,0.36161258816719055,0.361610472202301,0.36160871386528015,0.36161008477211,0.3616143465042114,0.36162111163139343,0.361629843711853,0.3616403043270111,0.361652135848999,0.3616652488708496,0.36167940497398376,0.3616943359375,0.3617100119590759,0.36172640323638916,0.3617432713508606,0.36176055669784546,0.3617785573005676,0.36179685592651367,0.36181554198265076,0.36183595657348633,0.3618580996990204,0.3618820011615753,0.36190736293792725,0.36193379759788513,0.36196112632751465,0.3619890809059143,0.3620173931121826,0.3620460331439972,0.36207443475723267,0.36210232973098755,0.36212971806526184,0.36215898394584656,0.3621898889541626,0.36222222447395325,0.36225560307502747,0.36228978633880615,0.36232590675354004,0.362358033657074,0.36239221692085266,0.36242738366127014,0.3624632656574249,0.36250028014183044,0.36253809928894043,0.36257657408714294,0.3626154959201813,0.3626548945903778,0.36269453167915344,0.3627341687679291,0.36277374625205994,0.362813264131546,0.3628525733947754,0.36289137601852417,0.36293330788612366,0.362995445728302,0.36305928230285645,0.36312270164489746,0.36318546533584595,0.3632476031780243,0.3633117377758026,0.3633773922920227,0.3634442389011383,0.36351215839385986,0.36358100175857544,0.36365023255348206,0.3637203276157379,0.3637913465499878,0.3638629913330078,0.36393463611602783,0.3640063405036926,0.3640778958797455,0.36414971947669983,0.3642217516899109,0.36429381370544434,0.3643846809864044,0.36448243260383606,0.36458003520965576,0.36467722058296204,0.36477386951446533,0.36486995220184326,0.3649655878543854,0.36506059765815735,0.3651563823223114,0.3652516007423401,0.3653460741043091,0.3654394745826721,0.3655320405960083,0.3656293451786041,0.36573153734207153,0.36583781242370605,0.36594754457473755,0.366060346364975,0.3661758303642273,0.36629343032836914,0.36641624569892883,0.3665445148944855,0.36667656898498535,0.3668118417263031,0.36695003509521484,0.3670746684074402,0.3671903908252716,0.3673075735569,0.3674258887767792,0.3675459921360016,0.3676677346229553,0.3677893877029419,0.36791011691093445,0.36803165078163147,0.3681539297103882,0.3682774603366852,0.3684018850326538,0.3685271441936493,0.3685881793498993,0.3684318959712982,0.36827680468559265,0.3681230843067169,0.3679705858230591,0.36781927943229675,0.3676692247390747,0.36752036213874817,0.3673703968524933,0.3672194480895996,0.3670696020126343,0.36692100763320923,0.3667735755443573,0.36662736535072327,0.3664827048778534,0.3663395941257477,0.3661946654319763,0.3660493791103363,0.36590543389320374,0.3657626807689667,0.3656209707260132,0.36548081040382385,0.3653416335582733,0.3652034401893616,0.3650662302970886,0.3649299442768097,0.36479443311691284,0.36465972661972046,0.364525705575943,0.3643925189971924,0.36426329612731934,0.36413487792015076,0.3640071153640747,0.3638802170753479,0.36375415325164795,0.36362871527671814,0.3635041117668152,0.3633798658847809,0.36325639486312866,0.3631334602832794,0.36301112174987793,0.36288943886756897,0.36276835203170776,0.3626478612422943,0.3625280261039734,0.362408846616745,0.36229023337364197,0.36217227578163147],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"On-policy Estimate\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395,0.8189834879576395],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"IS Variance\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672,0.03197002410888672],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"lines\",\"name\":\"Train Variance\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[1.9559787511825562,5.958237171173096,5.736608028411865,5.513529300689697,5.291527271270752,5.073310852050781,4.859893321990967,4.651905059814453,4.449740409851074,4.249609470367432,4.05202054977417,3.8608343601226807,3.676853656768799,3.497241735458374,3.3213343620300293,3.1518895626068115,2.9890599250793457,2.8326480388641357,2.6825554370880127,2.5390381813049316,2.400273561477661,2.266878604888916,2.1392877101898193,2.016944408416748,1.9002888202667236,1.7822109460830688,1.6707384586334229,1.5655491352081299,1.4658901691436768,1.3716444969177246,1.2824244499206543,1.198028564453125,1.118245244026184,1.0428553819656372,0.9715794324874878,0.9043043255805969,0.8408994674682617,0.7812319397926331,0.7253036499023438,0.6727993488311768,0.6234931349754333,0.5781171321868896,0.5355724096298218,0.4960065186023712,0.45898279547691345,0.4243837893009186,0.39208248257637024,0.3619525730609894,0.3338671922683716,0.30772894620895386,0.2834303081035614,0.26086318492889404,0.23992949724197388,0.22053185105323792,0.20257732272148132,0.18597733974456787,0.17063897848129272,0.1564769744873047,0.14343209564685822,0.131426602602005,0.12039575725793839,0.1102689653635025,0.10098223388195038,0.09254296869039536,0.08482713997364044,0.07778245210647583,0.07135672867298126,0.06550142168998718,0.060173265635967255,0.055329736322164536,0.05093110725283623,0.046940878033638,0.0433243103325367,0.0400494784116745,0.037086810916662216,0.03440847247838974,0.03198886662721634,0.029804550111293793,0.02783154509961605,0.026051433756947517,0.02444659173488617,0.023000182583928108,0.02169681154191494,0.02052156999707222,0.019461670890450478,0.01850498840212822,0.017641086131334305,0.0168532095849514,0.01603882573544979,0.015304191038012505,0.014641650952398777,0.014044092036783695,0.013503918424248695,0.013014988042414188,0.012572921812534332,0.012176310643553734,0.011832711286842823,0.011518695391714573,0.011231386102735996,0.010967337526381016,0.010723740793764591,0.010498277842998505,0.010289340279996395,0.010094596073031425,0.009912433102726936,0.009741435758769512,0.009580511599779129,0.009427961893379688,0.009283245541155338,0.009145732037723064,0.009014705196022987,0.008889530785381794,0.008769621141254902,0.008654466830193996,0.008543620817363262,0.008436656557023525,0.008333292789757252,0.008233191445469856,0.008136010728776455,0.008041562512516975,0.007949624210596085,0.00786001980304718,0.0077728102914988995,0.007688029203563929,0.0076051270589232445,0.007523861713707447,0.007444190327078104,0.007365867029875517,0.007289057597517967,0.007213675417006016,0.0071396613493561745,0.007064723409712315,0.006989806890487671,0.006915400270372629,0.006840913090854883,0.006767562590539455,0.006695164833217859,0.006623778957873583,0.006553460378199816,0.006484898738563061,0.006417077500373125,0.006350879091769457,0.006285798270255327,0.00622196402400732,0.006159048527479172,0.006096989382058382,0.006035995204001665,0.005976361222565174,0.005917505826801062,0.005859081167727709,0.005801467690616846,0.005744625348597765,0.005688555538654327,0.005633227061480284,0.005578579846769571,0.00552442716434598,0.005471270531415939,0.005418840330094099,0.005367031786590815,0.005315922666341066,0.005265706684440374,0.005216242279857397,0.0051673357374966145,0.005118983332067728,0.0050718290731310844,0.005025867372751236,0.004980425350368023,0.004935550503432751,0.004891258664429188,0.004847519565373659,0.004803645424544811,0.004760151728987694,0.004717246163636446,0.004674718715250492,0.004632426891475916,0.004590529482811689,0.004549006465822458,0.004507881589233875,0.004467412363737822,0.004427602514624596,0.004388457164168358,0.004349974915385246,0.004311892669647932,0.004274226259440184,0.004236896522343159,0.004199801944196224,0.004162869416177273,0.004126335494220257,0.004090201109647751,0.004054384771734476,0.004019079264253378,0.003984327428042889,0.003950081765651703,0.003916251473128796,0.0038826079107820988,0.003849242115393281,0.003816320328041911,0.003783781547099352,0.0037516446318477392,0.0037200588267296553,0.003688905155286193,0.0036581375170499086,0.003627820173278451,0.003597911447286606,0.0035683962050825357,0.003539367811754346,0.0035107629373669624,0.0034825587645173073,0.003454743418842554,0.003427303396165371,0.003400142304599285,0.003373227082192898,0.00334670627489686,0.003320553107187152,0.0032947389408946037,0.003269242588430643,0.0032442084047943354,0.0032194885425269604,0.0031950422562658787,0.0031708625610917807,0.0031465478241443634,0.0031232242472469807,0.00310057052411139,0.0030781261157244444,0.0030555466655641794,0.0030281883664429188,0.003001088509336114,0.0029743427876383066,0.002947971224784851,0.00292200711555779,0.002896537771448493,0.002871859585866332,0.0028484477661550045,0.0028249388560652733,0.0028019186574965715,0.0027797650545835495,0.0027579250745475292,0.0027364029083400965,0.002715182723477483,0.002694285474717617,0.0026737283915281296,0.002653526607900858,0.0026337113231420517,0.0026142036076635122,0.0025950297713279724,0.002576142083853483,0.002557538216933608,0.0025392144452780485,0.0025212187319993973,0.002503514289855957,0.0024860443081706762,0.0024687694385647774,0.002451736945658922,0.002435003174468875,0.00241886917501688,0.002402912825345993,0.0023871585726737976,0.0023715952411293983,0.002356218174099922,0.002341034123674035,0.0023260428570210934,0.002311240416020155,0.00229662680067122,0.0022821815218776464,0.00226790108717978,0.002254318678751588,0.00224107364192605,0.0022278681863099337,0.0022147949784994125,0.002201854018494487,0.0021890471689403057,0.0021763728000223637,0.0021639324259012938,0.002151667606085539,0.0021395378280431032,0.002127536805346608,0.002115665702149272,0.0021039308048784733,0.002092118375003338,0.0020803918596357107,0.0020687878131866455,0.002057300414890051,0.0020459010265767574,0.002034569624811411,0.0020233469549566507,0.0020121922716498375,0.0020011174492537975,0.0019901690538972616,0.0019801128655672073,0.0019708117470145226,0.001961734611541033,0.0019527690019458532,0.0019439270254224539,0.0019349576905369759,0.0019254181534051895,0.0019160225056111813,0.0019067751709371805,0.0018976753344759345,0.0018887203186750412,0.001879912568256259,0.0018712063319981098,0.0018622271018102765,0.001853479421697557,0.0018450348870828748,0.0018367175944149494,0.0018285363912582397,0.0018204592633992434,0.001811937429010868,0.0018027953337877989,0.001793805044144392,0.001784980995580554,0.0017763247014954686,0.001768194604665041,0.0017602323787286878,0.0017524552531540394,0.0017448568250983953,0.0017374478047713637,0.0017303198110312223,0.0017234188271686435,0.0017167618498206139,0.0017098026582971215,0.0017027555732056499,0.0016958595952019095,0.0016890845727175474,0.0016824600752443075,0.0016759881982579827,0.0016695926897227764,0.001663296134211123,0.0016571342712268233,0.001651101978495717,0.0016450185794383287,0.001638805028051138,0.001632706611417234,0.0016267132014036179,0.0016208318993449211,0.0016150716692209244,0.0016094434540718794,0.001603966113179922,0.0015985840000212193,0.001593308406881988,0.0015882375882938504,0.001583070494234562,0.001577895600348711,0.0015727519057691097,0.0015674534952268004,0.0015622754581272602,0.0015572019619867206,0.0015521456953138113,0.001547118416056037,0.0015421167481690645,0.0015372538473457098,0.0015325085259974003,0.0015278658829629421,0.0015231932047754526,0.0015184527728706598,0.001513863098807633,0.00150955724529922,0.0015052534872666001,0.0015009217895567417,0.001496539218351245,0.0014921126421540976,0.0014876590576022863,0.0014831754378974438,0.0014786573592573404,0.0014741331106051803,0.0014695875579491258,0.0014650353696197271,0.0014605071628466249,0.001453106408007443,0.0014447793364524841,0.0014364892849698663,0.0014282406773418188,0.0014200430596247315,0.0014120358973741531,0.0014042146503925323,0.0013965825783088803,0.0013890959089621902,0.001381915295496583,0.0013748961500823498,0.0013680299744009972,0.0013613319024443626,0.0013547915732488036,0.001348321558907628,0.0013419558526948094,0.0013357370626181364,0.0013296609977260232,0.001323737669736147,0.0013179621892049909,0.0013123532989993691,0.0013069033157080412,0.0013016150332987309,0.0012951736571267247,0.0012885608011856675,0.0012822154676541686,0.0012761072721332312,0.0012701513478532434,0.001264369348064065,0.00125876406673342,0.0012533037224784493,0.0012479914585128427,0.0012428242480382323,0.0012378125684335828,0.001232943614013493,0.0012280711671337485,0.0012231426080688834,0.001214998890645802,0.0012071005767211318,0.001199424033984542,0.0011920331744477153,0.0011849160073325038,0.0011780255008488894,0.001171397278085351,0.001165063469670713,0.0011588986963033676,0.001152929151430726,0.0011471475008875132,0.0011415714398026466,0.0011361978249624372,0.0011310060508549213,0.0011259854072704911,0.0011211320525035262,0.0011164932511746883,0.0011120019480586052,0.0011076482478529215,0.001103416085243225,0.0010992997558787465,0.0010952006559818983,0.0010910802520811558,0.0010870129335671663,0.0010830126702785492,0.0010790865635499358,0.0010752243688330054,0.0010713987285271287,0.0010676159290596843,0.0010638274252414703,0.001060073496773839,0.0010564184049144387,0.0010528498096391559,0.001047581434249878,0.0010422313353046775,0.0010372251272201538,0.0010325339389964938,0.0010281387949362397,0.0010239504044875503,0.0010200960095971823,0.001016496797092259,0.0010131236631423235,0.001009956351481378,0.0010069712297990918,0.0010042847134172916,0.0010019030887633562,0.0009996419539675117,0.000997736700810492,0.0009959654416888952,0.0009942681062966585,0.0009926480706781149,0.0009910785593092442,0.0009896078845486045,0.0009882149752229452,0.0009868742199614644,0.0009857594268396497,0.000984719954431057,0.0009837410179898143,0.000982733559794724,0.0009817027021199465,0.0009806409943848848,0.000979548436589539,0.0009784274734556675,0.0009772691410034895,0.0009760615066625178,0.0009748495649546385,0.0009736143983900547,0.000972413516137749,0.0009711738675832748,0.0009698978974483907,0.0009685842669568956,0.00096724065952003,0.0009658652707003057,0.0009644681704230607,0.0009630463900975883,0.0009616052848286927,0.000960132572799921,0.0009586497326381505,0.0009571624686941504,0.0009556704317219555,0.0009542345069348812,0.0009528545197099447,0.0009514618432149291,0.000950027140788734,0.0009485851041972637,0.000947102380450815,0.0009456275147385895,0.0009441598085686564,0.0009427022887393832,0.0009412305662408471,0.0009396997629664838,0.0009381810086779296,0.0009366674348711967,0.0009351348853670061,0.0009336181101389229],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"lines\",\"name\":\"Test Variance\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.041995901614427567,0.04190496727824211,0.04189683496952057,0.04196486994624138,0.042072050273418427,0.042201846837997437,0.042361337691545486,0.042532116174697876,0.042710497975349426,0.042897097766399384,0.04309380427002907,0.043295666575431824,0.043520838022232056,0.04376884177327156,0.04400818049907684,0.04424917325377464,0.04449192434549332,0.04473639279603958,0.04498325660824776,0.04523088410496712,0.04548007622361183,0.04573027417063713,0.045981865376234055,0.046248577535152435,0.04652733728289604,0.046810343861579895,0.04709045961499214,0.0473676435649395,0.04764113575220108,0.04790623486042023,0.048167984932661057,0.04842628538608551,0.048681095242500305,0.048932310193777084,0.049179792404174805,0.04942348226904869,0.04966355860233307,0.04989989474415779,0.05013252794742584,0.05036141350865364,0.050586577504873276,0.05080609396100044,0.05100944638252258,0.051208045333623886,0.05140194669365883,0.05159161984920502,0.0517771877348423,0.05195876955986023,0.0521363839507103,0.05231023579835892,0.05248044431209564,0.0526471883058548,0.052811965346336365,0.05297708511352539,0.05313872918486595,0.05329703912138939,0.053452104330062866,0.053604040294885635,0.05375289544463158,0.053898848593235016,0.05404196307063103,0.0541829839348793,0.05432432144880295,0.05446287989616394,0.05459858477115631,0.05473161116242409,0.05486195534467697,0.054989755153656006,0.055115047842264175,0.05523787438869476,0.05535834655165672,0.05547647550702095,0.05559230595827103,0.05570591986179352,0.05581733211874962,0.05592658370733261,0.056033775210380554,0.05613890290260315,0.056241992861032486,0.05634315311908722,0.056442394852638245,0.05653974413871765,0.05663526803255081,0.05672894045710564,0.0568208321928978,0.05691095441579819,0.056999340653419495,0.0570860281586647,0.057171549648046494,0.05725580453872681,0.057338763028383255,0.05742032825946808,0.05750051513314247,0.05757921561598778,0.057656317949295044,0.05773191899061203,0.057806000113487244,0.05787855014204979,0.057949651032686234,0.058019258081912994,0.05808744207024574,0.05815419182181358,0.05821961537003517,0.058283694088459015,0.05834643915295601,0.058407872915267944,0.05846800282597542,0.05852685123682022,0.05858442932367325,0.05864963307976723,0.058715060353279114,0.058779191225767136,0.05884207412600517,0.05890372022986412,0.05896412953734398,0.0590234212577343,0.05908156558871269,0.05913860723376274,0.05919456109404564,0.05924947187304497,0.05930342152714729,0.05935632064938545,0.0594082809984684,0.059459149837493896,0.05950908362865448,0.05955812707543373,0.05960623919963837,0.05965351685881615,0.05970464646816254,0.05975545197725296,0.059805430471897125,0.05985460802912712,0.059903040528297424,0.05995069444179535,0.059997618198394775,0.06004377454519272,0.06008930504322052,0.060134101659059525,0.060178242623806,0.06022170931100845,0.060264501720666885,0.06030663102865219,0.06034808233380318,0.06038883700966835,0.060428958386182785,0.06046842038631439,0.060507260262966156,0.06054539233446121,0.06058299541473389,0.06061999127268791,0.060656413435935974,0.060692254453897476,0.060727596282958984,0.06076236441731453,0.06079665571451187,0.060830503702163696,0.060863859951496124,0.06089675799012184,0.06092919036746025,0.06096122786402702,0.06099286302924156,0.061024125665426254,0.061055004596710205,0.06108551844954491,0.061115678399801254,0.06114550679922104,0.06117493659257889,0.06120401620864868,0.06123272329568863,0.061261050403118134,0.061289045959711075,0.06131664663553238,0.06134391948580742,0.061371300369501114,0.06140085682272911,0.06143011525273323,0.06145910173654556,0.06148780509829521,0.061516210436820984,0.061544328927993774,0.06157216802239418,0.0615997277200222,0.06162700429558754,0.06165401265025139,0.06168070808053017,0.06170713156461716,0.06173320487141609,0.061714284121990204,0.061691269278526306,0.061668265610933304,0.06164528802037239,0.06162237375974655,0.0615994930267334,0.0615767203271389,0.06155397370457649,0.06153130158782005,0.061508700251579285,0.061486177146434784,0.061463721096515656,0.06144503504037857,0.06143084913492203,0.06141667813062668,0.06140255182981491,0.061388421803712845,0.061374399811029434,0.06136036664247513,0.061346400529146194,0.06133244186639786,0.06131855398416519,0.06130467355251312,0.06129082664847374,0.061276961117982864,0.06126317381858826,0.06124938279390335,0.061235636472702026,0.061221905052661896,0.061208296567201614,0.06119498237967491,0.061181746423244476,0.06116857752203941,0.06115543469786644,0.06114230304956436,0.06112921983003616,0.061116110533475876,0.061103034764528275,0.06108992174267769,0.06107668951153755,0.061063338071107864,0.061049964278936386,0.061036571860313416,0.061023179441690445,0.06100977957248688,0.06099632382392883,0.0609828345477581,0.06096932664513588,0.06095578148961067,0.06094221770763397,0.060928668826818466,0.06091510131955147,0.06090143695473671,0.0608876571059227,0.06087386608123779,0.06086006015539169,0.060846250504255295,0.060832422226667404,0.06082725524902344,0.06082423776388168,0.060821160674095154,0.06081797927618027,0.06081473454833031,0.06081143021583557,0.060808051377534866,0.060804616659879684,0.06080108508467674,0.060797493904829025,0.06079382076859474,0.06079012528061867,0.060786329209804535,0.06078245863318443,0.06077852100133896,0.060774534940719604,0.060770466923713684,0.06076633557677269,0.06076213717460632,0.06075790897011757,0.06075352057814598,0.06072443351149559,0.06068651005625725,0.06064842268824577,0.06061020866036415,0.060571953654289246,0.060544367879629135,0.060525212436914444,0.06050604581832886,0.06048683077096939,0.0604676678776741,0.06044846400618553,0.06042930856347084,0.06041015312075615,0.06039106473326683,0.060372013598680496,0.060353003442287445,0.06034918874502182,0.06034698337316513,0.06034480407834053,0.06034257635474205,0.06034039705991745,0.060338180512189865,0.06033599004149437,0.060333769768476486,0.060331474989652634,0.06032916158437729,0.06032679229974747,0.06032435595989227,0.06032185256481171,0.06031933054327965,0.060316748917102814,0.0603141151368618,0.06031142920255661,0.060308702290058136,0.06030602753162384,0.060303810983896255,0.06030159816145897,0.06029925122857094,0.06029681861400604,0.06029432266950607,0.06029175966978073,0.06028911471366882,0.060286395251750946,0.06028357893228531,0.060280658304691315,0.06027769297361374,0.0602746456861496,0.06027153879404068,0.060268335044384,0.060265060514211655,0.06026175618171692,0.06025833263993263,0.060254842042922974,0.06025126576423645,0.06024743616580963,0.06024325639009476,0.06023897975683212,0.06023465842008591,0.06023025140166283,0.06022578105330467,0.06022121384739876,0.06021659076213837,0.0602119043469429,0.060207195580005646,0.060203056782484055,0.060199860483407974,0.06019672378897667,0.06019359827041626,0.06019047647714615,0.060187362134456635,0.060184258967638016,0.06018116697669029,0.06017807498574257,0.06017497181892395,0.06017189845442772,0.060168854892253876,0.06016584113240242,0.06016285717487335,0.06016002595424652,0.06015731021761894,0.06015470251441002,0.06015218421816826,0.06014975905418396,0.06014735996723175,0.06014503166079521,0.06014278158545494,0.06014053896069527,0.06013834476470947,0.06013621389865875,0.060134101659059525,0.06013203412294388,0.06013005971908569,0.06012808904051781,0.06012621149420738,0.06012440100312233,0.06012270599603653,0.06012110412120819,0.06011960282921791,0.06011819466948509,0.06011687591671944,0.06011559069156647,0.060114338994026184,0.06011315807700157,0.06011197715997696,0.060110706835985184,0.06010943278670311,0.060108233243227005,0.06010708212852478,0.06010602414608002,0.060104988515377045,0.060103997588157654,0.060103144496679306,0.06010224297642708,0.06010140851140022,0.06010066345334053,0.06009998172521591,0.06009940430521965,0.06009889766573906,0.06009847670793533,0.06009810045361519,0.060097817331552505,0.06009761989116669,0.06009742617607117,0.06009732186794281,0.06009726971387863,0.06009729951620102,0.06009731441736221,0.060097306966781616,0.06009723246097565,0.060097210109233856,0.06009724363684654,0.06009726971387863,0.06009732559323311,0.06009754538536072,0.06009785458445549,0.06009823456406593,0.060098715126514435,0.06009929999709129,0.06009991466999054,0.06010061502456665,0.060101307928562164,0.06010205298662186,0.06010285019874573,0.060103703290224075,0.0601046159863472,0.0601055882871151,0.06010666489601135,0.06010780110955238,0.06010889634490013,0.060110025107860565,0.06011124700307846,0.060112547129392624,0.060113877058029175,0.06011528894305229,0.06011679023504257,0.060118358582258224,0.06011994555592537,0.06012159585952759,0.06012330576777458,0.06012500822544098,0.060126759111881256,0.06012867018580437,0.06013080105185509,0.06013309955596924,0.06013553962111473,0.06013811007142067,0.06014079228043556,0.060143567621707916,0.06014658138155937,0.060149744153022766,0.0601530559360981,0.06015649437904358,0.06016009673476219,0.06016359105706215,0.06016714870929718,0.06017078831791878,0.060174498707056046,0.06017836928367615,0.060182396322488785,0.06018650904297829,0.06019077077507973,0.06019515544176102,0.06019965931773186,0.060204315930604935,0.06020909547805786,0.06021401658654213,0.060219116508960724,0.0602244958281517,0.06022994965314865,0.06023554503917694,0.060241248458623886,0.06024701148271561,0.06025288626551628,0.06025886535644531,0.06026487424969673,0.060270994901657104,0.060277216136455536,0.06028352305293083,0.060289885848760605,0.06029636412858963,0.06030288711190224,0.060309477150440216,0.060316018760204315,0.06032249704003334,0.06032903864979744,0.0603356696665287,0.06034229323267937,0.06034867838025093,0.06035512685775757,0.060361627489328384,0.06036815419793129,0.06037471815943718,0.06038128212094307,0.06038786470890045,0.06039441004395485,0.06040098890662193,0.060407597571611404,0.06041416898369789,0.06042075529694557,0.060427337884902954,0.0604337677359581,0.06044017896056175,0.06044663488864899,0.06045302748680115,0.060459449887275696,0.06046582758426666,0.06047222018241882,0.060478609055280685,0.06048499420285225,0.060491371899843216,0.06049776077270508,0.06050415337085724,0.0605105385184288,0.06051691249012947],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"lines\",\"name\":\"Train MSE Loss\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[21.885251998901367,20.26593017578125,19.245338439941406,18.26190757751465,17.31580352783203,16.41025161743164,15.550115585327148,14.727174758911133,13.940712928771973,13.190160751342773,12.473922729492188,11.789555549621582,11.138797760009766,10.520453453063965,9.932085037231445,9.374664306640625,8.845603942871094,8.343146324157715,7.865711212158203,7.413945198059082,6.987335681915283,6.585942268371582,6.207104682922363,5.849499702453613,5.512150764465332,5.194474697113037,4.894891738891602,4.613104820251465,4.348969459533691,4.100876331329346,3.868070363998413,3.6496057510375977,3.444667100906372,3.2527291774749756,3.0731914043426514,2.9052734375,2.748563528060913,2.6023123264312744,2.465934991836548,2.3391027450561523,2.221097707748413,2.1115188598632812,2.009584426879883,1.9151418209075928,1.8277219533920288,1.746917486190796,1.6722780466079712,1.6033872365951538,1.5398930311203003,1.4815086126327515,1.4278291463851929,1.3784629106521606,1.3331044912338257,1.2914494276046753,1.2532131671905518,1.2181968688964844,1.1861432790756226,1.1567769050598145,1.1298933029174805,1.1052364110946655,1.0825971364974976,1.0617998838424683,1.0426784753799438,1.0250732898712158,1.0088262557983398,0.9938222169876099,0.9799381494522095,0.9670481085777283,0.9550314545631409,0.9437801837921143,0.9332049489021301,0.923214316368103,0.9137462377548218,0.9047333598136902,0.8961177468299866,0.8878517746925354,0.8798841238021851,0.8721720576286316,0.8646789789199829,0.8573755025863647,0.8502330183982849,0.8432254791259766,0.8363410830497742,0.8295674920082092,0.8228921294212341,0.8163103461265564,0.8098101615905762,0.8033851385116577,0.7970205545425415,0.7907182574272156,0.7844704389572144,0.7782774567604065,0.7721396088600159,0.7660614252090454,0.7600370049476624,0.7540737986564636,0.7481874823570251,0.7423678636550903,0.7366077899932861,0.7309154272079468,0.7252987027168274,0.7197555303573608,0.7142878770828247,0.7088916897773743,0.7035656571388245,0.6983099579811096,0.6931312084197998,0.6880248785018921,0.6829891800880432,0.678022563457489,0.6731242537498474,0.668293297290802,0.6635289788246155,0.6588293313980103,0.65418940782547,0.6496115326881409,0.6450949311256409,0.640638530254364,0.6362438201904297,0.6319029331207275,0.6276158690452576,0.6233840584754944,0.6192049384117126,0.6150727272033691,0.6109912395477295,0.6069560050964355,0.602969229221344,0.5990279912948608,0.5951305031776428,0.5912792682647705,0.5874738693237305,0.5836904644966125,0.5799408555030823,0.5762335658073425,0.572565495967865,0.5689342021942139,0.5653334259986877,0.5617676973342896,0.5582398772239685,0.5547484755516052,0.5512897968292236,0.5478696823120117,0.544489324092865,0.5411465167999268,0.5378268361091614,0.5345401167869568,0.5312873125076294,0.5280687808990479,0.5248812437057495,0.521726667881012,0.5186042785644531,0.5155144333839417,0.5124554634094238,0.5094183683395386,0.5064050555229187,0.5034202337265015,0.5004613995552063,0.4975288510322571,0.49462535977363586,0.49174296855926514,0.4888773560523987,0.4860324561595917,0.4832138121128082,0.4804193079471588,0.4776497483253479,0.47490647435188293,0.47218841314315796,0.4694956839084625,0.46682703495025635,0.46418410539627075,0.46156448125839233,0.45896825194358826,0.4563908278942108,0.45382681488990784,0.4512768089771271,0.44874003529548645,0.4462220370769501,0.44372349977493286,0.4412473142147064,0.43879345059394836,0.4363589584827423,0.43394166231155396,0.43154290318489075,0.42916253209114075,0.4267979562282562,0.42445480823516846,0.42213404178619385,0.4198339879512787,0.4175543785095215,0.4152957797050476,0.4130575954914093,0.41084209084510803,0.4086466133594513,0.40646812319755554,0.40431222319602966,0.402174174785614,0.4000532031059265,0.3979438841342926,0.39585188031196594,0.39377737045288086,0.39172059297561646,0.3896835148334503,0.3876665532588959,0.3856683075428009,0.38368844985961914,0.38172611594200134,0.3797812759876251,0.3778556287288666,0.37594857811927795,0.3740573823451996,0.37218019366264343,0.37031370401382446,0.3684636652469635,0.3666337728500366,0.3648203909397125,0.36302322149276733,0.36124080419540405,0.3594607412815094,0.35769417881965637,0.3559407889842987,0.35419800877571106,0.35246920585632324,0.35075512528419495,0.34905514121055603,0.34736984968185425,0.34569793939590454,0.3440413177013397,0.3423977196216583,0.34076744318008423,0.3391510546207428,0.3375494182109833,0.33595040440559387,0.33434122800827026,0.3327406942844391,0.33115077018737793,0.32957085967063904,0.3280026614665985,0.3264464735984802,0.32490190863609314,0.3233717083930969,0.32185521721839905,0.3203502893447876,0.3188585042953491,0.3173789978027344,0.31591206789016724,0.3144569396972656,0.3130137622356415,0.31158265471458435,0.31016290187835693,0.3087503910064697,0.3073480725288391,0.3059588372707367,0.30458304286003113,0.3032188415527344,0.3018646538257599,0.3005208671092987,0.29918816685676575,0.2978660762310028,0.29655545949935913,0.2952566146850586,0.29396864771842957,0.2926921844482422,0.2914251983165741,0.29016491770744324,0.288913369178772,0.28766199946403503,0.28641822934150696,0.2851828932762146,0.2839563190937042,0.28273919224739075,0.2815316915512085,0.2803337872028351,0.27914372086524963,0.2779623866081238,0.2767893970012665,0.2756247818470001,0.2744692862033844,0.27332326769828796,0.27218613028526306,0.2710581421852112,0.2699388265609741,0.26882821321487427,0.26772597432136536,0.26663073897361755,0.2655426859855652,0.2644583582878113,0.26338326930999756,0.2623075246810913,0.2612325847148895,0.26016515493392944,0.25910434126853943,0.25805070996284485,0.2570044994354248,0.255964457988739,0.2549305856227875,0.253903865814209,0.2528829276561737,0.25186842679977417,0.2508603632450104,0.24985992908477783,0.24886642396450043,0.24787254631519318,0.24688158929347992,0.24589131772518158,0.24490687251091003,0.2439289093017578,0.24295759201049805,0.24198664724826813,0.2410120964050293,0.24004237353801727,0.23907531797885895,0.23811271786689758,0.2371543049812317,0.23619946837425232,0.23525036871433258,0.23430673778057098,0.23336486518383026,0.23241741955280304,0.23147132992744446,0.23053064942359924,0.22959281504154205,0.22865720093250275,0.22772216796875,0.2267894744873047,0.2258608490228653,0.22493667900562286,0.22401784360408783,0.22310404479503632,0.22219650447368622,0.22129414975643158,0.22039438784122467,0.2194962054491043,0.21860316395759583,0.21771542727947235,0.21683171391487122,0.2159535437822342,0.2150810807943344,0.21421422064304352,0.21335314214229584,0.2124975025653839,0.21164634823799133,0.21079827845096588,0.2099534422159195,0.2091139256954193,0.20827078819274902,0.20743213593959808,0.20659920573234558,0.20577193796634674,0.2049497663974762,0.20413413643836975,0.2033223956823349,0.20251400768756866,0.20170989632606506,0.20091217756271362,0.20011943578720093,0.19933253526687622,0.19855104386806488,0.19777487218379974,0.19700448215007782,0.1962355077266693,0.19546839594841003,0.1947060525417328,0.1939476579427719,0.1931953877210617,0.1924484521150589,0.19170670211315155,0.19096970558166504,0.19023855030536652,0.18951216340065002,0.18879076838493347,0.18807458877563477,0.1873556524515152,0.18664029240608215,0.18592806160449982,0.18521937727928162,0.18451611697673798,0.18381759524345398,0.18311838805675507,0.18242226541042328,0.1817297637462616,0.18104150891304016,0.18035611510276794,0.1796729415655136,0.17899401485919952,0.17831961810588837,0.17764978110790253,0.1769842654466629,0.17632362246513367,0.1756686419248581,0.17501848936080933,0.17437320947647095,0.1737326681613922,0.17309758067131042,0.17246633768081665,0.1718379110097885,0.17121443152427673,0.17059572041034698,0.16998179256916046,0.16936416923999786,0.16875018179416656,0.16814011335372925,0.16753415763378143,0.16693250834941864,0.16633455455303192,0.16573946177959442,0.16514824330806732,0.16456064581871033,0.1639767587184906,0.16339688003063202,0.1628209501504898,0.1622483879327774,0.16167844831943512,0.16111239790916443,0.16055016219615936,0.15999171137809753,0.15943710505962372,0.1588863581418991,0.15833918750286102,0.1577959954738617,0.157255157828331,0.1567174643278122,0.15618357062339783,0.15565389394760132,0.1551276594400406,0.15460461378097534,0.1540854573249817,0.15356038510799408,0.15303058922290802,0.1525016576051712,0.15197518467903137,0.15145176649093628,0.15093058347702026,0.15041203796863556,0.1498953402042389,0.14937011897563934,0.1488470584154129,0.1483258754014969,0.14780756831169128,0.14729101955890656,0.1467772126197815,0.1462661176919937,0.1457577347755432,0.14525175094604492,0.14474637806415558,0.14424341917037964,0.14374282956123352,0.14324529469013214,0.14275096356868744,0.142258420586586,0.14176733791828156,0.14127951860427856,0.14079497754573822,0.14031358063220978,0.13983623683452606,0.13936249911785126,0.1388917863368988,0.13842420279979706,0.13795961439609528,0.13749830424785614,0.1370401382446289,0.13658645749092102,0.1361362189054489,0.13568657636642456,0.13523994386196136,0.1347963809967041,0.13435588777065277,0.1339179426431656,0.13348184525966644,0.1330489069223404,0.13261918723583221,0.13219256699085236,0.13176913559436798,0.13134948909282684,0.13093310594558716,0.130519837141037,0.13010962307453156,0.12970241904258728,0.1292978823184967,0.12889645993709564,0.12849870324134827,0.12810389697551727,0.12771229445934296,0.12732365727424622,0.12693771719932556,0.12655498087406158,0.1261749118566513,0.1257983297109604,0.12542295455932617,0.12504853308200836,0.12467614561319351,0.1243073120713234,0.12394069880247116,0.12357566505670547,0.1232130154967308,0.12285269051790237,0.12249468266963959,0.12213864922523499,0.12178514152765274,0.12143384665250778,0.12108514457941055],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"mode\":\"lines\",\"name\":\"IS MSE\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195,0.356320343691195],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"mode\":\"lines\",\"name\":\"Train MSE\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[2.946229509024632,15.140130653176117,14.700734746511712,14.254570907160232,13.806115814451656,13.360327210859186,12.913135893853132,12.476218989093713,12.050846059734845,11.620580546503003,11.190413857358894,10.774533936965984,10.37233763637609,9.97654967311021,9.58608473709806,9.205946559720212,8.837650938589784,8.48463899694945,8.144167642881166,7.816790489676597,7.496671245824885,7.182573106600421,6.879845778168509,6.587279152036369,6.306022384627587,6.016504467592568,5.741659846294737,5.480054080349349,5.22952482163818,4.983506655923957,4.7474986967396875,4.522067823252955,4.306256070823237,4.099586081593635,3.9025565120927768,3.715368741151718,3.537281764133259,3.3680232966589077,3.2076770807761843,3.0548922376562375,2.9097858905946166,2.7745232422937653,2.645800807465895,2.5248688002076336,2.4107398692026827,2.302684647964746,2.2002472766144354,2.1031906527398396,2.0113269677202066,1.924251086900799,1.8421308691839198,1.7646448187410229,1.6914195466114357,1.6221745392154887,1.55679486677118,1.4951314011630885,1.4367714869186543,1.381736977455046,1.3298977035807584,1.2809849785527787,1.2348720011365402,1.1915490011866705,1.1509408846721625,1.1129276135472463,1.0771530252260413,1.0434870974522865,1.011835161514798,0.9821533350651607,0.9542737764350216,0.9281016890518634,0.9035473715772617,0.8805077469743436,0.8589137166759441,0.8386809128543483,0.8197165170008094,0.8019643499071488,0.7853507529155693,0.7697923628437492,0.755119585222832,0.7413812154163456,0.728628887216461,0.7167226530510572,0.7056084878241111,0.6952306433377113,0.6855378649353667,0.6764875211884093,0.6680518906653561,0.6601057862473969,0.6514492156536359,0.6433182751335064,0.6356936609050109,0.6285224287446832,0.6217764878768981,0.6153837590157656,0.6094582722006322,0.6040080273092064,0.5992410807635128,0.5947815087516882,0.590570300713825,0.586644675533056,0.5830006012690397,0.5796139508826738,0.5764857216663836,0.5735675186037782,0.5708491226613198,0.5683188399671653,0.5659703039485299,0.5638119396011534,0.5618352649902632,0.5600142286719549,0.5583266411185625,0.5567652733949148,0.5553238847794378,0.5539941180599747,0.552770821505331,0.5516480977864459,0.5506048010720275,0.5496495429788942,0.5487742666433877,0.5479758050861948,0.5472456066208168,0.5465802403942318,0.5459610619500659,0.5454170730646672,0.544948592639392,0.5445739290689767,0.544258681884094,0.5439805936895805,0.5437425824608749,0.5435477198524722,0.5434050989527044,0.5432876917965119,0.5431877986637348,0.5431190551042173,0.5430837191500759,0.5430615467377511,0.5430104829983798,0.5429613482465124,0.5429329141028107,0.5428893223890988,0.5428780785179056,0.5428508442669981,0.542816968534954,0.5427532325223198,0.5427187287472843,0.5426909764209933,0.5426697699211256,0.5426447289496708,0.5426259805723287,0.5426016054809143,0.5425878901385822,0.5425852870160517,0.542592259548772,0.5425736619849375,0.5425492390085513,0.5425443554050574,0.5425698243238153,0.5426494215521728,0.5427485432143486,0.5428520453878473,0.5429732900863635,0.5431079471785386,0.5432479156572633,0.5433937409118985,0.5435622093822269,0.5437541705031156,0.543953136347567,0.5441636669838795,0.5443882924152609,0.5446178729232956,0.5448858903068098,0.545170667041561,0.5454689849360806,0.5457607187221315,0.5460328362706748,0.5463067556492067,0.546581470625507,0.5468609229129882,0.5471335514184316,0.5473975635463023,0.5476552959638556,0.5479266374756457,0.5482082369384044,0.5484885214200124,0.5487560074584446,0.549021548230246,0.5492874341460129,0.5495522511007385,0.5498163730107305,0.5500717014391601,0.5503322661941871,0.550595591019946,0.550866688315968,0.551145296926235,0.5514025150770178,0.5516610147081165,0.551924327547663,0.5521916677639671,0.5524633882816055,0.5527286556998106,0.5529998691990213,0.5532642388089524,0.5535113918130473,0.5537616539837359,0.5540150232521603,0.5542866787141376,0.5545667488136399,0.5548518426273015,0.5551396500200096,0.5554259634675248,0.5557133980856894,0.5560064078017161,0.5563101541901853,0.5566149875829886,0.5569201703077762,0.5572241949481503,0.5575402288180829,0.5578699990374435,0.5581990460344001,0.5585276171709478,0.558896511081097,0.559240143326026,0.5595468841121916,0.5598334621018731,0.5600544856966937,0.5597559615446862,0.5594491583589007,0.5591398902656755,0.558826090827779,0.5584715002081764,0.5581264286308077,0.5578042743233902,0.5575272908448803,0.5572704508779047,0.5570368124175706,0.5568656170992857,0.5567025298981001,0.5565491488802845,0.5564063419080695,0.5562772974168256,0.556162206077597,0.5560593169977919,0.5559631386809226,0.555881693099164,0.5558178082191174,0.555767621659419,0.5557306201434085,0.5557069766266273,0.5556973595235042,0.5556996265746748,0.55571542843846,0.5557565424236282,0.5558085541826023,0.5558790712833784,0.5559975461341413,0.5561234556464522,0.5562567272421081,0.5563948459816446,0.5565399722605496,0.5566921823529942,0.5568501808627339,0.5570130452930835,0.5571802117806872,0.5573496635198905,0.5575192106386437,0.557814296459914,0.5581504235946722,0.5584845329611544,0.558808488554331,0.559121602593331,0.5594248460761005,0.5597182421583421,0.5600386452775017,0.5603639324054641,0.5606802244940889,0.5609873734371986,0.5612852163743703,0.5615733169923364,0.5617915313577291,0.5619936776385837,0.562189931574582,0.562378711229445,0.562558979823495,0.5627327436502201,0.5629004530940416,0.5630888857445004,0.5632745423643232,0.5632598764699097,0.5632008576141159,0.5631054137311261,0.562998179634305,0.5628813450299709,0.5627569334652641,0.5626428057063964,0.5625724564278083,0.562500000656153,0.5624262687524174,0.5623553988548076,0.5622844094628642,0.5622141507949189,0.5621443873909535,0.5620568663644975,0.5619612852145006,0.5618444142416276,0.5617200990848765,0.5615906810111857,0.5614542012171126,0.5613691330736759,0.561347462271955,0.5613154993359445,0.5612765919769919,0.5612329825447798,0.5612301577647005,0.5612448771660932,0.561258645225819,0.5612742086132885,0.5612936848423824,0.561305684558616,0.561309974997218,0.5613144203782319,0.5614027498110854,0.5615325410326838,0.5616603926112503,0.5617882029279048,0.5619142838758682,0.5620386145676429,0.5621722070994758,0.5623119299248406,0.5624534468223976,0.5625973448202403,0.5627600197383025,0.5629470723269827,0.5631369531589423,0.563330636289197,0.5635267233557344,0.5637236157726697,0.5639238613347913,0.5641270224302617,0.5643343416017618,0.564545005076616,0.5647658001242013,0.5650113971919631,0.565257646405329,0.5655097905696042,0.5657723375156597,0.5660310940491045,0.566287284527255,0.5665487497711176,0.5668145305264177,0.567078844143202,0.5673457481162626,0.5676202905449289,0.567901520045799,0.5681892751874483,0.5684859804839539,0.5687735229607492,0.5690397025050304,0.5693094294278636,0.569584619210692,0.5698802392054777,0.5701875585936111,0.5705002194097507,0.5708199095802157,0.5711457983690905,0.5714751518707378,0.5718091620387815,0.572147127181146,0.5724890813916719,0.5730214793906062,0.5736086490789298,0.5741792161360781,0.5747525544046829,0.5753221918366855,0.5758913168739401,0.5764592511335628,0.5770183584993618,0.5775706909482944,0.5781173435577961,0.5786544152215608,0.5791831632377199,0.579705296085383,0.5802210715205043,0.5807333136238128,0.5812408257119207,0.581739636274805,0.5822302573820509,0.5827117507126858,0.5831844631690984,0.5836538831657105,0.5841131957922959,0.5845617767952628,0.5851151383048306,0.5856861336664617,0.5862482397991173,0.5868012016086898,0.5873396500652455,0.5878658742722406,0.5883797627576542,0.5888304194594881,0.5892660896563029,0.589690410921993,0.5901020030755604,0.5905019318652452,0.5908755754978772,0.5912267474864414,0.5919215815288517,0.5926162830848606,0.5933016483960795,0.5939733240491002,0.5946323236798571,0.5952886219084328,0.5959306534735991,0.5965530910675143,0.5971551962939449,0.597712701694879,0.5982290651400676,0.5987311121787751,0.5992240988420111,0.5996991040845516,0.6001574790525804,0.6005981099005852,0.6010204351092925,0.6014243503534097,0.6018112183142137,0.602183114378681,0.6025404345782128,0.6028757786682272,0.6031849500257792,0.6034706625665632,0.6037368000378638,0.6039868620893337,0.6042230443883324,0.6044514053663802,0.604679373418891,0.6049843619088016,0.6052795489242955,0.6055681600537824,0.605850160679763,0.6066029442443619,0.6074519999238956,0.6082861630870943,0.609110188428464,0.6099164415838598,0.6106917880287945,0.6114505676349665,0.6121796450197435,0.6128878998052489,0.61356954790216,0.6142274022136666,0.6148554746645241,0.6154492684877487,0.6160149231204702,0.6165412415265147,0.6170243189061384,0.6174835297661084,0.6179034011466614,0.6182948708315739,0.6186744374495021,0.6190411608128737,0.6193910370847211,0.6197382032423404,0.6200843116775423,0.6204049351053141,0.6207089207717653,0.6209993590762948,0.6212759571823657,0.6215388730441486,0.6217877305175611,0.6220234926767234,0.6222481808172244,0.6224644300399834,0.622669103431901,0.6228729109955398,0.6230664884404995,0.623249892181641,0.6234231516226095,0.6235877340478754,0.623742143678183,0.6238907647358773,0.6240350389139592,0.6241728467256865,0.6242980972256708,0.6244170821997219,0.6245332767882597,0.6246446116153147,0.6247538031134042,0.6248674182567274,0.6249743452554225,0.6250780199344719,0.6251806571487807,0.6252873568187337,0.6253930227837347,0.6254976894033863,0.6256030759714525,0.6257080157923882,0.6258106675480556,0.6259165795888771,0.6260242643914067,0.6261344699993917,0.6262445599676971],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"mode\":\"lines\",\"name\":\"Test MSE\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.195914648725967,0.20841107775666706,0.22067534691843918,0.23299852390726647,0.2456662928415262,0.2521823258216963,0.2545064053560437,0.25666800576591964,0.25864382494673827,0.2606496148636719,0.26265677565778817,0.26460421008068996,0.2666436886450875,0.2689092997138586,0.27115927625006064,0.2733885159993744,0.2755903821506095,0.27777712746645566,0.2799626074439836,0.282142868334913,0.2842934303377024,0.2864184124165367,0.2885368236219341,0.2907183240208218,0.2928246733885762,0.29488700215778557,0.2969349977971862,0.2990934169980832,0.3012579019272217,0.30338711537613605,0.30549579756586503,0.30758413516295496,0.3096528421639717,0.31169623106329186,0.31371038176463906,0.315697285484568,0.3176525431288012,0.31957328912678296,0.3214564881459687,0.3233010840365733,0.3251052491266074,0.3268805725086549,0.3286699132789108,0.3304082712965669,0.3320825241718896,0.33371115717463573,0.33529055030770255,0.33681696302215797,0.33833857252462124,0.33980783816145843,0.3412129988895947,0.3425501999502603,0.3438211428272854,0.3450291740936303,0.34616202636907917,0.34721756862714226,0.34819363470922293,0.34908816883834215,0.3499003031068345,0.35062916733909877,0.35127393583729755,0.35183267499831955,0.3522966526199267,0.35267879498247634,0.35297980957435626,0.35320071812295034,0.3533427201176618,0.35340705598667355,0.3533956750222274,0.353310263059769,0.353153056039789,0.3529262753368076,0.35263235674549986,0.35227401612421233,0.35185404433068507,0.35137542952755085,0.3508410312416623,0.3502540937971858,0.34961714824161977,0.34893258273443645,0.3482037190658828,0.3474338220965706,0.34662567472715494,0.34578250340906996,0.34490633843485313,0.34400137980995565,0.34307118913863915,0.3421188022074662,0.3411435078029256,0.34014866637082675,0.3391375596367077,0.3381131581823635,0.33707801793761005,0.33603515073130813,0.334988890344626,0.33394004737390504,0.33289012420038205,0.3318415231781321,0.33079600406979637,0.3297552483919582,0.3287213490855384,0.32769626970184723,0.326680501988316,0.32567530176057763,0.3246816984499117,0.3237006019454813,0.32273381972421994,0.32178120334786203,0.32084335804914016,0.31989369790480965,0.31895565465236186,0.31803423958753174,0.3171297735327528,0.31624250862615555,0.31537250387886717,0.3145196970235608,0.31368423996055506,0.3128661787148484,0.3120655006045489,0.3112819846616154,0.3105153902986967,0.30976566668509864,0.3090373129218052,0.308335251674646,0.30764954438021597,0.3069796006514748,0.30632513407538603,0.30568588027265153,0.3050733124632069,0.30447653149592113,0.30389397287557696,0.3033254604884582,0.3027698512703333,0.3022268876947779,0.3016960444131641,0.3011770943534219,0.3006650793032567,0.30016278744317737,0.29967055517052515,0.2991887670315345,0.29871718462377395,0.29825532059961246,0.2978036226162545,0.2973617788038362,0.2969291261633967,0.29650523418893837,0.29608534033357425,0.29566544499370745,0.29525386867242476,0.294850595567115,0.29445520299724615,0.2940675172739108,0.2936873687363115,0.29331460492804085,0.2929478093910379,0.29258694249277173,0.29223202642760393,0.2918826210118739,0.2915387047903105,0.29119987714197093,0.29086503216967374,0.2905332761503515,0.2902046759884823,0.2898794992524767,0.28955774894376846,0.28923955318705963,0.288925149553509,0.2886090917841557,0.28829235515642654,0.2879799001201869,0.28767162339114866,0.2873672537922331,0.2870670476834699,0.28676885656400763,0.286464903854068,0.2861634996055337,0.28586452298226345,0.2855678163496437,0.2852735007424021,0.28498200465089796,0.2846931885883407,0.2844073843615045,0.2841242162789357,0.2838438621699386,0.2835659906206167,0.28329147901812973,0.2830211674390396,0.2828173696144591,0.282623366736473,0.28243184964510165,0.2822448741239518,0.2820619127633981,0.28188144884987393,0.28170319076170447,0.2815254888833356,0.2813464349655662,0.2811696584641211,0.2809952204170185,0.28082229778596607,0.2806596432312478,0.28050943127714945,0.2803606988220224,0.2802137810526356,0.2800687115860637,0.2799255448243284,0.27978438285622764,0.2796453300351446,0.2795083807150988,0.2793735408177756,0.27924077317170237,0.2791098240105885,0.27898077882114003,0.278853927585141,0.27872896434944056,0.27860588053604973,0.27848475611032364,0.27836528104688674,0.2782378787488939,0.27810741989019316,0.2779778090967565,0.27784892154827734,0.2777209082429821,0.2775938612347687,0.27746809345710743,0.2773437466701429,0.27722041652385127,0.27702577662516215,0.27679122647428844,0.2765588149093452,0.27632859784732344,0.2761007565953144,0.2758755289735798,0.27565034983740744,0.27542540714862207,0.2752007155634929,0.2749765319560328,0.2747550516250966,0.2745358084181678,0.27431782956419376,0.27410142043356045,0.2738866701971361,0.27367368078871346,0.27346241864549525,0.27325305746874545,0.27304568968546716,0.27293188594185935,0.2728432854629225,0.27275584999894537,0.2726696987322639,0.2725848444061596,0.27250109800141664,0.2724187729862536,0.2723379145724466,0.2722586454074994,0.2721808922297237,0.27210471406360215,0.2720301422729312,0.2719573169357881,0.2718861262996149,0.27181676867484417,0.2717491522991057,0.2716832154662016,0.2716190581408169,0.2715566484487536,0.27149596817033256,0.2714373239559817,0.27141628042800947,0.2714096297401306,0.2714050338930803,0.27140255803386676,0.2714021789419765,0.27136821642044784,0.27130787444240434,0.27124911233756516,0.27119186504568654,0.2711359317925218,0.2710812738271512,0.2710278434591234,0.27097570137666455,0.2709246681922257,0.2708750146835464,0.27082647083309186,0.27077086779005893,0.27071518547191353,0.2706603014004514,0.27060616811359783,0.2705524449261322,0.27049945589700986,0.2704490946244372,0.2704007579634492,0.27035333522220134,0.27030669077334657,0.2702608963531196,0.27021602242772536,0.27017266939927526,0.27013069412004304,0.27008959112730757,0.2700494768042332,0.2700102689887123,0.26997200589942855,0.2699344802275846,0.26989730651186883,0.26986147643068925,0.26982734293061306,0.26979468120832373,0.26976340416006594,0.26973353504052544,0.26970434947807176,0.2696768639374758,0.26965086484072576,0.26962650810471267,0.26960325311715516,0.26958114426604296,0.2695602310034724,0.2695405304502751,0.2695219321991639,0.2695037136806303,0.26948679421288413,0.2694711985495499,0.26945693520607594,0.2694443544134885,0.2694336318084528,0.2694241755078754,0.26941584678831143,0.2694086318986757,0.26940258042724896,0.2693976860931784,0.2693939898717156,0.269391402538006,0.2693898287825093,0.2693871348242556,0.26938189394277534,0.2693770943286903,0.26937276933120435,0.26936893875654927,0.2693656608490953,0.2693629120726805,0.2693607196894907,0.26935909978813777,0.2693580139376952,0.26935750312424334,0.2693569948673788,0.26935591667353553,0.2693545411509101,0.26935045589575946,0.26934384177146486,0.2693350457932008,0.2693245401230697,0.26931254666758264,0.2692993255887491,0.2692850034622376,0.26926980589897725,0.26925390751599354,0.26923737661651836,0.26922025542643546,0.26920271734167367,0.26918484299274226,0.26916640833622363,0.2691477055484819,0.26912874232119766,0.26910826645374764,0.26908632658662984,0.26906287335238066,0.26903818689225356,0.2690126141274325,0.2689863149466961,0.2689594787681244,0.2689323508323333,0.268904995688571,0.2688778600564692,0.26885109957851216,0.2688247998515807,0.2687968607088477,0.2687674742190741,0.2687368759652935,0.26870534934472157,0.2686731346864697,0.268639290967858,0.2686090484916249,0.2685769972983888,0.26854413982361786,0.2685106950942533,0.2684763233230308,0.26844129050265886,0.2684057477367262,0.26836984460991675,0.2683336024560962,0.2682972315128769,0.2682608674371455,0.26822465029501447,0.2681885428194269,0.2681527107361559,0.2681173289904447,0.2680790737100437,0.26802232711711976,0.26796409141117883,0.267906300134518,0.2678491071398157,0.26779252226909184,0.2677342892991391,0.2676747689921227,0.267614241995027,0.2675528471811116,0.26749072443338007,0.26742828814693825,0.26736516018906265,0.26730119352784576,0.26723671943447325,0.2671723077611148,0.2671079079955546,0.2670437136900865,0.2669793452376882,0.2669149016692505,0.26685050098111973,0.2667689716445704,0.26668123442558167,0.2665937448723676,0.2665067317053046,0.26642025454432305,0.26633439229968314,0.26624904384921105,0.266164348920094,0.26607898736526464,0.2659942213354848,0.26591020901531237,0.2658271802937136,0.26574497422623944,0.2656586489607184,0.2655681317886724,0.2654741028110742,0.2653771056179507,0.26527748226158954,0.2651755670556684,0.26507185589810006,0.2649636901472139,0.2648507684994642,0.26473460488663325,0.26461569203460045,0.26449433924148813,0.2643851722443168,0.26428415132575445,0.26418191996766294,0.2640787640850386,0.26397418191738753,0.2638683055305423,0.26376262514762444,0.26365795684251825,0.26355271489417786,0.2634469499071437,0.26334023926446537,0.26323287637250736,0.26312493422376426,0.2630750505248223,0.26322123286957827,0.2633664639992378,0.26351064861944984,0.26365388635048054,0.26379615453701455,0.2639374504500323,0.2640778193306095,0.26421925830724186,0.26436174261954903,0.2645033764463708,0.26464400917000674,0.264783690733589,0.2649224257885531,0.2650598457997219,0.2651959717737372,0.26533373656438086,0.26547180399733405,0.26560876172461323,0.2657447697352809,0.26587986526327606,0.26601335692873107,0.26614605892065335,0.266277959241909,0.26640903100000624,0.2665393386885564,0.2666689796580557,0.2667979448251349,0.2669262860112443,0.26705393796702015,0.2671780504298146,0.26730142703673343,0.26742425491534394,0.26754632505266346,0.2676675149128178,0.26778814796385536,0.26790809702383145,0.26802768793270937,0.26814663326764865,0.26826507531498156,0.2683830189275239,0.26850039067065634,0.2686172444507686,0.2687335761095301,0.2688493494287487,0.2689645564864237,0.26907926730095283,0.2691933960598433],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.45],\"title\":{\"text\":\"Epoch\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.625,1.0],\"title\":{\"text\":\"Estimate\"}},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.55,1.0],\"title\":{\"text\":\"Epoch\"}},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.625,1.0],\"title\":{\"text\":\"Variance\"}},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.0,0.45],\"title\":{\"text\":\"Epoch\"}},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,0.375],\"title\":{\"text\":\"MSE Loss\"}},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.55,1.0],\"title\":{\"text\":\"Epoch\"}},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.0,0.375],\"title\":{\"text\":\"MSE\"}},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Estimate over Epochs\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Variance over Epochs\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Shaping Train MSE Loss over Epochs\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Total MSE over Epochs\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Metrics over Epochs\"},\"showlegend\":true},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('588787dd-8b73-4a62-baf3-072f9086af03');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"9e55672b-1d15-4f17-b8c8-98b165ef02df\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"9e55672b-1d15-4f17-b8c8-98b165ef02df\")) {                    Plotly.newPlot(                        \"9e55672b-1d15-4f17-b8c8-98b165ef02df\",                        [{\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"z\":[[0.05949832499027252,0.06738251447677612,0.061809733510017395,0.050285324454307556,0.03859967738389969,0.026914019137620926,0.015228383243083954,0.0035427212715148926,-0.008142925798892975,-0.01982855796813965],[0.05679675191640854,0.0647890493273735,0.0651315450668335,0.05602329969406128,0.045101284980773926,0.03417924791574478,0.023257248103618622,0.012335207313299179,0.0014132261276245117,-0.009508773684501648],[0.050962183624506,0.048711035400629044,0.049974992871284485,0.05163733288645744,0.05023686960339546,0.03931484743952751,0.02839282527565956,0.017470791935920715,0.0065488070249557495,-0.0043732114136219025],[0.042032286524772644,0.034364089369773865,0.03988964855670929,0.03613002598285675,0.03814311325550079,0.04015621542930603,0.033528417348861694,0.022606387734413147,0.011684365570545197,0.0007623471319675446],[0.03310238942503929,0.024645574390888214,0.031479597091674805,0.028249986469745636,0.024544108659029007,0.024648889899253845,0.026662001386284828,0.025562647730112076,0.01681998372077942,0.005897954106330872],[0.02796558104455471,0.020026642829179764,0.02072971686720848,0.022128179669380188,0.016610316932201385,0.013589579612016678,0.012675546109676361,0.013167772442102432,0.015180878341197968,0.010640613734722137],[0.023692753165960312,0.015513241291046143,0.011011213064193726,0.01681385189294815,0.010488495230674744,0.004970625042915344,0.0026350654661655426,0.001721024513244629,0.0008069537580013275,0.0016866661608219147],[0.01918158307671547,0.011002074927091599,0.0030185095965862274,0.007095351815223694,0.0054510533809661865,-0.0011511743068695068,-0.006669029593467712,-0.008319459855556488,-0.009233519434928894,-0.010147564113140106],[0.014670416712760925,0.0064909085631370544,-0.0014954768121242523,-0.0026231519877910614,0.003179483115673065,-0.007272973656654358,-0.01279083639383316,-0.018308714032173157,-0.019273996353149414,-0.02018805593252182],[0.01015925407409668,0.0019797533750534058,-0.0060094669461250305,-0.01234167069196701,-0.006539009511470795,-0.00901821255683899,-0.01891264319419861,-0.024430513381958008,-0.029314473271369934,-0.03022851049900055]],\"type\":\"heatmap\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"Values\"},\"ticks\":\"outside\",\"tickvals\":[-0.03022851049900055,0.06738251447677612],\"ticktext\":[-0.03022851049900055,0.06738251447677612]}},\"xaxis\":{\"tickvals\":[0,1,2,3,4,5,6,7,8,9],\"ticktext\":[0,1,2,3,4,5,6,7,8,9],\"title\":{\"text\":\"X\"}},\"yaxis\":{\"tickvals\":[9,8,7,6,5,4,3,2,1,0],\"ticktext\":[9,8,7,6,5,4,3,2,1,0],\"title\":{\"text\":\"Y\"},\"autorange\":\"reversed\"},\"title\":{\"text\":\"Heatmap\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('9e55672b-1d15-4f17-b8c8-98b165ef02df');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"e5b61ff6-84e2-4218-9926-234d8ed84332\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e5b61ff6-84e2-4218-9926-234d8ed84332\")) {                    Plotly.newPlot(                        \"e5b61ff6-84e2-4218-9926-234d8ed84332\",                        [{\"colorbar\":{\"title\":{\"text\":\"Visits\"}},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"x\":[0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9],\"y\":[9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0],\"z\":[0,156,453,1104,2790,2864,2972,2808,2116,2129,0,282,738,1959,2242,0,1101,1588,1427,2288,0,515,1485,1891,874,0,410,533,817,2318,0,1046,1276,646,315,0,112,207,320,551,0,930,541,262,123,0,32,56,85,131,240,598,232,105,44,7,4,8,12,28,58,122,56,31,13,11,4,6,14,28,12,24,14,7,3,14,11,11,13,23,0,3,5,1,2,11,5,11,13,23,0,0,1,0,0,7,4,5,10,18],\"zmax\":2972,\"zmin\":0,\"type\":\"heatmap\"}],                        {\"title\":{\"text\":\"State Visitations Heatmap\"},\"xaxis\":{\"title\":{\"text\":\"X-axis\"}},\"yaxis\":{\"ticktext\":[9,8,7,6,5,4,3,2,1,0],\"tickvals\":[0,1,2,3,4,5,6,7,8,9],\"title\":{\"text\":\"Y-axis\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('e5b61ff6-84e2-4218-9926-234d8ed84332');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_trajectories = [200, 400, 600, 800, 1000]\n",
        "viz_over_num_trajectories(params, num_trajectories)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_CiwOKgruRPI",
        "outputId": "15bd1ca0-9be4-4434-9459-947aff5efb6a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"4dac218b-19d4-4bc6-b094-e3f7fa0825ae\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"4dac218b-19d4-4bc6-b094-e3f7fa0825ae\")) {                    Plotly.newPlot(                        \"4dac218b-19d4-4bc6-b094-e3f7fa0825ae\",                        [{\"mode\":\"lines\",\"name\":\"IS Bias\",\"x\":[200,400,600,800,1000],\"y\":[-0.7910840111391146,-0.7754583848851389,-0.7878696377843509,-0.7317661901798144,-0.569517620080633],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Train Bias\",\"x\":[200,400,600,800,1000],\"y\":[-0.8501098817752202,-0.8155757697510189,-0.7656738850742469,-0.7572505509343043,-0.7907660474865864],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Test Bias\",\"x\":[200,400,600,800,1000],\"y\":[-0.7462206306473811,-0.7697857214348978,-0.7808739896386753,-0.6814286744084254,-0.45681121217600806],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Bias over Trajectories\"},\"xaxis\":{\"title\":{\"text\":\"Number of Trajectories\"}},\"yaxis\":{\"title\":{\"text\":\"Bias\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('4dac218b-19d4-4bc6-b094-e3f7fa0825ae');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"5b1e60f9-4eb9-4584-b8c3-28bf502bedae\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"5b1e60f9-4eb9-4584-b8c3-28bf502bedae\")) {                    Plotly.newPlot(                        \"5b1e60f9-4eb9-4584-b8c3-28bf502bedae\",                        [{\"mode\":\"lines\",\"name\":\"IS Variance\",\"x\":[200,400,600,800,1000],\"y\":[0.0004088816058356315,0.0005283948848955333,0.000233165206736885,0.0015626709209755063,0.03197002410888672],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Train Variance\",\"x\":[200,400,600,800,1000],\"y\":[0.0017845697002485394,0.0025828590150922537,0.0011779131600633264,0.0014925855211913586,0.0009336181101389229],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Test Variance\",\"x\":[200,400,600,800,1000],\"y\":[0.0009481415036134422,0.00027270239661447704,0.00011801052460214123,0.0033278153277933598,0.06051691249012947],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Variance over Trajectories\"},\"xaxis\":{\"title\":{\"text\":\"Number of Trajectories\"}},\"yaxis\":{\"title\":{\"text\":\"Variance\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('5b1e60f9-4eb9-4584-b8c3-28bf502bedae');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"2ccac5a9-b896-4f2d-b1f8-de9fb6e751f6\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"2ccac5a9-b896-4f2d-b1f8-de9fb6e751f6\")) {                    Plotly.newPlot(                        \"2ccac5a9-b896-4f2d-b1f8-de9fb6e751f6\",                        [{\"mode\":\"lines\",\"name\":\"IS MSE\",\"x\":[200,400,600,800,1000],\"y\":[0.6262227942857865,0.6018641015735636,0.6209717313491813,0.5370444280112557,0.356320343691195],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Train MSE\",\"x\":[200,400,600,800,1000],\"y\":[0.7244713807921274,0.6677466952200591,0.5874344114447544,0.5749209824114987,0.6262445599676971],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Test MSE\",\"x\":[200,400,600,800,1000],\"y\":[0.5577933711073886,0.5928427593216605,0.6098821982188241,0.46767285363381716,0.2691933960598433],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"MSE over Trajectories\"},\"xaxis\":{\"title\":{\"text\":\"Number of Trajectories\"}},\"yaxis\":{\"title\":{\"text\":\"MSE\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('2ccac5a9-b896-4f2d-b1f8-de9fb6e751f6');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# max_length: 70\n",
        "\n",
        "list_trajectories = [200, 400, 600, 800, 1000]\n",
        "\n",
        "for i in list_trajectories:\n",
        "  params[\"num_trajectories\"] = i\n",
        "  test_experiment = SCOPE_experiment(**params)\n",
        "  print(f\"{i} trajectories:\")\n",
        "  test_load = existing_experiments(test_experiment)\n",
        "  test_load.plot_metrics()\n",
        "  test_load.get_heatmap()\n",
        "  test_load.get_state_visitation_heatmap()\n",
        "  # test_experiment.run_experiment()\n",
        "\n",
        "\n",
        "# test_experiment = SCOPE_experiment(**params)\n",
        "# test_experiment.run_experiment()\n",
        "# test_experiment.continue_training(300)\n",
        "# test_load = existing_experiments(test_experiment)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XAFMK0M74IYr",
        "outputId": "8a49a46c-5411-40d5-d91e-1de30a840181"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200 trajectories:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"73a8347d-84de-458c-97ac-be239cdda4f4\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"73a8347d-84de-458c-97ac-be239cdda4f4\")) {                    Plotly.newPlot(                        \"73a8347d-84de-458c-97ac-be239cdda4f4\",                        [{\"mode\":\"lines\",\"name\":\"IS Estimate\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189,0.04073905572295189],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"Train Estimate\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[-1.5462592840194702,0.16556741297245026,0.19398407638072968,0.22095654904842377,0.24718056619167328,0.27440643310546875,0.30560818314552307,0.33567002415657043,0.3655267655849457,0.3866831660270691,0.4071236550807953,0.42787832021713257,0.4468732476234436,0.4630236327648163,0.47831323742866516,0.4945683479309082,0.5123976469039917,0.5309240221977234,0.5484279990196228,0.5650159120559692,0.5806540846824646,0.5953940153121948,0.6088736057281494,0.6209450960159302,0.6303059458732605,0.6272101998329163,0.6235706210136414,0.6191449761390686,0.6138001084327698,0.6079642176628113,0.6022095680236816,0.5965915322303772,0.5909716486930847,0.5877963304519653,0.5850551128387451,0.5803640484809875,0.5757633447647095,0.5712854266166687,0.5668799877166748,0.5625342726707458,0.5580175518989563,0.5538384318351746,0.5497844219207764,0.5456840991973877,0.5418587923049927,0.5382200479507446,0.5345747470855713,0.5308900475502014,0.5272444486618042,0.5237876176834106,0.5203931331634521,0.5170625448226929,0.5137615203857422,0.5103012323379517,0.5069323182106018,0.5035644769668579,0.5001540780067444,0.49683326482772827,0.49369531869888306,0.4906626045703888,0.48778700828552246,0.48503896594047546,0.48241859674453735,0.47986114025115967,0.47742539644241333,0.47512978315353394,0.47293633222579956,0.47060689330101013,0.46827226877212524,0.4660586416721344,0.4643542468547821,0.46275097131729126,0.46123141050338745,0.45979273319244385,0.45842838287353516,0.4572732448577881,0.4562777876853943,0.45535117387771606,0.45452550053596497,0.4537622928619385,0.45304661989212036,0.45235127210617065,0.45168179273605347,0.45104894042015076,0.45045122504234314,0.44977685809135437,0.4490579068660736,0.4483657777309418,0.447757363319397,0.44720160961151123,0.4466613233089447,0.446137398481369,0.44562411308288574,0.4451189339160919,0.444621741771698,0.4441276788711548,0.44363412261009216,0.4431234896183014,0.4425816833972931,0.4420573115348816,0.4415278732776642,0.44101157784461975,0.4405041038990021,0.43998828530311584,0.4394626021385193,0.43892592191696167,0.43833836913108826,0.4376492202281952,0.4369533658027649,0.4362454116344452,0.4355243742465973,0.4347901940345764,0.43404296040534973,0.4332590401172638,0.43242979049682617,0.4315948784351349,0.43146005272865295,0.43150296807289124,0.43153131008148193,0.4315642714500427,0.4315909147262573,0.43159937858581543,0.43162801861763,0.43175289034843445,0.43195146322250366,0.43211689591407776,0.4322504997253418,0.4323803782463074,0.43247494101524353,0.4325404167175293,0.4325920343399048,0.432635635137558,0.4326530396938324,0.432643324136734,0.43260496854782104,0.43254268169403076,0.4322393536567688,0.43183809518814087,0.4314074218273163,0.43094608187675476,0.43045809864997864,0.4299469590187073,0.4294135272502899,0.4288615584373474,0.4282892644405365,0.4276972711086273,0.4270870089530945,0.426450252532959,0.4257907569408417,0.4251182973384857,0.42442983388900757,0.42370712757110596,0.4229944348335266,0.4222777783870697,0.4215724468231201,0.4208609461784363,0.4201451241970062,0.4194358289241791,0.4187208414077759,0.41799965500831604,0.4172728657722473,0.4165397882461548,0.41580626368522644,0.41510921716690063,0.4144079089164734,0.4136945307254791,0.4129754900932312,0.4122524857521057,0.4115249514579773,0.41079291701316833,0.4100562632083893,0.40930622816085815,0.40850064158439636,0.40766534209251404,0.406827449798584,0.405985951423645,0.40513327717781067,0.40416669845581055,0.4030006229877472,0.4018149673938751,0.40058478713035583,0.3993131220340729,0.3980390429496765,0.3967631459236145,0.395481675863266,0.39419740438461304,0.3929068148136139,0.39159852266311646,0.390275776386261,0.3889603912830353,0.3876454830169678,0.38633155822753906,0.3850652277469635,0.38379940390586853,0.3825322985649109,0.3812648355960846,0.37998753786087036,0.37869444489479065,0.37737905979156494,0.3760586678981781,0.3747406601905823,0.373425155878067,0.37211287021636963,0.3708042502403259,0.3695015013217926,0.36820200085639954,0.366904079914093,0.3656062185764313,0.36431238055229187,0.3631339371204376,0.36199843883514404,0.36087071895599365,0.35974910855293274,0.3586326539516449,0.35752201080322266,0.3564167022705078,0.35531678795814514,0.35422155261039734,0.35313108563423157,0.3520454466342926,0.3509645164012909,0.34988823533058167,0.348825603723526,0.3477729260921478,0.3467243015766144,0.3456760346889496,0.34463071823120117,0.34358924627304077,0.34255313873291016,0.3415197432041168,0.34048911929130554,0.3394613265991211,0.33842530846595764,0.33737635612487793,0.33632931113243103,0.33528444170951843,0.33424150943756104,0.33320069313049316,0.33216241002082825,0.3311266005039215,0.3300992548465729,0.3290879428386688,0.3280911445617676,0.3271089494228363,0.3261474668979645,0.3251931071281433,0.3242453336715698,0.3233036994934082,0.32242608070373535,0.3216004967689514,0.3207816779613495,0.3200111389160156,0.31923744082450867,0.3184678852558136,0.31770211458206177,0.3169395625591278,0.316179484128952,0.3154441714286804,0.3149345815181732,0.31446290016174316,0.3139866590499878,0.3135029375553131,0.31301262974739075,0.31249570846557617,0.31198278069496155,0.31149354577064514,0.3111814558506012,0.3109065592288971,0.31061458587646484,0.3102737069129944,0.30988967418670654,0.3095058500766754,0.30914586782455444,0.30878496170043945,0.30842408537864685,0.3080592155456543,0.30769678950309753,0.3073384761810303,0.30698007345199585,0.3066067695617676,0.3062121868133545,0.3058144450187683,0.30541256070137024,0.3050103485584259,0.3046058714389801,0.3041970133781433,0.303783655166626,0.303369402885437,0.3029542863368988,0.3025388717651367,0.30212295055389404,0.30156317353248596,0.3009769022464752,0.30038729310035706,0.29970479011535645,0.29902541637420654,0.29834893345832825,0.29765886068344116,0.2969644069671631,0.2962722182273865,0.29558199644088745,0.2948933243751526,0.29420480132102966,0.293842613697052,0.29349252581596375,0.2931520938873291,0.2928187847137451,0.2924914062023163,0.2921692132949829,0.29185155034065247,0.29153722524642944,0.2912197411060333,0.2908617854118347,0.2904815077781677,0.290103942155838,0.28976112604141235,0.2893948256969452,0.2890053391456604,0.2885945737361908,0.28816288709640503,0.2877116799354553,0.28724271059036255,0.28675684332847595,0.28625550866127014,0.28573980927467346,0.28521156311035156,0.28467196226119995,0.28412389755249023,0.28356844186782837,0.2830062210559845,0.28243792057037354,0.28186410665512085,0.28128495812416077,0.2807019352912903,0.28011465072631836,0.2795238792896271,0.27892959117889404,0.27833279967308044,0.2777332663536072,0.277131587266922,0.27652809023857117,0.2759251892566681,0.27532052993774414,0.2747145891189575,0.27410760521888733,0.2734994888305664,0.2728913128376007,0.2722831666469574,0.27167510986328125,0.27106615900993347,0.27045556902885437,0.26984429359436035,0.26923343539237976,0.26862263679504395,0.26801273226737976,0.2674039900302887,0.2667224109172821,0.2660008668899536,0.26528170704841614,0.264565646648407,0.2638721168041229,0.26318100094795227,0.2624913156032562,0.2618032395839691,0.2611168324947357,0.2604307532310486,0.25974419713020325,0.25905951857566833,0.2583759129047394,0.25769296288490295,0.25701045989990234,0.2563273310661316,0.2556505799293518,0.25497546792030334,0.2543017566204071,0.2536311745643616,0.25296252965927124,0.25229454040527344,0.25162652134895325,0.2509596645832062,0.2502904534339905,0.24962782859802246,0.24896889925003052,0.24831508100032806,0.24766916036605835,0.24702782928943634,0.2463979423046112,0.24577178061008453,0.2451387643814087,0.24450010061264038,0.24386397004127502,0.24323014914989471,0.24261577427387238,0.24202007055282593,0.24142426252365112,0.24082820117473602,0.24023212492465973,0.23963622748851776,0.23904475569725037,0.23845387995243073,0.23786376416683197,0.23727470636367798,0.23668642342090607,0.2360992431640625,0.23551316559314728,0.23492971062660217,0.23434856534004211,0.23377004265785217,0.23319342732429504,0.23261909186840057,0.23202729225158691,0.23142439126968384,0.23082531988620758,0.2302577942609787,0.22970722615718842,0.2291613221168518,0.22862175107002258,0.22808635234832764,0.22755585610866547,0.2270285189151764,0.22650407254695892,0.22598247230052948,0.22546344995498657,0.22494909167289734,0.22443713247776031,0.22392743825912476,0.2234199494123459,0.2229146659374237,0.22241126000881195,0.2219097912311554,0.22141045331954956,0.22091259062290192,0.22041645646095276,0.21992117166519165,0.21942773461341858,0.2189362794160843,0.2184465527534485,0.21795806288719177,0.2174641340970993,0.2169480174779892,0.21643340587615967,0.21592016518115997,0.21540549397468567,0.2148924320936203,0.21438109874725342,0.2138715386390686,0.21336372196674347,0.2128572314977646,0.21235255897045135,0.21185436844825745,0.2113589346408844,0.21086476743221283,0.2103719264268875,0.20988062024116516,0.20939086377620697,0.2089024931192398,0.20841586589813232,0.207930326461792,0.2074466049671173,0.2069641351699829,0.20648308098316193,0.2060033231973648,0.2055252641439438,0.20504851639270782,0.20457349717617035,0.2040998637676239,0.2036275565624237,0.2031560242176056,0.2026853859424591,0.20221561193466187,0.20174697041511536,0.20128078758716583,0.20086252689361572,0.20044556260108948,0.2000252604484558,0.19960293173789978,0.1991780698299408,0.19875140488147736,0.19832339882850647,0.19789491593837738,0.1974705010652542,0.19704557955265045,0.19662028551101685,0.1961948573589325,0.19576534628868103,0.19532813131809235,0.19489140808582306,0.19445544481277466,0.19402042031288147,0.1935863196849823,0.19315291941165924,0.19272002577781677,0.19228771328926086,0.19185663759708405,0.19142688810825348,0.19099895656108856,0.1905728578567505,0.19014853239059448,0.18972592055797577,0.18930502235889435],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"Test Estimate\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.26142174005508423,0.2454564869403839,0.22941391170024872,0.2131337672472,0.19676430523395538,0.18760955333709717,0.18247880041599274,0.17769469320774078,0.1730499416589737,0.16853658854961395,0.16404858231544495,0.1601697951555252,0.15671169757843018,0.15343856811523438,0.1501869261264801,0.14687320590019226,0.14356885850429535,0.1402226835489273,0.13682211935520172,0.13344983756542206,0.13009224832057953,0.1267617642879486,0.12310242652893066,0.11854145675897598,0.11405126005411148,0.10963962227106094,0.10524670779705048,0.10086387395858765,0.09655887633562088,0.09233223646879196,0.08818381279706955,0.08411354571580887,0.0801234021782875,0.07621412724256516,0.07238847762346268,0.0686475858092308,0.0649932250380516,0.06142638996243477,0.05794790759682655,0.0545588918030262,0.051260143518447876,0.0480673611164093,0.044967569410800934,0.04196047782897949,0.039046760648489,0.03622785210609436,0.033504292368888855,0.030868597328662872,0.028328442946076393,0.025886449962854385,0.023535137996077538,0.021266620606184006,0.019104937091469765,0.01704634167253971,0.01508778054267168,0.013228571973741055,0.011467167176306248,0.009801195934414864,0.00822377298027277,0.006740706041455269,0.005350854713469744,0.004052623640745878,0.0028444030322134495,0.00172427820507437,0.0006901033339090645,-0.0002604585897643119,-0.001129821059294045,-0.0019206806318834424,-0.00263134459964931,-0.003265787148848176,-0.0038271769881248474,-0.00431749178096652,-0.004739945288747549,-0.005098015535622835,-0.005395335610955954,-0.005635193083435297,-0.005820927210152149,-0.005955366883426905,-0.006042594090104103,-0.006085721775889397,-0.006087980233132839,-0.006052295211702585,-0.00598166836425662,-0.005878999829292297,-0.005746947135776281,-0.005589782260358334,-0.005407988093793392,-0.0052036806009709835,-0.0049792188219726086,-0.004736770875751972,-0.004478632938116789,-0.004206837620586157,-0.003923430573195219,-0.0036301235668361187,-0.0033286435063928366,-0.00302049214951694,-0.0027070518117398024,-0.002389834262430668,-0.0020704956259578466,-0.0017500232206657529,-0.0014297427842393517,-0.001110465032979846,-0.0007922265795059502,-0.0004758838622365147,-0.0001621568953851238,0.0001482797524658963,0.00045479866093955934,0.0007569489534944296,0.0010543493553996086,0.0013465688098222017,0.0016333486419171095,0.0019143627723678946,0.0021893149241805077,0.002457934897392988,0.002720809541642666,0.0029778101015836,0.003228641115128994,0.003470913739874959,0.0037047003861516714,0.0039433808997273445,0.004180764313787222,0.004409624729305506,0.0046301428228616714,0.004843379370868206,0.00505083380267024,0.005248292349278927,0.005436258390545845,0.0056153456680476665,0.005785936024039984,0.005948871839791536,0.006104609463363886,0.006254021544009447,0.006397412158548832,0.006535161752253771,0.006667556706815958,0.006794912740588188,0.0069174072705209255,0.00703901844099164,0.007159487344324589,0.007278763689100742,0.007396814879029989,0.007513703778386116,0.0076291803270578384,0.007741500157862902,0.007836422882974148,0.007930542342364788,0.008023736998438835,0.008115927688777447,0.008207407779991627,0.008295183070003986,0.008376844227313995,0.008458886295557022,0.00854796264320612,0.008636770769953728,0.008726813830435276,0.008817837573587894,0.008909502997994423,0.009001902304589748,0.009094692766666412,0.009187540039420128,0.009280177764594555,0.009373772889375687,0.009467237628996372,0.009561300277709961,0.009655715897679329,0.009750226512551308,0.009844773449003696,0.009939117357134819,0.010032975114881992,0.010126231238245964,0.010218732059001923,0.010310204699635506,0.010401985608041286,0.010493472218513489,0.010584408417344093,0.010674593970179558,0.010763873346149921,0.010852298699319363,0.01094236969947815,0.011034178547561169,0.011127361096441746,0.011221411637961864,0.011315351352095604,0.011410132981836796,0.011505422182381153,0.011601008474826813,0.01169663667678833,0.011791283264756203,0.011884957551956177,0.011977357789874077,0.012068557552993298,0.0121583491563797,0.012246750295162201,0.012335306964814663,0.012423884123563766,0.01251215860247612,0.012604488991200924,0.012698047794401646,0.01279070507735014,0.012882228009402752,0.012972654774785042,0.013061855919659138,0.013149830512702465,0.013236483559012413,0.013321861624717712,0.01340578030794859,0.013492411933839321,0.013578929007053375,0.013663901016116142,0.013747282326221466,0.013831975869834423,0.013917848467826843,0.014004654251039028,0.014092057943344116,0.014179832302033901,0.01426778081804514,0.0143990283831954,0.01454987470060587,0.014700251631438732,0.0148499496281147,0.014998863451182842,0.015146881341934204,0.015293873846530914,0.015439736656844616,0.01558438129723072,0.015727804973721504,0.015870075672864914,0.016011131927371025,0.016150901094079018,0.016289295628666878,0.016426293179392815,0.016561850905418396,0.016696151345968246,0.01682872697710991,0.016959616914391518,0.017088744789361954,0.01721614971756935,0.01734183542430401,0.017465882003307343,0.017588317394256592,0.017709186300635338,0.017831332981586456,0.017954455688595772,0.01807844452559948,0.018203064799308777,0.018328111618757248,0.018453340977430344,0.01857861503958702,0.0187037643045187,0.01882924884557724,0.018954968079924583,0.01908067613840103,0.019205832853913307,0.019330216571688652,0.019453812390565872,0.019576746970415115,0.01969890668988228,0.0198203194886446,0.019945265725255013,0.020095154643058777,0.02024255134165287,0.02038762904703617,0.020530806854367256,0.02067233994603157,0.020813042297959328,0.020953241735696793,0.021093057468533516,0.02122994139790535,0.02136370539665222,0.02149270474910736,0.021619750186800957,0.02174646407365799,0.021872755140066147,0.02199842780828476,0.02212345041334629,0.022248128429055214,0.022372547537088394,0.022496892139315605,0.022621093317866325,0.022744975984096527,0.022869044914841652,0.022993100807070732,0.023121356964111328,0.023281767964363098,0.02344195917248726,0.023601848632097244,0.02376171015202999,0.023921102285385132,0.02407992258667946,0.024238377809524536,0.024396343156695366,0.024553710594773293,0.02471139095723629,0.024869130924344063,0.025030361488461494,0.025194671005010605,0.025361521169543266,0.02553059160709381,0.02570239268243313,0.025876464322209358,0.026102609932422638,0.026341348886489868,0.02658177725970745,0.02683054469525814,0.027086591348052025,0.027349017560482025,0.02761678211390972,0.02788916602730751,0.028160396963357925,0.02839786373078823,0.028637561947107315,0.0288789551705122,0.0291238222271204,0.029371200129389763,0.02962009236216545,0.029870813712477684,0.030107341706752777,0.030331863090395927,0.03054865635931492,0.030753402039408684,0.03094182163476944,0.031121131032705307,0.03129196539521217,0.03145502880215645,0.03161101043224335,0.03176059201359749,0.03190453723073006,0.032043859362602234,0.03217900171875954,0.03231029212474823,0.03243809938430786,0.032562702894210815,0.032686248421669006,0.032808102667331696,0.03292744234204292,0.03304453566670418,0.03315954655408859,0.0332726389169693,0.03338401019573212,0.0334937684237957,0.033602066338062286,0.03370888531208038,0.03381431847810745,0.03391846641898155,0.03402144834399223,0.03412335366010666,0.03422427922487259,0.03432429954409599,0.034423474222421646,0.03452189639210701,0.03461936488747597,0.03471594676375389,0.034811727702617645,0.03490672633051872,0.03500102460384369,0.035094793885946274,0.03518911451101303,0.03528565168380737,0.035383082926273346,0.035481296479701996,0.035580094903707504,0.035679347813129425,0.03577891364693642,0.03587880730628967,0.035978976637125015,0.03607933223247528,0.036179475486278534,0.03627932444214821,0.0363791324198246,0.03647885099053383,0.03657851368188858,0.03667793050408363,0.03677724674344063,0.036876384168863297,0.03697546198964119,0.03707442060112953,0.03717323765158653,0.0372718945145607,0.037327490746974945,0.03721381351351738,0.03710062429308891,0.03698791190981865,0.03687569871544838,0.036763958632946014,0.03665270283818245,0.03654194623231888,0.036431651562452316,0.036321792751550674,0.03621239215135574,0.036103300750255585,0.03599456325173378,0.03588615730404854,0.03577810525894165,0.03567063808441162,0.03556375205516815,0.03545740991830826,0.03535163030028343,0.03524636849761009,0.03514162451028824,0.03503726050257683,0.03493335098028183,0.03482989966869354,0.034726932644844055,0.03462441265583038,0.03452229127287865,0.03442056477069855,0.03431924432516098,0.03421834111213684,0.03411787375807762,0.03401782363653183,0.03391820937395096,0.03381863236427307,0.033719129860401154,0.03361974656581879,0.03352048993110657,0.03342138230800629,0.033322468400001526,0.03322373703122139,0.033125244081020355,0.03302697092294693,0.0329289548099041,0.03283119574189186,0.03273369371891022,0.03263649344444275,0.032539572566747665,0.03244294598698616,0.03234664350748062,0.03225063905119896,0.03215495124459267,0.03205959126353264,0.03196455538272858,0.03186984360218048,0.03177545964717865,0.03168141469359398,0.03158772736787796,0.031494367867708206,0.03140132874250412,0.031308580189943314,0.03121677227318287,0.031126920133829117,0.03103713132441044,0.030947402119636536,0.030843591317534447,0.03073759190738201,0.030631784349679947,0.03052619658410549,0.030420828610658646,0.030315706506371498,0.030210837721824646,0.03010624647140503,0.030001940205693245,0.02989794872701168,0.029794253408908844,0.02969086356461048,0.029588287696242332,0.02948654815554619,0.029385091736912727,0.029283933341503143,0.02918306365609169,0.0290825292468071,0.02898233011364937,0.028882483020424843,0.028782980516552925,0.028684191405773163,0.028585778549313545,0.02848771959543228,0.028390008956193924,0.028292693197727203,0.02819579467177391,0.028099294751882553,0.02800319530069828,0.027907488867640495,0.02781217359006405,0.02771782875061035,0.02762438915669918,0.027531780302524567,0.027439972385764122,0.02734891138970852,0.027258548885583878,0.027168860659003258,0.027079815044999123,0.02699139155447483,0.026903539896011353,0.02681623212993145,0.026729440316557884,0.02664315141737461,0.02655734308063984,0.026471996679902077,0.02638734132051468,0.026303265243768692,0.026219600811600685,0.026136334985494614,0.02605343982577324,0.02597089298069477,0.02588866837322712,0.025806760415434837,0.02572515606880188,0.02564385160803795,0.025562845170497894,0.02548215351998806],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"On-policy Estimate\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641,0.8210778338655641],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"IS Variance\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117,0.0013326029293239117],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"lines\",\"name\":\"Train Variance\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.8603394031524658,0.8808960318565369,0.8039735555648804,0.7314749956130981,0.6632106900215149,0.5995612144470215,0.5409103035926819,0.4871397912502289,0.43956226110458374,0.40486305952072144,0.37437018752098083,0.34696027636528015,0.3220832645893097,0.29921284317970276,0.2783495783805847,0.25950807332992554,0.2412150502204895,0.22414478659629822,0.2088126689195633,0.19507257640361786,0.1828491985797882,0.1720084547996521,0.16243334114551544,0.15427573025226593,0.14825031161308289,0.1493307650089264,0.15058358013629913,0.15173599123954773,0.15279743075370789,0.15389804542064667,0.15514439344406128,0.15654507279396057,0.15806123614311218,0.16055643558502197,0.16335095465183258,0.1655815690755844,0.1678580343723297,0.17020069062709808,0.17259322106838226,0.17502178251743317,0.17746953666210175,0.18007132411003113,0.182723268866539,0.1853332221508026,0.18795929849147797,0.19053731858730316,0.1930590271949768,0.19550961256027222,0.19788123667240143,0.20016422867774963,0.20234794914722443,0.20441934466362,0.2063513547182083,0.20803166925907135,0.20959579944610596,0.21095120906829834,0.21206478774547577,0.21301935613155365,0.21383136510849,0.21449576318264008,0.21501651406288147,0.21538661420345306,0.21560610830783844,0.21565130352973938,0.2155475914478302,0.21530404686927795,0.21491685509681702,0.21455146372318268,0.214124396443367,0.21355991065502167,0.2130669206380844,0.2124471515417099,0.2116980254650116,0.21082526445388794,0.20983503758907318,0.20882241427898407,0.20773400366306305,0.20654356479644775,0.20525963604450226,0.20388853549957275,0.20243777334690094,0.20091432332992554,0.19932514429092407,0.19767698645591736,0.19597624242305756,0.1941942721605301,0.19235576689243317,0.19048021733760834,0.18857353925704956,0.18664078414440155,0.18468685448169708,0.1827172338962555,0.18073560297489166,0.17874613404273987,0.17675243318080902,0.17475798726081848,0.1727656126022339,0.17078661918640137,0.16883018612861633,0.166883647441864,0.16494929790496826,0.16301845014095306,0.1610921323299408,0.15918046236038208,0.1572851985692978,0.1554073989391327,0.15354831516742706,0.1517086774110794,0.14988955855369568,0.14809150993824005,0.14631500840187073,0.14456051588058472,0.1428283452987671,0.1411295384168625,0.13946601748466492,0.13782520592212677,0.13652515411376953,0.13532370328903198,0.1341324746608734,0.13297228515148163,0.13183407485485077,0.13070634007453918,0.12960177659988403,0.12854664027690887,0.12755095958709717,0.12657108902931213,0.12560586631298065,0.1246543824672699,0.1237153485417366,0.12278755009174347,0.12187075614929199,0.12096454948186874,0.12006815522909164,0.11918097734451294,0.11830271780490875,0.1174328550696373,0.1166534572839737,0.11590071767568588,0.11514942348003387,0.11439960449934006,0.11365162581205368,0.11290536820888519,0.11216045171022415,0.11141655594110489,0.11067458987236023,0.10993445664644241,0.1091964989900589,0.1084633395075798,0.10773777216672897,0.10701324790716171,0.10628990828990936,0.10556675493717194,0.10484139621257782,0.10411141812801361,0.10336033999919891,0.10261016339063644,0.10186130553483963,0.10111383348703384,0.10036830604076385,0.09962505102157593,0.09888458251953125,0.09814689308404922,0.09741037338972092,0.09665858000516891,0.09590911120176315,0.0951630175113678,0.09442002326250076,0.09368034452199936,0.0929441824555397,0.09221190214157104,0.09148372709751129,0.09075748175382614,0.0900198295712471,0.08929865062236786,0.08858184516429901,0.0878695622086525,0.0871618241071701,0.08641824126243591,0.08561957627534866,0.0848226547241211,0.08402998745441437,0.08324166387319565,0.08245822042226791,0.08168061822652817,0.08090909570455551,0.08014368265867233,0.0793830081820488,0.07862576842308044,0.0778755396604538,0.0771329328417778,0.07639770954847336,0.07567012310028076,0.07496683299541473,0.07427024841308594,0.07357979565858841,0.0728958249092102,0.07221885770559311,0.07154815644025803,0.07088419795036316,0.0702269971370697,0.06957682222127914,0.06893354654312134,0.06829729676246643,0.06766785681247711,0.06704513728618622,0.06642943620681763,0.06582174450159073,0.06522111594676971,0.06462729722261429,0.06401340663433075,0.06339725106954575,0.06279196590185165,0.062190067023038864,0.061591897159814835,0.060997869819402695,0.06040831655263901,0.05982353538274765,0.059243813157081604,0.05866922065615654,0.05810005962848663,0.05753650888800621,0.056978702545166016,0.056426793336868286,0.055880822241306305,0.05534115806221962,0.05480770766735077,0.05428032577037811,0.05375916510820389,0.05324363335967064,0.05273431912064552,0.05223137512803078,0.051734741777181625,0.051246386021375656,0.05076573044061661,0.05029033496975899,0.04982029274106026,0.04935593158006668,0.04889724776148796,0.04844431206583977,0.04799700155854225,0.04755428805947304,0.04711201786994934,0.04667208343744278,0.04623640701174736,0.045807331800460815,0.04538143053650856,0.04495885595679283,0.044539887458086014,0.04413604736328125,0.043743912130594254,0.04335479065775871,0.04298565536737442,0.042628899216651917,0.04227559268474579,0.041925735771656036,0.0415792353451252,0.04123598709702492,0.04090170934796333,0.04061790183186531,0.04034290835261345,0.04007013887166977,0.03979925811290741,0.039530351758003235,0.03926343098282814,0.038995929062366486,0.03872539848089218,0.038499608635902405,0.038289885967969894,0.03808454051613808,0.037879474461078644,0.03767438232898712,0.03746936470270157,0.03729565814137459,0.03712255880236626,0.03694945573806763,0.03677607700228691,0.03660218417644501,0.036427583545446396,0.03625262528657913,0.03607730194926262,0.035901594907045364,0.03572440147399902,0.035545963793992996,0.035367149859666824,0.03518800064921379,0.0350085087120533,0.034828394651412964,0.034648098051548004,0.03446774557232857,0.03428737074136734,0.0341070182621479,0.03395674005150795,0.03381170332431793,0.033666037023067474,0.033511191606521606,0.03335566073656082,0.033199578523635864,0.03303986415266991,0.032878145575523376,0.03271598368883133,0.03255343437194824,0.03239067643880844,0.03222734481096268,0.032009903341531754,0.03179134801030159,0.03157172352075577,0.031351398676633835,0.031130611896514893,0.030909590423107147,0.030688615515828133,0.03046790137887001,0.030245309695601463,0.030015908181667328,0.029785893857479095,0.02955605648458004,0.029475050047039986,0.029404057189822197,0.029330667108297348,0.02925502322614193,0.029177121818065643,0.029097070917487144,0.029015028849244118,0.02893099933862686,0.028845088556408882,0.028757384046912193,0.028668085113167763,0.028577595949172974,0.028486104682087898,0.028393689543008804,0.028300391510128975,0.02820628695189953,0.028111403807997704,0.028015775606036186,0.027919454500079155,0.0278224628418684,0.027724890038371086,0.027626730501651764,0.02752814255654812,0.027429021894931793,0.027329517528414726,0.027229631319642067,0.027129316702485085,0.027028599753975868,0.026927581056952477,0.026826266199350357,0.026724673807621002,0.026623042300343513,0.026521384716033936,0.026419658213853836,0.026321206241846085,0.026224149391055107,0.026127072051167488,0.026029933243989944,0.025932712480425835,0.025835437700152397,0.02573821134865284,0.02564200572669506,0.02554677426815033,0.02545175887644291,0.025357071310281754,0.02526712603867054,0.02517738565802574,0.025087639689445496,0.024997923523187637,0.024908285588026047,0.02481868490576744,0.024729125201702118,0.024639593437314034,0.02455001324415207,0.024460462853312492,0.024370916187763214,0.02428072690963745,0.02418990433216095,0.02409900352358818,0.024007920175790787,0.023916663601994514,0.02382528781890869,0.02373391203582287,0.023642532527446747,0.023551112040877342,0.02345975488424301,0.023368433117866516,0.02327721379697323,0.02318652905523777,0.023096755146980286,0.02300696261227131,0.02291657216846943,0.022826161235570908,0.022734107449650764,0.02264072746038437,0.022547803819179535,0.022455308586359024,0.022366512566804886,0.02228168584406376,0.022196896374225616,0.02211209572851658,0.022027328610420227,0.021942639723420143,0.02185795269906521,0.021773388609290123,0.02168899215757847,0.02160480245947838,0.021520784124732018,0.021436983719468117,0.021353423595428467,0.02127065137028694,0.021188581362366676,0.02110719494521618,0.021026408299803734,0.020946206524968147,0.020858213305473328,0.0207647867500782,0.020672358572483063,0.02058042399585247,0.020489154383540154,0.0203988216817379,0.02030966244637966,0.020221225917339325,0.020133471116423607,0.020046355202794075,0.01995985023677349,0.019873948767781258,0.019788598641753197,0.01970388926565647,0.01961970143020153,0.019536035135388374,0.019452860578894615,0.019370198249816895,0.019287966191768646,0.019206218421459198,0.019124938175082207,0.019044063985347748,0.018963683396577835,0.018883714452385902,0.01880413480103016,0.01872495748102665,0.01864616759121418,0.018567733466625214,0.018490470945835114,0.01841607131063938,0.018342144787311554,0.018268626183271408,0.018194956704974174,0.018121713772416115,0.018048904836177826,0.017976535484194756,0.01790461502969265,0.017833108082413673,0.017762036994099617,0.01769125461578369,0.01762077771127224,0.01755061373114586,0.01748073287308216,0.017411191016435623,0.017342006787657738,0.01727312058210373,0.01720461994409561,0.017136404290795326,0.017068585380911827,0.017001064494252205,0.01693386398255825,0.016866974532604218,0.016800476238131523,0.0167342908680439,0.016668446362018585,0.01660277508199215,0.016537277027964592,0.016471894457936287,0.016406655311584473,0.016341565176844597,0.0162766445428133,0.01621210016310215,0.01615641638636589,0.01610114425420761,0.016045507043600082,0.015989622101187706,0.015933461487293243,0.015877118334174156,0.015820661559700966,0.01576407253742218,0.015707267448306084,0.01565035805106163,0.01559341698884964,0.015536482445895672,0.015479633584618568,0.015422919765114784,0.015366336330771446,0.015309846960008144,0.015253518708050251,0.01519730780273676,0.01514128316193819,0.015085437335073948,0.01502986066043377,0.014974591322243214,0.014919601380825043,0.01486506499350071,0.014810973778367043,0.01475727278739214,0.014703979715704918,0.01465107873082161],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"lines\",\"name\":\"Test Variance\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.001974988728761673,0.0018770983442664146,0.0017789910780265927,0.0016822811448946595,0.0015873045194894075,0.0015125767095014453,0.0014585538301616907,0.0014105800073593855,0.001348650548607111,0.0012848959304392338,0.0012234008172526956,0.00116897898260504,0.0011206284398213029,0.0010766431223601103,0.0010351970558986068,0.0009964581113308668,0.0009600302437320352,0.0009249223512597382,0.0008907282026484609,0.0008584528113715351,0.0008280983893200755,0.0007995158666744828,0.0007673556101508439,0.0007227188907563686,0.0006802401039749384,0.0006398131372407079,0.0006013110978528857,0.0005647054058499634,0.0005300063639879227,0.0004971418529748917,0.0004660371341742575,0.0004366246284916997,0.00040884388727135956,0.00038263038732111454,0.00035793380811810493,0.0003346892190165818,0.0003128377429675311,0.00029232283122837543,0.00027308581047691405,0.00025506835663691163,0.000238217951846309,0.00022263101709540933,0.00020812080765608698,0.0001946214761119336,0.00018207708490081131,0.0001704401074675843,0.00015966188220772892,0.00014970322081353515,0.00014051288599148393,0.0001320462324656546,0.00012428127229213715,0.00011719943722710013,0.00011079815158154815,0.0001049825077643618,9.968102676793933e-05,9.48584420257248e-05,9.048011270351708e-05,8.649990195408463e-05,8.282827184302732e-05,7.951408042572439e-05,7.653032662346959e-05,7.385158824035898e-05,7.14541383786127e-05,6.931541429366916e-05,6.741510151186958e-05,6.573341670446098e-05,6.425259925890714e-05,6.295631465036422e-05,6.183078221511096e-05,6.086536086513661e-05,6.0047190345358104e-05,5.936564048170112e-05,5.880946991965175e-05,5.836882337462157e-05,5.8034562243847176e-05,5.7798995840130374e-05,5.7654840929899365e-05,5.760066051152535e-05,5.762350338045508e-05,5.771760697825812e-05,5.787750342278741e-05,5.80986998102162e-05,5.837655407958664e-05,5.87067443120759e-05,5.908541061216965e-05,5.950079139438458e-05,5.9955935284961015e-05,6.045016198186204e-05,6.098018275224604e-05,6.154293805593625e-05,6.213533197296783e-05,6.275432679103687e-05,6.339695391943678e-05,6.406050670193508e-05,6.474227120634168e-05,6.543993367813528e-05,6.615107122343034e-05,6.687326094834134e-05,6.760287942597643e-05,6.83379330439493e-05,6.907665374455974e-05,6.981715705478564e-05,7.055707828840241e-05,7.129482401069254e-05,7.202897540992126e-05,7.27581063983962e-05,7.348083454417065e-05,7.41961775929667e-05,7.490334246540442e-05,7.560111407656223e-05,7.628864113939926e-05,7.696499960729852e-05,7.762937457300723e-05,7.82810093369335e-05,7.892063877079636e-05,7.954765169415623e-05,8.016126957954839e-05,8.075359801296145e-05,8.132489892886952e-05,8.192117820726708e-05,8.252201951108873e-05,8.310222619911656e-05,8.366208930965513e-05,8.422156679444015e-05,8.481313852826133e-05,8.538150723325089e-05,8.59274878166616e-05,8.645242633065209e-05,8.695702126715332e-05,8.74432225828059e-05,8.791172876954079e-05,8.836422784952447e-05,8.880128734745085e-05,8.922362758312374e-05,8.963185246102512e-05,9.002664592117071e-05,9.040821169037372e-05,9.078587754629552e-05,9.115929424297065e-05,9.152846178039908e-05,9.189292177325115e-05,9.225304529536515e-05,9.260819206247106e-05,9.294774645240977e-05,9.318867523688823e-05,9.342811972601339e-05,9.366530866827816e-05,9.390015475219116e-05,9.413350198883563e-05,9.43201594054699e-05,9.443206363357604e-05,9.454621613258496e-05,9.467562631471083e-05,9.480552398599684e-05,9.494084224570543e-05,9.508067887509242e-05,9.522429900243878e-05,9.537139703752473e-05,9.552108531352133e-05,9.567233064444736e-05,9.582434722688049e-05,9.597763710189611e-05,9.613105794414878e-05,9.628802217775956e-05,9.644756210036576e-05,9.660933574195951e-05,9.677276102593169e-05,9.693700849311426e-05,9.710122685646638e-05,9.726499411044642e-05,9.742769179865718e-05,9.758861415321007e-05,9.775251965038478e-05,9.791683260118589e-05,9.808094910113141e-05,9.824406151892617e-05,9.84057696769014e-05,9.856624092208222e-05,9.872810187516734e-05,9.889221109915525e-05,9.905771003104746e-05,9.920605953084305e-05,9.928821964422241e-05,9.937146387528628e-05,9.945499186869711e-05,9.953858534572646e-05,9.962142212316394e-05,9.970046812668443e-05,9.97749884845689e-05,9.984489588532597e-05,9.991064143832773e-05,9.997186134569347e-05,0.00010002843919210136,0.00010008760000346228,0.0001001486016320996,0.00010021035268437117,0.00010029736586147919,0.00010039435437647626,0.00010048951662611216,0.00010058205953100696,0.00010067185939988121,0.00010075866157421842,0.00010084222594741732,0.00010092229786096141,0.00010099885548697785,0.00010107145499205217,0.0001010851192404516,0.00010107785783475265,0.00010106676199939102,0.00010105184628628194,0.00010104310786118731,0.0001010400737868622,0.00010104168904945254,0.00010104700777446851,0.00010105517139891163,0.00010106533591169864,0.00010108170681633055,0.00010110108269145712,0.00010112089512404054,0.00010114046017406508,0.00010115928307641298,0.0001011767890304327,0.00010119259241037071,0.00010120606748387218,0.0001012167995213531,0.00010122491949005052,0.00010123014362761751,0.00010123237007064745,0.00010123143874807283,0.00010122704406967387,0.00010121901141246781,0.00010120727529283613,0.00010119242506334558,0.00010117691272171214,0.00010116048360941932,0.0001011426211334765,0.0001011229760479182,0.00010110135190188885,0.00010107755224453285,0.00010105132241733372,0.00010102239320985973,0.00010100130748469383,0.00010098679194925353,0.00010097811173181981,0.00010097422637045383,0.00010097413178300485,0.00010097701306222007,0.00010098230268340558,0.0001009889820124954,0.00010099908104166389,0.00010101179941557348,0.00010102659143740311,0.00010104092507390305,0.00010105429828399792,0.00010106652916874737,0.00010107774141943082,0.00010108782589668408,0.0001010965061141178,0.00010102955275215209,0.00010060828208224848,0.0001001921555143781,9.978114394471049e-05,9.937534923665226e-05,9.897490963339806e-05,9.858006524154916e-05,9.819084516493604e-05,9.780754044186324e-05,9.741808025864884e-05,9.702138049760833e-05,9.632900764700025e-05,9.551658149575815e-05,9.47152148000896e-05,9.392490755999461e-05,9.314593626186252e-05,9.237810445483774e-05,9.162118658423424e-05,9.087494254345074e-05,9.013897943077609e-05,8.94135155249387e-05,8.869841985870153e-05,8.799308852758259e-05,8.729827095521614e-05,8.662030450068414e-05,8.600656292401254e-05,8.540443377569318e-05,8.48138370201923e-05,8.42345179989934e-05,8.366531255887821e-05,8.310620614793152e-05,8.255823195213452e-05,8.202131721191108e-05,8.149516361299902e-05,8.097926911432296e-05,8.04736846475862e-05,7.997727516340092e-05,7.949043356347829e-05,7.901347271399572e-05,7.854663272155449e-05,7.808998634573072e-05,7.764366455376148e-05,7.73652718635276e-05,7.711721991654485e-05,7.687559991609305e-05,7.664415898034349e-05,7.642235141247511e-05,7.62098643463105e-05,7.600626850035042e-05,7.581118552479893e-05,7.560243102489039e-05,7.523740350734442e-05,7.487784750992432e-05,7.45235665817745e-05,7.417518645524979e-05,7.383028423646465e-05,7.348674989771098e-05,7.314871618291363e-05,7.281231955857947e-05,7.247545727295801e-05,7.21316973795183e-05,7.178445957833901e-05,7.139905210351571e-05,7.101811934262514e-05,7.064168312354013e-05,7.026951789157465e-05,6.990157999098301e-05,6.953778938623145e-05,6.917746213730425e-05,6.882063462398946e-05,6.846726319054142e-05,6.811734056100249e-05,6.777095404686406e-05,6.74280890962109e-05,6.709137232974172e-05,6.675952317891642e-05,6.643115193583071e-05,6.610622949665412e-05,6.578471948159859e-05,6.546662916662171e-05,6.515197310363874e-05,6.48406712571159e-05,6.453280366258696e-05,6.422823207685724e-05,6.392700015567243e-05,6.362902786349878e-05,6.333435158012435e-05,6.304289127001539e-05,6.275461782934144e-05,6.246942939469591e-05,6.218731869012117e-05,6.190824933582917e-05,6.163225043565035e-05,6.135919829830527e-05,6.108918751124293e-05,6.082213076297194e-05,6.055800258764066e-05,6.0296755691524595e-05,6.004136594128795e-05,5.9792488173116e-05,5.954657171969302e-05,5.93035074416548e-05,5.906341539230198e-05,5.8826470194617286e-05,5.859249358763918e-05,5.836154377902858e-05,5.813354073325172e-05,5.790836803498678e-05,5.766648973803967e-05,5.7402696256758645e-05,5.714206417906098e-05,5.6884473451646045e-05,5.662988041876815e-05,5.6378245062660426e-05,5.612946915789507e-05,5.588347994489595e-05,5.564025559579022e-05,5.539974517887458e-05,5.5161883210530505e-05,5.492662967299111e-05,5.4677333537256345e-05,5.436520223156549e-05,5.4055748478276655e-05,5.374903048505075e-05,5.344500095816329e-05,5.314358713803813e-05,5.28448072145693e-05,5.254866846371442e-05,5.2255123591749e-05,5.196405982133001e-05,5.167544077266939e-05,5.138880806043744e-05,5.110417623654939e-05,5.082156712887809e-05,5.0540980737423524e-05,5.0263453886145726e-05,4.9988881073659286e-05,4.9717174988472834e-05,4.944822649122216e-05,4.9181977374246344e-05,4.891826756647788e-05,4.8657198931323364e-05,4.8398549552075565e-05,4.814223211724311e-05,4.78881411254406e-05,4.763633114635013e-05,4.7387195081682876e-05,4.7140201786533e-05,4.689516936196014e-05,4.6652079618070275e-05,4.641099076252431e-05,4.617187369149178e-05,4.5934713853057474e-05,4.569784505292773e-05,4.546140189631842e-05,4.522552262642421e-05,4.499017813941464e-05,4.475549212656915e-05,4.452163921087049e-05,4.4288713979767635e-05,4.405680738273077e-05,4.3825955799547955e-05,4.3596202885964885e-05,4.3367577745812014e-05,4.314016769058071e-05,4.29140345659107e-05,4.268916745786555e-05,4.246563548804261e-05,4.224344957037829e-05,4.202263517072424e-05,4.180322866886854e-05,4.1585230064811185e-05,4.136869029025547e-05,4.1153554775519297e-05,4.093985990039073e-05,4.072764204465784e-05,4.051695214002393e-05,4.030769196106121e-05,4.0099908801494166e-05,3.9893548091640696e-05,3.969065801356919e-05,3.949512029066682e-05,3.930041566491127e-05,3.9106580516090617e-05,3.886332706315443e-05,3.861340883304365e-05,3.836527685052715e-05,3.811900023720227e-05,3.787451350945048e-05,3.763188578886911e-05,3.739110616152175e-05,3.7152251024963334e-05,3.69153858628124e-05,3.668046701932326e-05,3.64475890819449e-05,3.621665382524952e-05,3.599095362005755e-05,3.5770728572970256e-05,3.555231523932889e-05,3.5335666325408965e-05,3.5120738175464794e-05,3.490768722258508e-05,3.469647344900295e-05,3.4487082302803174e-05,3.42794883181341e-05,3.4073244023602456e-05,3.386875323485583e-05,3.3665950468275696e-05,3.3464832085883245e-05,3.326555452076718e-05,3.3068110496969894e-05,3.287248546257615e-05,3.267864667577669e-05,3.2486554118804634e-05,3.229618596378714e-05,3.210911381756887e-05,3.1925159419188276e-05,3.174404992023483e-05,3.156567254336551e-05,3.138985630357638e-05,3.121645931969397e-05,3.1045365176396444e-05,3.0876442906446755e-05,3.0709583370480686e-05,3.0544666515197605e-05,3.0381595934159122e-05,3.022030614374671e-05,3.0060726203373633e-05,2.990280518133659e-05,2.9746412110398524e-05,2.9591259590233676e-05,2.94373749056831e-05,2.928487811004743e-05,2.9133727366570383e-05,2.8983844458707608e-05,2.883514025597833e-05,2.86876402242342e-05,2.854124795703683e-05,2.8395992558216676e-05,2.825183401000686e-05,2.810875594150275e-05,2.7966823836322874e-05],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"lines\",\"name\":\"Train MSE Loss\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[25.396820068359375,24.255537033081055,23.026750564575195,21.84567642211914,20.711366653442383,19.62667465209961,18.60062599182129,17.62017250061035,16.68452262878418,15.792348861694336,14.941758155822754,14.12899398803711,13.35513973236084,12.620294570922852,11.923026084899902,11.265339851379395,10.64126968383789,10.048590660095215,9.485523223876953,8.951775550842285,8.447185516357422,7.972337245941162,7.524096488952637,7.100855350494385,6.701838493347168,6.326242446899414,5.972498893737793,5.639874458312988,5.328122138977051,5.035315990447998,4.759843349456787,4.50095796585083,4.257970333099365,4.030184745788574,3.8168556690216064,3.6170008182525635,3.4300825595855713,3.2552385330200195,3.091898202896118,2.9396092891693115,2.797682285308838,2.6652822494506836,2.542009115219116,2.4274163246154785,2.321063756942749,2.2224297523498535,2.131011486053467,2.0464084148406982,1.968117356300354,1.895668625831604,1.828689694404602,1.7668260335922241,1.7096843719482422,1.6569650173187256,1.6082839965820312,1.5632894039154053,1.5216424465179443,1.483059287071228,1.44728422164917,1.4140770435333252,1.3831982612609863,1.354469656944275,1.3276970386505127,1.3026999235153198,1.2792885303497314,1.2573223114013672,1.2366544008255005,1.2170979976654053,1.198585033416748,1.1810263395309448,1.1643128395080566,1.1483509540557861,1.1330703496932983,1.1184154748916626,1.104323148727417,1.0907495021820068,1.0776641368865967,1.0650200843811035,1.0527783632278442,1.0409018993377686,1.0293519496917725,1.0180962085723877,1.0071154832839966,0.9964011907577515,0.985939621925354,0.97569739818573,0.9656664729118347,0.9558413028717041,0.9462124705314636,0.9367717504501343,0.927512526512146,0.9184281229972839,0.9095149636268616,0.9007647037506104,0.892168402671814,0.8837273120880127,0.8754379153251648,0.8672940731048584,0.8592916131019592,0.8514271378517151,0.8436955809593201,0.8360785245895386,0.828587532043457,0.8212214708328247,0.8139773011207581,0.8068510293960571,0.799834668636322,0.7929275631904602,0.7861290574073792,0.7794382572174072,0.7728509902954102,0.7663649916648865,0.7599782943725586,0.7536867260932922,0.7474895119667053,0.7413836717605591,0.7353845238685608,0.7295144200325012,0.7237530946731567,0.7180920243263245,0.712529718875885,0.707063615322113,0.7016904354095459,0.6964115500450134,0.6912270188331604,0.6861217617988586,0.6810944676399231,0.676137387752533,0.6712477207183838,0.6664260029792786,0.6616683602333069,0.6569774746894836,0.6523510217666626,0.6477863788604736,0.6432812809944153,0.6388362646102905,0.6344438195228577,0.6301165223121643,0.6258547902107239,0.6216566562652588,0.6175190806388855,0.6134446263313293,0.609427273273468,0.6054650545120239,0.6015557050704956,0.5976985692977905,0.5938906073570251,0.59012371301651,0.586374044418335,0.582669198513031,0.5790089964866638,0.5753890872001648,0.571810781955719,0.5682713389396667,0.5647618770599365,0.5612913966178894,0.5578584671020508,0.5544593930244446,0.5510984063148499,0.5477769374847412,0.5444917678833008,0.5412423610687256,0.5380272269248962,0.5348390340805054,0.5316846370697021,0.5285609364509583,0.5254706144332886,0.5224143862724304,0.5193906426429749,0.516398549079895,0.5134342908859253,0.5104920268058777,0.507564902305603,0.5046674013137817,0.5017985701560974,0.4989582598209381,0.4961438477039337,0.4933396577835083,0.4905189871788025,0.48771268129348755,0.48492076992988586,0.48214390873908997,0.4793786406517029,0.47662922739982605,0.47389811277389526,0.4711846113204956,0.46848881244659424,0.4658091962337494,0.46315011382102966,0.460511177778244,0.4578934609889984,0.45529821515083313,0.4527251124382019,0.45017707347869873,0.4476549029350281,0.44515833258628845,0.4426877200603485,0.44024401903152466,0.43782633543014526,0.4354332387447357,0.43306413292884827,0.4307188391685486,0.4283967912197113,0.4260980486869812,0.42382505536079407,0.42157676815986633,0.4193502962589264,0.41715019941329956,0.4149727523326874,0.41280093789100647,0.41064539551734924,0.4085019826889038,0.40637972950935364,0.404278427362442,0.4021977186203003,0.40013349056243896,0.3980884552001953,0.3960619270801544,0.3940562903881073,0.39207011461257935,0.39010319113731384,0.38815608620643616,0.38622817397117615,0.3843214213848114,0.3824322521686554,0.3805595934391022,0.37870463728904724,0.3768674433231354,0.3750437796115875,0.3732365667819977,0.3714456856250763,0.36966943740844727,0.3679080903530121,0.36616477370262146,0.3644393980503082,0.3627324402332306,0.3610379099845886,0.3593587577342987,0.3576948940753937,0.35604599118232727,0.3543926775455475,0.35273125767707825,0.3510820269584656,0.3494451344013214,0.34782007336616516,0.3462097942829132,0.3446141481399536,0.3430328369140625,0.3414497971534729,0.3398677706718445,0.33830001950263977,0.33674412965774536,0.3351912498474121,0.3336530029773712,0.33212172985076904,0.33060234785079956,0.32909685373306274,0.32760512828826904,0.32611730694770813,0.32464075088500977,0.32318031787872314,0.3217320740222931,0.3202987611293793,0.3188733756542206,0.3174607455730438,0.316061794757843,0.31467360258102417,0.313300222158432,0.31194713711738586,0.31060779094696045,0.3092818260192871,0.3079715371131897,0.3066467344760895,0.3053368330001831,0.3040407598018646,0.302756667137146,0.30148565769195557,0.3002263903617859,0.2989802062511444,0.2977446913719177,0.29651734232902527,0.29530373215675354,0.29410240054130554,0.2929132580757141,0.2917359173297882,0.290569007396698,0.2894115447998047,0.2882653474807739,0.28712987899780273,0.2860049307346344,0.2848905026912689,0.28374913334846497,0.28261181712150574,0.28148385882377625,0.2803390324115753,0.279201477766037,0.27807140350341797,0.27694612741470337,0.27582675218582153,0.2747149169445038,0.2736101746559143,0.2725115418434143,0.27141913771629333,0.27032554149627686,0.2692349851131439,0.2681468427181244,0.2670636773109436,0.2659858763217926,0.26491427421569824,0.2638491094112396,0.26279085874557495,0.26172739267349243,0.26066750288009644,0.259613960981369,0.25856703519821167,0.25752899050712585,0.25651007890701294,0.2555083632469177,0.2545230984687805,0.2535534203052521,0.25259870290756226,0.25165894627571106,0.25073280930519104,0.24981926381587982,0.24891752004623413,0.2480258196592331,0.24713948369026184,0.24626177549362183,0.24539324641227722,0.24453388154506683,0.2436835765838623,0.24284180998802185,0.24200838804244995,0.24118322134017944,0.24036599695682526,0.23955661058425903,0.23875480890274048,0.23796044290065765,0.23717336356639862,0.23639331758022308,0.23562023043632507,0.234854593873024,0.23409585654735565,0.23334382474422455,0.232598215341568,0.23185881972312927,0.23112498223781586,0.23039665818214417,0.2296740561723709,0.22895486652851105,0.2282404601573944,0.2275315225124359,0.226828470826149,0.22613093256950378,0.225438192486763,0.22475045919418335,0.2240619659423828,0.22337396442890167,0.22268997132778168,0.22201018035411835,0.22133344411849976,0.22066086530685425,0.21999283134937286,0.2193293273448944,0.21867051720619202,0.21801666915416718,0.21736781299114227,0.2167235165834427,0.2160838097333908,0.21544842422008514,0.2148173451423645,0.21419104933738708,0.2135688215494156,0.21294991672039032,0.21233457326889038,0.21172328293323517,0.21111592650413513,0.21051232516765594,0.20991195738315582,0.20931527018547058,0.20872285962104797,0.20813432335853577,0.20754946768283844,0.2069680392742157,0.20638996362686157,0.20581544935703278,0.20524437725543976,0.20467688143253326,0.20411279797554016,0.2035515308380127,0.2029930055141449,0.20243747532367706,0.20188622176647186,0.20134100317955017,0.2007998675107956,0.2002626359462738,0.19972892105579376,0.1991984248161316,0.1986711025238037,0.1981470286846161,0.19762620329856873,0.19710859656333923,0.19659417867660522,0.19608280062675476,0.1955719292163849,0.19506311416625977,0.19455647468566895,0.1940525323152542,0.19355113804340363,0.19305212795734406,0.1925552785396576,0.1920585036277771,0.19156207144260406,0.19106636941432953,0.1905713975429535,0.19007769227027893,0.18958434462547302,0.1890922337770462,0.1886013001203537,0.18811151385307312,0.18762318789958954,0.1871364563703537,0.18665145337581635,0.18616840243339539,0.18568719923496246,0.18520797789096832,0.18473082780838013,0.18425580859184265,0.18378283083438873,0.18331195414066315,0.18284323811531067,0.18237653374671936,0.18191196024417877,0.1814497411251068,0.180989608168602,0.18053168058395386,0.1800760179758072,0.17962254583835602,0.17917141318321228,0.17872165143489838,0.1782730668783188,0.17782655358314514,0.17738227546215057,0.17694002389907837,0.17649951577186584,0.17606081068515778,0.175623819231987,0.175188809633255,0.17475590109825134,0.174325093626976,0.17389637231826782,0.173469677567482,0.1730450540781021,0.17262226343154907,0.17220115661621094,0.17178182303905487,0.17136438190937042,0.17094868421554565,0.1705351322889328,0.17012402415275574,0.1697147935628891,0.16930736601352692,0.16890178620815277,0.16849811375141144,0.16809453070163727,0.16769252717494965,0.16729304194450378,0.16689634323120117,0.1665017157793045,0.166109099984169,0.16571839153766632,0.16532951593399048,0.16494394838809967,0.1645616739988327,0.16418246924877167,0.1638062447309494,0.1634327620267868,0.16306190192699432,0.162693589925766,0.1623278260231018,0.16196316480636597,0.1616007536649704,0.16124005615711212,0.16088131070137024,0.16052456200122833,0.16016946732997894,0.15981534123420715,0.15946248173713684,0.15911121666431427,0.15876150131225586,0.15841326117515564,0.1580660343170166,0.1577185094356537,0.15737223625183105,0.15702706575393677,0.15668223798274994,0.15633843839168549,0.15599575638771057,0.15565435588359833,0.15531422197818756],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"mode\":\"lines\",\"name\":\"IS MSE\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289,0.6102612116024289],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"mode\":\"lines\",\"name\":\"Train MSE\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[6.464624432868686,1.3105899437560042,1.1972201362413286,1.0916205521036735,0.9925687638650724,0.8984108348560262,0.806619264406123,0.7227605329767115,0.6470890369161963,0.5935617869672378,0.5457282496543532,0.5015661338986432,0.46211233695394627,0.4274156541055975,0.3958371469511349,0.3661165177352388,0.3364985080431208,0.308334021021675,0.2831506013610824,0.26064028420444096,0.24065277775104615,0.2229416407564822,0.20746397558491136,0.19432884301145623,0.18464422486123092,0.18691542453434307,0.18959267926483386,0.1925128702691368,0.19576148621430076,0.1993154588316609,0.2030477112366942,0.20693917241580467,0.21101009259774356,0.21497669541993086,0.2190576794927362,0.2235246955497564,0.22803723293514305,0.2325969373462961,0.23720976605511665,0.2418665555527319,0.24667024861045295,0.2514882221075913,0.2563233842311833,0.26117493124528857,0.2659225716614821,0.270545845639937,0.2751430459294409,0.2797185638868828,0.2842192949327026,0.28854570131538115,0.29275923838354306,0.2968446406354405,0.30079467124903647,0.3046137653161237,0.3082832044522281,0.3117659408773835,0.31505684482000706,0.31815389668208555,0.32101067634535213,0.32366998693282334,0.3260992884787072,0.3283087349598282,0.33029618719523424,0.3320801355308857,0.33364458919470275,0.33498410066073137,0.3361193602608072,0.3373813439033858,0.3385961632042677,0.339598537480697,0.3403186381679234,0.3408452919653987,0.34118747387156245,0.34135218842227455,0.34134966189389315,0.3411761932621009,0.3408130773561171,0.34029955462231476,0.3396202491138758,0.33880924216235897,0.3378847478056677,0.33687360067682937,0.3357785794930792,0.3345983684403544,0.3333403255908584,0.33205868677141037,0.3307545929771394,0.3293944941257062,0.32794171298586117,0.3264242152068684,0.32487457785909213,0.32329756398234527,0.3217010994244491,0.3200912284939571,0.3184716224553944,0.3168494066111277,0.31522936776853794,0.31363610552177973,0.3120895220479164,0.3105402037896874,0.30900747048724464,0.3074688091067311,0.3059284962706025,0.3044097063839127,0.3029153836553839,0.3014474827451051,0.30003781303266014,0.2987261791669541,0.29744116551822414,0.2961875031385102,0.294966478626025,0.2937786565667796,0.29262433857313125,0.29153295520124917,0.29051331909901335,0.2895221784929485,0.2883271694918195,0.287092279346411,0.2858789688531359,0.2846931004571119,0.28353413503547964,0.2823998072016384,0.28127293519653407,0.2801205519215251,0.2789702919169376,0.2778617002814121,0.27679256208757275,0.275740094472154,0.27472755687337436,0.2737488746158095,0.27279197258238275,0.27185189123451653,0.27094197595644376,0.27006234569278953,0.26921388489308606,0.26839241954259385,0.26784882097505935,0.2674082918413546,0.2669924534980917,0.2666023884091979,0.2662354033519478,0.26588872946735276,0.26556138078664765,0.2652501626518876,0.26495745014331995,0.26468272380140667,0.2644252691052672,0.26419426745600166,0.2639896453504204,0.2637972024739004,0.26361954417531175,0.26347023315812845,0.2633117887974782,0.2631529023776638,0.2629648942751319,0.2627837205806075,0.26260834321701176,0.2624301336203694,0.2622594554204405,0.2620970692924516,0.2619430347763758,0.26179792343762054,0.2616554189861573,0.26146909774939525,0.2612895390598622,0.2611241731886942,0.26096754625497215,0.26081850978208976,0.26067774594390236,0.26054561513814833,0.26042245864300223,0.26031333701845794,0.26023976916185876,0.2602085389763701,0.26018522586393955,0.26017083307782846,0.2601716983453418,0.2602331360910858,0.26040813053072326,0.2606040059261784,0.2608443898070724,0.26112713601949644,0.26142003904184397,0.2617235726298022,0.2620411854108726,0.26237058373251354,0.2627134297380343,0.2630782471740093,0.2634659523888546,0.2638584170258429,0.26426131231061406,0.2646744472814144,0.2650738256897487,0.26548267372110235,0.2659019821907249,0.2663312983559994,0.26677950693510144,0.26725121927752465,0.2677528000651329,0.2682690552153776,0.26879369482545,0.2693264666524991,0.26986683534698896,0.2704141569231915,0.2709663213998691,0.2715259563305623,0.2720955432799621,0.2726755082808615,0.27326197656309337,0.2737260192004418,0.2741511420110422,0.27458255451524227,0.27501425982161615,0.27544744158543194,0.2758818709144075,0.27631828376783724,0.27675688726752046,0.27719860050448497,0.27764337983643467,0.278091439900352,0.27854304014527076,0.27899834031272397,0.2794489622109968,0.2798983579637084,0.2803524316572233,0.2808145783277129,0.2812821797666821,0.2817545163893067,0.28222951721147005,0.2827102814394984,0.28319688770416895,0.2836892018487094,0.2841998462959934,0.2847328500091401,0.2852714652617138,0.2858155126035378,0.28636553836263456,0.28692135221331616,0.2874826037391175,0.28804921263113703,0.28861425311498085,0.28916607074260564,0.2897079592681608,0.2902416658093403,0.2907633999471436,0.29128309274795505,0.2918013892058081,0.29231897630803516,0.29278961829464667,0.2932215224037175,0.29365103427029293,0.2940534881550383,0.2944726793042529,0.29489235312624185,0.2953128505358394,0.29573463194096716,0.29615833066377917,0.2965671099372998,0.2967988937286599,0.29700159940434034,0.29721159844751116,0.29743153347726947,0.29766060339364436,0.2979192092591972,0.2981737022251451,0.29840154515409756,0.2984939249486803,0.2985646154323714,0.29865726806371873,0.2988003305728556,0.29898771692484427,0.29917525930040056,0.29936999599598807,0.299566545673559,0.299763321575755,0.2999641797451562,0.30016228088714186,0.3003557111795638,0.30054913254882576,0.30075777795514375,0.30098822942153586,0.3012207613598833,0.30145663774149567,0.30169279925090015,0.3019312886219806,0.3021742912998026,0.30242166196722187,0.302670117559453,0.3029197560760177,0.3031700259575558,0.30342118917517696,0.3038522223525015,0.3043166823953621,0.3047846762654312,0.30534104235587756,0.3058943873451315,0.30644508184459374,0.3070072856396978,0.30757302983070894,0.30813691789419795,0.30869930952261043,0.3092608144664734,0.30982253723363673,0.30998688072767117,0.31013760528009326,0.31027731045232276,0.31040902168741774,0.3105342234063088,0.31065391933698216,0.3107690746894183,0.31088115755559353,0.310994908158369,0.31114496621955484,0.3113183551149218,0.31148933016195196,0.311772494060135,0.3120908783650539,0.3124318067457593,0.3127934455441478,0.3131754623080413,0.3135765250756836,0.31399496769149376,0.3144299202671619,0.31488000809333644,0.31534418461978925,0.3158207452462665,0.3163088550408106,0.31680563440419246,0.3173100360287843,0.31782145202163115,0.31833924314654993,0.318862847420176,0.3193921243072103,0.31992556626003305,0.32046362835401354,0.32100557575520716,0.32155144754989623,0.3221003146971484,0.3226523409396873,0.3232070367171655,0.3237640546038658,0.32432072262655837,0.3248796345445387,0.3254403762669928,0.32600269722514824,0.32656671775888796,0.32713150413708525,0.3276969714836152,0.3282630113549824,0.328834048719342,0.3294090279249628,0.3299854879710923,0.3305621733702206,0.3311394572506531,0.33171644430596237,0.33229293669598176,0.3329519406788637,0.3336572135349933,0.33436109346138615,0.3350628858315059,0.3357453371646254,0.33642626183752744,0.3371065380738531,0.3377859953320303,0.33846460864424693,0.3391438339297724,0.33982457693224816,0.34050418015860673,0.3411834650971543,0.34186297570320867,0.3425429185602809,0.3432238573218493,0.34389788382600683,0.3445708922524101,0.34524304191319893,0.34591237475408954,0.3465802866923174,0.347248346955358,0.34791732985433754,0.34858583898674467,0.34925798854418094,0.3499235416381399,0.3505858468638941,0.3512437001250012,0.3518942619914431,0.3525403703661236,0.353173549932978,0.3538032161479676,0.35443991920792556,0.355082609943464,0.3557236484101445,0.3563632553176187,0.3569848669538668,0.3575895790968149,0.3581951591436598,0.35880173196635745,0.359409066205482,0.36001698134974025,0.3606204567811476,0.3612240602826631,0.36182764325213607,0.36243089414046187,0.36303410472622877,0.36363693529858304,0.36423940432441404,0.36484027374684425,0.36543981590686075,0.3660376365584975,0.36663448375418384,0.3672298975578524,0.3678387538811932,0.36845596911525125,0.3690703888314335,0.3696487431942163,0.3702083500449137,0.3707639785625014,0.3713138724878172,0.3718601230693463,0.3724018091968841,0.372940943795819,0.3734778078853272,0.37401243812400053,0.37454509296293004,0.3750733665338674,0.37559982798273195,0.37612463010831537,0.3766478074279909,0.3771693737156456,0.3776896328451507,0.3782085617358078,0.3787259054660008,0.3792423831818716,0.3797577737021828,0.38027304696027864,0.3807869767311467,0.3812994090758625,0.3818106285660439,0.3823211916116295,0.38283996949400945,0.38338890635912437,0.3839370290859456,0.38448443015081446,0.3850339400138659,0.38558245509382905,0.3861298332393955,0.38667602044688076,0.38722105683066493,0.38776540922706254,0.3883084972902302,0.3888444854308559,0.3893779137830274,0.3899106001771394,0.39044243825357955,0.39097322495866477,0.39150295616475583,0.392031768399982,0.392559306937822,0.3930862701262541,0.3936118704603298,0.39413669941981927,0.3946605742531392,0.395183628206329,0.3957054423290218,0.39622641085411703,0.39674604351884796,0.39726459066816694,0.39778212196968954,0.39829925729654414,0.3988158749599146,0.3993320149100979,0.3998473629650917,0.4003604787385291,0.40082344338867404,0.401285560389108,0.40175180599161275,0.40222067607577766,0.4026927779948572,0.4031673025462597,0.4036437479180258,0.40412102173366493,0.40459337297062253,0.40506661247391856,0.40554064668582135,0.4060152167736832,0.4064953407042081,0.40698561000336414,0.4074757761615786,0.40796546542223355,0.4084545185994303,0.4089429081713761,0.40943098135388195,0.40991897231991226,0.4104068763947957,0.41089390515578034,0.41137991487390074,0.411864456618769,0.41234749855024166,0.4128290562470852,0.4133092181528574,0.4137879640898637],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"mode\":\"lines\",\"name\":\"Test MSE\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.3151899320679663,0.33321703338022507,0.35184518787007096,0.3712782692813686,0.39135468655193995,0.4027946391451939,0.4092672793528885,0.41535244569008384,0.4212887996263235,0.42709497276893027,0.43291083820976245,0.4379684146141553,0.4425029914849159,0.4468188322939995,0.4511298071428707,0.4555483384812563,0.4599784419388083,0.46448865806394984,0.469096611042735,0.4736907141071197,0.47828917782026525,0.4828743203403827,0.4879370248568902,0.4942800800488066,0.5005668161795365,0.5067841420540258,0.5130155121463691,0.5192728534507378,0.5254577261842636,0.5315672875781532,0.5375996832521212,0.5435529866365671,0.5494223137242864,0.5552045718314742,0.5608936859583303,0.5664859674091318,0.5719767734488201,0.5773626390553376,0.5826403701774057,0.5878063568973092,0.5928574943232148,0.5977678219969672,0.6025552633996986,0.60721847595355,0.611754676561951,0.6161599339753075,0.620431745147823,0.6245803407290459,0.6285921096892102,0.6324613832655723,0.6361986330070605,0.6398151762926687,0.6432713253118137,0.6465716229459058,0.6497196470822069,0.652715288381189,0.655559911729728,0.6582562831548231,0.6608145525695519,0.6632244718332447,0.6654870348432248,0.6676040457311487,0.6695774014716942,0.6714095645877809,0.6731034435083914,0.674662324070139,0.6760896804162935,0.6773895111796557,0.678558641470052,0.6796032708680181,0.68052832412187,0.681336809239624,0.6820338138372791,0.6826249029571473,0.6831159344268085,0.6835122279230171,0.6838192159094844,0.6840415158016324,0.6841858258449481,0.6842572653883902,0.6842611615169828,0.684202349127186,0.6840857967827184,0.6839163115389345,0.6836983038885267,0.6834388483427098,0.6831387698351198,0.6828015913110926,0.682431234477572,0.682031304342112,0.6816056152133501,0.681157543316794,0.6806904832794711,0.6802072755590236,0.6797107822040452,0.6792034908745369,0.678687688941592,0.6781658737131057,0.6776407752241091,0.677114020330161,0.6765877903000769,0.6760634160027362,0.6755409533342716,0.6750218059363814,0.6745071514004539,0.6739980909227287,0.6734956467429947,0.673000550400514,0.6725134184906574,0.6720349480239636,0.6715655530045872,0.671105757373061,0.6706560358285858,0.6702168199959956,0.6697871398990741,0.6693671965343196,0.6689574633521179,0.668561829435428,0.6681801642328823,0.6677906354019846,0.6674033442617917,0.6670300660400229,0.6666704942982697,0.6663229062710482,0.6659848779701745,0.6656632223179053,0.6653571071311866,0.6650655220836152,0.6647878357073014,0.6645226679557962,0.6642692682212885,0.6640262093540816,0.6637929908000677,0.6635689883210749,0.66335373139425,0.6631467022817449,0.662947608445113,0.6627499788953874,0.6625542340981115,0.6623604550818567,0.6621686935807377,0.661978846809802,0.6617913201356712,0.6616089394755374,0.6614547812121907,0.6613019458312409,0.661150629741085,0.6610009610493467,0.660852463106529,0.6607099575936629,0.6605773306226247,0.6604441001659185,0.6602994672549364,0.6601552865279116,0.66000912059436,0.6598613822551163,0.6597126219632166,0.6595626900176618,0.6594121425141459,0.6592615215397468,0.6591112587982549,0.6589594602423376,0.6588078909814211,0.6586553723086246,0.6585023010895883,0.6583490957889064,0.6581958510738447,0.6580429544274351,0.6578908641327703,0.6577397667979261,0.6575899106743435,0.6574417371174939,0.6572930834677045,0.6571449241793578,0.6569976736438905,0.6568516552944551,0.6567071203823356,0.6565639840763497,0.6564181984014748,0.6562696157320507,0.6561188260489559,0.6559666306828232,0.6558145663060196,0.6556611573182162,0.6555069447503937,0.6553522694300119,0.6551975437848591,0.6550444214514807,0.6548928860651745,0.6547434252817935,0.6545959198012279,0.6544507046035181,0.6543077501888626,0.6541645624178128,0.6540213590349697,0.6538786615663378,0.6537294467382024,0.6535782728828349,0.6534285720813209,0.6532807193847388,0.6531346523327399,0.6529905792774514,0.652848500827689,0.6527085695629737,0.652570709546242,0.6524352175529677,0.6522952988358824,0.6521555592055289,0.6520183257214123,0.6518836712951055,0.6517469183591229,0.6516082821010623,0.6514681589421489,0.6513270895485619,0.6511854400986177,0.651043527034452,0.6508317769212776,0.650588449997484,0.6503459260248776,0.6501045417821681,0.6498644658273853,0.6496258770246758,0.6493889828163653,0.64915394974157,0.6489209189299753,0.6486898939555817,0.64846076399734,0.6482336269397101,0.648008598539659,0.6477858183215515,0.6475653209400416,0.6473471741136223,0.6471310835981192,0.6469178028435979,0.6467072673163424,0.6464995979747148,0.6462947302172984,0.6460926565422711,0.6458932467281107,0.6456964544017129,0.6455022062835126,0.6453059424898386,0.6451081473663349,0.644908997392088,0.6447088690295633,0.6445080906991085,0.6443070535969961,0.6441059785189869,0.6439051364859658,0.6437037912476128,0.6435021036155827,0.6433004675938855,0.6430997469315028,0.6429002961346906,0.6427021383349172,0.6425050700355246,0.6423092727471434,0.6421147008515935,0.6419144212878392,0.6416738606965451,0.6414373418906671,0.6412045852362809,0.6409749178057026,0.6407479296062042,0.6405223166879834,0.6402975537761515,0.6400734500074489,0.639854069165214,0.6396397086532889,0.6394327077118278,0.639228744140816,0.639025353948205,0.6388226827681893,0.6386210431211162,0.6384204849419683,0.6382205194743638,0.6380210093515958,0.6378216594678127,0.6376225800415785,0.6374240503930502,0.6372252638467065,0.6370265394120018,0.6368211593334794,0.6365645693303574,0.6363083930311655,0.6360527608611088,0.6357972356515746,0.6355425200161524,0.6352887767890528,0.6350356769596371,0.6347834189553172,0.6345321741159149,0.6342804906595773,0.6340287723239876,0.6337715555531374,0.6335094993584818,0.6332434637632656,0.6329739612977787,0.6327001824236059,0.6324228617881807,0.632062971939412,0.6316831977768108,0.6313008595621726,0.63090540051336,0.6304985155459152,0.630081643697413,0.629656446915342,0.629224073972553,0.628793664174589,0.6284167724563765,0.6280364624057077,0.6276535869722794,0.6272653317366794,0.6268732241861014,0.6264788433355583,0.6260816974557094,0.6257071317855107,0.6253516657544361,0.6250085121860863,0.6246844920009137,0.624386316876086,0.6241026104699042,0.6238323597185915,0.6235744437940959,0.6233277668818891,0.6230912460741822,0.622863669583629,0.6226434335545646,0.6224298346257826,0.6222223522444107,0.6220204017567132,0.6218235398598666,0.6216283833710683,0.6214359286465125,0.6212474708106156,0.62106258529967,0.6208810121993305,0.6207024918171601,0.620526711820704,0.6203535008090408,0.6201826172466907,0.6200140893782954,0.6198477696603719,0.6196834987867674,0.6195210883418613,0.6193603968067117,0.6192012710685211,0.6190435931967162,0.6188872688642526,0.6187321510240847,0.6185785556777941,0.6184263766846184,0.618275478888153,0.6181258324536428,0.6179773080616748,0.617829635891293,0.6176811205746776,0.6175291460661403,0.6173757882252738,0.6172212230600979,0.6170657613295814,0.616909608363651,0.6167529865901302,0.6165958728534112,0.6164383491621342,0.6162805559342296,0.6161230994762354,0.6159661030894722,0.6158091941148088,0.6156524484019837,0.6154958132490678,0.6153395866385626,0.6151835404292655,0.615027797186352,0.6148721698370438,0.6147167517554627,0.6145615778486098,0.6144066771915818,0.6143192776720435,0.6144971676047055,0.6146743208775229,0.6148507547430521,0.6150264337749585,0.6152013984695448,0.6153756309945394,0.6155491076529477,0.6157218865264399,0.6158940081247605,0.6160654370380121,0.616236406447657,0.6164068459739452,0.6165767905086126,0.6167462047303723,0.6169147266386997,0.617082361603503,0.6172491676980545,0.6174151151956001,0.6175802739397201,0.6177446434433065,0.6179084401717451,0.61807154652052,0.6182339562609638,0.6183956279917641,0.6185566200636412,0.6187170087783554,0.6188767992215782,0.6190359733849665,0.6191945134157989,0.6193523898031392,0.6195096315754158,0.6196662091436305,0.6198227481935032,0.6199791901745861,0.6201354647763997,0.6202915601632368,0.6204474411723699,0.6206030374589929,0.6207583666126376,0.6209133405555523,0.6210679885404031,0.6212222517595793,0.6213761300910173,0.6215296234712576,0.6216826613196205,0.6218352786996184,0.6219874520147453,0.6221391340932497,0.6222903659138711,0.6224411179516519,0.622591372388863,0.6227411349682194,0.6228904054503446,0.6230391778066806,0.6231874342435734,0.6233351452098679,0.6234823574691483,0.6236290826521717,0.6237753675994387,0.623920187277857,0.6240619412258936,0.6242036120873845,0.624345205751522,0.6245090214225213,0.6246763114673508,0.6248433224721182,0.6250100102086321,0.625176374472165,0.6253423739514248,0.6255079966955831,0.6256732043158608,0.6258379849156261,0.6260022911148723,0.626166152289386,0.6263295534159476,0.626491692648939,0.6266525343406122,0.6268129502544226,0.6269729165734319,0.6271324478232886,0.6272914702253802,0.6274499835374485,0.6276079609829561,0.6277654141316492,0.6279217578547186,0.62807752649261,0.6282327551892088,0.6283874525916342,0.6285415448182426,0.6286949961866,0.6288478359803311,0.6290000609814683,0.629151682738244,0.6293027039582888,0.629452206829817,0.6296002940797829,0.6297470831753946,0.6298926208467736,0.6300369922309863,0.6301802736654467,0.6303225031030721,0.6304637303338887,0.6306039874456534,0.6307433538685527,0.6308818735875868,0.6310195906400307,0.631156525402759,0.6312927130822983,0.6314281829016373,0.6315625702010835,0.6316960523028666,0.6318288955317789,0.631961120369058,0.6320927709627954,0.6322238825835511,0.6323544965566236,0.6324846215144779,0.6326142780710384,0.6327434719640764,0.6328722059944528,0.6330004534083763],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.45],\"title\":{\"text\":\"Epoch\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.625,1.0],\"title\":{\"text\":\"Estimate\"}},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.55,1.0],\"title\":{\"text\":\"Epoch\"}},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.625,1.0],\"title\":{\"text\":\"Variance\"}},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.0,0.45],\"title\":{\"text\":\"Epoch\"}},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,0.375],\"title\":{\"text\":\"MSE Loss\"}},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.55,1.0],\"title\":{\"text\":\"Epoch\"}},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.0,0.375],\"title\":{\"text\":\"MSE\"}},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Estimate over Epochs\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Variance over Epochs\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Shaping Train MSE Loss over Epochs\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Total MSE over Epochs\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Metrics over Epochs\"},\"showlegend\":true},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('73a8347d-84de-458c-97ac-be239cdda4f4');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"7b063ff8-f606-4d47-86b8-b715f0e196db\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"7b063ff8-f606-4d47-86b8-b715f0e196db\")) {                    Plotly.newPlot(                        \"7b063ff8-f606-4d47-86b8-b715f0e196db\",                        [{\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"z\":[[0.06756025552749634,0.07613781094551086,0.06539362668991089,0.051842041313648224,0.03829044848680496,0.024738870561122894,0.011179327964782715,-0.0043767765164375305,-0.019932858645915985,-0.03548894077539444],[0.05893360450863838,0.07811497151851654,0.07799799740314484,0.06369960308074951,0.0422125943005085,0.020725581794977188,-0.0007614158093929291,-0.022248446941375732,-0.04373547434806824,-0.060916170477867126],[0.04541879519820213,0.05872845649719238,0.07799480855464935,0.07724854350090027,0.05663276091217995,0.03514574095606804,0.013658739626407623,-0.007828272879123688,-0.029315300285816193,-0.05080230534076691],[0.03495156392455101,0.03907203674316406,0.06007630005478859,0.0745924562215805,0.06777609884738922,0.04956592619419098,0.02807890810072422,0.006591882556676865,-0.014895126223564148,-0.036382146179676056],[0.03025042451918125,0.03194402903318405,0.041151054203510284,0.0618068166077137,0.07119010388851166,0.057635288685560226,0.042499080300331116,0.021012086421251297,-0.0004749372601509094,-0.02196197211742401],[0.025549285113811493,0.027973731979727745,0.02773961052298546,0.04346856847405434,0.06302510201931,0.06144550070166588,0.04749445617198944,0.03543228656053543,0.013945210725069046,-0.00754181295633316],[0.020848147571086884,0.024003442376852036,0.019067838788032532,0.028672251850366592,0.046173132956027985,0.05962274223566055,0.05103694275021553,0.03735361620783806,0.025547213852405548,0.006878364831209183],[0.016147010028362274,0.02003314346075058,0.015097539871931076,0.017628580331802368,0.03073953278362751,0.04887766391038895,0.05630985274910927,0.04062841832637787,0.027212781831622124,0.015406440943479538],[0.011445879936218262,0.01606285572052002,0.011127252131700516,0.00658489391207695,0.018561217933893204,0.033371906727552414,0.051582179963588715,0.05388150364160538,0.03021988645195961,0.017071902751922607],[0.006744742393493652,0.011700861155986786,0.00715695321559906,0.0022213533520698547,0.007517531514167786,0.01949385553598404,0.036076441407203674,0.050324782729148865,0.05063703656196594,0.01981135830283165]],\"type\":\"heatmap\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"Values\"},\"ticks\":\"outside\",\"tickvals\":[-0.060916170477867126,0.07811497151851654],\"ticktext\":[-0.060916170477867126,0.07811497151851654]}},\"xaxis\":{\"tickvals\":[0,1,2,3,4,5,6,7,8,9],\"ticktext\":[0,1,2,3,4,5,6,7,8,9],\"title\":{\"text\":\"X\"}},\"yaxis\":{\"tickvals\":[9,8,7,6,5,4,3,2,1,0],\"ticktext\":[9,8,7,6,5,4,3,2,1,0],\"title\":{\"text\":\"Y\"},\"autorange\":\"reversed\"},\"title\":{\"text\":\"Heatmap\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('7b063ff8-f606-4d47-86b8-b715f0e196db');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"bfc0a262-55a5-40e2-9c58-a1e0fe2c4e1f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"bfc0a262-55a5-40e2-9c58-a1e0fe2c4e1f\")) {                    Plotly.newPlot(                        \"bfc0a262-55a5-40e2-9c58-a1e0fe2c4e1f\",                        [{\"colorbar\":{\"title\":{\"text\":\"Visits\"}},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"x\":[0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9],\"y\":[9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0],\"z\":[0,33,134,277,686,663,650,600,480,482,0,63,209,519,582,0,223,315,285,457,0,113,402,516,226,0,69,89,164,444,0,324,375,183,83,0,8,24,57,112,0,322,190,91,55,0,1,8,14,30,98,220,95,34,17,5,0,4,3,6,18,33,23,16,12,9,0,7,2,7,3,5,3,4,1,4,0,4,1,6,0,0,0,0,0,5,0,3,1,6,0,0,0,0,0,2,0,3,1,5],\"zmax\":686,\"zmin\":0,\"type\":\"heatmap\"}],                        {\"title\":{\"text\":\"State Visitations Heatmap\"},\"xaxis\":{\"title\":{\"text\":\"X-axis\"}},\"yaxis\":{\"ticktext\":[9,8,7,6,5,4,3,2,1,0],\"tickvals\":[0,1,2,3,4,5,6,7,8,9],\"title\":{\"text\":\"Y-axis\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('bfc0a262-55a5-40e2-9c58-a1e0fe2c4e1f');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "400 trajectories:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"22eb2fa3-dfba-433b-a801-fd1d72ed139e\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"22eb2fa3-dfba-433b-a801-fd1d72ed139e\")) {                    Plotly.newPlot(                        \"22eb2fa3-dfba-433b-a801-fd1d72ed139e\",                        [{\"mode\":\"lines\",\"name\":\"IS Estimate\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948,0.0405864417552948],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"Train Estimate\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[-0.43180033564567566,1.7324312925338745,1.6888880729675293,1.6427555084228516,1.5972721576690674,1.553525686264038,1.512945294380188,1.4720124006271362,1.432582139968872,1.3900521993637085,1.345958948135376,1.303370475769043,1.2609657049179077,1.2192720174789429,1.1786823272705078,1.1391823291778564,1.1035822629928589,1.070417881011963,1.0384150743484497,1.0074909925460815,0.977912962436676,0.9492351412773132,0.9211165904998779,0.8934122920036316,0.8672743439674377,0.8436856269836426,0.8209826946258545,0.7985977530479431,0.7750362157821655,0.7517598271369934,0.7289427518844604,0.7067188620567322,0.6845148801803589,0.6622538566589355,0.6406075954437256,0.6196308135986328,0.5991015434265137,0.5795159935951233,0.5606361031532288,0.5423892736434937,0.5245864391326904,0.5073362588882446,0.4906010627746582,0.47443079948425293,0.45869991183280945,0.44342514872550964,0.428663969039917,0.41445639729499817,0.4007129967212677,0.3875483274459839,0.37474578619003296,0.36227157711982727,0.35027557611465454,0.33876049518585205,0.32765689492225647,0.31753626465797424,0.307878315448761,0.2985609471797943,0.28961917757987976,0.281044602394104,0.27280548214912415,0.26493963599205017,0.2574203312397003,0.2502886950969696,0.2434733659029007,0.2369718700647354,0.23076240718364716,0.2248467355966568,0.21924589574337006,0.21396911144256592,0.20898261666297913,0.204252228140831,0.19979193806648254,0.19556604325771332,0.19155631959438324,0.1877545714378357,0.18415498733520508,0.18073448538780212,0.17750446498394012,0.1744692325592041,0.17160600423812866,0.16890716552734375,0.16636916995048523,0.16402839124202728,0.1618155539035797,0.1597377061843872,0.15780729055404663,0.15599186718463898,0.15428900718688965,0.15269926190376282,0.15120266377925873,0.14979055523872375,0.14846143126487732,0.14721305668354034,0.14603768289089203,0.1449280083179474,0.1438765525817871,0.14286865293979645,0.1418943703174591,0.1409664750099182,0.1400805413722992,0.13925519585609436,0.1384783536195755,0.1377277672290802,0.1370391547679901,0.1363687664270401,0.13571637868881226,0.1350698173046112,0.13442055881023407,0.13378110527992249,0.13315023481845856,0.13252772390842438,0.13190971314907074,0.13129445910453796,0.130681574344635,0.1300709992647171,0.12945938110351562,0.12884503602981567,0.12822747230529785,0.12760648131370544,0.1269797682762146,0.12634742259979248,0.1257084310054779,0.12506449222564697,0.12441486865282059,0.12375903129577637,0.12309790402650833,0.12243187427520752,0.12176435440778732,0.12108977138996124,0.12040888518095016,0.11969994008541107,0.11897160857915878,0.11823436617851257,0.11749107390642166,0.11674327403306961,0.11599110066890717,0.11524708569049835,0.11449992656707764,0.11374682933092117,0.11299344152212143,0.1122388169169426,0.11146830022335052,0.1106894314289093,0.10990288108587265,0.10910850763320923,0.10831021517515182,0.10750880092382431,0.10669583827257156,0.10583819448947906,0.10496402531862259,0.10408911108970642,0.10322719812393188,0.10237006843090057,0.10153066366910934,0.10069066286087036,0.09984651207923889,0.09900224208831787,0.09815910458564758,0.09731984883546829,0.09648288786411285,0.0956481471657753,0.09480804204940796,0.093970388174057,0.09315559267997742,0.09234286099672318,0.09153866022825241,0.09073802083730698,0.08994079381227493,0.08915070444345474,0.08838056772947311,0.0876350849866867,0.08689132332801819,0.08615046739578247,0.08541329205036163,0.08467953652143478,0.08394937217235565,0.08322333544492722,0.08250120282173157,0.08178286999464035,0.08106956630945206,0.08036047220230103,0.07965506613254547,0.07896421104669571,0.07827707380056381,0.07759277522563934,0.07691074907779694,0.07623521983623505,0.0755705013871193,0.0749070942401886,0.07423615455627441,0.07356978952884674,0.07291550934314728,0.0722806304693222,0.07164499163627625,0.07099760323762894,0.07032322138547897,0.06963922828435898,0.06896006315946579,0.06830701977014542,0.06767579168081284,0.06704720109701157,0.06642034649848938,0.06580803543329239,0.06521479785442352,0.06462465971708298,0.06403736770153046,0.06345859169960022,0.0629313513636589,0.062429554760456085,0.06194041296839714,0.06145491451025009,0.06096537038683891,0.06047710031270981,0.05999041721224785,0.0595054067671299,0.05902180075645447,0.0585365854203701,0.05805220827460289,0.057568762451410294,0.05708649381995201,0.05661641061306,0.05615036189556122,0.05568674951791763,0.05522841960191727,0.054766565561294556,0.05430584028363228,0.05384671688079834,0.0533892884850502,0.05292031168937683,0.05244440212845802,0.05197547748684883,0.05150892958045006,0.05104454979300499,0.05058227479457855,0.05012190714478493,0.04964020475745201,0.0491606667637825,0.048683710396289825,0.04820932447910309,0.047737471759319305,0.04726780578494072,0.04680030792951584,0.046335089951753616,0.04587208107113838,0.04540922865271568,0.04494812339544296,0.04449738934636116,0.0440511554479599,0.043607182800769806,0.04315262287855148,0.04270268604159355,0.042254138737916946,0.04180680587887764,0.041361693292856216,0.04091860353946686,0.04047644883394241,0.04003623127937317,0.03959748521447182,0.03915884345769882,0.038721803575754166,0.03828643262386322,0.03785240277647972,0.0374206006526947,0.03699029982089996,0.03656155243515968,0.0361342690885067,0.03570416569709778,0.0352744460105896,0.034845951944589615,0.034418534487485886,0.033992014825344086,0.03356659412384033,0.03314117714762688,0.03271697834134102,0.03229429945349693,0.031888652592897415,0.03148570656776428,0.031085481867194176,0.030686691403388977,0.030289068818092346,0.02989363484084606,0.029499268159270287,0.029114820063114166,0.028734911233186722,0.028358422219753265,0.027983123436570168,0.027606839314103127,0.0272310022264719,0.026855889707803726,0.02648136019706726,0.026107724756002426,0.025735653936862946,0.025366615504026413,0.02500011771917343,0.024635013192892075,0.02427315153181553,0.02391238324344158,0.023572275415062904,0.02323867194354534,0.022926829755306244,0.022616224363446236,0.022306842729449272,0.02199910208582878,0.021693412214517593,0.021392229944467545,0.021092498674988747,0.02079380676150322,0.020500781014561653,0.02024530991911888,0.019991209730505943,0.019739825278520584,0.019488675519824028,0.01923266425728798,0.01896701194345951,0.01870568096637726,0.018447764217853546,0.01819179765880108,0.017948687076568604,0.017722496762871742,0.017632434144616127,0.01760137639939785,0.017570653930306435,0.017538579180836678,0.017503464594483376,0.01745883747935295,0.01740930788218975,0.017358047887682915,0.017305245622992516,0.017252452671527863,0.017199691385030746,0.017147542908787727,0.017086463049054146,0.01702122576534748,0.01700267754495144,0.017005303874611855,0.01701563037931919,0.01702731102705002,0.017040567472577095,0.017054911702871323,0.01706955023109913,0.017084384337067604,0.01709877699613571,0.01711227186024189,0.017128517851233482,0.017155110836029053,0.017184175550937653,0.017216386273503304,0.01725516840815544,0.017295436933636665,0.017337726429104805,0.017383204773068428,0.0174314696341753,0.0174813624471426,0.01753179542720318,0.017583699896931648,0.017637673765420914,0.01768895797431469,0.01774071343243122,0.017794208601117134,0.01784917525947094,0.017905348911881447,0.017962541431188583,0.018021034076809883,0.0180803295224905,0.01813988946378231,0.01819838024675846,0.01825745590031147,0.01831687055528164,0.018376195803284645,0.01842820830643177,0.018480585888028145,0.018529651686549187,0.01856609620153904,0.01860342174768448,0.018640032038092613,0.01866789162158966,0.018707338720560074,0.018761303275823593,0.018818533048033714,0.0188774261623621,0.01893819496035576,0.019002050161361694,0.019068704918026924,0.019137488678097725,0.019208287820219994,0.019280683249235153,0.01935451664030552,0.019429510459303856,0.019505375996232033,0.019586173817515373,0.01966787502169609,0.01974983885884285,0.019832076504826546,0.01991807296872139,0.02000506967306137,0.020093323662877083,0.02018265426158905,0.02027270570397377,0.02036341279745102,0.020454632118344307,0.020546557381749153,0.02063881605863571,0.020726416260004044,0.020813671872019768,0.02090059593319893,0.020987335592508316,0.021073928102850914,0.021160608157515526,0.021248577162623405,0.0213443823158741,0.021439820528030396,0.02153618261218071,0.021632451564073563,0.021731853485107422,0.021834706887602806,0.02193763293325901,0.02204042114317417,0.022143132984638214,0.02224551886320114,0.022347595542669296,0.022449083626270294,0.02254987694323063,0.022650133818387985,0.022747471928596497,0.02283930405974388,0.022917218506336212,0.02299320697784424,0.023069219663739204,0.02314634621143341,0.023225318640470505,0.023304015398025513,0.023382311686873436,0.023460254073143005,0.023535307496786118,0.023607604205608368,0.023677518591284752,0.02374538965523243,0.023805083706974983,0.023861423134803772,0.02391800470650196,0.023975690826773643,0.024034082889556885,0.024100426584482193,0.024171896278858185,0.024243267253041267,0.024314217269420624,0.02438502199947834,0.02445533685386181,0.02452520653605461,0.024598488584160805,0.024679433554410934,0.02475951798260212,0.02483888529241085,0.02491769567131996,0.02499549463391304,0.025072945281863213,0.02515038475394249,0.02522752620279789,0.02530062571167946,0.02537192776799202,0.025442447513341904,0.025512345135211945,0.025590628385543823,0.02566724829375744,0.025742754340171814,0.025817852467298508,0.025892483070492744,0.025944426655769348,0.02599044144153595,0.026035785675048828,0.026080794632434845,0.02612512744963169,0.026168549433350563,0.026201125234365463,0.02622023969888687,0.026242362335324287,0.026266997680068016,0.026302030310034752,0.02633155882358551,0.026362957432866096,0.026395922526717186,0.026430224999785423,0.026463037356734276,0.026495616883039474,0.026529250666499138,0.026563409715890884,0.026597753167152405,0.02663203701376915,0.026665734127163887,0.026699399575591087,0.026732904836535454,0.02676638402044773,0.026799792423844337,0.026832791045308113,0.026856012642383575,0.026886850595474243,0.026918483898043633,0.02695007063448429,0.026981253176927567],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"Test Estimate\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.19859562814235687,0.182793989777565,0.16732433438301086,0.15204769372940063,0.13705036044120789,0.1298743337392807,0.1273355931043625,0.12484686076641083,0.12229244410991669,0.11977260559797287,0.11725092679262161,0.11471571028232574,0.11204756051301956,0.10926450043916702,0.10647653788328171,0.10366279631853104,0.10084250569343567,0.0980488583445549,0.09529463946819305,0.0925503596663475,0.08980601280927658,0.08707177639007568,0.08454078435897827,0.08227928727865219,0.0800214633345604,0.07774469256401062,0.07533110678195953,0.07293205708265305,0.07054551690816879,0.0681731104850769,0.06581681221723557,0.0634789764881134,0.06116258725523949,0.05887211859226227,0.056610144674777985,0.054378967732191086,0.05218171328306198,0.050020650029182434,0.04790082573890686,0.04582235962152481,0.04383421316742897,0.04208378121256828,0.04037600755691528,0.0387127548456192,0.03709616884589195,0.03552999347448349,0.034014467149972916,0.032551124691963196,0.031141778454184532,0.02978339232504368,0.02845466323196888,0.027184640988707542,0.025974158197641373,0.024815112352371216,0.023718949407339096,0.022686270996928215,0.021716689690947533,0.020810898393392563,0.01996893621981144,0.01919078640639782,0.018476121127605438,0.017757758498191833,0.017095347866415977,0.016497371718287468,0.015962915495038033,0.015490998513996601,0.015079766511917114,0.01472801249474287,0.01443430781364441,0.01419701986014843,0.014014528132975101,0.013885529711842537,0.013808324933052063,0.013781318441033363,0.013802595436573029,0.013870210386812687,0.013981697149574757,0.014134583994746208,0.014326698146760464,0.014555240981280804,0.01481811236590147,0.015113351866602898,0.015438658185303211,0.01579219661653042,0.01617206074297428,0.016576459631323814,0.01700371503829956,0.017451733350753784,0.01791851781308651,0.018402088433504105,0.018900657072663307,0.019412629306316376,0.019935566931962967,0.02046833373606205,0.02100972644984722,0.021558208391070366,0.022112246602773666,0.022670568898320198,0.02323184162378311,0.023794930428266525,0.024358699098229408,0.024934982880949974,0.025519484654068947,0.026102280244231224,0.026682641357183456,0.02725979872047901,0.02783283032476902,0.02840106561779976,0.028964083641767502,0.029521312564611435,0.030072296038269997,0.03061693161725998,0.031154775992035866,0.03168565779924393,0.03220914304256439,0.03272519260644913,0.03323345631361008,0.03373377397656441,0.034225910902023315,0.03470976650714874,0.035185277462005615,0.035606350749731064,0.03590306267142296,0.03619281202554703,0.03647575527429581,0.03675186634063721,0.03702115640044212,0.03728349506855011,0.037539053708314896,0.03778770938515663,0.03802982345223427,0.03826538845896721,0.038494598120450974,0.03871748223900795,0.03893441706895828,0.03914542868733406,0.03935055434703827,0.03955565765500069,0.03975589573383331,0.03995059058070183,0.04014004021883011,0.040324222296476364,0.040503304451704025,0.040677376091480255,0.04084714874625206,0.04101254418492317,0.04117345064878464,0.04133015125989914,0.04148261621594429,0.041631072759628296,0.04177560284733772,0.04191640764474869,0.042053572833538055,0.0421852208673954,0.042311061173677444,0.0424334779381752,0.0425538569688797,0.042671456933021545,0.04278602451086044,0.042897820472717285,0.04300675541162491,0.04311303794384003,0.04321669787168503,0.043306462466716766,0.04339045658707619,0.04347192868590355,0.04355163499712944,0.04362967982888222,0.04370598867535591,0.0437808483839035,0.04385523498058319,0.04393452778458595,0.04401225596666336,0.0440889410674572,0.0441645011305809,0.04423891752958298,0.044312234967947006,0.04438437521457672,0.04445517435669899,0.04452463239431381,0.04459305852651596,0.044660478830337524,0.04472677782177925,0.04479191452264786,0.044855788350105286,0.04491893947124481,0.04498118534684181,0.04504256695508957,0.04510299861431122,0.04516255110502243,0.04522097855806351,0.04527856037020683,0.04533516988158226,0.04539095610380173,0.045445721596479416,0.045499417930841446,0.045551326125860214,0.045602232217788696,0.04564874619245529,0.04569306969642639,0.04573691263794899,0.04577968642115593,0.0458219088613987,0.04586341977119446,0.045904338359832764,0.04594454914331436,0.045984163880348206,0.04602299630641937,0.04606102779507637,0.04609822481870651,0.04617539793252945,0.04634042829275131,0.04650425538420677,0.046666715294122696,0.046827852725982666,0.046987637877464294,0.04714597016572952,0.04730282723903656,0.04745824635028839,0.047612156718969345,0.04776449128985405,0.047915246337652206,0.048064541071653366,0.048212792724370956,0.04836243391036987,0.0485105961561203,0.04865728318691254,0.048802562057971954,0.04894641786813736,0.049088794738054276,0.04923006147146225,0.04937024787068367,0.049509428441524506,0.04964741691946983,0.04978429526090622,0.0499199815094471,0.050054460763931274,0.05018853768706322,0.05032196640968323,0.05045478045940399,0.05058452859520912,0.05070846527814865,0.050831712782382965,0.05095435306429863,0.05107642337679863,0.05119844898581505,0.051319703459739685,0.05144018679857254,0.051560431718826294,0.05168035998940468,0.05179992690682411,0.05191907286643982,0.05203763395547867,0.05215592682361603,0.052273932844400406,0.05239148065447807,0.05250859260559082,0.05262516438961029,0.05274093151092529,0.0528540164232254,0.05296633765101433,0.05307788774371147,0.05318861082196236,0.05329857021570206,0.05340757966041565,0.05351542308926582,0.05362226441502571,0.05372821167111397,0.053833235055208206,0.05393734574317932,0.054040491580963135,0.05414262041449547,0.05424371361732483,0.05434384196996689,0.054443322122097015,0.05454205349087715,0.05463990941643715,0.054736871272325516,0.05483288690447807,0.05491534247994423,0.05499564856290817,0.05507513880729675,0.0551537349820137,0.05523133650422096,0.05530811846256256,0.05538325011730194,0.055455729365348816,0.05552747845649719,0.05559832230210304,0.0556681752204895,0.05573710799217224,0.05580512061715126,0.05587220937013626,0.055938445031642914,0.056003864854574203,0.05606847628951073,0.05613228306174278,0.056195277720689774,0.056257426738739014,0.056318964809179306,0.056379955261945724,0.0564403310418129,0.05650222674012184,0.05656367912888527,0.05662456154823303,0.0566849559545517,0.05674474313855171,0.05680391937494278,0.05686256289482117,0.05692089721560478,0.056978821754455566,0.0570363886654377,0.057093504816293716,0.05715026706457138,0.0572071298956871,0.05726402625441551,0.05732094123959541,0.05737779662013054,0.057434551417827606,0.05749112367630005,0.05754745379090309,0.05760335177183151,0.05765872821211815,0.057705946266651154,0.057747066020965576,0.0577876940369606,0.05782780796289444,0.057867396622896194,0.057906389236450195,0.05794482305645943,0.05798272788524628,0.058020129799842834,0.05805700644850731,0.058093395084142685,0.05812764912843704,0.05815936252474785,0.0581902451813221,0.058219823986291885,0.058248650282621384,0.05827675014734268,0.05830414965748787,0.05833088979125023,0.05835653841495514,0.058381013572216034,0.058404918760061264,0.05842828378081322,0.05845114588737488,0.05847354605793953,0.05849550664424896,0.058517009019851685,0.05853807553648949,0.0585586242377758,0.05857861414551735,0.058598097413778305,0.05861704796552658,0.05863545462489128,0.05865326523780823,0.0586705319583416,0.05868726223707199,0.05870340019464493,0.0587189644575119,0.05873401463031769,0.05874854698777199,0.05876262113451958,0.05877620354294777,0.05878809839487076,0.05879934877157211,0.05881049111485481,0.05882174149155617,0.05883258208632469,0.05884302407503128,0.058853138238191605,0.05886290967464447,0.05887221544981003,0.05888110399246216,0.05888953432440758,0.05889744311571121,0.05890476703643799,0.058912213891744614,0.05891968309879303,0.05892720818519592,0.05893496051430702,0.05894294008612633,0.05895102024078369,0.05895921587944031,0.05896749347448349,0.058975737541913986,0.05898392200469971,0.05899196118116379,0.058999866247177124,0.059007611125707626,0.05902110040187836,0.059034641832113266,0.059047967195510864,0.05906100943684578,0.05907430499792099,0.05908795818686485,0.05910187214612961,0.059115972369909286,0.0591302365064621,0.05914458632469177,0.059159014374017715,0.059173595160245895,0.05918819084763527,0.05920269712805748,0.05921714007854462,0.059231437742710114,0.059244103729724884,0.05925470590591431,0.05926525220274925,0.05927575007081032,0.05928606539964676,0.05929619073867798,0.0593060739338398,0.059315796941518784,0.0593259260058403,0.059338804334402084,0.059360429644584656,0.0593843087553978,0.059408314526081085,0.05943228676915169,0.0594562329351902,0.05948008969426155,0.05950382724404335,0.059527430683374405,0.059550829231739044,0.059573907405138016,0.05959735065698624,0.059621091932058334,0.05964500829577446,0.059669043868780136,0.05969291552901268,0.059716496616601944,0.059740033000707626,0.059763502329587936,0.059786804020404816,0.059808943420648575,0.05982184410095215,0.059834569692611694,0.05984713137149811,0.05985960736870766,0.059872645884752274,0.059886205941438675,0.05990013852715492,0.059914324432611465,0.05992864444851875,0.059943072497844696,0.05995754897594452,0.05997205153107643,0.059986524283885956,0.060000933706760406,0.06001533940434456,0.06002899259328842,0.060040928423404694,0.06005308777093887,0.060086674988269806,0.06012037396430969,0.06015415117144585,0.060187928378582,0.06022166833281517,0.06025535240769386,0.060289472341537476,0.060324639081954956,0.060359641909599304,0.060394614934921265,0.06042967364192009,0.06046474725008011,0.06049980968236923,0.060534801334142685,0.060569655150175095,0.06060430407524109,0.060638707131147385,0.06067286431789398,0.060706768184900284,0.060740403831005096,0.06077370047569275,0.06080951541662216,0.0608474500477314,0.06088736653327942,0.0609290711581707,0.06097233295440674,0.061016980558633804,0.0610627681016922,0.061109546571969986,0.06115715950727463,0.061205510050058365,0.061254438012838364,0.06130390614271164,0.06135370954871178,0.06140700727701187,0.06146082654595375,0.0615227110683918,0.061588648706674576,0.06165460869669914,0.061720509082078934,0.06178274378180504,0.06184335798025131,0.06190239265561104,0.06196090206503868,0.06201919540762901],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"On-policy Estimate\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824,0.8214166746973824],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"IS Variance\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962,0.0006751575274392962],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"lines\",\"name\":\"Train Variance\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.6234005093574524,1.414181113243103,1.3554474115371704,1.2942333221435547,1.2343804836273193,1.1762715578079224,1.1202501058578491,1.0660842657089233,1.0160977840423584,0.9612501859664917,0.9053537845611572,0.8525124192237854,0.801757276058197,0.7521448135375977,0.7050195932388306,0.6592178344726562,0.6183522939682007,0.5808679461479187,0.546052098274231,0.5135306119918823,0.48306596279144287,0.4539247751235962,0.42629119753837585,0.40010762214660645,0.37619370222091675,0.3549620509147644,0.3348369896411896,0.31564590334892273,0.2972891628742218,0.28007593750953674,0.2638157308101654,0.24848172068595886,0.23381701111793518,0.21979020535945892,0.2065993845462799,0.19418740272521973,0.18250086903572083,0.1716528683900833,0.16149096190929413,0.1519584059715271,0.14302338659763336,0.13465158641338348,0.12679380178451538,0.11944064497947693,0.1125289648771286,0.1060420572757721,0.09999002516269684,0.09436073899269104,0.08910861611366272,0.08423852920532227,0.07966537773609161,0.07536525279283524,0.07137318700551987,0.06767375022172928,0.06422092020511627,0.061149898916482925,0.05831089988350868,0.055670056492090225,0.05321113392710686,0.05092259496450424,0.04879360646009445,0.04681325703859329,0.044969312846660614,0.043251097202301025,0.04165244475007057,0.04024624824523926,0.03896992653608322,0.037783872336149216,0.03668048977851868,0.03565360605716705,0.03470296785235405,0.03381707891821861,0.032995712012052536,0.03222816810011864,0.03150847926735878,0.03083282895386219,0.030195580795407295,0.02959252893924713,0.029025910422205925,0.028494829311966896,0.02799372747540474,0.02751953899860382,0.027069637551903725,0.02663993276655674,0.02622963674366474,0.025837626308202744,0.02546287328004837,0.02510371245443821,0.02475886046886444,0.024427121505141258,0.02410702593624592,0.02379785291850567,0.023498881608247757,0.02320939488708973,0.022928478196263313,0.022655414417386055,0.022389860823750496,0.022131422534585,0.021879788488149643,0.02163422852754593,0.021394316107034683,0.0211651511490345,0.020944764837622643,0.02072872407734394,0.02051938697695732,0.020311901345849037,0.020107919350266457,0.019907081499695778,0.019709035754203796,0.019513877108693123,0.019321484491229057,0.01913171075284481,0.018944405019283295,0.01875951513648033,0.018576819449663162,0.018396152183413506,0.018217582255601883,0.018040956929326057,0.017866233363747597,0.01769336313009262,0.01752222143113613,0.01735280267894268,0.017185090109705925,0.017019005492329597,0.016854550689458847,0.01669166050851345,0.01653023436665535,0.01637033186852932,0.016211960464715958,0.016054563224315643,0.01589810848236084,0.01574305258691311,0.015589430928230286,0.015437223948538303,0.015286448411643505,0.0151371443644166,0.014989354647696018,0.014846858568489552,0.014706392772495747,0.014567308127880096,0.014429545029997826,0.014292986132204533,0.014155631884932518,0.014019422233104706,0.013884535990655422,0.013751087710261345,0.013619063422083855,0.013488486409187317,0.013359478674829006,0.01322931982576847,0.013099397532641888,0.012970949523150921,0.01284385472536087,0.012718357145786285,0.012595118954777718,0.012473490089178085,0.01235373318195343,0.012235447764396667,0.012118618004024029,0.012003243900835514,0.01188923791050911,0.011776565574109554,0.011664807796478271,0.011554315686225891,0.011445991694927216,0.01133941300213337,0.011237484402954578,0.011136612854897976,0.011036764830350876,0.010938383638858795,0.010842379182577133,0.01074716541916132,0.010652869939804077,0.010559415444731712,0.010466879233717918,0.010375226847827435,0.01028450857847929,0.010194653645157814,0.010105742141604424,0.010017751716077328,0.009930753149092197,0.009844744578003883,0.009759707376360893,0.009676191955804825,0.009593840688467026,0.009512298740446568,0.009431562386453152,0.009351613000035286,0.009272324852645397,0.009193881414830685,0.009116481989622116,0.00903987418860197,0.008965019136667252,0.008893261663615704,0.008822187781333923,0.008751630783081055,0.008681616745889187,0.008612284436821938,0.008543921634554863,0.008479385636746883,0.008417333476245403,0.008355897851288319,0.00829505268484354,0.008234540931880474,0.008174406364560127,0.008114935830235481,0.00805610790848732,0.007997813634574413,0.007939881645143032,0.007882542908191681,0.007825619541108608,0.007769422605633736,0.007713908329606056,0.007658901624381542,0.007604418322443962,0.007550450041890144,0.007496983744204044,0.0074436175636947155,0.007390737067908049,0.007338357158005238,0.007286463864147663,0.00723504601046443,0.007183803245425224,0.007132713682949543,0.007080934941768646,0.00702843489125371,0.0069762179628014565,0.0069243041798472404,0.006872728932648897,0.006818186491727829,0.0067628188990056515,0.006708495318889618,0.006654729135334492,0.006601505912840366,0.006548816803842783,0.006496652960777283,0.006445014849305153,0.006393854971975088,0.0063431719318032265,0.006292965728789568,0.006243232171982527,0.006194000132381916,0.006145267281681299,0.006097049918025732,0.006049327086657286,0.0060020936653018,0.0059553938917815685,0.005909135099500418,0.0058632888831198215,0.005817892961204052,0.005771299824118614,0.0057248203083872795,0.005678833927959204,0.00563329691067338,0.005588212516158819,0.005543590057641268,0.005499407183378935,0.0054556699469685555,0.005412365775555372,0.005369517486542463,0.005327105522155762,0.005285161081701517,0.005243659019470215,0.005202618893235922,0.005162025336176157,0.005121871829032898,0.005082176066935062,0.0050427294336259365,0.005003593862056732,0.004964910913258791,0.00492667593061924,0.004888895899057388,0.004851561971008778,0.0048146541230380535,0.004778142087161541,0.004741967655718327,0.004706073086708784,0.0046705687418580055,0.004635467194020748,0.004600779619067907,0.004566494841128588,0.0045326161198318005,0.004499123431742191,0.004466320853680372,0.004433884751051664,0.004401788581162691,0.004370066802948713,0.004338734317570925,0.004307770635932684,0.004277286119759083,0.004247245844453573,0.0042176395654678345,0.004188473802059889,0.004159719217568636,0.004131358582526445,0.004103379789739847,0.0040757982060313225,0.0040485975332558155,0.0040218885987997055,0.003995727282017469,0.003970052115619183,0.003944908268749714,0.003920262213796377,0.0038961092941462994,0.003872570116072893,0.0038493983447551727,0.0038266486953943968,0.0038043002132326365,0.003782111220061779,0.0037583871744573116,0.0037349907215684652,0.0037119309417903423,0.0036892243660986423,0.0036668037064373493,0.003644562093541026,0.0036225065123289824,0.003600702155381441,0.003579162061214447,0.0035589621402323246,0.003540363861247897,0.00351748988032341,0.0034929760731756687,0.0034687304869294167,0.0034447426442056894,0.003420995781198144,0.003397467778995633,0.0033741712104529142,0.003351128427311778,0.0033283415250480175,0.0033058025874197483,0.0032834780868142843,0.0032613612711429596,0.003239500103518367,0.0032182540744543076,0.003200792009010911,0.0031851583626121283,0.0031702432315796614,0.0031555527821183205,0.003141087479889393,0.0031268366146832705,0.003112772013992071,0.003098894841969013,0.0030851871706545353,0.003071635030210018,0.0030583436600863934,0.0030451857019215822,0.0030323313549160957,0.0030197356827557087,0.003007312072440982,0.0029951296746730804,0.002983196172863245,0.0029715076088905334,0.002960105426609516,0.002948981709778309,0.002938054036349058,0.002927329856902361,0.0029168641194701195,0.0029067054856568575,0.0028967976104468107,0.0028871011454612017,0.0028775897808372974,0.0028682444244623184,0.0028590545989573,0.0028500263579189777,0.0028411380480974913,0.0028323952574282885,0.002823777496814728,0.0028152931481599808,0.0028069266118109226,0.002798666013404727,0.0027905621100217104,0.0027817809022963047,0.00277083832770586,0.0027602200862020254,0.002749861916527152,0.002739840419963002,0.0027305360417813063,0.0027216458693146706,0.002713052788749337,0.0027047155890613794,0.002696612384170294,0.0026887012645602226,0.0026809663977473974,0.00267339451238513,0.0026659660506993532,0.002658683806657791,0.0026515189092606306,0.0026444820687174797,0.0026375604793429375,0.002630745293572545,0.0026243317406624556,0.0026180464774370193,0.002611843403428793,0.002605726709589362,0.0025992407463490963,0.002592789474874735,0.0025864122435450554,0.0025800953153520823,0.002573844278231263,0.0025676439981907606,0.00256150565110147,0.0025553954765200615,0.0025493018329143524,0.002543174894526601,0.002537077758461237,0.0025310132186859846,0.0025250043254345655,0.0025190587621182203,0.0025131746660917997,0.002507357858121395,0.0025014353450387716,0.0024955770932137966,0.0024896040558815002,0.002483701566234231,0.0024776868522167206,0.0024715247564017773,0.0024653703439980745,0.002459227805957198,0.00245309853926301,0.002446983940899372,0.0024408982135355473,0.00243483018130064,0.0024287905544042587,0.0024227802641689777,0.002416822360828519,0.002410924294963479,0.0024049952626228333,0.002399047138169408,0.0023931022733449936,0.002387162996456027,0.0023812372237443924,0.0023753258865326643,0.0023694296833127737,0.0023635507095605135,0.0023576784878969193,0.0023518309462815523,0.0023460090160369873,0.00234021432697773,0.0023345821537077427,0.0023290133103728294,0.0023234544787555933,0.0023178327828645706,0.0023121924605220556,0.002306551905348897,0.0023009052965790033,0.0022952586878091097,0.002289609285071492,0.002283968962728977,0.002278333529829979,0.002272713929414749,0.0022671299520879984,0.002261603018268943,0.0022560912184417248,0.0022505938541144133,0.002245117910206318,0.002239624038338661,0.002234129002317786,0.0022286376915872097,0.002223151968792081,0.0022176895290613174,0.0022122494410723448,0.0022068186663091183,0.0022014020942151546,0.002195856301113963,0.002190259052440524,0.002184652490541339,0.0021790543105453253,0.0021734603215008974,0.002168284496292472,0.002163216471672058,0.002158150775358081,0.0021530978847295046,0.0021480522118508816,0.0021430281922221184,0.0021380481775850058,0.0021333107724785805,0.002128365682438016,0.0021232443396002054,0.0021179704926908016,0.002112611662596464,0.0021071473602205515,0.0021015903912484646,0.0020959549583494663,0.0020902282558381557,0.0020844589453190565,0.002078665653243661,0.0020728548988699913,0.002067028544843197,0.0020611844956874847,0.0020553285721689463,0.002049465896561742,0.0020435983315110207,0.002037742407992482,0.0020318918395787477,0.0020260470919311047,0.0020196966361254454,0.002012837678194046,0.0020059400703758,0.00199904921464622,0.0019921800121665],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"lines\",\"name\":\"Test Variance\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.007930450141429901,0.007587512023746967,0.007257567252963781,0.006923196371644735,0.006584602873772383,0.006355383899062872,0.006137662101536989,0.005928669590502977,0.0057223206385970116,0.005524087231606245,0.00533490302041173,0.0051015750505030155,0.004858843050897121,0.004638404119759798,0.0044294483959674835,0.004231045953929424,0.004043606109917164,0.003864253405481577,0.00369126140139997,0.0035284289624542,0.0033754967153072357,0.00323182949796319,0.0030749973375350237,0.0028993592131882906,0.002736184047535062,0.0025851645041257143,0.002445138292387128,0.002315354300662875,0.0021952029783278704,0.0020840363577008247,0.001981206936761737,0.001886120531708002,0.0017982159042730927,0.0017169113270938396,0.001641746610403061,0.001572279492393136,0.0015080830780789256,0.0014487877488136292,0.0013940450735390186,0.0013435196597129107,0.0012951234821230173,0.0012436514953151345,0.0011967518366873264,0.0011541133280843496,0.0011154388776049018,0.0010804296471178532,0.0010488406987860799,0.001020427094772458,0.0009949632221832871,0.0009720736416056752,0.0009505441412329674,0.0009314028429798782,0.0009144775685854256,0.0008995304233394563,0.0008864816627465189,0.0008751990390010178,0.0008655620040372014,0.0008574470411986113,0.0008507407619617879,0.000845338508952409,0.0008411404560320079,0.0008378879283554852,0.0008354657329618931,0.0008338227635249496,0.0008329016854986548,0.0008326480747200549,0.0008330038981512189,0.0008339298074133694,0.0008353807497769594,0.0008373120799660683,0.000839683401864022,0.0008424590923823416,0.0008456051000393927,0.0008490896434523165,0.0008528829202987254,0.0008569561177864671,0.0008612839155830443,0.000865840760525316,0.0008706047083251178,0.0008755506714805961,0.0008806592668406665,0.000885911809746176,0.0008912911871448159,0.0008967840694822371,0.0009023761958815157,0.0009080557501874864,0.0009138124296441674,0.0009196330211125314,0.0009255085606127977,0.0009314277558587492,0.0009373825159855187,0.0009433706291019917,0.0009493465768173337,0.0009553306153975427,0.00096132728504017,0.0009673289023339748,0.0009733284241519868,0.000979321775957942,0.0009853022638708353,0.000991266337223351,0.0009972103871405125,0.0010031556012108922,0.001009093364700675,0.0010150049347430468,0.0010208931053057313,0.0010267553152516484,0.0010325900511816144,0.0010383914923295379,0.001044155564159155,0.001049881218932569,0.0010555650806054473,0.0010612097103148699,0.0010668111499398947,0.001072371145710349,0.0010778863215819001,0.0010833552805706859,0.0010887749958783388,0.0010941437212750316,0.0010994578478857875,0.0011047181906178594,0.0011099224211648107,0.0011132479412481189,0.0011118914699181914,0.0011105125304311514,0.0011091127526015043,0.0011076919035986066,0.0011062503326684237,0.001104787108488381,0.0011033029295504093,0.001101797679439187,0.0011002729879692197,0.0010987292043864727,0.0010971671435981989,0.001095586339943111,0.0010939879575744271,0.0010923735098913312,0.0010907433461397886,0.0010889938566833735,0.0010872135171666741,0.0010854210704565048,0.001083618146367371,0.0010818042792379856,0.0010799801675602794,0.0010781452292576432,0.001076300977729261,0.001074447762221098,0.0010725859319791198,0.0010707161854952574,0.0010688375914469361,0.0010669530602172017,0.0010650618933141232,0.0010631654877215624,0.001061263494193554,0.0010593744227662683,0.0010574974585324526,0.0010556163033470511,0.0010537318885326385,0.0010518442140892148,0.0010499528143554926,0.0010480597848072648,0.001046164077706635,0.0010442673228681087,0.0010423696367070079,0.0010399327147752047,0.0010373505065217614,0.0010347756324335933,0.001032210304401815,0.0010296560358256102,0.0010271124774590135,0.0010245635639876127,0.0010219990508630872,0.0010196822695434093,0.0010173763148486614,0.0010150831658393145,0.0010128030553460121,0.0010105357505381107,0.0010082811350002885,0.0010060396743938327,0.0010038097389042377,0.0010015915613621473,0.0009993832791224122,0.0009971845429390669,0.0009949953528121114,0.000992816174402833,0.00099064817186445,0.0009884948376566172,0.0009863544255495071,0.0009842284489423037,0.0009821155108511448,0.0009800167754292488,0.000977930729277432,0.0009758583619259298,0.0009737981599755585,0.0009717527427710593,0.0009697205969132483,0.0009677017224021256,0.0009656940237618983,0.00096369837410748,0.0009616699535399675,0.0009596390300430357,0.0009576260927133262,0.0009556752047501504,0.0009537405567243695,0.0009518206352367997,0.0009499153820797801,0.000948022585362196,0.0009461425943300128,0.0009442749433219433,0.0009424197487533092,0.0009405756718479097,0.0009387563914060593,0.0009369695326313376,0.0009351980988867581,0.0009334411006420851,0.0009316975483670831,0.0009299673838540912,0.0009282503160648048,0.0009265455882996321,0.0009248527348972857,0.0009231717558577657,0.0009215016616508365,0.0009198421612381935,0.0009181943023577332,0.0009165530209429562,0.0009148961398750544,0.0009132472332566977,0.0009116071159951389,0.000909975788090378,0.0009083535405807197,0.0009067410719580948,0.000905125867575407,0.0009035144466906786,0.0009019116405397654,0.0009003172744996846,0.0008987317560240626,0.0008971550269052386,0.0008955869125202298,0.0008940298575907946,0.0008924842695705593,0.0008909492171369493,0.0008894210332073271,0.0008878952939994633,0.0008863790426403284,0.0008848722209222615,0.0008833739557303488,0.000881883199326694,0.0008804007666185498,0.000878926133736968,0.0008774629677645862,0.0008760112687014043,0.0008745698141865432,0.0008731383713893592,0.0008717159507796168,0.0008703045314177871,0.0008689030655659735,0.0008675120770931244,0.0008661305182613432,0.0008647582144476473,0.0008633946999907494,0.0008620377629995346,0.0008606899064034224,0.0008593499660491943,0.0008580182329751551,0.0008566943579353392,0.0008553783991374075,0.0008541407878510654,0.0008529354818165302,0.0008517372771166265,0.0008505451260134578,0.0008493593195453286,0.000848181254696101,0.0008470095344819129,0.0008458439842797816,0.0008446841384284198,0.0008435312192887068,0.0008423850522376597,0.0008412477327510715,0.0008401185623370111,0.0008389967260882258,0.0008378758793696761,0.0008367614937014878,0.0008356537437066436,0.0008345529204234481,0.0008334587328135967,0.0008323705988004804,0.0008312601712532341,0.0008300913614220917,0.0008289299439638853,0.0008277756278403103,0.0008266274235211313,0.0008254856220446527,0.00082434993237257,0.0008232201216742396,0.0008220967720262706,0.0008209797670133412,0.0008198691066354513,0.0008187656057998538,0.0008176695555448532,0.0008165797335095704,0.0008154927636496723,0.0008144080638885498,0.0008133263327181339,0.0008123541483655572,0.0008113918011076748,0.0008104335865937173,0.0008094788063317537,0.0008085278677754104,0.0008075804798863828,0.0008066369919106364,0.0008056984515860677,0.0008047647424973547,0.0008038358646444976,0.000802913389634341,0.0008019975502975285,0.0008010889287106693,0.0008001876412890851,0.0007992925820872188,0.0007984036928974092,0.0007975205662660301,0.000796644133515656,0.0007957737543620169,0.0007949085556901991,0.0007940488285385072,0.0007932078442536294,0.0007923820521682501,0.0007915609749034047,0.000790744845289737,0.0007899329648353159,0.0007891252753324807,0.0007883214857429266,0.0007875220035202801,0.000786726304795593,0.0007859345059841871,0.0007851455011405051,0.0007843575440347195,0.0007835744181647897,0.0007827980443835258,0.000782027083914727,0.0007812620606273413,0.000780502799898386,0.0007797486614435911,0.0007789999363012612,0.0007782555767334998,0.0007775152917020023,0.0007767790812067688,0.0007760468288324773,0.0007753170793876052,0.0007745905313640833,0.0007738666608929634,0.0007731457590125501,0.0007724279421381652,0.0007717126281931996,0.0007709995261393487,0.0007702891598455608,0.0007695811218582094,0.0007688758778385818,0.0007681727292947471,0.0007674721418879926,0.0007667745812796056,0.0007660792907699943,0.0007653866778127849,0.0007646972080692649,0.0007640102994628251,0.0007633267086930573,0.0007626456208527088,0.0007619664538651705,0.000761290779337287,0.0007606184226460755,0.0007599499076604843,0.0007592849433422089,0.0007586225983686745,0.000757963745854795,0.000757307221647352,0.0007566519780084491,0.0007559980149380863,0.0007553454488515854,0.0007546929991804063,0.0007540417136624455,0.000753394269850105,0.0007527508423663676,0.000752111489418894,0.0007514768512919545,0.0007508467533625662,0.0007502213702537119,0.0007496001198887825,0.0007489835843443871,0.0007483711815439165,0.0007477630279026926,0.0007471585995517671,0.0007465580711141229,0.0007459615590050817,0.000745458179153502,0.0007449609693139791,0.0007444671355187893,0.0007439759210683405,0.0007434901199303567,0.0007430095574818552,0.000742534059099853,0.0007420632755383849,0.0007415969739668071,0.0007411348633468151,0.0007406770600937307,0.0007402232149615884,0.0007397747249342501,0.0007393314735963941,0.000738892937079072,0.0007384588825516403,0.000738037982955575,0.0007376330322586,0.0007372308173216879,0.0007368315709754825,0.0007364347111433744,0.0007360410527326167,0.0007356504211202264,0.0007352628745138645,0.0007348807412199676,0.0007344883633777499,0.0007340668817050755,0.0007336690905503929,0.000733275490347296,0.0007328854990191758,0.0007324990583583713,0.0007321162847802043,0.0007317363051697612,0.000731359759811312,0.0007309864740818739,0.0007306166808120906,0.0007302512531168759,0.0007298897835426033,0.0007295322720892727,0.0007291783113032579,0.0007288366323336959,0.0007285166066139936,0.0007281997241079807,0.0007278851699084044,0.0007275731768459082,0.0007272546063177288,0.0007268544868566096,0.0007264576852321625,0.000726063852198422,0.0007256733370013535,0.0007252870709635317,0.0007249049958772957,0.0007245271117426455,0.0007241536513902247,0.0007237843819893897,0.0007234191289171576,0.0007230578921735287,0.0007227002643048763,0.0007223464199341834,0.0007219957769848406,0.0007216489175334573,0.0007213136996142566,0.0007210022886283696,0.0007206937298178673,0.0007203822024166584,0.0007200735853984952,0.0007197678787633777,0.0007194654317572713,0.0007191657787188888,0.000718868977855891,0.0007185446447692811,0.0007181554101407528,0.0007177687366493046,0.0007173849153332412,0.0007170040044002235,0.0007166260620579123,0.0007162507972680032,0.0007158786174841225,0.000715508998837322,0.0007151414756663144,0.0007147740107029676,0.0007144096889533103,0.0007140481029637158,0.0007136893109418452,0.0007133333128876984,0.0007129806908778846,0.0007126312702894211,0.0007122851093299687,0.0007119417423382401,0.0007116013439372182,0.000711263797711581,0.0007109291618689895,0.0007105975528247654,0.0007102685049176216,0.0007099423091858625,0.0007096186745911837,0.0007092976593412459,0.000708979438059032,0.0007086648838594556,0.0007083530654199421,0.0007079415954649448,0.0007074809982441366,0.0007070235442370176,0.0007065691752359271,0.0007060780772008002,0.0007055749883875251,0.0007050680578686297,0.0007045621750876307,0.0007040593191049993],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"lines\",\"name\":\"Train MSE Loss\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[26.116947174072266,25.072866439819336,23.790647506713867,22.5589542388916,21.376792907714844,20.247314453125,19.17703628540039,18.154142379760742,17.17890167236328,16.249614715576172,15.362747192382812,14.515628814697266,13.70895767211914,12.942737579345703,12.214889526367188,11.526067733764648,10.872233390808105,10.252071380615234,9.663846969604492,9.107731819152832,8.582853317260742,8.08924388885498,7.6237664222717285,7.184940814971924,6.771476745605469,6.382281303405762,6.015939712524414,5.672802448272705,5.351483345031738,5.049720287322998,4.766186714172363,4.499965190887451,4.25037956237793,4.016520977020264,3.7978124618530273,3.5930917263031006,3.401818037033081,3.223240375518799,3.0565972328186035,2.9014039039611816,2.7568819522857666,2.6221182346343994,2.4969327449798584,2.3807241916656494,2.272958278656006,2.1730990409851074,2.0805399417877197,1.9948573112487793,1.9156936407089233,1.8425829410552979,1.7750838994979858,1.7128223180770874,1.655287265777588,1.6020739078521729,1.5529932975769043,1.507761001586914,1.4660605192184448,1.4275779724121094,1.392113208770752,1.3594413995742798,1.3293113708496094,1.3014522790908813,1.2756779193878174,1.2517741918563843,1.2295867204666138,1.2089530229568481,1.1897283792495728,1.171781301498413,1.1549893617630005,1.139234185218811,1.1243815422058105,1.110331416130066,1.096996545791626,1.0842976570129395,1.0721595287322998,1.0605140924453735,1.0492924451828003,1.0384342670440674,1.0279216766357422,1.0177139043807983,1.0077779293060303,0.9980846643447876,0.9886051416397095,0.9793134331703186,0.9701936841011047,0.9612274169921875,0.9523928165435791,0.9436903595924377,0.9351125359535217,0.9266546964645386,0.9183120727539062,0.9100666642189026,0.9019309878349304,0.8939024209976196,0.8859831690788269,0.8781741857528687,0.870470404624939,0.8628767728805542,0.8553924560546875,0.8480187058448792,0.8407409191131592,0.8335530757904053,0.826461911201477,0.8194717168807983,0.812572181224823,0.8057693243026733,0.7990649342536926,0.7924553155899048,0.7859389185905457,0.7795171737670898,0.7731873989105225,0.7669417262077332,0.760776698589325,0.7547000646591187,0.7487125396728516,0.7428149580955505,0.737002968788147,0.7312802672386169,0.7256452441215515,0.7200931310653687,0.7146227359771729,0.7092311382293701,0.7039158940315247,0.6986792087554932,0.6935151219367981,0.688424825668335,0.6834151148796082,0.6784775257110596,0.6736158132553101,0.668819010257721,0.6640884280204773,0.6594238877296448,0.6548215746879578,0.6502794623374939,0.6457980871200562,0.6413755416870117,0.6370103359222412,0.6326997876167297,0.62844318151474,0.6242409944534302,0.6200922131538391,0.615995466709137,0.6119493842124939,0.6079410314559937,0.6039612889289856,0.6000264286994934,0.596140444278717,0.5922991633415222,0.5885026454925537,0.5847511291503906,0.5810409784317017,0.577373206615448,0.5737447142601013,0.5701606869697571,0.5666199922561646,0.5631187558174133,0.5596495270729065,0.5562185645103455,0.5528253316879272,0.5494691729545593,0.5461491346359253,0.5428655743598938,0.5396199822425842,0.5364095568656921,0.5332300066947937,0.5300812125205994,0.5269502401351929,0.5238524675369263,0.5207870602607727,0.5177538990974426,0.5147536396980286,0.5117825865745544,0.5088340640068054,0.5059108138084412,0.5030160546302795,0.5001513361930847,0.4973183572292328,0.49451160430908203,0.4917331337928772,0.4889746904373169,0.4862414598464966,0.48353439569473267,0.4808536767959595,0.47820529341697693,0.47557559609413147,0.47297149896621704,0.4703925549983978,0.4678384065628052,0.46530982851982117,0.4628080129623413,0.4603271186351776,0.4578695595264435,0.45543575286865234,0.45302385091781616,0.4506361186504364,0.4482719600200653,0.4459250569343567,0.4435950517654419,0.44128692150115967,0.4390021860599518,0.4367452561855316,0.43451032042503357,0.43229734897613525,0.4301064610481262,0.42793601751327515,0.42578327655792236,0.42365139722824097,0.4215398132801056,0.41944822669029236,0.41737061738967896,0.41530707478523254,0.4132623076438904,0.4112371504306793,0.4092293381690979,0.4072394371032715,0.4052680432796478,0.4033147692680359,0.4013794958591461,0.3994620442390442,0.39756259322166443,0.39568132162094116,0.393820583820343,0.3919762372970581,0.39014944434165955,0.38834184408187866,0.38655105233192444,0.38477715849876404,0.38302046060562134,0.3812796175479889,0.3795536458492279,0.3778443932533264,0.3761501610279083,0.3744698762893677,0.37280401587486267,0.371152400970459,0.36951541900634766,0.3678811192512512,0.3662586808204651,0.3646492063999176,0.3630523979663849,0.36146798729896545,0.3598942756652832,0.358332097530365,0.35678160190582275,0.35524293780326843,0.3537147641181946,0.3521984815597534,0.350688099861145,0.34918656945228577,0.3476960361003876,0.3462158143520355,0.34474602341651917,0.34328606724739075,0.34183356165885925,0.34039178490638733,0.3389609158039093,0.3375406265258789,0.336130827665329,0.33473193645477295,0.33334487676620483,0.3319678008556366,0.33060064911842346,0.32924455404281616,0.32789918780326843,0.3265647292137146,0.32523900270462036,0.3239227533340454,0.32261693477630615,0.32132095098495483,0.3200339674949646,0.3187570571899414,0.3174908757209778,0.3162342607975006,0.31498485803604126,0.3137418031692505,0.31250905990600586,0.31128883361816406,0.31007879972457886,0.30887749791145325,0.3076849579811096,0.3065015971660614,0.3053281903266907,0.3041648268699646,0.3030095398426056,0.3018626868724823,0.3007247745990753,0.29959526658058167,0.2984747886657715,0.2973610460758209,0.29625555872917175,0.2951582670211792,0.2940689027309418,0.2929874360561371,0.2919137179851532,0.2908478379249573,0.28978973627090454,0.28874102234840393,0.28769931197166443,0.28665825724601746,0.28562089800834656,0.2845888137817383,0.28356319665908813,0.28254401683807373,0.2815310060977936,0.28052371740341187,0.279522567987442,0.2785283327102661,0.2775408923625946,0.27655965089797974,0.27558454871177673,0.2746158242225647,0.27365416288375854,0.27269935607910156,0.27175018191337585,0.2708028554916382,0.2698601186275482,0.26892220973968506,0.26799044013023376,0.26706475019454956,0.26614466309547424,0.26522961258888245,0.26431939005851746,0.26341497898101807,0.26251667737960815,0.26162445545196533,0.26073703169822693,0.259853333234787,0.25897499918937683,0.2581023871898651,0.25723475217819214,0.25637248158454895,0.2555159628391266,0.2546594738960266,0.25380244851112366,0.2529512941837311,0.2521059215068817,0.25126540660858154,0.25042980909347534,0.2495991736650467,0.24877363443374634,0.24795347452163696,0.24713845551013947,0.24632838368415833,0.24552054703235626,0.2447100579738617,0.24390049278736115,0.24309097230434418,0.24228498339653015,0.24148264527320862,0.24068209528923035,0.2398838847875595,0.23908458650112152,0.2382880002260208,0.23749397695064545,0.23670317232608795,0.23591622710227966,0.23512977361679077,0.2343471646308899,0.2335689663887024,0.23279525339603424,0.23202630877494812,0.23126168549060822,0.23050087690353394,0.22974342107772827,0.22899042069911957,0.2282424420118332,0.2274983674287796,0.2267579287290573,0.22602199018001556,0.2252902090549469,0.22455985844135284,0.223833829164505,0.22310973703861237,0.22237630188465118,0.2216431051492691,0.22090183198451996,0.22015444934368134,0.21940478682518005,0.2186538577079773,0.21790415048599243,0.21715521812438965,0.21640732884407043,0.21566158533096313,0.21491838991641998,0.21417860686779022,0.2134421318769455,0.21270892024040222,0.21197940409183502,0.21125361323356628,0.21053145825862885,0.20981311798095703,0.20909878611564636,0.2083878517150879,0.2076784074306488,0.20696590840816498,0.20625533163547516,0.20554709434509277,0.20484228432178497,0.2041410505771637,0.2034435123205185,0.20274963974952698,0.20205888152122498,0.20137183368206024,0.20069028437137604,0.2000129073858261,0.19933843612670898,0.19866599142551422,0.1979953795671463,0.1973264366388321,0.19665664434432983,0.19598785042762756,0.1953228861093521,0.19466206431388855,0.19400478899478912,0.1933489292860031,0.19269490242004395,0.19204428791999817,0.1913972795009613,0.19075395166873932,0.19011443853378296,0.18947869539260864,0.1888466477394104,0.18821820616722107,0.18759311735630035,0.1869717240333557,0.1863548308610916,0.18573850393295288,0.18512481451034546,0.18451446294784546,0.18390794098377228,0.18330499529838562,0.18270526826381683,0.18210916221141815,0.1815166026353836,0.18092764914035797,0.18034228682518005,0.17976054549217224,0.17918287217617035,0.17860835790634155,0.17803362011909485,0.17745904624462128,0.17688505351543427,0.17631393671035767,0.17574648559093475,0.17518295347690582,0.17462271451950073,0.174065500497818,0.17351160943508148,0.17296122014522552,0.17241419851779938,0.1718706488609314,0.17132976651191711,0.17079226672649384,0.1702577918767929,0.16972650587558746,0.16919630765914917,0.16866947710514069,0.16814596951007843,0.16762571036815643,0.16710856556892395,0.16659434139728546,0.16608335077762604,0.16557511687278748,0.1650698333978653,0.16456681489944458,0.1640666127204895,0.1635691523551941,0.16307473182678223,0.16258320212364197,0.16209475696086884,0.16160868108272552,0.16112549602985382,0.16064533591270447,0.16016748547554016,0.15969283878803253,0.1592085361480713,0.1587252914905548,0.15824350714683533,0.15776300430297852,0.1572832465171814,0.1568024605512619,0.15632343292236328,0.15584628283977509,0.1553688496351242,0.15489165484905243,0.154416024684906,0.1539420783519745,0.15347005426883698,0.15300019085407257,0.15253256261348724,0.15206725895404816,0.15160396695137024,0.15114305913448334,0.1506844460964203,0.1502283662557602,0.14977240562438965,0.14931625127792358,0.14886191487312317,0.14841005206108093,0.14796048402786255],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"mode\":\"lines\",\"name\":\"IS MSE\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341,0.6103710102038341],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"mode\":\"lines\",\"name\":\"Train MSE\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[2.193953384370645,2.244128747154873,2.107954038353934,1.9688308019290686,1.8363322140845457,1.712255162625028,1.5984619376982554,1.4893590643069867,1.3896210099828747,1.2845965458790396,1.1804983811846559,1.084791885591207,0.9949606260260013,0.9104336873174306,0.8326583397473317,0.7601928456400602,0.6979697131863329,0.642869546894035,0.5931404037253553,0.548154263754741,0.5075570508676226,0.47026233552244107,0.43623127074940055,0.40529099105791433,0.37829662805179853,0.3554579571506921,0.33483717797989204,0.316166606534166,0.2994403098434079,0.284928013921588,0.27236715721057564,0.26163730891050857,0.2525591124599165,0.24512300800539868,0.23929130768683507,0.2349049364645836,0.23192488662770444,0.23016880790782018,0.22949746840418958,0.2298146965104148,0.23113157534302392,0.23329809400822438,0.23623277087632188,0.23983984257689842,0.2440924149400835,0.24891965098231708,0.25424471296395657,0.2599774063761166,0.26610020077629315,0.27248027195198243,0.27918026037603666,0.2861794734223379,0.2933471217792596,0.3006307378423959,0.30801964032869716,0.31504536653796505,0.3220325463032749,0.3290481682900366,0.33601971186754714,0.34292457148984384,0.34976784704931657,0.3564799516448492,0.3630611882802964,0.3694382662847506,0.37567091293038424,0.3818219779073322,0.3878423902682704,0.3936795645747927,0.39929013680460074,0.4046461481613814,0.40977844329284097,0.41470903301167306,0.4194130252034882,0.4239171809735512,0.428232546197835,0.43236049006117466,0.4362980389750968,0.44006619663776403,0.443648844240254,0.4470358222010985,0.45024763491810965,0.4532881985559286,0.45615687102704006,0.4587992879909351,0.4613032752961055,0.46365668368062407,0.4658402880031458,0.4678938869078099,0.4698181852268551,0.4716100996785335,0.4732938463672048,0.47487949725760215,0.47636764127155,0.4777599134300444,0.47906526076981476,0.4802923301572126,0.4814504779001663,0.4825588403657184,0.48363035063795085,0.48464670278225586,0.4856132426814103,0.48650943436396765,0.4873495152341964,0.4881592462725447,0.4888919767616631,0.4896025379714204,0.49029281529650726,0.49097909015262886,0.491672698998232,0.49235655343676754,0.4930321767548374,0.4936996972719563,0.4943642550428683,0.49502818759125683,0.49569179830898324,0.49635499512286174,0.4970224784133507,0.49769643161600474,0.498377503676722,0.4990659475731879,0.49976483843093794,0.5004740678904458,0.5011950504505804,0.5019253675254788,0.5026660683188399,0.5034178479051961,0.5041793398379362,0.5049500830897571,0.5057253297513302,0.5065123347204777,0.5073100294450754,0.508149428221401,0.5090185018420659,0.5099025829624654,0.5107976998605586,0.5117017459682238,0.5126145951410999,0.5135223470066411,0.5144376815596206,0.5153639181688713,0.5162930223324881,0.5172262200982582,0.5181823263032528,0.5191526365571081,0.5201364144900976,0.5211340125765834,0.5221398860344146,0.52315293864507,0.5241853526946103,0.5252818811624212,0.5264037963344861,0.5275297830344754,0.5286399789862077,0.5297463791291313,0.5308309878289766,0.5319194742269422,0.5330172327627276,0.5341180602062734,0.535220130727955,0.5363194571241348,0.5374182332029335,0.5385165211295068,0.5396249128350374,0.5407324154628019,0.5418101952760888,0.542888038826157,0.5439594004083542,0.54502790806167,0.5460937291469948,0.5471518348307849,0.5481843133012454,0.5491825868175171,0.5501803617440921,0.551175811044411,0.5521678585015749,0.5531568376155128,0.5541425308720187,0.5551240597618483,0.5561018167188202,0.5570759167751314,0.5580445940474621,0.559009039834435,0.5599699913170553,0.5609118527367791,0.5618503071095499,0.5627862921657963,0.5637206356691289,0.5646470136690115,0.5655588390942085,0.5664704351292063,0.5673952116679588,0.568314837844883,0.5692190136733154,0.5700980744252819,0.5709797645016178,0.5718804135935996,0.5728229923538897,0.5737816133721083,0.5747348738816781,0.5756535379813689,0.5765426522068434,0.577429200551389,0.5783145082786542,0.5791789566624103,0.5800156849053737,0.5808490897681773,0.5816795225740043,0.5824982692162474,0.5832398673578062,0.583943991138342,0.5846298116709427,0.5853112995523582,0.5860000945572129,0.5866879374891083,0.5873743639102624,0.5880592302409752,0.5887429275556075,0.589429648178997,0.590116045664843,0.5908019902005356,0.5914870892642732,0.5921544899539137,0.5928163327547201,0.5934750319982983,0.5941253771880023,0.5947808247296292,0.5954352502377614,0.5960879443224,0.5967387949047959,0.5974048464482602,0.5980811748788218,0.5987482512836689,0.5994126651263738,0.6000747167425261,0.6007344888773586,0.6013922714147927,0.6020839344022455,0.6027731967615154,0.6034594060493569,0.6041425721603625,0.6048227412308592,0.6055004713707948,0.6061757829463313,0.6068485129298211,0.6075187437895533,0.6081896499820681,0.6088588050527142,0.6095127110498421,0.6101604394010441,0.6108054986456708,0.6114662341775826,0.6121202964365954,0.6127730913707445,0.6134248444698797,0.6140739865301745,0.6147208291388679,0.6153670435550197,0.6160110673030933,0.6166536108192707,0.6172968320223559,0.6179383668022581,0.6185781371318303,0.6192166272504046,0.6198524630107194,0.620486762938036,0.6211194347702815,0.6217506326257979,0.6223868762331484,0.6230231975866944,0.6236584128051097,0.6242927486244553,0.6249264908736527,0.6255593114307456,0.6261929141603527,0.6268253531192735,0.62745609076627,0.6280605707749289,0.6286615031520538,0.629258861554409,0.629854686099187,0.6304493836254259,0.6310413387435638,0.6316323022097918,0.6322085497105816,0.6327782628797588,0.6333431804040337,0.6339068670692928,0.6344727890687999,0.6350386529940051,0.6356041271630146,0.6361694000841686,0.6367339654223283,0.6372967606005622,0.6378554159593143,0.6384106908115513,0.6389643958995961,0.639513594730844,0.6400616924207081,0.6405775740649651,0.6410838513621219,0.64155608459124,0.642027067722449,0.6424967857616147,0.642964564694295,0.6434298666723101,0.6438885105469649,0.6443454354213178,0.6448012768751049,0.6452483799738132,0.6456339429151228,0.6460177666189426,0.6463977018359428,0.6467777402310207,0.6471659903121909,0.6475700233474256,0.6479674459689468,0.6483597733520632,0.6487493651548586,0.6491197692716726,0.6494646955070769,0.6495865952413107,0.6496120098510536,0.6496371555899918,0.6496647350955144,0.6496974451591461,0.6497456718032872,0.6498020171035527,0.6498614037744115,0.6499235318931056,0.6499858985738677,0.6500484343348336,0.6501101976191229,0.650186589473763,0.6502702923370244,0.6502826708237622,0.6502628118715811,0.6502312833315704,0.6501978011680807,0.6501620093540209,0.6501246823823214,0.6500870686511707,0.6500493281582388,0.6500124677332078,0.6499772074534192,0.6499377829030619,0.6498818488066314,0.6498222440382524,0.6497578395838061,0.6496830402697995,0.6496060946973716,0.6495261512210827,0.6494413283674233,0.6493523153871368,0.649260967992669,0.6491689531555798,0.6490747812334445,0.6489775464586524,0.6488849481145327,0.6487918483255902,0.6486961691601043,0.6485983159337352,0.6484986950900359,0.6483975988614881,0.6482945817260591,0.6481904215270506,0.6480859889526557,0.647983406036984,0.6478800238868813,0.6477762220248916,0.6476726767558667,0.6475810392669127,0.6474881436147596,0.6473984100469041,0.6473292714773125,0.6472589810282029,0.6471901784192842,0.6471361447714475,0.6470639239336657,0.64696869806063,0.6468684925680495,0.6467658578233254,0.6466604117056097,0.6465501960670306,0.6464356591214387,0.6463178583704654,0.646196979782717,0.6460736676857628,0.6459481874558929,0.6458209720819778,0.6456924762781382,0.645556483881921,0.6454191842588408,0.6452815590868047,0.6451435947691107,0.6449992493193479,0.6448533501425331,0.6447055251567142,0.6445560508190574,0.644405503332743,0.6442539723987109,0.6441016993034864,0.6439483402856763,0.6437944807189709,0.6436480648510424,0.6435022458914489,0.6433570055786705,0.6432121312253002,0.6430675707885968,0.6429229466999518,0.642776342170517,0.6426171083816405,0.6424585442999066,0.6422984056743459,0.6421385051391847,0.641973500129525,0.6418028480029613,0.641632108564079,0.6414616225523191,0.641291293021297,0.6411215202582407,0.6409522914746968,0.6407840417632765,0.6406169511083771,0.6404507670919632,0.6402893178121566,0.6401367411894878,0.6400063768000194,0.6398790809434619,0.63975176123204,0.639622680337521,0.6394906781077163,0.639359142820424,0.6392282742289016,0.6390979999250086,0.6389723546137898,0.6388511439052301,0.6387337702009059,0.6386196933077727,0.6385188322359567,0.638423392605421,0.6383275831159789,0.6382299555393891,0.6381311901786874,0.6380197514101809,0.6379001420121808,0.6377807002242307,0.6376619369227672,0.6375434243650814,0.6374257075471642,0.6373087259577314,0.6371863516728528,0.6370518344423824,0.6369187165633198,0.6367867684274257,0.6366557414997662,0.6365263200920278,0.6363974643817355,0.6362686421918776,0.6361403121493237,0.6360184529816676,0.6358994885549496,0.6357817890075397,0.6356651039100233,0.6355349522894467,0.6354074086741387,0.6352816400271541,0.635156540244442,0.6350321997851173,0.6349443819006702,0.6348661090232564,0.6347889093973159,0.6347122600034142,0.6346366973355723,0.6345626089281795,0.634505818285353,0.6344706810067952,0.63443055272291,0.6343862532003397,0.6343252682119092,0.6342729531466456,0.634217560696346,0.6341595867732588,0.6340994101611395,0.6340415137769649,0.633983947101993,0.6339246825356969,0.6338645677506072,0.6338041465673212,0.63374380479356,0.633684386109416,0.6336250132735668,0.6335658924117586,0.6335068268809293,0.6334478814336967,0.6333895952515443,0.6333463423214035,0.6332904790656032,0.6332333152537983,0.63317623418588,0.6331198189785493],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"mode\":\"lines\",\"name\":\"Test MSE\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.3958365061733272,0.4154264457179434,0.4350943569108955,0.4549780290537591,0.47494185496235347,0.4845861932368743,0.4878862099268734,0.4911381752703314,0.494497010433113,0.4978284869339833,0.5011843035426828,0.5045278281556742,0.5080633832096048,0.5117991234204634,0.5155688476237326,0.5194016758818124,0.5232707391456456,0.5271252511405397,0.5309444714467801,0.534774534149374,0.5386296573036596,0.5424942591679319,0.5460610750995508,0.5492234366933745,0.5524030434792586,0.5556331815143039,0.5590888129440662,0.5625445771065306,0.5660026985780421,0.5694599033849584,0.5729123591167786,0.576355674898473,0.5797844933767586,0.5831911113726486,0.58657077497562,0.5899191233988119,0.59323050894017,0.5965006146227159,0.5997208136634903,0.6028900612377016,0.6059296079611046,0.6086034103627278,0.6112212755639134,0.6137795394793998,0.6162740947767428,0.6186983053706603,0.6210510771493198,0.623329283080125,0.6255293748543805,0.6276553274012087,0.6297392957685076,0.6317359262119976,0.6336432746240263,0.6354735795538523,0.637208142595656,0.6388454568344916,0.6403856280233294,0.6418270560925129,0.6431692182727748,0.6444117143532118,0.645554673022972,0.6467055415148132,0.6477682625280883,0.648728907071877,0.6495886598986869,0.6503488436063678,0.6510122134002467,0.6515805275336977,0.6520559212110569,0.6524408832355093,0.6527379096786767,0.6529490092140394,0.6530768517091043,0.6531239583187722,0.6530933839405837,0.6529882481382888,0.6528125268832118,0.6525702147297447,0.6522648349568086,0.6519009238898836,0.6514819000220526,0.6510109602177024,0.6504918542878902,0.6499275837525275,0.6493212644984654,0.648675827537767,0.6479940220971294,0.6472792599356005,0.6465347966770735,0.6457638535084065,0.6449693410602241,0.6441538594527372,0.6433213126817012,0.6424735755040891,0.6416126100879727,0.6407408950242197,0.6398608971958016,0.6389746633051246,0.6380843300126005,0.6371917132681303,0.6362986268533606,0.6353862409999774,0.634461430483543,0.6335399909591256,0.6326230768544863,0.6317118989766465,0.6308079081003979,0.6299121477361911,0.6290252646349168,0.628148145786325,0.6272814907159822,0.6264254433659026,0.6255806796953194,0.6247474501966783,0.6239264143422726,0.6231176092033637,0.6223215607376797,0.6215384958092371,0.6207687564526067,0.6200124775848547,0.6192697324198577,0.6186111131639609,0.6181435261479878,0.6176870270397086,0.617241359737362,0.6168065533771263,0.616382579456994,0.615969630503311,0.6155674276170306,0.6151761529557488,0.6147952316917571,0.6144246663412707,0.6140641451351327,0.6137136122149347,0.6133724714608499,0.613040675844005,0.6127181599459788,0.612395643827231,0.6120807868870691,0.6117746616951154,0.6114767977285008,0.6111872234768997,0.6109056719960243,0.6106319976168938,0.6103650858213017,0.6101050546831287,0.6098520746057295,0.6096057002342744,0.6093659731707743,0.6091325380496427,0.6089052628088008,0.6086838318228489,0.6084681080410267,0.6082610330607615,0.6080630544826813,0.6078704371365409,0.6076810207285155,0.6074959584049511,0.6073156422242415,0.6071396661680927,0.6069681665201662,0.6068008183066582,0.606637573568223,0.6064954350924268,0.6063621465735476,0.606232803479298,0.606106230292278,0.605982265422398,0.6058610236303101,0.6057420419302348,0.6056237915853248,0.6054981710376747,0.6053750065768959,0.6052534886360753,0.6051337443696634,0.6050158019869092,0.6048995913822001,0.6047852341139305,0.60467298275055,0.6045628369551951,0.6044543139199041,0.6043473723607821,0.6042421912614472,0.6041388342908668,0.6040374583763332,0.6039372276489775,0.603838423548563,0.6037409836215837,0.6036450391844628,0.6035504811695722,0.6034576894344794,0.6033662308732698,0.6032763002771324,0.6031876686614543,0.6031006406532371,0.6030152910705164,0.6029327331377716,0.6028517475340304,0.6027775488503657,0.6027067503857223,0.6026367193612926,0.6025684127869653,0.6025009813488988,0.6024346718618415,0.6023692991938046,0.6023050400967065,0.6022417214263399,0.6021796314319902,0.6021187989320469,0.6020592743941209,0.6019377935914054,0.6016801572733238,0.6014244557046857,0.6011709406959947,0.600919540671408,0.6006703004536802,0.600423374212007,0.6001787944150628,0.5999365015444013,0.599696603799662,0.5994592025528868,0.5992243018357811,0.5989917168858253,0.5987607961190776,0.5985277553386594,0.5982970534792884,0.5980686842836268,0.597842542837674,0.5976186512264205,0.5973970952344285,0.5971772915128922,0.5969591996225638,0.5967427084628415,0.5965281045255698,0.5963152607508221,0.5961043026268245,0.5958952519968356,0.5956868691739985,0.5954795334188625,0.5952731915841488,0.5950716184976896,0.594879039360201,0.5946875625721815,0.5944970612771637,0.5943074767603905,0.5941179984176017,0.5939297458760093,0.5937427180507231,0.5935560978208223,0.5933700054489204,0.5931845082939025,0.5929996975949613,0.5928158242837116,0.5926324027507242,0.5924494604106889,0.5922672611498199,0.5920857692243388,0.5919051445357529,0.591725792863243,0.5915505974564382,0.5913766104130802,0.5912038415034878,0.5910323763587517,0.590862116790465,0.5906933484586381,0.590526473009163,0.5903611919426485,0.590197313540751,0.5900348819389248,0.5898738796915393,0.5897143876690204,0.5895564839101805,0.5894001961966234,0.5892454148468901,0.5890916547798618,0.5889390697028586,0.5887878555074609,0.5886380395422209,0.5884897004330049,0.5883621681704773,0.588237950794722,0.5881150033740822,0.5879934457016622,0.5878734311949828,0.5877546905350006,0.5876384677451392,0.5875262611353647,0.5874151908624731,0.5873055244932607,0.5871973918746343,0.5870906844919231,0.5869854016735193,0.5868815485148535,0.586779016864221,0.5866777492384763,0.5865777339128104,0.5864789656869309,0.5863814559465059,0.5862852544701463,0.5861899984398228,0.5860955901484237,0.5860021326853622,0.5859064668421263,0.5858114966312112,0.585717409921735,0.5856240804576958,0.5855316907816885,0.5854402460816593,0.585349626866114,0.5852594922390538,0.5851699957544892,0.5850810575389221,0.5849928214067099,0.5849051393862597,0.5848173172947251,0.5847294577636897,0.5846415824704807,0.5845538109064432,0.584466205257003,0.58437889163638,0.5842919604026338,0.5842057008342622,0.5841202496479263,0.5840472845644519,0.5839836532681599,0.5839207810793783,0.5838587022461494,0.5837974330129044,0.5837370812799667,0.5836775897337625,0.5836189131486759,0.5835610110662968,0.5835039176150169,0.5834475747006527,0.5833944940980249,0.5833452990031593,0.5832973807562174,0.5832514600192413,0.5832066955497567,0.5831630472421387,0.5831204745342073,0.5830789150621092,0.58303902716009,0.5830009354404218,0.5829637187797609,0.5829273315022879,0.5828917152317221,0.5828568080695056,0.5828225753244505,0.5827890456499007,0.5827561849998245,0.582724117779225,0.5826929061526703,0.5826624710088275,0.5826328516641168,0.5826040655731167,0.5825761915396889,0.5825491504051733,0.58252293121333,0.5824976183934583,0.5824731838829543,0.5824495371750431,0.5824266833235455,0.5824045321245591,0.5823831338635108,0.5823643118470611,0.5823464765815709,0.5823288096609539,0.5823109820588591,0.5822937832467725,0.5822771952218684,0.5822611108830025,0.5822455517720004,0.582230704307181,0.5822164946052165,0.5822029852542381,0.5821902715310827,0.5821784510383952,0.5821664470183466,0.5821544130392657,0.5821422980314577,0.5821298413148531,0.5821170427253988,0.5821040955961831,0.5820909766270027,0.5820777375318134,0.5820645538320529,0.5820514654064443,0.5820386023798398,0.5820259478785111,0.5820135417752432,0.581992469884525,0.5819713250050943,0.581950513313593,0.5819301362759037,0.5819093787589207,0.5818880815740549,0.5818663922478554,0.5818444240444972,0.5818222108237666,0.5817998715754099,0.5817774177817439,0.581754735517219,0.5817320363168186,0.5817094790756479,0.581687023510252,0.5816647943142016,0.5816450659184046,0.5816284997043455,0.5816120216279146,0.5815956205616217,0.5815795003396812,0.5815636731221825,0.5815482182172881,0.5815330107507717,0.5815171899824552,0.5814971688603533,0.5814637875056748,0.5814269958336892,0.5813900164613031,0.5813530929453796,0.5813162138687935,0.5812794758509983,0.5812429234196249,0.581206579904048,0.5811705529611615,0.581135018756317,0.5810989337344831,0.5810623997043024,0.581025604004372,0.5809886313842918,0.5809519219139263,0.5809156778949067,0.5808795062304327,0.5808434401478337,0.5808076330842755,0.5807735909468114,0.5807535404780619,0.5807337603487298,0.5807142331737944,0.5806948401352531,0.5806745948911356,0.5806535598395247,0.580631961972444,0.5806099831101602,0.5805878045942837,0.5805654659756571,0.5805430580366301,0.5805206144131826,0.5804982203786541,0.5804759264052829,0.5804536423035546,0.5804325161594592,0.5804140293028849,0.580395205227318,0.5803437506594941,0.5802921310952597,0.5802403976038405,0.58018866965385,0.5801370034930725,0.580085427527643,0.5800331628108046,0.579979242087376,0.5799255758923941,0.5798719603604323,0.5798182197797865,0.5797644619478224,0.5797107262615439,0.5796571038302374,0.5796036961527058,0.5795506047673489,0.5794978899449144,0.5794455547196564,0.5793936099691931,0.5793420783701201,0.5792910675457058,0.5792362314400257,0.5791781767544608,0.5791171136858991,0.5790533368791515,0.5789871982328448,0.5789189586440141,0.5788489924371967,0.5787775266311371,0.5787047989420154,0.5786309571636268,0.57855624475584,0.5784807185791878,0.5784046904286484,0.5783233594562818,0.5782412442049772,0.5781467775552427,0.5780461100791799,0.5779454204778637,0.5778448332258306,0.577749787075453,0.5776571984570508,0.5775670126832961,0.5774776327596779,0.5773885908707365],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.45],\"title\":{\"text\":\"Epoch\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.625,1.0],\"title\":{\"text\":\"Estimate\"}},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.55,1.0],\"title\":{\"text\":\"Epoch\"}},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.625,1.0],\"title\":{\"text\":\"Variance\"}},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.0,0.45],\"title\":{\"text\":\"Epoch\"}},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,0.375],\"title\":{\"text\":\"MSE Loss\"}},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.55,1.0],\"title\":{\"text\":\"Epoch\"}},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.0,0.375],\"title\":{\"text\":\"MSE\"}},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Estimate over Epochs\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Variance over Epochs\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Shaping Train MSE Loss over Epochs\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Total MSE over Epochs\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Metrics over Epochs\"},\"showlegend\":true},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('22eb2fa3-dfba-433b-a801-fd1d72ed139e');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"dd059c77-a18c-4161-b3a5-644d1e8955ea\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"dd059c77-a18c-4161-b3a5-644d1e8955ea\")) {                    Plotly.newPlot(                        \"dd059c77-a18c-4161-b3a5-644d1e8955ea\",                        [{\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"z\":[[0.05766526609659195,0.06269030272960663,0.059559229761362076,0.050260938704013824,0.04096264764666557,0.03166435658931732,0.02236608788371086,0.013067804276943207,0.003769494593143463,-0.0055288150906562805],[0.051970988512039185,0.06281931698322296,0.06431861221790314,0.05903001129627228,0.05050976946949959,0.0419895201921463,0.03346928209066391,0.024949029088020325,0.016428783535957336,0.00790850818157196],[0.04785449057817459,0.04807412624359131,0.0545162670314312,0.0583435483276844,0.0552731491625309,0.04985849931836128,0.04133826121687889,0.0328180193901062,0.02429775334894657,0.015777505934238434],[0.041271887719631195,0.03711417689919472,0.04603395611047745,0.04686849191784859,0.05146029219031334,0.04929809272289276,0.04622771218419075,0.040686994791030884,0.0321667343378067,0.02364649623632431],[0.03458394110202789,0.030061837285757065,0.03558040037751198,0.038755178451538086,0.0403774231672287,0.04381252080202103,0.04332303628325462,0.04025264456868172,0.03718224912881851,0.031515464186668396],[0.02787701226770878,0.023023882880806923,0.027763478457927704,0.03404662758111954,0.032508380711078644,0.03467436879873276,0.03684037923812866,0.03734799474477768,0.03427756205201149,0.03120717965066433],[0.02152160182595253,0.015985924750566483,0.020725522190332413,0.02546512708067894,0.028222426772117615,0.026805322617292404,0.028971321880817413,0.03113729879260063,0.031567417085170746,0.0283025074750185],[0.017288871109485626,0.010594610124826431,0.013687565922737122,0.01842717081308365,0.02316676452755928,0.020943649113178253,0.021102264523506165,0.023268263787031174,0.025434255599975586,0.02753707952797413],[0.01305614784359932,0.0063661448657512665,0.006649617105722427,0.011389210820198059,0.01612880825996399,0.018108833581209183,0.01366487517952919,0.015399228781461716,0.017565172165632248,0.019731171429157257],[0.008823417127132416,0.0021376833319664,-0.00038833916187286377,0.004351258277893066,0.009090855717658997,0.013830464333295822,0.010410916060209274,0.0075301676988601685,0.009696148335933685,0.011862117797136307]],\"type\":\"heatmap\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"Values\"},\"ticks\":\"outside\",\"tickvals\":[-0.0055288150906562805,0.06431861221790314],\"ticktext\":[-0.0055288150906562805,0.06431861221790314]}},\"xaxis\":{\"tickvals\":[0,1,2,3,4,5,6,7,8,9],\"ticktext\":[0,1,2,3,4,5,6,7,8,9],\"title\":{\"text\":\"X\"}},\"yaxis\":{\"tickvals\":[9,8,7,6,5,4,3,2,1,0],\"ticktext\":[9,8,7,6,5,4,3,2,1,0],\"title\":{\"text\":\"Y\"},\"autorange\":\"reversed\"},\"title\":{\"text\":\"Heatmap\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('dd059c77-a18c-4161-b3a5-644d1e8955ea');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"a685c7d3-da21-43e6-9ae9-365687a8997c\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a685c7d3-da21-43e6-9ae9-365687a8997c\")) {                    Plotly.newPlot(                        \"a685c7d3-da21-43e6-9ae9-365687a8997c\",                        [{\"colorbar\":{\"title\":{\"text\":\"Visits\"}},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"x\":[0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9],\"y\":[9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0],\"z\":[0,78,254,608,1416,1356,1329,1169,844,884,0,128,396,989,1149,0,486,663,599,911,0,265,778,963,447,0,169,208,362,898,0,630,752,376,170,0,32,66,127,218,0,627,351,167,95,0,4,17,25,46,194,444,187,72,32,7,0,8,10,10,38,86,48,19,13,13,0,9,8,9,6,19,7,6,1,10,0,7,4,9,2,5,3,0,0,8,0,5,5,9,0,1,0,0,0,5,0,5,4,7],\"zmax\":1416,\"zmin\":0,\"type\":\"heatmap\"}],                        {\"title\":{\"text\":\"State Visitations Heatmap\"},\"xaxis\":{\"title\":{\"text\":\"X-axis\"}},\"yaxis\":{\"ticktext\":[9,8,7,6,5,4,3,2,1,0],\"tickvals\":[0,1,2,3,4,5,6,7,8,9],\"title\":{\"text\":\"Y-axis\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('a685c7d3-da21-43e6-9ae9-365687a8997c');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "600 trajectories:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"2755d5bb-4b0f-45e4-91bf-4b25641883b3\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"2755d5bb-4b0f-45e4-91bf-4b25641883b3\")) {                    Plotly.newPlot(                        \"2755d5bb-4b0f-45e4-91bf-4b25641883b3\",                        [{\"mode\":\"lines\",\"name\":\"IS Estimate\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312,1.9262851476669312],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"Train Estimate\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.47055497765541077,0.8223621249198914,0.8046172857284546,0.7878119945526123,0.7715666890144348,0.7560262084007263,0.7440030574798584,0.732063353061676,0.7201693654060364,0.7079929709434509,0.6944270133972168,0.6800996661186218,0.6642965078353882,0.645799458026886,0.6280496120452881,0.6110179424285889,0.594392716884613,0.5787868499755859,0.5634856224060059,0.5482367277145386,0.5333153605461121,0.5189358592033386,0.504810631275177,0.490874320268631,0.4773762822151184,0.4643799364566803,0.4512561559677124,0.4380808174610138,0.42660975456237793,0.41852691769599915,0.41048192977905273,0.4026070237159729,0.39476099610328674,0.38700616359710693,0.3794495463371277,0.3720284104347229,0.36473414301872253,0.3575715720653534,0.35065510869026184,0.343946635723114,0.3373028635978699,0.33089470863342285,0.32476377487182617,0.3188227415084839,0.3131260871887207,0.30637404322624207,0.2991286516189575,0.29164981842041016,0.2845296859741211,0.2776690423488617,0.2710384130477905,0.26471400260925293,0.2586187720298767,0.2527044713497162,0.24709172546863556,0.2417282909154892,0.2366066873073578,0.23171481490135193,0.22703319787979126,0.22258488833904266,0.2183753401041031,0.21448495984077454,0.21078823506832123,0.20724788308143616,0.2038436084985733,0.20061151683330536,0.19755344092845917,0.1946784406900406,0.19195282459259033,0.1893804371356964,0.18696528673171997,0.18469741940498352,0.18257185816764832,0.18058258295059204,0.17872394621372223,0.1769920140504837,0.17538057267665863,0.1738828420639038,0.1724902093410492,0.1711997538805008,0.1700056493282318,0.16889739036560059,0.16787311434745789,0.16692088544368744,0.16604691743850708,0.16524384915828705,0.16448992490768433,0.1638948917388916,0.1633688509464264,0.1629142016172409,0.1625337451696396,0.16219326853752136,0.16184480488300323,0.16153930127620697,0.16126979887485504,0.16103143990039825,0.1608150452375412,0.16057485342025757,0.16034016013145447,0.1601552963256836,0.15999451279640198,0.1598960906267166,0.1598058044910431,0.15972575545310974,0.15965352952480316,0.1595817506313324,0.159509539604187,0.15946707129478455,0.1594400554895401,0.15940116345882416,0.15915128588676453,0.15890073776245117,0.15865185856819153,0.15840454399585724,0.1581612080335617,0.15791307389736176,0.15765641629695892,0.1573973000049591,0.15713752806186676,0.15687227249145508,0.1566002368927002,0.15631639957427979,0.1560257524251938,0.15572421252727509,0.15542936325073242,0.1551334708929062,0.15483786165714264,0.15453305840492249,0.1542208045721054,0.15390366315841675,0.15357480943202972,0.15322767198085785,0.1528947353363037,0.15257342159748077,0.15221941471099854,0.1518728882074356,0.15152141451835632,0.15116606652736664,0.15078309178352356,0.15038657188415527,0.14998002350330353,0.14956600964069366,0.1491546630859375,0.14875249564647675,0.14834441244602203,0.14794094860553741,0.14753089845180511,0.1471259444952011,0.1468360722064972,0.14655575156211853,0.14628827571868896,0.1459740400314331,0.14565534889698029,0.14533349871635437,0.14499758183956146,0.14465826749801636,0.14433296024799347,0.14401347935199738,0.14369237422943115,0.14336884021759033,0.1430402398109436,0.14271123707294464,0.1423824280500412,0.1420501321554184,0.14171387255191803,0.1413772851228714,0.14103887975215912,0.1406983584165573,0.14035764336585999,0.14001549780368805,0.13967476785182953,0.13933579623699188,0.13899382948875427,0.13864579796791077,0.1382979452610016,0.13795195519924164,0.1376047283411026,0.13725627958774567,0.13690690696239471,0.13648973405361176,0.13605371117591858,0.1356174200773239,0.1351814717054367,0.13474628329277039,0.1343189775943756,0.13387146592140198,0.13341788947582245,0.13296788930892944,0.1324482560157776,0.13190767168998718,0.13138839602470398,0.1308818757534027,0.13036447763442993,0.1298193782567978,0.12928593158721924,0.12875190377235413,0.12821924686431885,0.1276818811893463,0.12711283564567566,0.12654541432857513,0.1259821653366089,0.12542082369327545,0.12486252188682556,0.12430907040834427,0.12376554310321808,0.12324445694684982,0.12272773683071136,0.12219465523958206,0.12166418135166168,0.12113755196332932,0.12061374634504318,0.12007619440555573,0.11956758797168732,0.11907022446393967,0.11857746541500092,0.1180717796087265,0.1175670176744461,0.11706210672855377,0.11655953526496887,0.11605893820524216,0.11555957049131393,0.11507073044776917,0.11458795517683029,0.11410462856292725,0.1136225089430809,0.1131417453289032,0.11261221766471863,0.1120850220322609,0.11160850524902344,0.11121439188718796,0.11082133650779724,0.11044523864984512,0.11007149517536163,0.10969725251197815,0.10932289808988571,0.10895012319087982,0.1085781380534172,0.10822564363479614,0.10787597298622131,0.1075303852558136,0.10718335956335068,0.10683366656303406,0.10648074001073837,0.1061294674873352,0.10577844083309174,0.10542461276054382,0.10507270693778992,0.10477358102798462,0.10449796169996262,0.10422219336032867,0.10394776612520218,0.10367448627948761,0.10340207815170288,0.10315769910812378,0.10292726755142212,0.10269797593355179,0.10246980935335159,0.10224255174398422,0.10201635956764221,0.10178562998771667,0.10154114663600922,0.10130011290311813,0.10105828195810318,0.10079924017190933,0.10048297047615051,0.10016704350709915,0.09985137730836868,0.09953606873750687,0.09922700375318527,0.09892098605632782,0.09861563891172409,0.09831205755472183,0.09801049530506134,0.09770923852920532,0.09740733355283737,0.09710536152124405,0.0968044102191925,0.09650541096925735,0.09620831161737442,0.09591368585824966,0.09562008827924728,0.09532661736011505,0.09501990675926208,0.09471376985311508,0.09440979361534119,0.0941077172756195,0.09380286186933517,0.09350034594535828,0.0932028666138649,0.0929083377122879,0.09261482954025269,0.09232445061206818,0.09203552454710007,0.0917545035481453,0.09162002801895142,0.09148874878883362,0.09135673940181732,0.0912223607301712,0.09108871966600418,0.09095988422632217,0.09083092957735062,0.09070241451263428,0.09057361632585526,0.09044462442398071,0.09031623601913452,0.09018847346305847,0.0900581032037735,0.08992736786603928,0.0897965058684349,0.08967091143131256,0.08956455439329147,0.08945897966623306,0.08936246484518051,0.08927147090435028,0.08919652551412582,0.08912498503923416,0.08905325829982758,0.08898190408945084,0.08891081809997559,0.08884020894765854,0.08876984566450119,0.08869432657957077,0.08861802518367767,0.08854187279939651,0.08846601843833923,0.08839033544063568,0.08831525593996048,0.08824042975902557,0.08816491812467575,0.08808755874633789,0.08800859749317169,0.08792885392904282,0.08784964680671692,0.08777184784412384,0.08769474923610687,0.08761806786060333,0.08752966672182083,0.08742687851190567,0.08732514083385468,0.08722443878650665,0.08712466061115265,0.08702550083398819,0.08692743629217148,0.086829774081707,0.08669888973236084,0.08654405176639557,0.08638986945152283,0.08623313158750534,0.08607561141252518,0.08591867983341217,0.08575603365898132,0.08558943122625351,0.08542342483997345,0.08525805920362473,0.08509302884340286,0.08492785692214966,0.08476130664348602,0.08459053933620453,0.08441650122404099,0.08424340188503265,0.08407000452280045,0.08389627188444138,0.08372225612401962,0.08354806900024414,0.0833735316991806,0.08319680392742157,0.08301922678947449,0.0828421488404274,0.0826655700802803,0.08248943835496902,0.08231387287378311,0.08213883638381958,0.08196429163217545,0.08179014176130295,0.08161648362874985,0.08144286274909973,0.08126948028802872,0.08109797537326813,0.08092713356018066,0.08075675368309021,0.08058670908212662,0.08041685819625854,0.0802474170923233,0.08007825165987015,0.07990843802690506,0.07973801344633102,0.07957086712121964,0.0794052705168724,0.07924012839794159,0.07907669991254807,0.07891432195901871,0.07875236868858337,0.07859045267105103,0.07842880487442017,0.07826743274927139,0.07810626178979874,0.07794555276632309,0.07778517156839371,0.07761958986520767,0.07744728773832321,0.07727890461683273,0.07711736112833023,0.07695683091878891,0.07679682970046997,0.07663765549659729,0.07648225128650665,0.07633247971534729,0.07618330419063568,0.07603418827056885,0.07588508725166321,0.07573641091585159,0.07558821141719818,0.07544336467981339,0.07529372721910477,0.07511701434850693,0.07492761313915253,0.07473920285701752,0.07455162703990936,0.07436475902795792,0.0741785392165184,0.07399309426546097,0.07380740344524384,0.07362225651741028,0.07343702763319016,0.07325243949890137,0.0730658695101738,0.07287835329771042,0.07269144803285599,0.07250530272722244,0.07231990993022919,0.07213503122329712,0.07195362448692322,0.07177460193634033,0.07159650325775146,0.07141923159360886,0.07124274969100952,0.07106729596853256,0.070892833173275,0.07072000950574875,0.07054854929447174,0.0703779011964798,0.07020848244428635,0.0700395256280899,0.06987442821264267,0.0697154775261879,0.06955704092979431,0.06939903646707535,0.06924142688512802,0.06908374279737473,0.0689256563782692,0.06876834481954575,0.06861259043216705,0.0684581995010376,0.06830193847417831,0.06814668327569962,0.06799253821372986,0.06783869862556458,0.06768453121185303,0.06753065437078476,0.06737722456455231,0.06722710281610489,0.06708268076181412,0.06693953275680542,0.06679783016443253,0.06665732711553574,0.06651739776134491,0.06637845188379288,0.06624064594507217,0.06610370427370071,0.06596773117780685,0.06583147495985031,0.06569331139326096,0.0655646026134491,0.06543785333633423,0.065311960875988,0.06518677622079849,0.0650622695684433,0.06493813544511795,0.06481439620256424,0.06469162553548813,0.06456954032182693,0.06444720923900604,0.06433184444904327,0.06423605978488922,0.06413978338241577,0.06404358148574829,0.06394869834184647,0.06385528296232224,0.06376218795776367,0.06366854161024094,0.06357356905937195,0.06347887217998505,0.06338448077440262,0.06329033523797989,0.06319670379161835,0.06310388445854187,0.06301090121269226,0.06291887164115906,0.06282801181077957,0.0627371296286583],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"Test Estimate\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[2.686868190765381,2.6737773418426514,2.6617343425750732,2.650141477584839,2.639045238494873,2.6368629932403564,2.6390292644500732,2.6411428451538086,2.6431312561035156,2.6450722217559814,2.6469454765319824,2.6490464210510254,2.6499602794647217,2.6496312618255615,2.649285078048706,2.6492598056793213,2.649460792541504,2.649643659591675,2.6498866081237793,2.650064706802368,2.650172710418701,2.6502156257629395,2.650411367416382,2.6518473625183105,2.6531903743743896,2.654262065887451,2.6552441120147705,2.6561079025268555,2.6567940711975098,2.6574113368988037,2.657963991165161,2.658461809158325,2.6589066982269287,2.6593005657196045,2.6596500873565674,2.659959554672241,2.6602323055267334,2.660475015640259,2.660691976547241,2.6608903408050537,2.661072015762329,2.661306381225586,2.661638021469116,2.6619608402252197,2.662282705307007,2.6626033782958984,2.662928581237793,2.663259267807007,2.6636040210723877,2.663956642150879,2.664391279220581,2.6648809909820557,2.6655020713806152,2.666205406188965,2.6669278144836426,2.6676740646362305,2.6684491634368896,2.6692538261413574,2.6700918674468994,2.6709628105163574,2.671816110610962,2.6727054119110107,2.6736350059509277,2.674603223800659,2.675614595413208,2.676666021347046,2.6777596473693848,2.67889404296875,2.6800684928894043,2.681283473968506,2.6825356483459473,2.6838250160217285,2.685150146484375,2.686509609222412,2.687899351119995,2.6893198490142822,2.6907687187194824,2.6922433376312256,2.693742036819458,2.695262908935547,2.6968038082122803,2.69836163520813,2.699934720993042,2.7015209197998047,2.7031171321868896,2.7047226428985596,2.706333875656128,2.7079498767852783,2.709568977355957,2.7111895084381104,2.7128138542175293,2.7144360542297363,2.716055154800415,2.717669725418091,2.71927809715271,2.720879077911377,2.7224693298339844,2.7240676879882812,2.7256603240966797,2.7272403240203857,2.7288079261779785,2.7303597927093506,2.73189640045166,2.7334160804748535,2.7349190711975098,2.736403465270996,2.737868547439575,2.739313840866089,2.7407398223876953,2.7421443462371826,2.7435319423675537,2.744904041290283,2.7462575435638428,2.7475922107696533,2.7489078044891357,2.750201940536499,2.751391887664795,2.752511739730835,2.7536122798919678,2.7546920776367188,2.755753517150879,2.756793975830078,2.7578139305114746,2.7588143348693848,2.7597949504852295,2.760755777359009,2.761697292327881,2.7626185417175293,2.7635207176208496,2.764404296875,2.7652695178985596,2.7661170959472656,2.7669458389282227,2.767756938934326,2.76855206489563,2.769329309463501,2.770089626312256,2.770834445953369,2.7715625762939453,2.771786689758301,2.770474672317505,2.7691659927368164,2.767862558364868,2.7665610313415527,2.7652652263641357,2.7639729976654053,2.762685775756836,2.7614033222198486,2.760132312774658,2.7588729858398438,2.7576231956481934,2.7563846111297607,2.7551586627960205,2.7539424896240234,2.752739906311035,2.7515480518341064,2.7503678798675537,2.749196767807007,2.7480366230010986,2.7468864917755127,2.745746374130249,2.744615316390991,2.7434933185577393,2.74235463142395,2.741203546524048,2.7400612831115723,2.7389278411865234,2.7378005981445312,2.736682653427124,2.7355735301971436,2.73447322845459,2.733380079269409,2.7323179244995117,2.731264352798462,2.7302186489105225,2.729182481765747,2.728154182434082,2.7271370887756348,2.726128578186035,2.7251317501068115,2.7241389751434326,2.723151445388794,2.7221689224243164,2.7211925983428955,2.7202212810516357,2.71925687789917,2.71829891204834,2.7173469066619873,2.716403007507324,2.7154622077941895,2.714524030685425,2.713789939880371,2.7130839824676514,2.71238112449646,2.7116823196411133,2.710986614227295,2.7102956771850586,2.7096028327941895,2.708909273147583,2.708219528198242,2.7075345516204834,2.7068545818328857,2.7061784267425537,2.7055094242095947,2.705010175704956,2.7046051025390625,2.704202651977539,2.703803539276123,2.70340633392334,2.7033467292785645,2.7034854888916016,2.703622579574585,2.7037572860717773,2.7038886547088623,2.70401668548584,2.7042319774627686,2.7044754028320312,2.704719066619873,2.704960584640503,2.705200672149658,2.705437660217285,2.7056732177734375,2.7059004306793213,2.7061238288879395,2.7063472270965576,2.7065680027008057,2.706784248352051,2.7069995403289795,2.7072131633758545,2.707425594329834,2.7076351642608643,2.707557201385498,2.707495927810669,2.7075116634368896,2.707526206970215,2.707540512084961,2.707554340362549,2.707566499710083,2.7075788974761963,2.7075908184051514,2.7076032161712646,2.707613945007324,2.7076258659362793,2.7076363563537598,2.7076468467712402,2.7076573371887207,2.7076680660247803,2.707679271697998,2.7076895236968994,2.7076995372772217,2.7077112197875977,2.7077221870422363,2.707732677459717,2.7077438831329346,2.707754373550415,2.7077670097351074,2.707778215408325,2.707791328430176,2.7078030109405518,2.707812786102295,2.7078232765197754,2.7078359127044678,2.7078490257263184,2.707862615585327,2.7078773975372314,2.7078912258148193,2.7079055309295654,2.7079198360443115,2.707934617996216,2.7079479694366455,2.707962989807129,2.707976818084717,2.707991361618042,2.70800518989563,2.708019256591797,2.7080318927764893,2.70804500579834,2.7080581188201904,2.70807147026062,2.708085060119629,2.708099126815796,2.7081127166748047,2.7081260681152344,2.708138942718506,2.7081527709960938,2.7081644535064697,2.708177328109741,2.7081851959228516,2.7081875801086426,2.70819091796875,2.7081947326660156,2.708197832107544,2.708202600479126,2.708207130432129,2.708211660385132,2.7082207202911377,2.7082319259643555,2.708245277404785,2.7082624435424805,2.7082812786102295,2.7083005905151367,2.708322763442993,2.708345651626587,2.7083699703216553,2.7083957195281982,2.708421468734741,2.708449125289917,2.7084767818450928,2.708505630493164,2.7085347175598145,2.708564281463623,2.7085938453674316,2.7086246013641357,2.708655595779419,2.708686351776123,2.7087173461914062,2.7087488174438477,2.7087793350219727,2.7088117599487305,2.7088425159454346,2.7088735103607178,2.708904266357422,2.7089359760284424,2.7089664936065674,2.7089967727661133,2.7090277671813965,2.7090582847595215,2.7090885639190674,2.7091188430786133,2.709149122238159,2.709179401397705,2.7092103958129883,2.709240436553955,2.70927095413208,2.709303140640259,2.7093334197998047,2.7093653678894043,2.7093966007232666,2.709429979324341,2.7094624042510986,2.709496021270752,2.7095303535461426,2.709564447402954,2.7095987796783447,2.7096328735351562,2.7096683979034424,2.709702253341675,2.7097373008728027,2.7097721099853516,2.709807872772217,2.7098419666290283,2.7098772525787354,2.709911823272705,2.709946632385254,2.7099807262420654,2.710015296936035,2.7100489139556885,2.710081100463867,2.710108518600464,2.7101376056671143,2.71016526222229,2.7101922035217285,2.7102198600769043,2.7102460861206055,2.710273027420044,2.710304021835327,2.710334062576294,2.7103638648986816,2.710393190383911,2.710422992706299,2.710451364517212,2.710479259490967,2.7105069160461426,2.7105343341827393,2.710561752319336,2.7105886936187744,2.7106146812438965,2.7106409072875977,2.7106659412384033,2.710692882537842,2.7107176780700684,2.7107431888580322,2.710768938064575,2.710794448852539,2.7108192443847656,2.710844039916992,2.710869073867798,2.7108936309814453,2.7109181880950928,2.7109427452087402,2.7109670639038086,2.7109906673431396,2.7110142707824707,2.71103835105896,2.71106219291687,2.7110846042633057,2.7111082077026367,2.7111315727233887,2.7111546993255615,2.7111778259277344,2.7112011909484863,2.711224317550659,2.711247205734253,2.711270809173584,2.711294412612915,2.711317300796509,2.7113430500030518,2.7113733291625977,2.7114031314849854,2.7114338874816895,2.7114639282226562,2.711494207382202,2.7115249633789062,2.7115554809570312,2.7115814685821533,2.7115933895111084,2.7116050720214844,2.711618185043335,2.7116310596466064,2.7116446495056152,2.7116587162017822,2.7116732597351074,2.711688756942749,2.7117040157318115,2.7117197513580322,2.7117364406585693,2.7117531299591064,2.7117695808410645,2.711787223815918,2.7118048667907715,2.711822032928467,2.7118401527404785,2.7118582725524902,2.7118771076202393,2.7118964195251465,2.71191668510437,2.711937189102173,2.7119574546813965,2.7119781970977783,2.7119998931884766,2.7120211124420166,2.712043046951294,2.712064504623413,2.7120871543884277,2.712108850479126,2.712130546569824,2.712153434753418,2.712175130844116,2.712197780609131,2.7122199535369873,2.712240695953369,2.7122628688812256,2.7122843265533447,2.7123055458068848,2.7123289108276367,2.712354898452759,2.7123851776123047,2.712416648864746,2.7124483585357666,2.712480068206787,2.7125120162963867,2.7125439643859863,2.712575912475586,2.7126107215881348,2.7126455307006836,2.7126805782318115,2.7127161026000977,2.7127528190612793,2.712789297103882,2.7128255367279053,2.712862014770508,2.7128982543945312,2.712935209274292,2.7129721641540527,2.7130095958709717,2.713045597076416,2.7130823135375977,2.7131166458129883,2.7131471633911133,2.713178873062134,2.713216781616211,2.7132599353790283,2.713301658630371,2.7133448123931885,2.7133867740631104,2.713427782058716,2.7134690284729004,2.713510274887085,2.713552951812744,2.713594436645508,2.713636636734009,2.7136788368225098,2.713721513748169,2.71376371383667,2.7138054370880127,2.713848114013672,2.7138898372650146,2.7139315605163574,2.7139732837677,2.7140140533447266],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"On-policy Estimate\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352,0.8194442378007352],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"IS Variance\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064,3.5907814502716064],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"lines\",\"name\":\"Train Variance\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.25492802262306213,0.2675679922103882,0.257716566324234,0.24848788976669312,0.23972059786319733,0.23118408024311066,0.2229248583316803,0.2149352878332138,0.20766523480415344,0.20122773945331573,0.19508741796016693,0.18893660604953766,0.18316024541854858,0.17824897170066833,0.17371001839637756,0.16953563690185547,0.16558153927326202,0.16181139647960663,0.15823473036289215,0.15483757853507996,0.15162082016468048,0.14858895540237427,0.1456085443496704,0.1427135169506073,0.14000153541564941,0.13755646347999573,0.13523803651332855,0.13304948806762695,0.1304321140050888,0.12696941196918488,0.12368685007095337,0.12057693302631378,0.11764928698539734,0.1149037554860115,0.11230425536632538,0.10982441902160645,0.10745537281036377,0.10521158576011658,0.10308648645877838,0.1010725274682045,0.09916193038225174,0.09738245606422424,0.09574941545724869,0.09420141577720642,0.09272685647010803,0.09154416620731354,0.09050610661506653,0.0892796739935875,0.08814208954572678,0.08705338835716248,0.08601213991641998,0.08504335582256317,0.08412342518568039,0.08324546366930008,0.08239952474832535,0.08158478885889053,0.08079973608255386,0.08003959059715271,0.07930245995521545,0.07858769595623016,0.07789302617311478,0.07721889019012451,0.07656203955411911,0.07590503245592117,0.07523069530725479,0.07456907629966736,0.07391861081123352,0.07327555865049362,0.07264211773872375,0.07201799750328064,0.07140185683965683,0.07079275697469711,0.07019027322530746,0.06959379464387894,0.0690029039978981,0.06841722130775452,0.06783628463745117,0.06725986301898956,0.06668759882450104,0.06611930578947067,0.06555488705635071,0.0649941936135292,0.06443721801042557,0.0638837069272995,0.0633334144949913,0.06278683990240097,0.06224672868847847,0.061710525304079056,0.061177611351013184,0.06064844876527786,0.060123227536678314,0.059598375111818314,0.05905346944928169,0.05851278826594353,0.05797634273767471,0.057444073259830475,0.056916214525699615,0.05637737363576889,0.0558379590511322,0.05531036853790283,0.05479007586836815,0.05429504066705704,0.053804025053977966,0.053316641598939896,0.0528329573571682,0.052352726459503174,0.05187657102942467,0.05140469968318939,0.050936322659254074,0.05046726018190384,0.049922309815883636,0.04938269779086113,0.04884853959083557,0.04832009598612785,0.047797463834285736,0.047280795872211456,0.04677019268274307,0.04626567289233208,0.04576721414923668,0.045274849981069565,0.04478858783841133,0.04430835694074631,0.04383415728807449,0.04336593300104141,0.04290326312184334,0.042446404695510864,0.04199521616101265,0.04154977202415466,0.04110997915267944,0.040675777941942215,0.04024716466665268,0.039826009422540665,0.039413079619407654,0.03900384157896042,0.038598526269197464,0.03819767385721207,0.03780179098248482,0.03741104155778885,0.03702510520815849,0.03664398565888405,0.03626742959022522,0.03589547798037529,0.035528041422367096,0.03516499325633049,0.03480652719736099,0.03445235639810562,0.0341026745736599,0.03376254439353943,0.03346314653754234,0.03316546604037285,0.03286843001842499,0.03257649391889572,0.03228820487856865,0.03200346231460571,0.03171970695257187,0.03143922612071037,0.03116273321211338,0.030889607965946198,0.03061964176595211,0.03035278245806694,0.03008907288312912,0.029828373342752457,0.0295705646276474,0.02931489795446396,0.029061300680041313,0.02881047874689102,0.02856229804456234,0.028316710144281387,0.02807377651333809,0.0278333630412817,0.02759549766778946,0.02736007422208786,0.027126925066113472,0.026895875111222267,0.026667216792702675,0.02644091099500656,0.026216894388198853,0.025995220988988876,0.025775864720344543,0.025541193783283234,0.025304039940238,0.025069257244467735,0.024836841970682144,0.02460680529475212,0.024378996342420578,0.024153297767043114,0.023929830640554428,0.02370861917734146,0.023473378270864487,0.023237083107233047,0.023009194061160088,0.022785471752285957,0.02256258949637413,0.022340059280395508,0.022119484841823578,0.021901220083236694,0.021685250103473663,0.021472424268722534,0.021266845986247063,0.021063437685370445,0.020862210541963577,0.020663108676671982,0.02046613208949566,0.02027134597301483,0.02007864974439144,0.019888123497366905,0.01969974674284458,0.019514277577400208,0.019330987706780434,0.019149798899888992,0.0189706739038229,0.01878996752202511,0.018611060455441475,0.018434152007102966,0.0182593185454607,0.018085068091750145,0.01791241392493248,0.017741577699780464,0.017572643235325813,0.017405537888407707,0.017240263521671295,0.017076939344406128,0.01691519469022751,0.016755007207393646,0.016596397385001183,0.016439491882920265,0.016287023201584816,0.016136080026626587,0.01599251478910446,0.015862278640270233,0.015733769163489342,0.015609671361744404,0.015486610122025013,0.015364572405815125,0.015243545174598694,0.015123551711440086,0.015004627406597137,0.014886739663779736,0.014769897796213627,0.0146541902795434,0.014539816416800022,0.01442655362188816,0.01431441679596901,0.014203309081494808,0.014093218371272087,0.013984091579914093,0.013875964097678661,0.013778213411569595,0.013685732148587704,0.013594094663858414,0.013503295369446278,0.013413342647254467,0.013324212282896042,0.013240640982985497,0.013160090893507004,0.013080286793410778,0.013001210056245327,0.01292283646762371,0.012845153920352459,0.012768113054335117,0.012691732496023178,0.012615937739610672,0.012540645897388458,0.012463727034628391,0.012379905208945274,0.012296389788389206,0.01221324224025011,0.012130482122302055,0.012048584409058094,0.01196728553622961,0.011886433698236942,0.011806083843111992,0.01172627229243517,0.011647013947367668,0.011568327434360981,0.011490194126963615,0.011412616819143295,0.011335588060319424,0.011259087361395359,0.011183097027242184,0.011107676662504673,0.01103282906115055,0.010958600789308548,0.010884888470172882,0.010811769403517246,0.010739296674728394,0.010667400434613228,0.010596074163913727,0.010525262914597988,0.010454978793859482,0.010385165922343731,0.010315898805856705,0.010247133672237396,0.010178744792938232,0.010132400318980217,0.010086801834404469,0.01004131231456995,0.009995950385928154,0.009950846433639526,0.009906250983476639,0.009861842729151249,0.009817622601985931,0.00977360736578703,0.00972980447113514,0.009686226025223732,0.009642863646149635,0.009599718265235424,0.009556801989674568,0.009514189325273037,0.009472602047026157,0.009434020146727562,0.009395664557814598,0.009357636794447899,0.009319886565208435,0.009282738901674747,0.009245888330042362,0.009209244512021542,0.009172827005386353,0.009136619046330452,0.009100631810724735,0.009064867161214352,0.009029323235154152,0.008993902243673801,0.008958694525063038,0.00892370194196701,0.00888892449438572,0.008854365907609463,0.00882002618163824,0.008785887621343136,0.0087519446387887,0.008718195371329784,0.008684626780450344,0.008651262149214745,0.008618099614977837,0.00858514104038477,0.008552382700145245,0.008519919589161873,0.0084877610206604,0.008455806411802769,0.00842403993010521,0.008392469957470894,0.008361097425222397,0.008329927921295166,0.008298956789076328,0.008268608711659908,0.008238761685788631,0.008209092542529106,0.008179598487913609,0.008150284178555012,0.00812113843858242,0.008092235773801804,0.008063554763793945,0.008035050705075264,0.008006714284420013,0.007978545501828194,0.00795054342597723,0.007922877557575703,0.007895038463175297,0.007866766303777695,0.007838566787540913,0.00781045388430357,0.007782414089888334,0.0077544632367789745,0.007726605981588364,0.007698866073042154,0.007671235129237175,0.007643706165254116,0.007616276387125254,0.007588965818285942,0.007561763282865286,0.0075346846133470535,0.007507726550102234,0.0074808974750339985,0.007454190868884325,0.007427623029798269,0.0074011823162436485,0.007374877575784922,0.00734871719032526,0.007322699762880802,0.007296823896467686,0.007271084003150463,0.007245479617267847,0.007220007479190826,0.007194675505161285,0.007169484626501799,0.007144443225115538,0.007119530811905861,0.00709475576877594,0.0070701176300644875,0.007045628037303686,0.007021278142929077,0.006997066084295511,0.006972992792725563,0.006949047092348337,0.00692524341866374,0.00690156826749444,0.006878024432808161,0.00685461750254035,0.006831334438174963,0.006808175239712,0.0067856949754059315,0.006764210760593414,0.0067428299225866795,0.006721568293869495,0.006700415164232254,0.00667934212833643,0.006658346392214298,0.006637440994381905,0.00661662919446826,0.006595906801521778,0.0065752798691391945,0.006554748397320509,0.0065343184396624565,0.006513980217278004,0.006493247579783201,0.006471023429185152,0.006448837462812662,0.0064266943372786045,0.006404601503163576,0.006382562220096588,0.0063605899922549725,0.006338687613606453,0.006316858809441328,0.006295125465840101,0.0062734754756093025,0.006252177059650421,0.0062311142683029175,0.006210159044712782,0.006189294159412384,0.006168526131659746,0.006147854961454868,0.006126659456640482,0.006105185952037573,0.006083805114030838,0.006062521133571863,0.006041339598596096,0.006020259577780962,0.005999281536787748,0.0059784152545034885,0.005957659333944321,0.005937014706432819,0.005916477646678686,0.005896053742617369,0.005875748116523027,0.005855560768395662,0.005835480522364378,0.0058155059814453125,0.005795636679977179,0.005775862373411655,0.005756158847361803,0.005736540537327528,0.005717020947486162,0.005697594024240971,0.0056778183206915855,0.0056539131328463554,0.0056302412413060665,0.005606755148619413,0.0055833254009485245,0.005559965036809444,0.00553668150678277,0.005513779819011688,0.005491537041962147,0.005469379480928183,0.005447313655167818,0.005425339564681053,0.005403457209467888,0.005381676368415356,0.005359996575862169,0.005338424816727638,0.00531696667894721,0.005295614246279001,0.005274360068142414,0.0052535925060510635,0.005232987459748983,0.005212488584220409,0.005192098207771778,0.0051718163304030895,0.005151635501533747,0.0051315524615347385,0.005111574660986662,0.005091700702905655,0.0050719305872917175,0.00505246315151453,0.005033602938055992,0.005014342721551657,0.004994960501790047,0.004975642543286085,0.004956379532814026,0.004937175661325455,0.004918040707707405,0.004898970481008291,0.004879968240857124,0.004861040040850639,0.00484218867495656,0.004823384806513786,0.004804589785635471,0.00478587718680501,0.0047674928791821,0.004749358631670475,0.004731263965368271],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"lines\",\"name\":\"Test Variance\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[6.3452372550964355,6.3548760414123535,6.368594169616699,6.383031845092773,6.398334503173828,6.4204792976379395,6.442625045776367,6.464548110961914,6.4862799644470215,6.507771015167236,6.529033660888672,6.550911903381348,6.566983222961426,6.5778961181640625,6.588741779327393,6.6011481285095215,6.6146931648254395,6.628097057342529,6.641528606414795,6.654699802398682,6.667628288269043,6.680307388305664,6.693191051483154,6.708643436431885,6.723761558532715,6.737681865692139,6.751241207122803,6.764476776123047,6.777397155761719,6.789993762969971,6.802282810211182,6.814267158508301,6.825955867767334,6.837357521057129,6.848480701446533,6.859330177307129,6.86990213394165,6.880213260650635,6.890264987945557,6.900069713592529,6.909635543823242,6.918512344360352,6.926431179046631,6.934146404266357,6.941679000854492,6.949026107788086,6.956218242645264,6.963250160217285,6.970139026641846,6.976885795593262,6.983493804931641,6.989976406097412,6.996871471405029,7.003934383392334,7.0108489990234375,7.017627239227295,7.02428674697876,7.030825138092041,7.037256240844727,7.043582916259766,7.050201892852783,7.056721210479736,7.063138008117676,7.069450378417969,7.075682163238525,7.081821918487549,7.087887287139893,7.093879222869873,7.099793910980225,7.105644702911377,7.111427307128906,7.117146968841553,7.122807502746582,7.128408432006836,7.133943557739258,7.139421463012695,7.144843578338623,7.150208473205566,7.155509948730469,7.160752773284912,7.1659393310546875,7.171065807342529,7.176136016845703,7.181146144866943,7.186098098754883,7.1909942626953125,7.195827007293701,7.200603485107422,7.205320835113525,7.209980010986328,7.214581489562988,7.219121932983398,7.223608016967773,7.228037357330322,7.23240852355957,7.236727237701416,7.240984916687012,7.245179176330566,7.24931526184082,7.25338888168335,7.257411956787109,7.261375904083252,7.265284061431885,7.269131660461426,7.27292537689209,7.27665901184082,7.280331611633301,7.2839484214782715,7.287512302398682,7.291014671325684,7.294467449188232,7.297875881195068,7.301230430603027,7.304532527923584,7.307784557342529,7.31097412109375,7.314704418182373,7.318726539611816,7.322683811187744,7.326574802398682,7.3304057121276855,7.334170341491699,7.337868690490723,7.341506481170654,7.345081329345703,7.34859561920166,7.352050304412842,7.355442523956299,7.3587775230407715,7.362053871154785,7.365277290344238,7.368446350097656,7.371548652648926,7.374598026275635,7.377597808837891,7.380544662475586,7.383437633514404,7.386280536651611,7.389070510864258,7.389193534851074,7.381109237670898,7.373083114624023,7.36511754989624,7.357201099395752,7.349349498748779,7.341547966003418,7.333804130554199,7.326117515563965,7.3185248374938965,7.3110246658325195,7.30360746383667,7.29627799987793,7.289048194885254,7.28190279006958,7.2748565673828125,7.267898082733154,7.261029243469238,7.254233360290527,7.247520923614502,7.240884304046631,7.234322547912598,7.227832317352295,7.221412181854248,7.214932918548584,7.208414554595947,7.201962947845459,7.195577621459961,7.189263820648193,7.1830153465271,7.1768269538879395,7.170701026916504,7.1646294593811035,7.158665657043457,7.1527557373046875,7.146905422210693,7.141116619110107,7.13538122177124,7.129714488983154,7.124104022979736,7.118565559387207,7.113058567047119,7.107587814331055,7.1021528244018555,7.0967559814453125,7.091397762298584,7.086075305938721,7.0807952880859375,7.075552940368652,7.070356845855713,7.065184116363525,7.060030460357666,7.055891990661621,7.051909923553467,7.047949314117432,7.044015407562256,7.040102958679199,7.03621768951416,7.032359600067139,7.028526782989502,7.024719715118408,7.020941734313965,7.017189979553223,7.013464450836182,7.009776592254639,7.006983280181885,7.004695892333984,7.002425193786621,7.000174045562744,6.997935771942139,6.997495174407959,6.998115062713623,6.998727321624756,6.999329090118408,6.99992036819458,7.00050163269043,7.00107479095459,7.001637935638428,7.002193450927734,7.002739906311035,7.003281593322754,7.003814220428467,7.004340648651123,7.004866123199463,7.005388259887695,7.0059123039245605,7.006425380706787,7.006926536560059,7.007425785064697,7.007920742034912,7.008410930633545,7.008895397186279,7.008007526397705,7.007228851318359,7.00687837600708,7.006527900695801,7.006178855895996,7.005831718444824,7.005481243133545,7.005135536193848,7.004791259765625,7.004453182220459,7.004110336303711,7.003777027130127,7.003442287445068,7.003110408782959,7.002783298492432,7.0024590492248535,7.002139568328857,7.001818656921387,7.001500606536865,7.001190662384033,7.0008769035339355,7.000566482543945,7.00026273727417,6.999958515167236,6.999666690826416,6.999373435974121,6.999091148376465,6.9988112449646,6.99853515625,6.99826192855835,6.997998237609863,6.997736930847168,6.997480869293213,6.997227191925049,6.99697732925415,6.996731281280518,6.99648904800415,6.996251106262207,6.996011734008789,6.995779991149902,6.995548248291016,6.995321273803711,6.995095729827881,6.994874477386475,6.994650840759277,6.994434356689453,6.9942193031311035,6.994006633758545,6.993796348571777,6.993590831756592,6.993386745452881,6.993184566497803,6.992983818054199,6.992789268493652,6.992589473724365,6.992401123046875,6.992208003997803,6.9920196533203125,6.9918389320373535,6.991662979125977,6.991485595703125,6.991317272186279,6.991151809692383,6.990986347198486,6.990847110748291,6.990723133087158,6.990614414215088,6.9905290603637695,6.990455627441406,6.9903883934021,6.990338325500488,6.990295886993408,6.99026346206665,6.990243911743164,6.990225791931152,6.9902215003967285,6.9902191162109375,6.990228176116943,6.990238189697266,6.990255355834961,6.99027681350708,6.990304946899414,6.99033784866333,6.990373134613037,6.990413665771484,6.990457057952881,6.990501880645752,6.990557670593262,6.9906086921691895,6.990663051605225,6.990720272064209,6.990781784057617,6.990841865539551,6.99090576171875,6.990970611572266,6.991040229797363,6.991107940673828,6.9911789894104,6.9912519454956055,6.991325855255127,6.991405010223389,6.991483211517334,6.991562366485596,6.991652011871338,6.991734027862549,6.991826057434082,6.99191427230835,6.992013454437256,6.992107391357422,6.992207050323486,6.992311000823975,6.9924139976501465,6.992519378662109,6.992624282836914,6.992738246917725,6.992844581604004,6.992955684661865,6.993070125579834,6.993188381195068,6.99329948425293,6.993418216705322,6.99353551864624,6.993654251098633,6.993771553039551,6.993891716003418,6.9940104484558105,6.9941511154174805,6.99430513381958,6.994470119476318,6.994631767272949,6.994793891906738,6.994963645935059,6.9951300621032715,6.995288848876953,6.995415210723877,6.995538711547852,6.995662689208984,6.995787620544434,6.995917320251465,6.996042251586914,6.9961676597595215,6.9962921142578125,6.9964189529418945,6.996547222137451,6.996676921844482,6.996801853179932,6.996930122375488,6.99705696105957,6.997189998626709,6.997317790985107,6.9974493980407715,6.997581958770752,6.997714996337891,6.997848033905029,6.997982501983643,6.9981184005737305,6.998250961303711,6.998388767242432,6.998526573181152,6.998663902282715,6.998801231384277,6.99893856048584,6.99907922744751,6.999221324920654,6.999357223510742,6.9995012283325195,6.999643325805664,6.999786853790283,6.9999308586120605,7.000075817108154,7.000222682952881,7.000369548797607,7.000519275665283,7.000669479370117,7.000816345214844,7.000981330871582,7.001171112060547,7.00135612487793,7.001549243927002,7.001737117767334,7.001926898956299,7.002121448516846,7.00231409072876,7.002484321594238,7.00258207321167,7.002677917480469,7.002780914306641,7.002880096435547,7.002979755401611,7.003083229064941,7.003187656402588,7.003294467926025,7.003398895263672,7.003507137298584,7.003617286682129,7.003728866577148,7.003839015960693,7.00395393371582,7.0040669441223145,7.004179954528809,7.00429630279541,7.004414081573486,7.004533767700195,7.004654407501221,7.0047783851623535,7.004902362823486,7.005027770996094,7.005151271820068,7.005281925201416,7.005411624908447,7.0055437088012695,7.005671977996826,7.005808353424072,7.005941390991211,7.00607442855835,7.00621223449707,7.006348609924316,7.006487846374512,7.006625652313232,7.006766319274902,7.00691032409668,7.007051467895508,7.007190704345703,7.00733757019043,7.007481575012207,7.007625579833984,7.007772445678711,7.0079193115234375,7.008067607879639,7.008216381072998,7.008363246917725,7.008513450622559,7.008665084838867,7.008816719055176,7.008969783782959,7.0091233253479,7.009282112121582,7.009439945220947,7.0095977783203125,7.009758472442627,7.009916305541992,7.0100789070129395,7.0102410316467285,7.0104079246521,7.010568618774414,7.0107340812683105,7.010898113250732,7.011064052581787,7.011238098144531,7.011404037475586,7.011573791503906,7.011737823486328,7.011907577514648,7.0120744705200195,7.012239933013916,7.0124053955078125,7.012569427490234,7.012740612030029,7.012906074523926,7.013076305389404,7.013246059417725,7.013419151306152,7.013588905334473,7.013759136199951,7.013931751251221,7.014101982116699,7.014275074005127,7.014449596405029,7.014622688293457],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"lines\",\"name\":\"Train MSE Loss\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[26.742828369140625,25.614978790283203,24.31153106689453,23.060230255126953,21.859800338745117,20.712146759033203,19.625038146972656,18.586606979370117,17.596899032592773,16.653812408447266,15.754683494567871,14.89586067199707,14.078526496887207,13.301956176757812,12.564038276672363,11.865066528320312,11.201382637023926,10.571213722229004,9.972652435302734,9.405969619750977,8.870373725891113,8.36546802520752,7.888917446136475,7.439364910125732,7.015395164489746,6.61590051651001,6.239422798156738,5.885374546051025,5.553727149963379,5.242091655731201,4.94926118850708,4.67401123046875,4.415551662445068,4.173305511474609,3.946470022201538,3.734131097793579,3.535670042037964,3.350273609161377,3.1773149967193604,3.01613187789917,2.8660197257995605,2.726156711578369,2.5958383083343506,2.474783420562744,2.3624675273895264,2.2583584785461426,2.16186785697937,2.07255220413208,1.9899771213531494,1.9136706590652466,1.8432337045669556,1.7782608270645142,1.7183531522750854,1.6630864143371582,1.612061858177185,1.56503164768219,1.5216244459152222,1.4816042184829712,1.4446933269500732,1.4106088876724243,1.3790950775146484,1.3499239683151245,1.3228622674942017,1.2977544069290161,1.274399995803833,1.2526284456253052,1.2322877645492554,1.2132139205932617,1.1952940225601196,1.1784250736236572,1.1624780893325806,1.147343397140503,1.1329302787780762,1.119157075881958,1.105953335762024,1.0932435989379883,1.0809694528579712,1.069051742553711,1.057471752166748,1.046216368675232,1.0352485179901123,1.0245361328125,1.0140562057495117,1.0037862062454224,0.9937049746513367,0.983799934387207,0.9740590453147888,0.9644729495048523,0.9550325274467468,0.9457260370254517,0.9365365505218506,0.9274829626083374,0.9185643792152405,0.9097753763198853,0.9011110067367554,0.892569899559021,0.8841366171836853,0.8758090734481812,0.8675960302352905,0.8595079779624939,0.8515372276306152,0.8436771035194397,0.835932731628418,0.8282880187034607,0.8207624554634094,0.813352644443512,0.8060572147369385,0.7988720536231995,0.7917946577072144,0.7848219871520996,0.7779488563537598,0.7711781859397888,0.7645171284675598,0.7579628229141235,0.7515111565589905,0.745165228843689,0.7389167547225952,0.732763409614563,0.7267042398452759,0.7207408547401428,0.7148678302764893,0.7090857028961182,0.7033872604370117,0.6977744698524475,0.6922507286071777,0.6868125796318054,0.6814592480659485,0.6761866211891174,0.6709932088851929,0.6658766269683838,0.6608309149742126,0.655855655670166,0.6509518623352051,0.6461179256439209,0.6413487195968628,0.6366204023361206,0.6319475173950195,0.6273359656333923,0.6227849721908569,0.618290901184082,0.6138554215431213,0.609478235244751,0.6051582098007202,0.6008870601654053,0.5966672897338867,0.5925012826919556,0.5883916616439819,0.5843327641487122,0.5803311467170715,0.5763830542564392,0.5724878907203674,0.5686451196670532,0.5648626089096069,0.5611297488212585,0.5574430823326111,0.5538025498390198,0.5501987934112549,0.546635627746582,0.5431143045425415,0.5396350622177124,0.5361971259117126,0.532800018787384,0.5294437408447266,0.5261276364326477,0.5228492021560669,0.5196084976196289,0.5164066553115845,0.5132432579994202,0.5101152062416077,0.5070196986198425,0.5039570927619934,0.5009247064590454,0.4979262948036194,0.49496397376060486,0.49203652143478394,0.4891398251056671,0.4862804710865021,0.48345211148262024,0.4806544780731201,0.4778890311717987,0.4751526713371277,0.4724441468715668,0.46976393461227417,0.46710774302482605,0.4644743502140045,0.46185797452926636,0.4592685401439667,0.45670467615127563,0.45416587591171265,0.45164912939071655,0.4491530656814575,0.4466811716556549,0.4442325234413147,0.4418022632598877,0.4393916726112366,0.43700286746025085,0.4346352517604828,0.43228864669799805,0.42996013164520264,0.4276539385318756,0.425370454788208,0.42310643196105957,0.4208678901195526,0.41865310072898865,0.41646111011505127,0.41429489850997925,0.41215014457702637,0.4100263714790344,0.40792396664619446,0.40584224462509155,0.40378111600875854,0.4017409086227417,0.3997189700603485,0.39771580696105957,0.39573049545288086,0.3937566876411438,0.3917999267578125,0.38986265659332275,0.38794267177581787,0.386038601398468,0.3841533362865448,0.38227593898773193,0.38041093945503235,0.37856200337409973,0.37672924995422363,0.3749080300331116,0.37310591340065,0.37131601572036743,0.36953654885292053,0.36776232719421387,0.3660014569759369,0.3642391562461853,0.3624894320964813,0.3607528805732727,0.35902974009513855,0.3573210835456848,0.3556262254714966,0.3539450466632843,0.35227733850479126,0.3506234586238861,0.3489811420440674,0.34735217690467834,0.34573695063591003,0.34413138031959534,0.3425358831882477,0.34094929695129395,0.3393763601779938,0.3378118872642517,0.3362578749656677,0.3347172141075134,0.3331894874572754,0.3316740393638611,0.3301708400249481,0.328679621219635,0.3271988034248352,0.32572484016418457,0.3242631256580353,0.3228099048137665,0.3213682472705841,0.3199351727962494,0.318494588136673,0.31706270575523376,0.3156386911869049,0.314219206571579,0.31278809905052185,0.31136414408683777,0.3099469542503357,0.3085371255874634,0.30713585019111633,0.3057398200035095,0.3043520152568817,0.3029731512069702,0.3016033470630646,0.30024048686027527,0.2988869249820709,0.29754364490509033,0.2962080240249634,0.29487690329551697,0.2935529947280884,0.2922387719154358,0.2909339368343353,0.28963804244995117,0.2883457541465759,0.2870578169822693,0.2857777774333954,0.2845076322555542,0.28324681520462036,0.281991571187973,0.2807370126247406,0.2794886827468872,0.2782483994960785,0.27701708674430847,0.2757924795150757,0.2745749056339264,0.27336615324020386,0.27215775847435,0.27095675468444824,0.2697645425796509,0.2685791254043579,0.267402321100235,0.26623326539993286,0.26507189869880676,0.26391884684562683,0.26277419924736023,0.2616373598575592,0.26050812005996704,0.2593863904476166,0.25827300548553467,0.2571684718132019,0.25607097148895264,0.25498175621032715,0.2539006769657135,0.252828985452652,0.25176647305488586,0.25071239471435547,0.24966655671596527,0.24862855672836304,0.24759860336780548,0.24657662212848663,0.24556216597557068,0.24455486238002777,0.24355387687683105,0.24255958199501038,0.2415720671415329,0.2405916154384613,0.23961836099624634,0.2386522889137268,0.23769327998161316,0.2367410808801651,0.23579658567905426,0.23485825955867767,0.23392587900161743,0.23300020396709442,0.23208202421665192,0.23117031157016754,0.23026424646377563,0.2293616235256195,0.22846285998821259,0.22757023572921753,0.22668306529521942,0.22580185532569885,0.22492659091949463,0.22405719757080078,0.2231934666633606,0.22233472764492035,0.22148171067237854,0.22063441574573517,0.219792902469635,0.2189570963382721,0.2181270867586136,0.21730384230613708,0.21648703515529633,0.2156759649515152,0.21486935019493103,0.21406817436218262,0.21327228844165802,0.2124818116426468,0.211693674325943,0.2109067440032959,0.21012428402900696,0.20934554934501648,0.2085702270269394,0.20779956877231598,0.20703254640102386,0.20626980066299438,0.20551073551177979,0.20475715398788452,0.20400826632976532,0.2032642364501953,0.20252493023872375,0.20179031789302826,0.2010602504014969,0.20033420622348785,0.19961242377758026,0.1988959014415741,0.19818425178527832,0.19747717678546906,0.19677458703517914,0.1960763931274414,0.19537945091724396,0.19468583166599274,0.19399648904800415,0.19331145286560059,0.1926305741071701,0.19195349514484406,0.19128067791461945,0.19061177968978882,0.18994683027267456,0.18928606808185577,0.18862950801849365,0.18797722458839417,0.18732914328575134,0.18668535351753235,0.18604575097560883,0.18541035056114197,0.18477891385555267,0.18415163457393646,0.18352866172790527,0.18290969729423523,0.18229468166828156,0.18168364465236664,0.18107615411281586,0.18047264218330383,0.17987312376499176,0.17927485704421997,0.17867912352085114,0.178086519241333,0.17749735713005066,0.17691174149513245,0.17632970213890076,0.17575126886367798,0.17517635226249695,0.17460426688194275,0.1740352213382721,0.17346706986427307,0.17289958894252777,0.17233526706695557,0.17177392542362213,0.1712154746055603,0.1706600785255432,0.17010749876499176,0.1695576012134552,0.1690106987953186,0.16846761107444763,0.1679278314113617,0.16739164292812347,0.16685891151428223,0.16632957756519318,0.16580355167388916,0.16528068482875824,0.16476115584373474,0.16424456238746643,0.16373048722743988,0.16321951150894165,0.1627115160226822,0.16220678389072418,0.16170531511306763,0.16120706498622894,0.16071200370788574,0.16022014617919922,0.1597314029932022,0.15924569964408875,0.158763125538826,0.15828421711921692,0.15780900418758392,0.15733662247657776,0.15686725080013275,0.15640079975128174,0.15593618154525757,0.1554720103740692,0.15501028299331665,0.15455126762390137,0.1540948450565338,0.1536407172679901,0.15318740904331207,0.15273644030094147,0.15228813886642456,0.15184077620506287,0.15139545500278473,0.1509523242712021,0.15051165223121643,0.15007361769676208,0.14963676035404205,0.14920228719711304,0.1487700641155243,0.1483396738767624,0.14791177213191986,0.1474863588809967,0.1470634937286377,0.14664329588413239,0.14622561633586884,0.14581046998500824,0.14539805054664612,0.144988015294075,0.14458084106445312,0.14417634904384613,0.1437741070985794,0.14337250590324402,0.14297333359718323,0.14257650077342987,0.1421818882226944,0.14178964495658875,0.14139869809150696,0.14100630581378937,0.140615314245224,0.1402266025543213,0.13983933627605438,0.13945332169532776,0.13906942307949066,0.13868729770183563,0.1383068561553955,0.13792799413204193,0.13755115866661072,0.13717637956142426,0.1368035525083542,0.13643218576908112,0.13606268167495728,0.13569560647010803,0.13533121347427368,0.134969100356102],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"mode\":\"lines\",\"name\":\"IS MSE\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035,4.815878250025035],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"mode\":\"lines\",\"name\":\"Train MSE\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.37665173846781397,0.26757650627562835,0.2579364048319877,0.24948848857960154,0.2420128575409819,0.23520592669609106,0.22861623001988735,0.22257070685099453,0.21752073509313716,0.21364912433740932,0.2107167243577266,0.20835351570680927,0.2072310635319488,0.20840148124337693,0.21034192116444522,0.21297715750441265,0.21622972633992177,0.2197273747944309,0.22374954315767911,0.2283910920622344,0.23349055456367165,0.2388942410096105,0.24460285070495016,0.25067170765766106,0.2570120216541729,0.26362712156893753,0.27080050011720924,0.27848754644083795,0.28475104522623595,0.28770410952914827,0.2909370194533748,0.29433019607225974,0.29800514276405077,0.30190644350695417,0.3058995838824805,0.3100053415992198,0.3142166431070307,0.31853794511362427,0.3228497340309344,0.32717049704977225,0.3316222351004791,0.33606309851382676,0.3404581758608084,0.34482329832709896,0.3490849261092786,0.35478519076802173,0.36123441583875343,0.3678466231226019,0.3742756673015942,0.3805737507640782,0.3867610885393774,0.3927689896581604,0.39864862824278074,0.40443942654625564,0.40998692312119156,0.4153405041444069,0.4204993463476741,0.4254654651387948,0.4302533001754296,0.4348287789960649,0.43917684595135914,0.4431946181799614,0.4470241692163194,0.45068940918751893,0.4541948301044725,0.4575230128396202,0.46066677404566797,0.4636078598898552,0.4663875913886785,0.46899839041175434,0.47143148038501853,0.4736962804382264,0.47579670116481815,0.4777380086817423,0.479525396049245,0.4811620811093977,0.48265428937050975,0.48400937868467536,0.4852371137647172,0.4863402167224817,0.4873253672535083,0.4882053943213215,0.4889821469285915,0.4896704322985794,0.4902614727515314,0.4907649884023311,0.49121188066568683,0.4914554704261898,0.4916125245870441,0.49168013717637815,0.491654622865507,0.49157721170925234,0.4914904836230043,0.491351693769287,0.4911699347930718,0.4909514856987804,0.49070862782214447,0.49048623930967844,0.4902561442514054,0.4899722768891968,0.4896640156766588,0.4892987991077379,0.48892688775324306,0.4885451175499941,0.4881567360844242,0.4877712284328934,0.48739037691319376,0.4869745599924127,0.48654184332752326,0.4861241201686253,0.48590909216314876,0.4857004132336876,0.48549510804264134,0.4852935727717746,0.48509270929233816,0.48490427668756336,0.4847333133734571,0.48457182073709626,0.48441739191436234,0.48427645919487144,0.4841507573781824,0.48404688677163826,0.4839582440260519,0.4838902049500439,0.4838190167454992,0.4837551997251787,0.483696851371731,0.48365664850968526,0.4836321952691647,0.4836200344371696,0.48362926030271924,0.4836705219953716,0.4837013188549888,0.48372052708255514,0.4837874908163278,0.48384918065503146,0.4839226888439887,0.4840067557582665,0.4841328334012093,0.48428214598062586,0.4844497638151027,0.4846323185432119,0.4848161553937114,0.48499240625024476,0.4851815027884875,0.485369023798075,0.48557021016869034,0.4857744319068055,0.4858648909615882,0.4859443809528698,0.4860073793050302,0.48613860120231855,0.48627967168872516,0.48642875086349585,0.48659799868978165,0.4867753318380921,0.48693797029100844,0.48709631742458337,0.48726022288604237,0.4874307256752743,0.4876114413797031,0.4877959276167922,0.4879832588505323,0.48817767231748255,0.4883797486603364,0.48858527106073535,0.488796127873579,0.4890126789252823,0.48923237925449475,0.48945677577525676,0.48968202994240556,0.4899075665083515,0.490139683238055,0.4903823907900301,0.490627488633327,0.4908726422404005,0.49112201104835124,0.4913756313197964,0.4916330727082707,0.49196804797176286,0.49232665182078217,0.4926883738821953,0.49305237503507127,0.4934180942021431,0.4937756185152525,0.49416332330935536,0.4945619812365689,0.49495839621598453,0.49543685725954223,0.495943612846592,0.49643003546328296,0.4969035981804877,0.4973935053672269,0.49792250618139083,0.4984379724773328,0.4989571203688094,0.49947723819852247,0.5000075822932648,0.5005896163962378,0.501172217254474,0.5017518564882046,0.5023316080060465,0.5029098921714067,0.5034842469186621,0.5040474960004326,0.5045822583583649,0.5051136294667578,0.5056712579591025,0.5062279948848526,0.5067820263851104,0.5073347296920269,0.5079056276444267,0.5084383854313732,0.5089579105645927,0.5094735511798574,0.5100083932020512,0.5105440460571398,0.5110822357492795,0.5116195482941185,0.5121564175754492,0.5126938883949659,0.513218977205125,0.5137375738446175,0.5142589715671373,0.5147807103126092,0.5153027027548425,0.515898527891147,0.5164931401592175,0.5170239390661229,0.5174517932829971,0.5178801854003102,0.5182892521587081,0.5186962981018695,0.5191053555322942,0.5195158622873304,0.5199254386066824,0.520335239176561,0.5207186283511545,0.5210992932873517,0.5214755237248957,0.5218553750842903,0.5222403798616109,0.5226313659769157,0.5230212706287534,0.5234120881327338,0.5238081165224495,0.5242026482051466,0.5245323610635642,0.5248339098589498,0.5251366675173732,0.5254384963495831,0.5257396798400429,0.5260405866777462,0.5263070464952274,0.526556659548762,0.5268054906939917,0.5270535411036976,0.52730109495027,0.5275479143863901,0.527801990422455,0.528076580799892,0.5283469218645749,0.5286190274493204,0.5289143596515635,0.5292852091219181,0.5296560720193142,0.5300271271118365,0.5303982540062717,0.5307614486281613,0.5311210418405642,0.5314803026745317,0.5318377052294807,0.5321929171037494,0.5325484231208428,0.5329056185302489,0.5332636463116815,0.533620937226225,0.5339761354007929,0.534329292283699,0.5346795566214398,0.5350290760930099,0.5353791572937365,0.5357492121941944,0.5361191396417493,0.5364867146587404,0.5368523646822099,0.5372228068982285,0.5375906082860449,0.5379517921379835,0.5383093929111897,0.5386661546346269,0.5390190837271491,0.5393705697895466,0.5397110941295431,0.5398604806634582,0.5400059958169612,0.5401527176393641,0.5403030526301037,0.540452607230952,0.540595704386207,0.540739195649376,0.5408822676112516,0.5410259902149647,0.5411702407745926,0.5413138690072535,0.5414568334658787,0.5416038516075325,0.5417516655089906,0.541900002039223,0.5420417099273179,0.5421583723976778,0.5422741416515102,0.542377031996374,0.5424721560823309,0.5425444602015014,0.5426120992841595,0.5426802274483168,0.542748047976322,0.5428156963460166,0.542882878787072,0.5429499344848694,0.5430247559848937,0.5431008552918664,0.5431769616896132,0.5432528591241861,0.5433287326503156,0.5434039540243825,0.5434790350763355,0.5435553310072234,0.5436345366362654,0.5437162912834651,0.5437993836213998,0.5438819077209196,0.5439625858397974,0.5440424550549798,0.544121925709388,0.544218858946793,0.5443371753208517,0.5444541785554033,0.5445698739985424,0.5446844330925998,0.5447983036851873,0.5449107924136316,0.5450229092393956,0.545184353827503,0.5453814443749582,0.5455777994983918,0.5457781247623418,0.5459798263490849,0.546180882629855,0.5463906166705537,0.5466064318962638,0.5468216045646528,0.5470360591274481,0.5472502435989237,0.5474648572049525,0.547681886891383,0.5479049966101747,0.5481325398408359,0.5483588359186886,0.548585716853414,0.5488132242534857,0.5490412975590924,0.5492697772368291,0.5494989504538833,0.5497315190142764,0.5499655030081895,0.5501989138478144,0.5504317710262143,0.5506641397090147,0.5508958595106885,0.5511269815086612,0.5513575684758157,0.5515877562726362,0.5518174178562739,0.5520472118943484,0.5522768502047278,0.5525039204309353,0.5527302130187348,0.5529560230885237,0.5531815317473199,0.553406947422327,0.5536319472246148,0.553856736967215,0.5540826837736204,0.5543097415737636,0.5545321354525736,0.554752428867342,0.5549722412068473,0.5551897191959199,0.5554058343994688,0.5556215110531485,0.5558373237337058,0.5560529189273223,0.5562682997649593,0.5564835629434862,0.5566983243405704,0.556912788027169,0.5571351427228443,0.5573676491416335,0.5575950767553789,0.5578134025908013,0.5580303793008635,0.5582467410519113,0.5584620338785862,0.5586718555335051,0.5588734313969703,0.5590742564253386,0.5592751309369126,0.5594761171667793,0.5596766116389752,0.5598765363844258,0.5600716176443564,0.5602739626161792,0.5605162631518865,0.560776027826661,0.5610344265333364,0.5612916959033577,0.561548031191477,0.5618035237063173,0.5620579973903029,0.5623129763612849,0.5625672865748256,0.5628218830878038,0.5630756753285339,0.5633328457117313,0.5635917341720866,0.5638498880708231,0.5641070668881656,0.5643632874276151,0.5646189051968549,0.5648688764488993,0.5651150703456344,0.5653600391751038,0.5656039310447433,0.5658468064082041,0.566088306643901,0.5663284869065314,0.5665663852904265,0.5668024115972147,0.5670373913401524,0.5672706947512272,0.5675034763691826,0.5677306475624523,0.5679487747512052,0.5681662885533216,0.5683833100250956,0.5685998941856554,0.5688167348350998,0.5690342999077524,0.5692508368404336,0.569465183637684,0.5696776237453158,0.5698925721582783,0.5701019285681451,0.570309898053505,0.5705176416674183,0.5707259818515507,0.5709340019832785,0.5711414739047757,0.5713443979834971,0.5715394495519918,0.5717327105941798,0.5719239285829992,0.5721134724636475,0.5723022836611694,0.5724897542871173,0.5726756473601343,0.5728603842715245,0.573043812711639,0.5732278105629508,0.573414819128268,0.5735880968561666,0.573758615272827,0.573927979683924,0.5740964165567815,0.5742639703244297,0.5744310939933989,0.5745977502920153,0.574763080382201,0.5749275095967789,0.5750924437243321,0.5752471897448348,0.5753729950800697,0.5754991615857068,0.575625112062903,0.5757491526855634,0.5758710482066193,0.5759925361162007,0.5761149436599337,0.576239438344524,0.5763636022589715,0.5764873962355677,0.5766109130358413,0.5767337175013841,0.5768553198794293,0.5769772698885244,0.5770981225220628,0.577217472062954,0.5773369115235155],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"mode\":\"lines\",\"name\":\"Test MSE\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[9.832509475202539,9.793427302158081,9.762626999766141,9.73448422884591,9.709282304900936,9.72349023026164,9.75351471498284,9.783133926994042,9.812114305173107,9.840688550967734,9.868794438452916,9.898356052335576,9.917772201750616,9.927480661072913,9.937059279966793,9.949373140960354,9.963653755450713,9.97772698086642,9.99204787748864,10.00587110392644,10.019195028723153,10.03203126328672,10.045631681216115,10.066344647906618,10.086386451931519,10.104238327956992,10.121402385287071,10.13781019344823,10.153251566044874,10.168116820336941,10.18243769372237,10.19625278627027,10.20957801108452,10.222428828440234,10.234838270186035,10.246826808945748,10.258402844224065,10.269607585603037,10.280458223384679,10.290993463862321,10.301228416383001,10.310968499741938,10.320109115633057,10.329013834476223,10.337732618175355,10.346261724978955,10.354652767142824,10.362904025094313,10.371064332878394,10.37911180539481,10.387323390575483,10.395613216089826,10.404800996326669,10.414461196458994,10.424044565136505,10.43358073203166,10.443105962005522,10.452620651208942,10.462152889959693,10.471703941370661,10.48148344803125,10.491298189944334,10.501161412811078,10.511065241754235,10.521050559717741,10.531094671766489,10.54122344858019,10.551432800809241,10.561716529604489,10.572090044245165,10.582536911176254,10.59306265504147,10.603666040443628,10.614341533168801,10.625068068228146,10.635856264423932,10.646698891224442,10.65758494153146,10.668502188136898,10.679448460262883,10.690418287670509,10.701396393622707,10.712380474222538,10.72335878179157,10.734321671799997,10.74526892742351,10.756179512739756,10.76705703358384,10.777892366192221,10.788680179965205,10.799429993933266,10.810115917316283,10.82074098745014,10.83129735917047,10.84177721669979,10.852181688887999,10.862489417595167,10.872769663334878,10.882975029494247,10.893074788278366,10.90308165128066,10.912974162074953,10.922757335860085,10.932419875010787,10.941969214268491,10.951391691624199,10.96068344344656,10.969847714252591,10.97888902575203,10.98779037830721,10.996580944053441,11.005271336049077,11.013839945868781,11.022287133587731,11.030614212520453,11.038799427767234,11.047126139997637,11.055476506630093,11.063689826234777,11.071759003988522,11.079699337425158,11.087494348934063,11.095145756110249,11.102662854574717,11.110042217560927,11.117286112823775,11.12439723223287,11.131368899358815,11.138210882430538,11.144923502548952,11.151513311012016,11.157981566742038,11.164311139043054,11.170520407674104,11.176619130480473,11.182596455168895,11.188455065235665,11.194204281125591,11.19983651834575,11.200834584566753,11.187628994081594,11.174498036295056,11.161451501806196,11.148464907084428,11.135568818282628,11.12274006394425,11.109991805392191,11.097322601121887,11.084795041839888,11.072408534553064,11.06014513647933,11.048016009709915,11.036038530020083,11.024186276376938,11.0124887092635,11.000923230935454,10.989495354961825,10.978178187356134,10.966989511867329,10.955917946454,10.944962468340247,10.934115999192665,10.923377047016121,10.912517300452771,10.901573395260652,10.890732782583989,10.879994925126852,10.869354945919689,10.858818488880686,10.848378419067501,10.838037061961225,10.827779864639504,10.817751398308026,10.807811889414609,10.797964272362648,10.788216779572675,10.778554874513475,10.769006502643894,10.759549196850262,10.75021045394653,10.740920609508086,10.73168894655378,10.722514049877763,10.713402808270107,10.70435113044822,10.695363373416505,10.686444361997914,10.677587480839316,10.668809419822448,10.660068258901624,10.651357881757544,10.644437629649211,10.63778140613565,10.631159371130735,10.624580365929209,10.618035520496637,10.611536855335927,10.605059114294768,10.598604902787766,10.592191812734596,10.58582676745392,10.579507786312783,10.573230350558124,10.567018479638126,10.562342186366509,10.558527378274942,10.554739473596882,10.550984022619556,10.547248951568816,10.546583771804332,10.54772649852566,10.54885534523441,10.549964754002914,10.55105112861079,10.552114943264257,10.553499614534907,10.554980428777673,10.556454631106764,10.557911800511018,10.559358923011118,10.560785409826957,10.562200413539983,10.563583090849432,10.564948139312676,10.56631519493807,10.567661484757403,10.568978851987898,10.57029080516719,10.571592258401953,10.572884533235001,10.57416037195264,10.57297808965454,10.571968035467727,10.571676979755416,10.571381422998702,10.57108639686197,10.570791477840807,10.570486919051216,10.570188029261617,10.569888769613774,10.569597509821701,10.569295179516327,10.569006887958722,10.568711764010828,10.568419501305982,10.568132007192814,10.567848274697923,10.567571111565854,10.567288916630474,10.567008682537901,10.566742857645806,10.566470517125625,10.566199713893697,10.56593828783588,10.565673683942212,10.565429581832326,10.565178646961424,10.564945883065137,10.564710101058713,10.564470930464541,10.564237322431797,10.564021355455587,10.563809573907434,10.563604838847803,10.563406990717416,10.563209355793617,10.56301733692633,10.562829133165584,10.562647022353078,10.562458078411547,10.56228306782969,10.56210355508509,10.561931512682333,10.561758199605457,10.561590078988134,10.561414171286096,10.561247217570596,10.561081694710472,10.56091945694763,10.560760504301165,10.560608121557083,10.560455368545373,10.56030362265793,10.560151506438624,10.560009191858615,10.559853526939882,10.559713809475083,10.559550410885853,10.559371066432757,10.559202953883052,10.559041410979818,10.558875735710014,10.558725424773835,10.558577074273693,10.558428723814592,10.558323711557108,10.558242064045631,10.558183781424429,10.558163274705235,10.558160994175374,10.558166714591652,10.558200410132958,10.55824443814671,10.558303885046346,10.558381612063542,10.558460770918257,10.558560965354745,10.558663068669635,10.558781121478003,10.558901030413654,10.559029895203832,10.559163053276484,10.559307392972956,10.559457403778993,10.559608899831229,10.559766543859633,10.559928852613318,10.560088990237734,10.560267304340918,10.560434545625345,10.560606027611769,10.560779471577645,10.56096081288838,10.561136220725112,10.561314544112836,10.561496526078942,10.561681476261326,10.561863619905035,10.562049103242504,10.562236495762264,10.562424843789994,10.56262114219178,10.562812884339454,10.56300738424531,10.563218684513146,10.563415148099661,10.563627935389714,10.56383420642481,10.564059557599789,10.564276060869815,10.564502794521678,10.564736525757535,10.564968404396883,10.565203570842666,10.565437361496466,10.56568562235371,10.565919946920776,10.566163548960244,10.566409589937853,10.566663053617662,10.566903057412098,10.567155200067962,10.56740321036646,10.567653555028432,10.567899767167628,10.568150645643389,10.568396489954786,10.568658861878172,10.568916556511535,10.56919153077023,10.569457759462644,10.569721761784812,10.569996099728893,10.57026169171311,10.570522360530173,10.570765933603221,10.571003040987595,10.571239725353221,10.571475561819843,10.57171797175566,10.57195020487942,10.572181113018496,10.572410167310506,10.572640705575992,10.57287267585646,10.57310427461579,10.573327499332935,10.573554965053688,10.573776492613245,10.574011434846652,10.574233016853306,10.574461120311204,10.574691080598857,10.574920617183594,10.575147449435772,10.57537571342906,10.575606311065044,10.575831768267388,10.576062471884573,10.576293176707864,10.576522503951672,10.576749126498896,10.576975750160365,10.57720751676068,10.577439813038403,10.577660499541391,10.577893803357542,10.578124298912435,10.578355324032755,10.578586827059912,10.578820186891017,10.57905455309151,10.579288018279673,10.579527051817632,10.579766563306993,10.580000031703854,10.580262446484118,10.58056679880187,10.580864580268862,10.581174078426862,10.581475626711596,10.58177998634953,10.582090920621264,10.582399047207224,10.582667621703411,10.582810485529954,10.58295054003943,10.583103160930282,10.583251065202726,10.58340215345773,10.583558861335488,10.5837183278533,10.583883788149016,10.584045962439438,10.584213756507117,10.584387067678684,10.58456180991879,10.584734219873393,10.584915910436678,10.58509569427388,10.585273674021304,10.585458601676038,10.585644960498904,10.58583593447348,10.586029667614705,10.586230348965763,10.586431933549111,10.586634047064083,10.58683605891261,10.58704883394154,10.587258851335408,10.587473961199382,10.58768345238477,10.58790556313364,10.588120727076253,10.588335891960309,10.588560338726339,10.58877884340511,10.589003820188246,10.589225562394114,10.589444751270058,10.589672694262102,10.589895069484495,10.590114635692455,10.59034995557059,10.590592344222287,10.590850981448693,10.591116994728205,10.591383912643247,10.59165226308077,10.59192199505146,10.592189821714877,10.592460988279765,10.592744420174814,10.593027854493211,10.593313624511813,10.593601679388756,10.593899495996396,10.594195458808583,10.594490521447451,10.594789350587783,10.595084418497171,10.595386966064813,10.595689039526624,10.595997689935762,10.596294726625121,10.596599243148718,10.596893302117657,10.597174822971343,10.597468966933153,10.597778485184925,10.598111687897863,10.59843375391781,10.598766963956272,10.599092801183978,10.599413598933939,10.599735303188552,10.600055580334224,10.600388432526255,10.600711050307618,10.601041149565994,10.601370775548908,10.601705549476982,10.602035182623531,10.602363489565084,10.60269779746182,10.603026111446272,10.603357289935333,10.603689902417528,10.60401747426385],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.45],\"title\":{\"text\":\"Epoch\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.625,1.0],\"title\":{\"text\":\"Estimate\"}},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.55,1.0],\"title\":{\"text\":\"Epoch\"}},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.625,1.0],\"title\":{\"text\":\"Variance\"}},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.0,0.45],\"title\":{\"text\":\"Epoch\"}},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,0.375],\"title\":{\"text\":\"MSE Loss\"}},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.55,1.0],\"title\":{\"text\":\"Epoch\"}},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.0,0.375],\"title\":{\"text\":\"MSE\"}},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Estimate over Epochs\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Variance over Epochs\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Shaping Train MSE Loss over Epochs\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Total MSE over Epochs\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Metrics over Epochs\"},\"showlegend\":true},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('2755d5bb-4b0f-45e4-91bf-4b25641883b3');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"4e5e9e76-bb0a-4272-b8cd-b59d644c6ec6\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"4e5e9e76-bb0a-4272-b8cd-b59d644c6ec6\")) {                    Plotly.newPlot(                        \"4e5e9e76-bb0a-4272-b8cd-b59d644c6ec6\",                        [{\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"z\":[[0.05695229023694992,0.06021043285727501,0.05452115833759308,0.04347718507051468,0.03234117105603218,0.021205175668001175,0.010069161653518677,-0.0010668300092220306,-0.010484162718057632,-0.018306713551282883],[0.05211315304040909,0.060832150280475616,0.06059904024004936,0.05242564529180527,0.04192110896110535,0.031416554003953934,0.020911991596221924,0.010407447814941406,-9.710714221000671e-05,-0.010601665824651718],[0.04866671562194824,0.04874328896403313,0.04995996132493019,0.051645636558532715,0.048672184348106384,0.03982558846473694,0.029321031644940376,0.018816489726305008,0.008311960846185684,-0.0021925978362560272],[0.043235886842012405,0.03835252299904823,0.04314318299293518,0.0404556505382061,0.04214132949709892,0.04173160344362259,0.03674532473087311,0.02722552791237831,0.01672099158167839,0.006216432899236679],[0.03718101978302002,0.03203738480806351,0.03567025065422058,0.03391745686531067,0.03142035752534866,0.032637011259794235,0.03432267904281616,0.029804745689034462,0.024818474426865578,0.014625463634729385],[0.031126152724027634,0.025722259655594826,0.028813423588871956,0.031578417867422104,0.02469172142446041,0.023508690297603607,0.023132702335715294,0.02481839247047901,0.022864168509840965,0.017877880483865738],[0.02507130429148674,0.019407127052545547,0.022498302161693573,0.0255894735455513,0.022352684289216995,0.016018230468034744,0.015597019344568253,0.015175793319940567,0.015314053744077682,0.015923578292131424],[0.018645986914634705,0.013092007488012314,0.01618315652012825,0.01927434280514717,0.021422047168016434,0.01312694326043129,0.008106544613838196,0.007685322314500809,0.007264092564582825,0.006842870265245438],[0.014071021229028702,0.007169332355260849,0.009868036955595016,0.01295921579003334,0.01605037972331047,0.011531319469213486,0.003901202231645584,0.00019485875964164734,-0.00022635608911514282,-0.0006475783884525299],[0.009880851954221725,0.002982698380947113,0.003552909940481186,0.006644081324338913,0.009735260158777237,0.012472372502088547,0.0016405917704105377,-0.005324523895978928,-0.00771678239107132,-0.008138027042150497]],\"type\":\"heatmap\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"Values\"},\"ticks\":\"outside\",\"tickvals\":[-0.018306713551282883,0.060832150280475616],\"ticktext\":[-0.018306713551282883,0.060832150280475616]}},\"xaxis\":{\"tickvals\":[0,1,2,3,4,5,6,7,8,9],\"ticktext\":[0,1,2,3,4,5,6,7,8,9],\"title\":{\"text\":\"X\"}},\"yaxis\":{\"tickvals\":[9,8,7,6,5,4,3,2,1,0],\"ticktext\":[9,8,7,6,5,4,3,2,1,0],\"title\":{\"text\":\"Y\"},\"autorange\":\"reversed\"},\"title\":{\"text\":\"Heatmap\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('4e5e9e76-bb0a-4272-b8cd-b59d644c6ec6');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"e0037098-5860-498c-998d-32e9a075c567\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e0037098-5860-498c-998d-32e9a075c567\")) {                    Plotly.newPlot(                        \"e0037098-5860-498c-998d-32e9a075c567\",                        [{\"colorbar\":{\"title\":{\"text\":\"Visits\"}},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"x\":[0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9],\"y\":[9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0],\"z\":[0,130,377,934,2156,2075,2028,1751,1270,1329,0,213,612,1528,1722,0,717,981,877,1392,0,435,1202,1461,655,0,256,330,510,1358,0,962,1131,565,245,0,61,103,191,325,0,931,505,258,130,0,15,31,43,67,270,640,270,119,49,13,3,10,13,12,63,126,62,39,20,20,3,11,11,11,9,23,10,9,1,15,4,9,8,11,2,6,4,1,0,16,5,6,7,13,0,1,0,1,0,10,3,6,6,9],\"zmax\":2156,\"zmin\":0,\"type\":\"heatmap\"}],                        {\"title\":{\"text\":\"State Visitations Heatmap\"},\"xaxis\":{\"title\":{\"text\":\"X-axis\"}},\"yaxis\":{\"ticktext\":[9,8,7,6,5,4,3,2,1,0],\"tickvals\":[0,1,2,3,4,5,6,7,8,9],\"title\":{\"text\":\"Y-axis\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('e0037098-5860-498c-998d-32e9a075c567');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "800 trajectories:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"8414bc63-863c-43ec-8f4b-1515946b619f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"8414bc63-863c-43ec-8f4b-1515946b619f\")) {                    Plotly.newPlot(                        \"8414bc63-863c-43ec-8f4b-1515946b619f\",                        [{\"mode\":\"lines\",\"name\":\"IS Estimate\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929,1.6968721151351929],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"Train Estimate\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.47848764061927795,0.23847633600234985,0.2272220253944397,0.21621760725975037,0.20445962250232697,0.19370552897453308,0.18554584681987762,0.17736400663852692,0.17015206813812256,0.16406454145908356,0.15776918828487396,0.1517898291349411,0.1459726095199585,0.14048223197460175,0.13511641323566437,0.1304267942905426,0.12624911963939667,0.12209079414606094,0.11816417425870895,0.1145399883389473,0.11202678084373474,0.109671451151371,0.10719048976898193,0.10492785274982452,0.1030188724398613,0.10216493159532547,0.10158701986074448,0.10100944340229034,0.10090547800064087,0.10074441134929657,0.10040964186191559,0.10003610700368881,0.09950356185436249,0.09879227727651596,0.0981074795126915,0.09725061058998108,0.09611909091472626,0.09504163265228271,0.0939607173204422,0.09279318153858185,0.09146268665790558,0.09030311554670334,0.08916664123535156,0.08797349035739899,0.08670329302549362,0.08546102046966553,0.08423317968845367,0.08298233896493912,0.081785649061203,0.0806339681148529,0.07948453724384308,0.0783456340432167,0.07720577716827393,0.07613090425729752,0.07516062259674072,0.07425949722528458,0.07317428290843964,0.07204636931419373,0.07096685469150543,0.06991072744131088,0.06890412420034409,0.06800006330013275,0.06715928018093109,0.06639168411493301,0.06553665548563004,0.06471666693687439,0.06396172195672989,0.06321979314088821,0.06255028396844864,0.06196705251932144,0.061434656381607056,0.06096925213932991,0.06057189404964447,0.060257505625486374,0.060032378882169724,0.05986672267317772,0.059758227318525314,0.05970175936818123,0.05969667434692383,0.05974037945270538,0.059829652309417725,0.05996253713965416,0.06013569235801697,0.06034528836607933,0.06058807298541069,0.06086251884698868,0.06116323173046112,0.0614933967590332,0.06180717796087265,0.06213684007525444,0.06248321384191513,0.06285236030817032,0.06323789060115814,0.06363746523857117,0.06405436247587204,0.064486563205719,0.0649213120341301,0.06536562740802765,0.06582485139369965,0.06626827269792557,0.06669759750366211,0.0671311542391777,0.06756586581468582,0.06788349896669388,0.06818541884422302,0.0684823989868164,0.068782739341259,0.06909714639186859,0.06942148506641388,0.06972824782133102,0.0700150728225708,0.07028494030237198,0.07055162638425827,0.07081548869609833,0.07107453793287277,0.0713263601064682,0.07156988978385925,0.07180433720350266,0.07202162593603134,0.07222902774810791,0.07242771238088608,0.07259806245565414,0.07275010645389557,0.07288622856140137,0.07300295680761337,0.07310797274112701,0.0732022374868393,0.07334877550601959,0.07348064333200455,0.07359571009874344,0.07370033115148544,0.07378710061311722,0.07386217266321182,0.07392611354589462,0.07397914677858353,0.0740223079919815,0.07400334626436234,0.07397499680519104,0.07393838465213776,0.07388841360807419,0.07382945716381073,0.07376445084810257,0.07369288057088852,0.07361497730016708,0.0735313817858696,0.07344212383031845,0.07334671914577484,0.07324529439210892,0.07314027845859528,0.07303019613027573,0.0729176476597786,0.07280169427394867,0.07267415523529053,0.0725361779332161,0.07238344848155975,0.07221978157758713,0.07203426957130432,0.07183046638965607,0.07162198424339294,0.07140829414129257,0.07118739187717438,0.07096239179372787,0.07073355466127396,0.07050063461065292,0.070262111723423,0.07002060860395432,0.06977967172861099,0.06953614205121994,0.06929252296686172,0.06905108690261841,0.06880691647529602,0.06854314357042313,0.06827236711978912,0.06799311935901642,0.06771119683980942,0.06742827594280243,0.06714226305484772,0.06685464084148407,0.06656689196825027,0.06627896428108215,0.06599107384681702,0.06572235375642776,0.06545364856719971,0.06513693183660507,0.06482019275426865,0.06450910866260529,0.06419892609119415,0.06388981640338898,0.0635814368724823,0.06327386200428009,0.06296740472316742,0.06265965104103088,0.06234952434897423,0.062042396515607834,0.06175360828638077,0.06146769970655441,0.061183277517557144,0.06100717931985855,0.0608808659017086,0.06075933203101158,0.060637786984443665,0.06051592901349068,0.0603916309773922,0.060264702886343,0.06014179810881615,0.06001898646354675,0.05990604683756828,0.05980444326996803,0.05970526114106178,0.05960581824183464,0.05950762331485748,0.05941859632730484,0.05933445319533348,0.05924495309591293,0.05915465205907822,0.059063561260700226,0.05897434055805206,0.058904316276311874,0.05883333086967468,0.05876421555876732,0.05871555954217911,0.05866878107190132,0.05862242355942726,0.058579180389642715,0.05854278430342674,0.05850614607334137,0.05848164111375809,0.05845711752772331,0.05843555927276611,0.0584162175655365,0.058400146663188934,0.05838572978973389,0.05837124586105347,0.058354951441287994,0.058338463306427,0.058321595191955566,0.058304399251937866,0.05832095444202423,0.05834772810339928,0.058374498039484024,0.05840194225311279,0.05842095986008644,0.05843954533338547,0.05845821648836136,0.05847665295004845,0.05849437788128853,0.05851012095808983,0.058524638414382935,0.05853724852204323,0.05854756012558937,0.0585566908121109,0.058567579835653305,0.05857833847403526,0.05858825519680977,0.058596864342689514,0.058604735881090164,0.05860608071088791,0.058602772653102875,0.05859886482357979,0.058595411479473114,0.05859113112092018,0.05856143310666084,0.0585269033908844,0.05849277973175049,0.05845905840396881,0.05842465162277222,0.05838856101036072,0.05835247039794922,0.05831737816333771,0.058283813297748566,0.05825185403227806,0.058221422135829926,0.058192163705825806,0.058163922280073166,0.0581350214779377,0.05810731276869774,0.05808030441403389,0.05805845931172371,0.058038871735334396,0.058010634034872055,0.057985905557870865,0.057962916791439056,0.05793272703886032,0.057904694229364395,0.057878874242305756,0.05785498768091202,0.05783248320221901,0.0578109435737133,0.05777653306722641,0.057709790766239166,0.05764404311776161,0.057583220303058624,0.057523827999830246,0.05746447294950485,0.0573800764977932,0.05727313086390495,0.057169292122125626,0.05706798657774925,0.056965284049510956,0.05686579644680023,0.05677368864417076,0.05668024718761444,0.05658617615699768,0.056494202464818954,0.05640418082475662,0.05631503835320473,0.05622672289609909,0.05614394694566727,0.0560632087290287,0.05598387494683266,0.05590441823005676,0.05582522600889206,0.055747438222169876,0.055671654641628265,0.05559481307864189,0.055518489331007004,0.05544019863009453,0.0553421750664711,0.05524570867419243,0.05514993146061897,0.055056385695934296,0.05496438592672348,0.0548730343580246,0.05478225275874138,0.054692674428224564,0.05460464581847191,0.05451768636703491,0.05443372204899788,0.0543428510427475,0.05424470081925392,0.05414034426212311,0.054042138159275055,0.05394461750984192,0.05384298041462898,0.053742699325084686,0.05364374816417694,0.05354620888829231,0.05345159396529198,0.053359247744083405,0.053268395364284515,0.05317717418074608,0.05308341607451439,0.05299152806401253,0.0529014877974987,0.052812617272138596,0.05272185057401657,0.05263304337859154,0.05254611372947693,0.052462123334407806,0.05238037183880806,0.05229638144373894,0.05221828073263168,0.05214430391788483,0.0520719476044178,0.05199990049004555,0.05192934721708298,0.05187191069126129,0.051823243498802185,0.05177517607808113,0.05172485485672951,0.05167567729949951,0.05162863805890083,0.05158393457531929,0.051541656255722046,0.051499806344509125,0.05145920440554619,0.05144856125116348,0.05144152045249939,0.05143529549241066,0.051429279148578644,0.05142360180616379,0.051417987793684006,0.05141301825642586,0.05140915513038635,0.05140727013349533,0.05140578746795654,0.05140525475144386,0.0514054149389267,0.05140606686472893,0.05140717327594757,0.05140865966677666,0.051410380750894547,0.05141230300068855,0.05141490325331688,0.0514177568256855,0.05142050236463547,0.05142304673790932,0.05142538994550705,0.05142750218510628,0.0514293871819973,0.05143167823553085,0.051435377448797226,0.05143868550658226,0.051441553980112076,0.05144399404525757,0.05144595354795456,0.05144742876291275,0.05144839361310005,0.051448822021484375,0.051448725163936615,0.051448285579681396,0.05144720897078514,0.05144562944769859,0.05144358053803444,0.05144098401069641,0.05143735930323601,0.0514330193400383,0.051428161561489105,0.05142274871468544,0.051422368735075,0.05142350494861603,0.05142395198345184,0.05142366886138916,0.051422227174043655,0.05141884833574295,0.0514148510992527,0.051410142332315445,0.051404863595962524,0.051398780196905136,0.05139220505952835,0.051385216414928436,0.05137835815548897,0.0513717457652092,0.05136879161000252,0.05136459320783615,0.05135825648903847,0.05133002996444702,0.05127650871872902,0.05122361332178116,0.05117284506559372,0.05112272873520851,0.051073573529720306,0.0510203056037426,0.05096660926938057,0.05091065168380737,0.050855282694101334,0.05080082267522812,0.05074719712138176,0.05070048198103905,0.050664883106946945,0.05063025280833244,0.05059636011719704,0.050563618540763855,0.050531886518001556,0.05050161853432655,0.05047048255801201,0.05043746158480644,0.05040527135133743,0.05037391930818558,0.050342969596385956,0.05031272768974304,0.050283338874578476,0.050256822258234024,0.05023247003555298,0.05020884424448013,0.05018582195043564,0.05016319453716278,0.05014120787382126,0.05011598765850067,0.050097353756427765,0.05008028447628021,0.050064437091350555,0.0500497967004776,0.05003616213798523,0.05002357438206673,0.05001186951994896,0.050000984221696854,0.04999084770679474,0.04998130723834038,0.049971770495176315,0.049963463097810745,0.049956489354372025,0.049950260668992996,0.04994622990489006,0.04994279146194458,0.04993981868028641,0.04993734136223793,0.049934979528188705,0.04993283376097679,0.04993031173944473,0.04992740601301193,0.049924131482839584,0.04991227388381958,0.04989083856344223,0.04987072944641113,0.0498519204556942,0.049834467470645905,0.049819737672805786,0.04980592802166939,0.049792539328336716,0.049779631197452545,0.049767374992370605,0.04975518956780434,0.04974306374788284,0.04973045364022255,0.0497191846370697,0.049708425998687744,0.04969317466020584,0.04967808723449707,0.049663059413433075],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"Test Estimate\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[2.373932123184204,2.3597311973571777,2.3464057445526123,2.333468198776245,2.3209331035614014,2.317171812057495,2.317786693572998,2.3184776306152344,2.3192074298858643,2.3199400901794434,2.3206348419189453,2.32148814201355,2.321584939956665,2.3206262588500977,2.319658041000366,2.318833112716675,2.3182895183563232,2.3177430629730225,2.3172481060028076,2.3167049884796143,2.3161065578460693,2.3154611587524414,2.3150675296783447,2.3155910968780518,2.316049098968506,2.3162930011749268,2.316477060317993,2.316484212875366,2.316409111022949,2.3162877559661865,2.31612229347229,2.3159210681915283,2.315685510635376,2.3154191970825195,2.31512713432312,2.3148131370544434,2.3144800662994385,2.314133405685425,2.3137784004211426,2.313419818878174,2.313058853149414,2.312854766845703,2.3126659393310547,2.3124806880950928,2.3123059272766113,2.312141180038452,2.3119890689849854,2.311858892440796,2.3117542266845703,2.311673164367676,2.3116743564605713,2.3117311000823975,2.311923027038574,2.312180519104004,2.312472343444824,2.3128013610839844,2.3131680488586426,2.3135764598846436,2.3140270709991455,2.3145205974578857,2.3150079250335693,2.315537691116333,2.316114902496338,2.316739320755005,2.317411422729492,2.3181309700012207,2.318896770477295,2.3197102546691895,2.320568799972534,2.3214731216430664,2.322420120239258,2.323409080505371,2.3244383335113525,2.3255066871643066,2.3266115188598633,2.3277506828308105,2.328922986984253,2.330124616622925,2.331355094909668,2.3326117992401123,2.3338921070098877,2.335193395614624,2.336514949798584,2.3378515243530273,2.3392043113708496,2.340568780899048,2.3419432640075684,2.343327045440674,2.3447182178497314,2.346114158630371,2.3475165367126465,2.348921775817871,2.3503267765045166,2.3517301082611084,2.353130340576172,2.3545267581939697,2.3559374809265137,2.357339382171631,2.3587324619293213,2.360114812850952,2.3614859580993652,2.362844228744507,2.3641879558563232,2.3655176162719727,2.3668315410614014,2.3681304454803467,2.3694117069244385,2.370676279067993,2.3719239234924316,2.373152732849121,2.3743646144866943,2.3755576610565186,2.3767333030700684,2.3778903484344482,2.3790292739868164,2.3801491260528564,2.3812508583068848,2.3823344707489014,2.3833985328674316,2.3844082355499268,2.3853118419647217,2.3861982822418213,2.3870670795440674,2.387918472290039,2.3887524604797363,2.3895697593688965,2.3903698921203613,2.3911542892456055,2.3919248580932617,2.392679214477539,2.3934175968170166,2.3941402435302734,2.394848346710205,2.3955414295196533,2.396219253540039,2.396883010864258,2.3975331783294678,2.3981690406799316,2.398791790008545,2.3994016647338867,2.399998188018799,2.400583267211914,2.4011552333831787,2.4017159938812256,2.4022648334503174,2.402801513671875,2.4033281803131104,2.4038424491882324,2.4043471813201904,2.4048409461975098,2.405325412750244,2.4058001041412354,2.406264543533325,2.40671968460083,2.4066250324249268,2.4057297706604004,2.4048314094543457,2.4039390087127686,2.403053045272827,2.402172565460205,2.4012985229492188,2.400430202484131,2.399568557739258,2.3987131118774414,2.39786434173584,2.397020101547241,2.3961825370788574,2.39534854888916,2.394519567489624,2.3936965465545654,2.3928799629211426,2.39206862449646,2.3912651538848877,2.3904688358306885,2.389681339263916,2.388916492462158,2.3881583213806152,2.3874073028564453,2.3866629600524902,2.3859262466430664,2.3851959705352783,2.3844730854034424,2.383756637573242,2.383047342300415,2.3823463916778564,2.381653070449829,2.380967378616333,2.3802895545959473,2.3796186447143555,2.3789544105529785,2.3782966136932373,2.3776450157165527,2.3769991397857666,2.3763585090637207,2.375722646713257,2.3750922679901123,2.374466896057129,2.3738462924957275,2.3732309341430664,2.372619867324829,2.372013568878174,2.371412754058838,2.370816469192505,2.370227336883545,2.369640350341797,2.3690578937530518,2.368479013442993,2.3679049015045166,2.3673346042633057,2.366771697998047,2.366218328475952,2.3656699657440186,2.365126848220825,2.3645899295806885,2.3640568256378174,2.36352801322937,2.3630030155181885,2.3624844551086426,2.3619697093963623,2.3614604473114014,2.360956907272339,2.360456943511963,2.3600528240203857,2.359790325164795,2.359529495239258,2.359272003173828,2.3590171337127686,2.358764410018921,2.3585124015808105,2.358262062072754,2.3580119609832764,2.3577628135681152,2.357513666152954,2.357264757156372,2.3570172786712646,2.3567700386047363,2.3565256595611572,2.3562827110290527,2.3560397624969482,2.3557987213134766,2.3555588722229004,2.3553202152252197,2.3550825119018555,2.354846239089966,2.35461163520813,2.3543777465820312,2.3541464805603027,2.353916883468628,2.3537020683288574,2.353595733642578,2.353490114212036,2.353386640548706,2.3532826900482178,2.353179931640625,2.3530783653259277,2.3529772758483887,2.352876663208008,2.3527767658233643,2.3527209758758545,2.352870225906372,2.353017568588257,2.353163719177246,2.3533103466033936,2.3534557819366455,2.353600263595581,2.3537445068359375,2.3538877964019775,2.3540284633636475,2.3541712760925293,2.3543097972869873,2.3544461727142334,2.354584217071533,2.3547210693359375,2.3548583984375,2.354994773864746,2.3551318645477295,2.3552675247192383,2.3554036617279053,2.355539321899414,2.3556737899780273,2.3558084964752197,2.355942726135254,2.356076717376709,2.3562097549438477,2.356342315673828,2.3564746379852295,2.3566057682037354,2.356687307357788,2.356672763824463,2.356656551361084,2.356638193130493,2.356618642807007,2.3566064834594727,2.3566434383392334,2.356680154800415,2.3567163944244385,2.356753349304199,2.3567898273468018,2.356825113296509,2.356860399246216,2.35689640045166,2.35693097114563,2.3569653034210205,2.356999635696411,2.3570337295532227,2.3570621013641357,2.357090950012207,2.357118844985962,2.3571460247039795,2.357173442840576,2.3571996688842773,2.3572254180908203,2.357250928878784,2.3572754859924316,2.3572998046875,2.357323408126831,2.357346534729004,2.3573691844940186,2.357391357421875,2.3574130535125732,2.3574342727661133,2.357454776763916,2.357473373413086,2.3574907779693604,2.3575081825256348,2.3575246334075928,2.357539415359497,2.3575549125671387,2.3575692176818848,2.3575832843780518,2.357595920562744,2.3576085567474365,2.357621192932129,2.3576319217681885,2.3576438426971436,2.357654571533203,2.3576653003692627,2.357675313949585,2.357685089111328,2.3576948642730713,2.357703685760498,2.3577141761779785,2.3577232360839844,2.3577332496643066,2.3577423095703125,2.357752561569214,2.3577616214752197,2.357771873474121,2.3577818870544434,2.3577914237976074,2.357801675796509,2.3578124046325684,2.3578217029571533,2.3578317165374756,2.3578410148620605,2.3578550815582275,2.3578686714172363,2.3578832149505615,2.357896327972412,2.357910633087158,2.357923746109009,2.357937812805176,2.3579514026641846,2.3579649925231934,2.3579788208007812,2.357992172241211,2.3580057621002197,2.358018636703491,2.358031749725342,2.3580446243286133,2.3580586910247803,2.3580715656280518,2.3580851554870605,2.3580987453460693,2.358111619949341,2.3581247329711914,2.3581383228302,2.35815167427063,2.3581652641296387,2.358180046081543,2.3581936359405518,2.3582077026367188,2.358222723007202,2.35823655128479,2.3582510948181152,2.3582656383514404,2.3582799434661865,2.3582968711853027,2.358315944671631,2.358335494995117,2.3583545684814453,2.3583731651306152,2.3583920001983643,2.358410596847534,2.3584296703338623,2.358447551727295,2.3584659099578857,2.3584842681884766,2.3585026264190674,2.3585205078125,2.358538866043091,2.3585565090179443,2.3585739135742188,2.3585922718048096,2.358609676361084,2.3586268424987793,2.3586442470550537,2.35866117477417,2.358678102493286,2.3586950302124023,2.3587112426757812,2.35872745513916,2.358743190765381,2.3587589263916016,2.358774185180664,2.3587896823883057,2.3588051795959473,2.3588192462921143,2.3588342666625977,2.3588483333587646,2.35886287689209,2.358877182006836,2.3588905334472656,2.3589046001434326,2.3589184284210205,2.3589181900024414,2.3589160442352295,2.3589136600494385,2.3589110374450684,2.3589093685150146,2.358907461166382,2.358905553817749,2.358903408050537,2.3589017391204834,2.3588995933532715,2.3588974475860596,2.3588953018188477,2.3588926792144775,2.358891010284424,2.35888934135437,2.3588881492614746,2.3588874340057373,2.358886957168579,2.35888671875,2.358887195587158,2.3588879108428955,2.358889102935791,2.3588905334472656,2.3588922023773193,2.358893632888794,2.358896017074585,2.358898162841797,2.358898162841797,2.3588969707489014,2.3588953018188477,2.3588945865631104,2.358893632888794,2.3588926792144775,2.3588922023773193,2.3588919639587402,2.358891725540161,2.3588931560516357,2.3588948249816895,2.3588979244232178,2.358901023864746,2.358905076980591,2.3589088916778564,2.3589136600494385,2.3589189052581787,2.358924150466919,2.3589298725128174,2.358935832977295,2.3589422702789307,2.3589489459991455,2.3589560985565186,2.3589632511138916,2.358970880508423,2.358978509902954,2.3589866161346436,2.358994960784912,2.3590028285980225,2.35901141166687,2.359020233154297,2.3590285778045654,2.359039783477783,2.359053373336792,2.359066963195801,2.3590807914733887,2.359095335006714,2.359110116958618,2.3591248989105225,2.3591394424438477,2.359158992767334,2.359182119369507,2.3592047691345215,2.3592276573181152,2.359250545501709,2.359273910522461,2.3592967987060547,2.3593196868896484],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"On-policy Estimate\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397,0.818598120170397],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"IS Variance\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498,2.087684154510498],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"lines\",\"name\":\"Train Variance\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.12060171365737915,0.1394006758928299,0.13299208879470825,0.1267429143190384,0.12074364721775055,0.11491920799016953,0.10927857458591461,0.10389895737171173,0.09896201640367508,0.09398536384105682,0.0893602967262268,0.08493569493293762,0.08065947890281677,0.07656056433916092,0.07263112813234329,0.06882476061582565,0.0650579035282135,0.06146536022424698,0.05786113068461418,0.054461851716041565,0.05144449323415756,0.0485675074160099,0.04583093151450157,0.04320633411407471,0.04074333235621452,0.038434892892837524,0.03626656532287598,0.03424171358346939,0.03233100473880768,0.030552959069609642,0.02890406735241413,0.027375126257538795,0.025959322229027748,0.024648500606417656,0.023434506729245186,0.022283194586634636,0.021169885993003845,0.020140286535024643,0.019190292805433273,0.018313808366656303,0.01750640571117401,0.016739843413233757,0.016035372391343117,0.01539078913629055,0.014801990240812302,0.014264571480453014,0.013775214552879333,0.013331483118236065,0.012929767370223999,0.012564453296363354,0.012231933884322643,0.0119323106482625,0.011662381701171398,0.011420737951993942,0.0112021304666996,0.011003931984305382,0.010830159299075603,0.010673245415091515,0.010528615675866604,0.010394997894763947,0.010271023958921432,0.01015486940741539,0.010046293959021568,0.009944401681423187,0.009846508502960205,0.009753411635756493,0.00966495182365179,0.009580891579389572,0.009499872103333473,0.009422537870705128,0.009347427636384964,0.009274040348827839,0.009202064014971256,0.009131263941526413,0.009061506949365139,0.008992567658424377,0.008924273774027824,0.008856519125401974,0.00878918543457985,0.008722185157239437,0.008655443787574768,0.008588944561779499,0.00852261483669281,0.008456412702798843,0.008390309289097786,0.008324328809976578,0.008259336464107037,0.008194093592464924,0.008129012770950794,0.008063874207437038,0.00799869280308485,0.007933555170893669,0.007868515327572823,0.007803625427186489,0.007739070802927017,0.007674901280552149,0.007610720582306385,0.007546921726316214,0.007483605295419693,0.007418042980134487,0.007350514177232981,0.007284145802259445,0.007218490820378065,0.007149387151002884,0.007080594543367624,0.00701257586479187,0.006945423781871796,0.006879202555865049,0.006813832558691502,0.006749019492417574,0.006684834603220224,0.006621291860938072,0.006558535620570183,0.006496549118310213,0.006435309071093798,0.006374802440404892,0.006315023172646761,0.006255957763642073,0.006197579205036163,0.006139873526990414,0.006082834210246801,0.006026377435773611,0.005970533937215805,0.005915272049605846,0.005860601086169481,0.005806479603052139,0.005752920173108578,0.005699640605598688,0.005645201075822115,0.005591150373220444,0.005537592805922031,0.005484485067427158,0.00543186254799366,0.005379720591008663,0.005328051745891571,0.005276889074593782,0.005226288456469774,0.005176425911486149,0.005127046722918749,0.005078155547380447,0.005029819905757904,0.004982011392712593,0.004934726282954216,0.004887940362095833,0.00484165083616972,0.004795831628143787,0.004750473890453577,0.004705608822405338,0.00466121593490243,0.004617272410541773,0.004573751240968704,0.004530551843345165,0.004487681668251753,0.004445135593414307,0.004402907565236092,0.00436100410297513,0.004319010768085718,0.004277052357792854,0.004235430154949427,0.004194118082523346,0.004153111949563026,0.004112442024052143,0.004072101786732674,0.004032088443636894,0.003992409445345402,0.003953087609261274,0.00391412666067481,0.0038755061104893684,0.003837254364043474,0.0037993979640305042,0.003761871950700879,0.00372394360601902,0.003686124226078391,0.0036486987955868244,0.0036116268020123243,0.0035749017260968685,0.0035384311340749264,0.0035022657830268145,0.0034664436243474483,0.0034309611655771732,0.0033958246931433678,0.0033612127881497145,0.0033269489649683237,0.003293165471404791,0.00325970072299242,0.003227030858397484,0.00319466064684093,0.0031625903211534023,0.0031308247707784176,0.003099364461377263,0.0030682310461997986,0.0030374133493751287,0.0030068987980484962,0.002976730465888977,0.0029471679590642452,0.0029179228004068136,0.0028889880049973726,0.0028691317420452833,0.002853068057447672,0.0028371051885187626,0.0028212561737746,0.0028055140282958746,0.002789746504276991,0.0027739289216697216,0.0027582747861742973,0.002742739859968424,0.002727648476138711,0.0027129531372338533,0.002698346972465515,0.002683822764083743,0.002669376553967595,0.0026549550238996744,0.0026405705139040947,0.0026261729653924704,0.002611867617815733,0.002597643295302987,0.0025835188571363688,0.0025695792865008116,0.0025557319168001413,0.0025419602170586586,0.0025282283313572407,0.002514609368517995,0.00250107585452497,0.002487943274900317,0.002475550165399909,0.0024632313288748264,0.002450923901051283,0.002438706811517477,0.0024264950770884752,0.002414311980828643,0.002402357989922166,0.002390566049143672,0.002378869568929076,0.002367296488955617,0.002355813281610608,0.0023444155231118202,0.002333099953830242,0.0023218910209834576,0.002310767536982894,0.0022997399792075157,0.0022888074163347483,0.0022775179240852594,0.0022663017734885216,0.002255162922665477,0.0022440990433096886,0.002233098726719618,0.0022221615072339773,0.0022112468723207712,0.0022003918420523405,0.0021896297112107277,0.0021789399906992912,0.0021682637743651867,0.0021576539147645235,0.002147108083590865,0.0021366297733038664,0.002126211766153574,0.0021158778108656406,0.0021056225523352623,0.002095424337312579,0.0020852703601121902,0.0020751666743308306,0.002065154956653714,0.002055185614153743,0.002045266330242157,0.002035400364547968,0.0020256019197404385,0.002015878213569522,0.0020062203984707594,0.001996675506234169,0.0019872377160936594,0.0019779056310653687,0.001968672266229987,0.0019595297053456306,0.0019504772499203682,0.001941502676345408,0.0019326051697134972,0.0019237849628552794,0.0019151184242218733,0.0019065929809585214,0.0018983292393386364,0.0018902381416410208,0.0018822626443579793,0.0018740898231044412,0.0018660470377653837,0.001858124858699739,0.0018503133906051517,0.0018426047172397375,0.0018349832389503717,0.0018269531428813934,0.0018178235040977597,0.0018087975913658738,0.0017998766852542758,0.001791048445738852,0.0017823096131905913,0.0017729682149365544,0.0017629011999815702,0.0017529192846268415,0.001743026776239276,0.0017331009730696678,0.0017232887912541628,0.0017137002432718873,0.0017042261315509677,0.0016948714619502425,0.0016855995636433363,0.00167642452288419,0.0016673370264470577,0.0016583334654569626,0.0016494194278493524,0.0016405885107815266,0.0016318325651809573,0.0016231272602453828,0.0016144838882610202,0.0016059408662840724,0.0015975171700119972,0.001589156687259674,0.0015808595344424248,0.0015725473640486598,0.0015634984010830522,0.0015545159112662077,0.001545618288218975,0.0015368335880339146,0.0015281513333320618,0.0015195640735328197,0.0015110740205273032,0.0015026784967631102,0.0014943759888410568,0.0014861602103337646,0.0014780255733057857,0.0014701647451147437,0.0014623402385041118,0.001453982898965478,0.001445663976483047,0.0014374215388670564,0.0014292079722508788,0.0014210782246664166,0.0014130338095128536,0.0014050763566046953,0.001397229265421629,0.0013894801959395409,0.0013818213483318686,0.0013742531882598996,0.0013667718740180135,0.0013593800831586123,0.001352078514173627,0.001344857388176024,0.0013376895803958178,0.0013306102482602,0.0013236189261078835,0.0013167074648663402,0.0013098715571686625,0.0013030760455876589,0.0012963362969458103,0.001289650215767324,0.0012830366613343358,0.0012765033170580864,0.0012700427323579788,0.001263534533791244,0.0012570461258292198,0.0012506445636972785,0.0012443234445527196,0.0012380911502987146,0.00123193662147969,0.0012258667265996337,0.0012198772747069597,0.0012139453319832683,0.0012080826563760638,0.0012029818026348948,0.0011980003910139203,0.001193071249872446,0.0011881929822266102,0.0011833627941086888,0.0011785777751356363,0.0011738394387066364,0.0011691390536725521,0.0011644968762993813,0.0011599136050790548,0.0011553827207535505,0.0011508989846333861,0.0011464584385976195,0.001142058172263205,0.001137697952799499,0.0011333742877468467,0.0011290855472907424,0.0011248335940763354,0.0011206152848899364,0.0011164231691509485,0.001112259109504521,0.0011081198463216424,0.001104004099033773,0.00109991489443928,0.001095842570066452,0.0010917717590928078,0.0010877209715545177,0.0010836889268830419,0.0010796751594170928,0.001075679436326027,0.0010717014083638787,0.001067740493454039,0.001063795411027968,0.0010598677909001708,0.0010559576330706477,0.001052062027156353,0.0010481819044798613,0.0010443174978718162,0.001040468574501574,0.0010366225615143776,0.0010327836498618126,0.001028951141051948,0.0010251326020807028,0.0010214530630037189,0.001017836038954556,0.0010142337996512651,0.0010106457630172372,0.0010070684365928173,0.0010034985607489944,0.0009999426547437906,0.0009964009514078498,0.0009928734507411718,0.000989360036328435,0.0009858584962785244,0.0009823685977607965,0.0009789270116016269,0.0009755139471963048,0.0009720716043375432,0.0009686442790552974,0.0009652120643295348,0.0009613920701667666,0.0009571095579303801,0.0009528633090667427,0.0009486509370617568,0.0009444753522984684,0.0009403379517607391,0.0009362550335936248,0.00093221222050488,0.0009282059036195278,0.0009242380037903786,0.0009203081135638058,0.000916415941901505,0.0009124792413786054,0.0009084377088584006,0.0009044342441484332,0.0009004676248878241,0.0008965394226834178,0.0008926496375352144,0.0008888058946467936,0.0008849742589518428,0.0008811274892650545,0.0008773177396506071,0.0008735464070923626,0.0008698104065842927,0.0008661121246404946,0.0008624507463537157,0.0008589053177274764,0.0008554477244615555,0.0008520254632458091,0.0008486367878504097,0.0008452823967672884,0.0008419598452746868,0.0008387285633943975,0.0008355047320947051,0.00083231768803671,0.0008291673730127513,0.0008260530885308981,0.0008229722734540701,0.0008199253934435546,0.0008169105276465416,0.0008139266283251345,0.0008109731716103852,0.0008080480620265007,0.0008051536860875785,0.0008022850379347801,0.0007994422921910882,0.0007966237608343363,0.0007938318885862827,0.0007910640561021864,0.0007883192738518119,0.0007855970761738718,0.0007828960078768432,0.000780215545091778,0.0007775495760142803,0.0007748952484689653,0.0007722548907622695,0.000769534963183105,0.0007667270256206393,0.0007639296818524599,0.0007611486362293363,0.0007583909900858998,0.0007556593045592308,0.0007529473514296114,0.0007502571679651737,0.0007475814200006425,0.0007449214463122189,0.0007422773633152246,0.000739648356102407,0.0007370294770225883,0.0007344201439991593,0.000731831300072372,0.0007292901282198727,0.0007267690380103886,0.0007242661667987704],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"lines\",\"name\":\"Test Variance\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[3.6111509799957275,3.616269588470459,3.623737096786499,3.631601095199585,3.639890432357788,3.6519882678985596,3.664191961288452,3.6762616634368896,3.6882126331329346,3.700043201446533,3.7117531299591064,3.7237801551818848,3.733177661895752,3.739185094833374,3.7451467514038086,3.7516024112701416,3.759030342102051,3.7663893699645996,3.7737526893615723,3.7809770107269287,3.7880609035491943,3.7950096130371094,3.802250623703003,3.810757637023926,3.8190834522247314,3.8267264366149902,3.834192991256714,3.841486930847168,3.8486053943634033,3.8555567264556885,3.8623406887054443,3.8689656257629395,3.8754360675811768,3.8817508220672607,3.8879151344299316,3.893925428390503,3.899789810180664,3.9055113792419434,3.91109037399292,3.916536569595337,3.9218502044677734,3.9264144897460938,3.930818557739258,3.935108184814453,3.9392964839935303,3.943385362625122,3.9473836421966553,3.9512972831726074,3.955129384994507,3.958888530731201,3.9625754356384277,3.9661953449249268,3.9701011180877686,3.9740476608276367,3.977919340133667,3.9817183017730713,3.985445022583008,3.98911190032959,3.9927172660827637,3.996267318725586,3.9999659061431885,4.003624439239502,4.00722599029541,4.010773181915283,4.01426887512207,4.017717361450195,4.021119117736816,4.024479389190674,4.027801990509033,4.031087398529053,4.034334182739258,4.037548065185547,4.0407257080078125,4.043873310089111,4.046987533569336,4.050070285797119,4.053122520446777,4.056142330169678,4.059131145477295,4.0620903968811035,4.065017223358154,4.06791353225708,4.070781230926514,4.07361364364624,4.076419830322266,4.079193592071533,4.081935882568359,4.084649085998535,4.087335109710693,4.089987277984619,4.092610836029053,4.095204830169678,4.097768783569336,4.100302219390869,4.102804660797119,4.105275630950928,4.107707500457764,4.110105037689209,4.11246919631958,4.114799976348877,4.117097854614258,4.11936092376709,4.121585845947266,4.123778343200684,4.125935077667236,4.128057956695557,4.13014554977417,4.132198810577393,4.134221076965332,4.136206150054932,4.1381635665893555,4.140084266662598,4.1419758796691895,4.143834590911865,4.145661354064941,4.14745569229126,4.149219989776611,4.150954723358154,4.152656555175781,4.154470443725586,4.156610012054443,4.158714771270752,4.16078519821167,4.162821292877197,4.164822101593018,4.1667914390563965,4.168725967407227,4.170629501342773,4.172501564025879,4.174341678619385,4.176151275634766,4.177929878234863,4.179679870605469,4.181398868560791,4.183088779449463,4.184751510620117,4.186387062072754,4.187991619110107,4.189570903778076,4.191123008728027,4.192646503448486,4.194145679473877,4.19561767578125,4.197063446044922,4.198486328125,4.199880599975586,4.201253414154053,4.202598571777344,4.203922748565674,4.205221176147461,4.20649528503418,4.207748889923096,4.208976745605469,4.210184574127197,4.209462642669678,4.2059326171875,4.202394008636475,4.198887348175049,4.195415496826172,4.1919732093811035,4.188565254211426,4.1851887702941895,4.181845188140869,4.178532123565674,4.175253391265869,4.171998977661133,4.168776512145996,4.165575981140137,4.162398815155029,4.159250736236572,4.156132698059082,4.153040885925293,4.149983882904053,4.146960258483887,4.143967628479004,4.14103364944458,4.13812780380249,4.135252475738525,4.132408618927002,4.129594326019287,4.126811981201172,4.124060153961182,4.121337413787842,4.1186442375183105,4.115981101989746,4.113349437713623,4.110745906829834,4.1081719398498535,4.105625629425049,4.103106498718262,4.100612163543701,4.098141193389893,4.095694541931152,4.093269348144531,4.0908637046813965,4.088476181030273,4.086108684539795,4.083760738372803,4.08143424987793,4.079126834869385,4.076840877532959,4.0745768547058105,4.072325229644775,4.070101737976074,4.06788969039917,4.065701484680176,4.063526630401611,4.061375141143799,4.05924129486084,4.057136535644531,4.055064678192139,4.05301570892334,4.050988674163818,4.048985481262207,4.047001838684082,4.045034885406494,4.043086051940918,4.041159629821777,4.039247512817383,4.037357330322266,4.035487174987793,4.033631324768066,4.0321125984191895,4.0307159423828125,4.02932596206665,4.027950286865234,4.026586055755615,4.025233268737793,4.023885250091553,4.022547721862793,4.021214008331299,4.019887924194336,4.018563747406006,4.017246723175049,4.015936851501465,4.014632701873779,4.013339996337891,4.012056827545166,4.010778427124023,4.0095109939575195,4.008252143859863,4.006999492645264,4.0057549476623535,4.004518032073975,4.003293037414551,4.002070903778076,4.000864028930664,3.9996657371520996,3.9985246658325195,3.9977827072143555,3.997044563293457,3.9963159561157227,3.995589256286621,3.9948713779449463,3.9941580295562744,3.9934518337249756,3.9927494525909424,3.9920523166656494,3.991516590118408,3.9917216300964355,3.991922616958618,3.9921202659606934,3.9923181533813477,3.9925129413604736,3.9927051067352295,3.99289870262146,3.9930901527404785,3.9932806491851807,3.9934773445129395,3.9936747550964355,3.993873357772827,3.994077682495117,3.9942805767059326,3.9944875240325928,3.994692802429199,3.9949045181274414,3.995112180709839,3.995321035385132,3.9955315589904785,3.9957430362701416,3.9959561824798584,3.9961702823638916,3.996386766433716,3.9966025352478027,3.9968209266662598,3.997039794921875,3.997258186340332,3.9972939491271973,3.996978759765625,3.996659517288208,3.996335983276367,3.9960098266601562,3.9957187175750732,3.995628595352173,3.995537519454956,3.9954466819763184,3.995359182357788,3.995272636413574,3.9951839447021484,3.9950947761535645,3.995008945465088,3.9949214458465576,3.9948339462280273,3.994749069213867,3.9946649074554443,3.9945805072784424,3.994499921798706,3.994417905807495,3.9943385124206543,3.994259834289551,3.9941794872283936,3.99410080909729,3.9940237998962402,3.9939444065093994,3.993868589401245,3.9937915802001953,3.993713855743408,3.993637800216675,3.993563413619995,3.9934890270233154,3.993415594100952,3.9933419227600098,3.9932687282562256,3.9931952953338623,3.9931228160858154,3.9930500984191895,3.9929749965667725,3.9929039478302,3.992830753326416,3.9927589893341064,3.9926857948303223,3.9926133155822754,3.992544174194336,3.9924700260162354,3.9924020767211914,3.9923312664031982,3.9922640323638916,3.9921958446502686,3.9921295642852783,3.992063283920288,3.9919962882995605,3.9919350147247314,3.991870164871216,3.9918100833892822,3.9917471408843994,3.991689682006836,3.9916293621063232,3.991572618484497,3.9915175437927246,3.991461753845215,3.991408348083496,3.991358518600464,3.9913063049316406,3.991257429122925,3.9912075996398926,3.991145133972168,3.991079330444336,3.9910175800323486,3.9909520149230957,3.9908928871154785,3.9908316135406494,3.9907727241516113,3.990715742111206,3.990659475326538,3.9906046390533447,3.990549325942993,3.9904956817626953,3.990443706512451,3.9903910160064697,3.990339756011963,3.9902939796447754,3.9902446269989014,3.99019718170166,3.9901511669158936,3.990105390548706,3.990061044692993,3.990017890930176,3.989976167678833,3.989936590194702,3.989899158477783,3.989861011505127,3.98982572555542,3.9897918701171875,3.9897565841674805,3.9897263050079346,3.989694118499756,3.98966383934021,3.9896464347839355,3.989638328552246,3.989631175994873,3.9896254539489746,3.989619016647339,3.9896135330200195,3.9896080493927,3.989607572555542,3.9896020889282227,3.9895989894866943,3.9895987510681152,3.989598512649536,3.989598035812378,3.989600419998169,3.9896018505096436,3.989603042602539,3.989607810974121,3.989612102508545,3.9896159172058105,3.9896199703216553,3.9896247386932373,3.9896321296691895,3.9896388053894043,3.9896459579467773,3.9896535873413086,3.9896609783172607,3.9896702766418457,3.9896790981292725,3.9896891117095947,3.98970103263855,3.9897093772888184,3.9897220134735107,3.989732027053833,3.9897453784942627,3.989758253097534,3.9897706508636475,3.9897842407226562,3.989797592163086,3.9897613525390625,3.9897172451019287,3.9896724224090576,3.989625930786133,3.989582061767578,3.989537239074707,3.9894933700561523,3.989447832107544,3.989403009414673,3.9893572330474854,3.989311695098877,3.989264488220215,3.9892172813415527,3.9891715049743652,3.9891250133514404,3.9890804290771484,3.9890365600585938,3.9889917373657227,3.9889488220214844,3.9889075756073,3.9888672828674316,3.9888267517089844,3.9887888431549072,3.9887502193450928,3.9887115955352783,3.9886772632598877,3.988640308380127,3.9886016845703125,3.9885623455047607,3.9885218143463135,3.9884848594665527,3.9884469509124756,3.9884092807769775,3.988373279571533,3.9883382320404053,3.9883029460906982,3.9882702827453613,3.988238573074341,3.9882102012634277,3.9881811141967773,3.9881553649902344,3.9881279468536377,3.9881021976470947,3.9880800247192383,3.9880566596984863,3.988035202026367,3.9880130290985107,3.9879934787750244,3.9879751205444336,3.9879579544067383,3.987940788269043,3.9879255294799805,3.9879109859466553,3.987898111343384,3.9878852367401123,3.987872362136841,3.9878621101379395,3.987851142883301,3.9878408908843994,3.9878320693969727,3.9878227710723877,3.9878129959106445,3.9878056049346924,3.9877994060516357,3.9877939224243164,3.9877891540527344,3.987785577774048,3.9877800941467285,3.9877758026123047,3.9877710342407227,3.987767457962036,3.987764596939087,3.987765073776245,3.9877631664276123,3.987762689590454],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"lines\",\"name\":\"Train MSE Loss\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[26.38118553161621,25.119956970214844,23.843137741088867,22.617589950561523,21.441434860229492,20.317380905151367,19.25048065185547,18.23116111755371,17.259647369384766,16.333370208740234,15.44994068145752,14.606287956237793,13.80316162109375,13.040449142456055,12.315731048583984,11.62990951538086,10.97881031036377,10.360380172729492,9.772809028625488,9.216672897338867,8.69102668762207,8.195794105529785,7.72838830947876,7.287272930145264,6.8712158203125,6.4791388511657715,6.1098198890686035,5.762641429901123,5.437394142150879,5.132013320922852,4.845222473144531,4.575770854949951,4.322934150695801,4.086055755615234,3.864368200302124,3.65693736076355,3.463118553161621,3.2821528911590576,3.113365650177002,2.9561073780059814,2.809758186340332,2.6732282638549805,2.546287775039673,2.4284703731536865,2.3192741870880127,2.218101739883423,2.1244051456451416,2.037780284881592,1.9578036069869995,1.8839930295944214,1.8159483671188354,1.7532508373260498,1.6954981088638306,1.6422475576400757,1.593145728111267,1.5479356050491333,1.506290078163147,1.4679319858551025,1.432584524154663,1.3999557495117188,1.3697896003723145,1.3419333696365356,1.3161364793777466,1.2922245264053345,1.270003080368042,1.249299168586731,1.2299726009368896,1.2118724584579468,1.194869875907898,1.1788604259490967,1.1637461185455322,1.1493908166885376,1.135717511177063,1.1226532459259033,1.110124945640564,1.0980695486068726,1.0864275693893433,1.075146198272705,1.064168930053711,1.0534793138504028,1.0430556535720825,1.0328729152679443,1.0229063034057617,1.0131434202194214,1.0035594701766968,0.9941442012786865,0.9848719239234924,0.9757319688796997,0.9667259454727173,0.9578428268432617,0.9490823149681091,0.9404368996620178,0.9319132566452026,0.9235060214996338,0.9152254462242126,0.9070726633071899,0.8990328907966614,0.8911091685295105,0.8833020329475403,0.8756057024002075,0.8680200576782227,0.860545814037323,0.8531829714775085,0.8459272384643555,0.8387796878814697,0.83174067735672,0.8248122334480286,0.8179857730865479,0.8112627863883972,0.804639458656311,0.7981158494949341,0.7916906476020813,0.7853524684906006,0.7791045904159546,0.7729493975639343,0.7668851017951965,0.760910153388977,0.7550229430198669,0.7492230534553528,0.743509829044342,0.737879753112793,0.7323391437530518,0.7268790602684021,0.7214996814727783,0.7161976099014282,0.7109704613685608,0.7058132886886597,0.7007246017456055,0.6957048773765564,0.6907609701156616,0.6858826279640198,0.6810690760612488,0.6763185858726501,0.6716302633285522,0.6670045256614685,0.6624391078948975,0.6579321026802063,0.653483510017395,0.6490922570228577,0.6447322368621826,0.6404134035110474,0.6361457109451294,0.6319282650947571,0.6277603507041931,0.623641848564148,0.619573175907135,0.6155522465705872,0.6115716099739075,0.6076326966285706,0.6037390828132629,0.5998899340629578,0.596084713935852,0.5923240184783936,0.5886070132255554,0.5849312543869019,0.5812975764274597,0.5777053833007812,0.5741541385650635,0.5706430673599243,0.5671703219413757,0.5637350678443909,0.5603381395339966,0.5569785833358765,0.5536555647850037,0.5503666400909424,0.5471089482307434,0.5438770055770874,0.5406726598739624,0.5375014543533325,0.5343653559684753,0.5312626957893372,0.5281965732574463,0.5251639485359192,0.5221636295318604,0.5191935896873474,0.5162541270256042,0.5133439898490906,0.5104634165763855,0.5076130032539368,0.5047915577888489,0.5019984841346741,0.49923378229141235,0.4964972138404846,0.49377328157424927,0.4910752475261688,0.4884030520915985,0.48575541377067566,0.483132928609848,0.48053601384162903,0.4779605567455292,0.47540605068206787,0.4728759825229645,0.4703703224658966,0.46788448095321655,0.46540936827659607,0.4629560708999634,0.4605248272418976,0.4581167995929718,0.455732136964798,0.4533693492412567,0.4510287046432495,0.448710173368454,0.4464150667190552,0.4441418945789337,0.4418843686580658,0.4396478533744812,0.43743452429771423,0.43524235486984253,0.43307259678840637,0.4309239387512207,0.428795725107193,0.4266883432865143,0.42460283637046814,0.4225339889526367,0.42048323154449463,0.4184509813785553,0.41643625497817993,0.4144333004951477,0.41244634985923767,0.4104744791984558,0.408517986536026,0.406578004360199,0.4046541154384613,0.40274617075920105,0.4008561074733734,0.3989812135696411,0.39711910486221313,0.3952714204788208,0.39343783259391785,0.3916154205799103,0.3898073434829712,0.38801276683807373,0.3862312138080597,0.3844641149044037,0.3827110230922699,0.3809725046157837,0.3792472183704376,0.37753432989120483,0.37583446502685547,0.374146968126297,0.3724724352359772,0.37080854177474976,0.3691568076610565,0.36751800775527954,0.3658912777900696,0.36427733302116394,0.36267608404159546,0.3610873222351074,0.3595083951950073,0.35793986916542053,0.3563818633556366,0.3548344671726227,0.35329920053482056,0.35177579522132874,0.3502637445926666,0.34876319766044617,0.3472742736339569,0.3457960784435272,0.3443293273448944,0.3428734540939331,0.3414282202720642,0.3399876654148102,0.33855676651000977,0.33713576197624207,0.33572348952293396,0.33431902527809143,0.332923948764801,0.3315364420413971,0.33014777302742004,0.3287680447101593,0.32739686965942383,0.3260347247123718,0.3246810734272003,0.3233363926410675,0.32200002670288086,0.3206722140312195,0.31935328245162964,0.31804388761520386,0.31674259901046753,0.3154454231262207,0.31415459513664246,0.3128722012042999,0.3115968108177185,0.3103301227092743,0.30907145142555237,0.307821124792099,0.3065798580646515,0.30534791946411133,0.30412158370018005,0.3028940260410309,0.30167368054389954,0.3004617393016815,0.29925766587257385,0.2980602979660034,0.29685866832733154,0.2956586480140686,0.2944658100605011,0.29327917098999023,0.2920974791049957,0.29092106223106384,0.2897520959377289,0.2885880172252655,0.2874302268028259,0.28627315163612366,0.2851158678531647,0.2839635908603668,0.282817006111145,0.28167685866355896,0.28054338693618774,0.2794175446033478,0.2782989740371704,0.27718740701675415,0.2760832905769348,0.2749866247177124,0.2738986313343048,0.2728169858455658,0.27174267172813416,0.27067577838897705,0.2696131467819214,0.26855772733688354,0.26750993728637695,0.2664681077003479,0.2654326856136322,0.26440420746803284,0.2633822560310364,0.26236405968666077,0.2613474726676941,0.26032960414886475,0.2593008875846863,0.2582694888114929,0.2572406828403473,0.25621166825294495,0.25518599152565,0.25416502356529236,0.2531486451625824,0.252137154340744,0.2511308789253235,0.2501288652420044,0.24913176894187927,0.24813960492610931,0.24715113639831543,0.24616612493991852,0.24518361687660217,0.2442057579755783,0.2432331144809723,0.24226340651512146,0.24129973351955414,0.24034135043621063,0.23938164114952087,0.23842544853687286,0.23747499287128448,0.23652973771095276,0.2355888932943344,0.23465129733085632,0.23371869325637817,0.23278965055942535,0.23186010122299194,0.2309316247701645,0.230006605386734,0.22908516228199005,0.2281670719385147,0.22725419700145721,0.2263462394475937,0.22544342279434204,0.22454574704170227,0.22365331649780273,0.22276650369167328,0.2218852937221527,0.22100970149040222,0.2201380431652069,0.21927188336849213,0.2184111475944519,0.21755602955818176,0.21670681238174438,0.2158634215593338,0.2150251567363739,0.21419022977352142,0.2133602350950241,0.21253524720668793,0.21171501278877258,0.2109004408121109,0.21009181439876556,0.2092883437871933,0.2084888517856598,0.2076936662197113,0.2069033831357956,0.20611777901649475,0.20533707737922668,0.2045615017414093,0.2037910521030426,0.2030259221792221,0.20226655900478363,0.20151229202747345,0.20076321065425873,0.20001868903636932,0.19927921891212463,0.19854478538036346,0.19781535863876343,0.19709154963493347,0.19637267291545868,0.19565875828266144,0.1949496865272522,0.19424548745155334,0.19354550540447235,0.1928495615720749,0.19215737283229828,0.19146840274333954,0.1907838135957718,0.19010503590106964,0.18943078815937042,0.1887616217136383,0.18809717893600464,0.1874372959136963,0.1867820769548416,0.1861310601234436,0.18548458814620972,0.18484245240688324,0.1842048019170761,0.18357139825820923,0.1829424649477005,0.18231837451457977,0.18169794976711273,0.18108026683330536,0.18046621978282928,0.17985625565052032,0.17924776673316956,0.17864128947257996,0.1780376136302948,0.1774369180202484,0.17683877050876617,0.1762438714504242,0.17565177381038666,0.17505992949008942,0.17447051405906677,0.17388346791267395,0.17329944670200348,0.17271852493286133,0.17214074730873108,0.171565443277359,0.17099180817604065,0.17042139172554016,0.16985410451889038,0.16928988695144653,0.16872896254062653,0.16817113757133484,0.16761662065982819,0.1670653074979782,0.16651704907417297,0.16597212851047516,0.16543033719062805,0.16489169001579285,0.16435618698596954,0.1638248711824417,0.16329754889011383,0.1627734750509262,0.16225263476371765,0.16173531115055084,0.16122134029865265,0.16071006655693054,0.16019900143146515,0.15969052910804749,0.15918488800525665,0.15868209302425385,0.15818224847316742,0.15768544375896454,0.15719161927700043,0.1567007154226303,0.15621285140514374,0.1557278335094452,0.155244842171669,0.15476466715335846,0.15428729355335236,0.15381285548210144,0.15334127843379974,0.15287263691425323,0.15240690112113953,0.15194393694400787,0.15148353576660156,0.1510256975889206,0.15057030320167542,0.15011711418628693,0.14966616034507751,0.14921750128269196,0.14877083897590637,0.1483267843723297,0.14788474142551422,0.14744499325752258,0.14700783789157867,0.14657168090343475,0.14613689482212067,0.14570380747318268,0.14527298510074615,0.14484462141990662,0.1444183886051178,0.14399386942386627,0.1435716450214386,0.14315101504325867,0.14273229241371155,0.14231587946414948,0.14190183579921722],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"mode\":\"lines\",\"name\":\"IS MSE\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204,2.8590493647419204],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"mode\":\"lines\",\"name\":\"Train MSE\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.23627685195787132,0.4759419603591482,0.48271777426717033,0.48960519665353214,0.49790974153574463,0.5054099585216507,0.5100337553801753,0.5150801457287151,0.5194442987999183,0.522399569501696,0.526055173943188,0.5295689919265629,0.53308455648058,0.5364017221627333,0.539778371846759,0.5424045343790624,0.5444050420644886,0.5465878154298178,0.5484688432700318,0.5501597047140325,0.5506875507920308,0.5511445294624215,0.551931748107858,0.5525315847142261,0.552796992138814,0.5517114065846815,0.5503714832901346,0.5491752226092717,0.5474137333634134,0.5458669063378189,0.5446987577274662,0.5437064930237313,0.5430563060287605,0.5427689520705883,0.5425412700045962,0.5426254241645029,0.5431458337072202,0.5436742771645757,0.544289658414561,0.5451066173089892,0.5462323443805729,0.5471534571730597,0.5481056548527108,0.549203138825671,0.5504720282422804,0.5517545784380533,0.5530670803619275,0.5544620606767522,0.5558223849522609,0.5571555430154216,0.5585208223508505,0.5599060538657338,0.5613249879633492,0.562678304657743,0.5639014432652798,0.5650439175921317,0.5664868564574167,0.5680127621215542,0.5694811247974355,0.5709278099262408,0.5723121115524672,0.5735523123848318,0.5747066242037357,0.575758924124686,0.5769480780961268,0.5780906571652444,0.5791410453325482,0.5801773085252891,0.5811082027289817,0.5819131104055116,0.5826439385330232,0.5832755420228639,0.5838058235018415,0.5842117516098791,0.5844834908055229,0.5846659012065077,0.584762256757468,0.5847802055642488,0.5847205899075378,0.5845872558043987,0.5843850316076727,0.5841168924021747,0.5837878692397426,0.5834037696420658,0.582969540922483,0.5824875703229238,0.5819669466901252,0.5814016558042626,0.5808615429813304,0.5802975424906188,0.5797084443752137,0.5790852087206281,0.5784375917424661,0.5777692159222779,0.5770753530787011,0.576359141628243,0.5756394517047777,0.574906109879329,0.5741511994801736,0.5734182423780866,0.5727049101637421,0.5719867466881318,0.5712679379029998,0.5707218296400224,0.5701998168550132,0.5696861710315552,0.5691685291098171,0.5686309122508274,0.5680794631444182,0.567555105204524,0.567061413379778,0.5665939070251332,0.5661320924863059,0.565675413052937,0.5652268150723144,0.5647898858294469,0.5643662001670889,0.563956912041647,0.563574040948312,0.5632066956502619,0.5628531116710118,0.5625424635461733,0.5622597935020663,0.5620014973366724,0.5617727487161455,0.5615620395171669,0.5613679420947087,0.5610962263282827,0.5608452553658344,0.5606197413857927,0.5604103088911849,0.5602279399213818,0.5600634940574185,0.5599161180411716,0.5597854672809698,0.5596700291557408,0.5596476657846486,0.5596400217616408,0.5596451684250425,0.5596707025955214,0.559710181302376,0.5597592063488257,0.5598185422657553,0.5598878235229012,0.5599660954831276,0.560053290509719,0.5601501246196158,0.5602564437180845,0.5603686097045201,0.5604888017680378,0.5606131183246279,0.5607428607232617,0.5608902431327617,0.561053557248129,0.5612392438089153,0.5614416284235383,0.5616765937894301,0.5619389810909854,0.5622087777993875,0.5624867542039267,0.5627759087173685,0.5630716243693648,0.5633735101308821,0.5636819363444484,0.563999190983695,0.5643213784322689,0.5646431953874386,0.5649693531743039,0.5652961323645902,0.5656201530445589,0.5659487210892493,0.5663064115284064,0.5666748599170403,0.5670565660386395,0.5674427984308881,0.5678310366030056,0.5682243363273398,0.5686205244965665,0.5690174118155767,0.5694150734835884,0.5698131908690467,0.5701831324415713,0.5705535440714276,0.5709969277967747,0.5714408645827465,0.5718772681351959,0.5723128046741918,0.5727472140960279,0.573181016828962,0.5736140994355721,0.5740460091734919,0.5744803824590248,0.5749188374799222,0.5753532934607107,0.575760783128019,0.5761643963921619,0.5765662318758236,0.5768131654008494,0.5769885054739279,0.5771567339970911,0.577325122857136,0.5774941225775522,0.5776668267586591,0.5778435006913809,0.5780142672613547,0.5781850419554039,0.5783413106142051,0.5784807972413064,0.578616718458184,0.5787531371509017,0.5788877589703575,0.5790085044465239,0.5791218865023243,0.5792434053114418,0.5793662488747634,0.5794903894734507,0.5796118054096808,0.5797042549615655,0.5797982669779711,0.5798895228144139,0.5799497342782545,0.5800072097911945,0.5800641352938537,0.5801167321003622,0.5801596637452529,0.580203040415634,0.580227985634513,0.5802530507101268,0.5802736140675329,0.5802908370287743,0.580303316914388,0.5803134445374254,0.5803237699910835,0.5803369720882321,0.580350559136532,0.5803648099564065,0.5803796420218661,0.5803432597489511,0.5802914261750066,0.5802396956250527,0.580187036336382,0.5801468329815329,0.580107360671725,0.5800678360923999,0.5800287439725251,0.579990797768627,0.5799559280538022,0.5799229445410307,0.5798929204529076,0.5798664835356365,0.5798419143316859,0.5798146860158877,0.5797877224845499,0.5797621029407611,0.5797385386329964,0.5797161559296676,0.5797037778526897,0.579698550800268,0.5796942924650292,0.5796893875776535,0.5796857900783824,0.5797209206394733,0.5797634401908426,0.5798053948935928,0.5798467935876938,0.5798893042034672,0.5799344520518662,0.5799796683964021,0.5800234821730389,0.5800650829513295,0.5801043500612446,0.5801413951801813,0.5801767483321449,0.5802106465710206,0.5802456271492825,0.580278873312202,0.5803111330456847,0.5803356941632477,0.5803569633610658,0.580391653305296,0.5804211791594126,0.5804481752637067,0.5804859301310598,0.5805205353076707,0.5805518959841035,0.5805804270205193,0.5806069591088373,0.5806321113129039,0.5806764405450688,0.580768873327548,0.5808599049743941,0.5809435545053494,0.5810251266486681,0.5811067385449681,0.5812258782276827,0.5813786405425119,0.5815267794675909,0.5816711711458752,0.5818176780306141,0.5819594217966046,0.5820901647135297,0.5822230713021586,0.5823570742810302,0.5824879809458339,0.5826160256981099,0.5827428338511633,0.5828684808474224,0.5829857856956555,0.583100079677677,0.5832123195830877,0.583324810239706,0.5834369719557795,0.5835471038151593,0.5836543089742315,0.5837632033202148,0.5838713825364221,0.5839825605737632,0.5841231361375703,0.584261420048337,0.5843987551324599,0.5845328138723048,0.5846646314082695,0.5847955707726484,0.5849257533303472,0.5850542085313103,0.5851804048411667,0.5853050695314678,0.585425252929546,0.5855562811344908,0.5856984899122886,0.5858496740455902,0.5859915136054741,0.5861324006699226,0.5862796317551152,0.5864248930211262,0.5865682250609434,0.5867095033130061,0.5868464358291611,0.5869800120682355,0.5871114090201318,0.587243477747952,0.5873795340610247,0.5875128339599104,0.587643411341371,0.5877722938373146,0.5879041499112634,0.5880331091129367,0.5881592954982674,0.5882810731127412,0.5883995094154989,0.588521430821087,0.5886343945936008,0.5887411026638071,0.5888454098899837,0.5889493337341425,0.5890510501540982,0.5891326148360347,0.5892007576205687,0.5892680721501042,0.5893389284973994,0.5894081245293638,0.5894741231118563,0.5895366276306799,0.589595496107992,0.5896537684065036,0.589710198737247,0.5897214275526095,0.5897272488817406,0.5897318708177792,0.5897362236169866,0.5897401044215019,0.5897439332886866,0.5897468200374569,0.5897480471328352,0.5897462972566432,0.5897439889624911,0.5897402754704976,0.5897355459450151,0.5897301050939647,0.5897240071690651,0.5897173662606355,0.5897104018033532,0.589703163613644,0.589694921913316,0.5896863251866135,0.5896779204312741,0.5896698524056474,0.5896621178470335,0.5896547611989666,0.5896477797694658,0.5896401922010688,0.5896304455792203,0.5896213191652584,0.5896128859757521,0.5896051283902435,0.5895981261898338,0.5895918847353451,0.5895864434503896,0.5895818410613972,0.5895780620496783,0.589574826345633,0.5895725825815511,0.5895711259265197,0.589570405176414,0.589570540135255,0.5895722555757957,0.5895750755819162,0.5895786965330454,0.5895831831702897,0.5895800866533547,0.5895747262796422,0.5895704381329825,0.5895672845042945,0.589565919231345,0.589567533693499,0.5895701109974316,0.5895737942906926,0.5895783663840273,0.5895841872920901,0.589590774677384,0.5895980082866586,0.5896050902378137,0.5896118235301258,0.5896129142075713,0.5896159291744659,0.5896222204861192,0.5896617143184526,0.5897395649587149,0.5898164970702231,0.5898902038067447,0.5899629518108943,0.590034267647737,0.5901119564485149,0.5901903487486823,0.5902722551749681,0.5903533024999441,0.5904329981544487,0.5905114559691262,0.5905792619781727,0.5906298942956074,0.590679079544786,0.5907271710697007,0.5907735351161624,0.5908183889145113,0.5908610417202168,0.5909050419229354,0.5909519248879133,0.5909975707163931,0.5910419691974758,0.5910857867900807,0.591128556423793,0.5911700539039952,0.5912072553950747,0.5912412200316031,0.5912741048212007,0.5913060968435333,0.5913375173297215,0.5913679859016618,0.5914035165534262,0.5914289327109529,0.5914519814680063,0.591473189400057,0.5914925785969548,0.5915104556080688,0.5915267578271818,0.59154173521656,0.5915554840168699,0.5915681124555485,0.5915798531838586,0.5915916191011422,0.591601521091027,0.5916093989157095,0.5916161556769245,0.5916195602973232,0.5916220784080013,0.5916239037235136,0.5916249899541396,0.5916259197898202,0.5916265380759678,0.5916277492940575,0.5916295620516934,0.5916319557756015,0.5916474652444949,0.5916776118211747,0.5917057309311601,0.5917318682120271,0.5917559447023495,0.591775860700172,0.5917943820602758,0.5918122783018629,0.5918294504066421,0.5918456361773116,0.5918617293008984,0.5918777461425698,0.5918945181125782,0.5919092376508617,0.591923193103537,0.5919441053582499,0.5919647860881558,0.5919853938281145],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"mode\":\"lines\",\"name\":\"Test MSE\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[6.030214840926681,5.991360750069655,5.957933233906928,5.9264324502548735,5.896900834678238,5.897711377914687,5.911758339909379,5.925900209289135,5.9400409335376665,5.954070912357178,5.967867443440232,5.982458572937597,5.992147042346992,5.995273624218981,5.9983276373258825,6.002307444130472,6.008104631894909,6.0138249294952875,6.019704469397057,6.025301199602179,6.030592424459027,6.035608569310181,6.041671317296069,6.0517456093359705,6.061442886128146,6.069816393202164,6.0778343105944,6.085149677566128,6.092043158682108,6.098630971625814,6.104919338328963,6.1109416364336315,6.1167067222704175,6.122224158355627,6.127514224630853,6.13258480513983,6.137452606935472,6.14213716946246,6.146654444443618,6.151028480522941,6.155263086883955,6.159217415879425,6.163057205990742,6.166793311563737,6.170459497003586,6.174056234305155,6.177600168197992,6.181125017174196,6.1846445434150725,6.188161618335908,6.1918520830128605,6.195641440625817,6.200120395560619,6.204836043231905,6.20957953509744,6.2143616269297395,6.219184294322195,6.224072136544356,6.229025013059536,6.234051376779524,6.239208210233826,6.244452518303305,6.2497825036432495,6.255200238804374,6.260710191050173,6.266316129171948,6.272015157849516,6.277817029530195,6.2837179134943275,6.289720668580529,6.2958147906303665,6.302004091529814,6.308280456122548,6.31464673936875,6.321091944196292,6.327611743181613,6.3342037237630695,6.340854679647732,6.347564810099607,6.354327817291319,6.361133089910073,6.367974761756831,6.374852732595,6.381744549766751,6.388663019039413,6.395588284190339,6.402516309820652,6.409447381554389,6.416377662251475,6.4232925257370725,6.430202360471112,6.437095321203927,6.443961460204464,6.450795912297847,6.457593796260597,6.464352412051875,6.47111981058779,6.477829709074359,6.4844829869847755,6.491073690161675,6.497600735043385,6.504056967613371,6.510433786122914,6.516738270619836,6.522961803231098,6.529108383876016,6.535168330635106,6.541145421904345,6.547042128231377,6.55284619385563,6.558572951426577,6.5642072786189205,6.569761127858982,6.575226844036536,6.580606739865784,6.585897236263781,6.591103569782074,6.596226097478734,6.601256886752592,6.606231761150442,6.611201898113068,6.616085039397108,6.620880074730395,6.625587660454115,6.6302067539852745,6.634743330222417,6.639192470505957,6.643562406239269,6.647858588288882,6.6520729700745544,6.656207659660298,6.6602628607162115,6.664244647272265,6.668149069462176,6.671977219903978,6.67573470681265,6.679422979956542,6.683035912029446,6.68658293797463,6.6900628552325205,6.6934726780394165,6.6968226849338475,6.700104692361624,6.703325648107617,6.706486586875826,6.709580991957186,6.712622777673981,6.715598154460551,6.718522833503125,6.721387479269943,6.724198786051952,6.726959027844062,6.729661417479502,6.732314677536164,6.731292116714334,6.724919493174623,6.71853005666905,6.712193081059365,6.705912906507519,6.699681233156028,6.693505819167671,6.687381506931193,6.681312712607545,6.675295510583027,6.66933518984346,6.663414928954736,6.657549104618404,6.651717895604941,6.645927223275757,6.640185789034456,6.634496018473765,6.628850313909409,6.623265481836388,6.617737805234285,6.612270109796258,6.606933439801627,6.601647029025552,6.596414727418592,6.591235961001457,6.586111782051615,6.581040805969039,6.576024560704774,6.571058598386514,6.5661456061415295,6.561289758632313,6.5564902153066615,6.551743606566738,6.5470520762079865,6.542410707472545,6.537818251654754,6.533271554241119,6.5287684159019985,6.524308279869376,6.51988677734961,6.515500495842723,6.511150213227296,6.506836332319073,6.502557615894084,6.49831743615851,6.494110425498299,6.489940433816943,6.485810141923904,6.481707032685694,6.477654964133931,6.47362169017424,6.469626994178153,6.465657413733073,6.461726643831689,6.457825992021304,6.453977962728198,6.450192987347869,6.446447004289912,6.442739780849093,6.439076156025914,6.4354444489891165,6.4318432598737045,6.428272532715141,6.424744645030826,6.421243375247265,6.417781490833221,6.414357803138366,6.410959955884305,6.408195202440446,6.405989355118307,6.403795464738261,6.4016263006341045,6.399476793038469,6.397345469123561,6.395221244183303,6.393112775857098,6.39100898161756,6.388915877596428,6.3868248050727985,6.38474174294878,6.382670358743983,6.380605552533755,6.37856111275441,6.376530728509318,6.374505230683787,6.372496682112165,6.37050049720966,6.368514290074947,6.366539233696743,6.364576314957889,6.362630555793123,6.3606899646791355,6.358772796026792,6.356869442087709,6.355068797484213,6.354000380579647,6.352937996666577,6.351891758400762,6.350845985307693,6.349812714040192,6.348787652328852,6.347771227104083,6.346760100216557,6.345756433443222,6.345049526516276,6.345712524535939,6.346365660641588,6.3470118436159435,6.347659771344273,6.34830098324303,6.348936687055139,6.349573131113726,6.35020454268375,6.350826987983724,6.351462261701597,6.352085110328686,6.352702598275522,6.353330972368704,6.353954291658971,6.35458316661391,6.3552074799123925,6.355840465737668,6.35646503958633,6.357092307946998,6.357719816562714,6.3583446509847175,6.358971923499073,6.359598719853134,6.360227203301205,6.360852074638487,6.361478137470755,6.36210397896815,6.362725711749373,6.363012296869966,6.362652369217207,6.362283255044966,6.361903249307465,6.361516954711547,6.361188443122215,6.3612119960932505,6.3612338647065725,6.36125450757055,6.361280691269448,6.361306364439837,6.361326227083948,6.361345615381097,6.36137054458138,6.361389406236146,6.361407536730486,6.361428292186605,6.361449031672551,6.361451928708931,6.3614601092733665,6.3614639264945065,6.361468166965333,6.361473857819197,6.361474212933144,6.361474771003193,6.361476265642449,6.361472442602436,6.361471463337016,6.361467091996806,6.361460539050035,6.361454188616326,6.361448040630879,6.361440426100202,6.361432298636539,6.361421732302194,6.361405773298976,6.36138590756142,6.361366996104017,6.361344911563583,6.361315306605078,6.361291956694268,6.36126279230213,6.361234324985369,6.361200024442805,6.361166439475325,6.361136192687299,6.361095068476786,6.361063812749067,6.361026026884672,6.36099181752918,6.360954453061488,6.360918262249061,6.360882071627741,6.360842230329986,6.360813248585064,6.36077628730723,6.360747030231517,6.360711976647923,6.360686076484541,6.360653645855244,6.360628461343571,6.360604212032087,6.360577779776062,6.3605559337355615,6.360539132092859,6.36051554273854,6.360497493308056,6.360476288498664,6.360457127153065,6.360433160380085,6.3604161830447286,6.360390987465592,6.360375899537592,6.3603549962119486,6.360339413472547,6.360324270435605,6.360309843023769,6.3602975805266375,6.360283373493994,6.360271569794633,6.36025923323547,6.360246915811182,6.360235295176916,6.360232828860079,6.360223116268164,6.360217513609751,6.36021334183218,6.360207206550319,6.360203236214881,6.360201926535964,6.360201313621491,6.3602035809535185,6.360211665070057,6.360215363684697,6.3602233919775415,6.360235787777578,6.36024308273187,6.360257587349502,6.36027018504153,6.360283956327657,6.360318678660796,6.360369307639059,6.360422359426995,6.360475374064428,6.360526205729581,6.360578725991601,6.360630512723279,6.3606887754343635,6.360738360794325,6.3607917995117,6.360848099926074,6.360904401014498,6.360958995773734,6.361017920797118,6.361073689891578,6.3611284868722695,6.361189798042315,6.361247695709407,6.361304382802201,6.361362043254088,6.361418950848741,6.3614784816208605,6.3615372977103375,6.3615943880600625,6.361651955772634,6.361707816795288,6.3617655856617965,6.361821409359783,6.361879160036837,6.361938818542851,6.3619904946404695,6.362049400434655,6.362102746280645,6.362160899293199,6.362217841429275,6.3622713692619275,6.36232829296958,6.362384244172382,6.362347270066457,6.362296552297324,6.362244384801921,6.362189813909342,6.362140803544532,6.362090105034192,6.3620403602054445,6.361988211979066,6.361938247965407,6.36188586133682,6.36183371313602,6.361779896014376,6.3617246099623515,6.3616736923101875,6.361622059407856,6.361573802794542,6.361527730373938,6.361481438746935,6.3614377889358025,6.361398011455521,6.361359922117361,6.361323063297368,6.361289561553187,6.3612560790267585,6.361221862035708,6.361194874467353,6.361164529833644,6.36112590602383,6.361082894598223,6.3610372221404745,6.360998063848433,6.360957217412905,6.360916609397776,6.360879139253199,6.360843357252675,6.360807336833686,6.360779080305749,6.360752511926867,6.360733688244705,6.3607141493260215,6.3607008861881145,6.360685219675543,6.360674160039958,6.360668145692679,6.360660939307529,6.360657109300639,6.3606532985936965,6.360653579548606,6.360655787175741,6.360660655984518,6.360665524895612,6.3606737702713705,6.3606827310192795,6.3606948298423776,6.360707663315292,6.360719027882839,6.360735218756938,6.360751429053083,6.3607668856914135,6.3607925874502,6.3608251580803294,6.3608572522426705,6.360892465519494,6.360931074970086,6.360971134672749,6.361011910068163,6.36105314340608,6.3611078963233645,6.361174861200627,6.3612398810731925,6.361306828694029,6.36137449261834,6.361446964753203,6.361515584469135,6.361585635744279],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.45],\"title\":{\"text\":\"Epoch\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.625,1.0],\"title\":{\"text\":\"Estimate\"}},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.55,1.0],\"title\":{\"text\":\"Epoch\"}},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.625,1.0],\"title\":{\"text\":\"Variance\"}},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.0,0.45],\"title\":{\"text\":\"Epoch\"}},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,0.375],\"title\":{\"text\":\"MSE Loss\"}},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.55,1.0],\"title\":{\"text\":\"Epoch\"}},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.0,0.375],\"title\":{\"text\":\"MSE\"}},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Estimate over Epochs\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Variance over Epochs\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Shaping Train MSE Loss over Epochs\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Total MSE over Epochs\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Metrics over Epochs\"},\"showlegend\":true},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('8414bc63-863c-43ec-8f4b-1515946b619f');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"ae9a33aa-ab15-494a-bec9-6f56f089b892\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"ae9a33aa-ab15-494a-bec9-6f56f089b892\")) {                    Plotly.newPlot(                        \"ae9a33aa-ab15-494a-bec9-6f56f089b892\",                        [{\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"z\":[[0.055948153138160706,0.060045916587114334,0.05716259032487869,0.04722787067294121,0.03726142644882202,0.02729497104883194,0.017328530550003052,0.007362067699432373,-0.0026043616235256195,-0.012570824474096298],[0.05035095661878586,0.06048576906323433,0.06274893879890442,0.0559733584523201,0.04665524140000343,0.037337109446525574,0.02801901288330555,0.01870087906718254,0.009382758289575577,6.464868783950806e-05],[0.04663404822349548,0.04815834015607834,0.05234150588512421,0.05497381091117859,0.05291709303855896,0.045465998351573944,0.03614788502454758,0.026829766109585762,0.017511650919914246,0.008193541318178177],[0.043442945927381516,0.038568686693906784,0.04547495022416115,0.04388255625963211,0.04651486501097679,0.046914272010326385,0.04308526962995529,0.03495865315198898,0.025640539824962616,0.01632240042090416],[0.03740215301513672,0.032264117151498795,0.035752903670072556,0.03793366998434067,0.03682921826839447,0.0380558967590332,0.040688205510377884,0.03708243370056152,0.033253416419029236,0.024451296776533127],[0.031361356377601624,0.02595953829586506,0.02925921231508255,0.03335569053888321,0.030064396560192108,0.030196059495210648,0.030777785927057266,0.03222927451133728,0.031079627573490143,0.02725059539079666],[0.02532055787742138,0.01965496689081192,0.022954627871513367,0.026254301890730858,0.027535106986761093,0.022981194779276848,0.023562902584671974,0.024144630879163742,0.024726344272494316,0.025076769292354584],[0.01927976682782173,0.01335039734840393,0.016650062054395676,0.019949715584516525,0.023249391466379166,0.019665811210870743,0.01634804904460907,0.016929779201745987,0.017511483281850815,0.018093198537826538],[0.013238970190286636,0.007045820355415344,0.01034548506140709,0.013645149767398834,0.01694481447339058,0.018541812896728516,0.011796530336141586,0.009714893996715546,0.010296598076820374,0.010878335684537888],[0.008575145155191422,0.0017254427075386047,0.004040911793708801,0.007340565323829651,0.010640230029821396,0.013939913362264633,0.010064821690320969,0.003927234560251236,0.0030817463994026184,0.003663472831249237]],\"type\":\"heatmap\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"Values\"},\"ticks\":\"outside\",\"tickvals\":[-0.012570824474096298,0.06274893879890442],\"ticktext\":[-0.012570824474096298,0.06274893879890442]}},\"xaxis\":{\"tickvals\":[0,1,2,3,4,5,6,7,8,9],\"ticktext\":[0,1,2,3,4,5,6,7,8,9],\"title\":{\"text\":\"X\"}},\"yaxis\":{\"tickvals\":[9,8,7,6,5,4,3,2,1,0],\"ticktext\":[9,8,7,6,5,4,3,2,1,0],\"title\":{\"text\":\"Y\"},\"autorange\":\"reversed\"},\"title\":{\"text\":\"Heatmap\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('ae9a33aa-ab15-494a-bec9-6f56f089b892');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"de3054eb-6379-4745-9bd4-d484d36b592b\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"de3054eb-6379-4745-9bd4-d484d36b592b\")) {                    Plotly.newPlot(                        \"de3054eb-6379-4745-9bd4-d484d36b592b\",                        [{\"colorbar\":{\"title\":{\"text\":\"Visits\"}},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"x\":[0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9],\"y\":[9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0],\"z\":[0,167,513,1244,2817,2719,2664,2379,1762,1813,0,285,806,2028,2259,0,931,1317,1167,1853,0,588,1611,1924,871,0,333,440,682,1811,0,1296,1514,765,321,0,84,142,252,440,0,1266,690,345,162,0,20,43,60,94,360,862,356,159,62,15,4,14,15,14,88,170,100,54,25,24,4,14,13,12,10,27,16,20,9,21,5,11,10,12,2,6,4,4,1,21,7,9,9,17,0,1,0,1,0,14,4,8,8,10],\"zmax\":2817,\"zmin\":0,\"type\":\"heatmap\"}],                        {\"title\":{\"text\":\"State Visitations Heatmap\"},\"xaxis\":{\"title\":{\"text\":\"X-axis\"}},\"yaxis\":{\"ticktext\":[9,8,7,6,5,4,3,2,1,0],\"tickvals\":[0,1,2,3,4,5,6,7,8,9],\"title\":{\"text\":\"Y-axis\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('de3054eb-6379-4745-9bd4-d484d36b592b');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000 trajectories:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"b23211a6-6ea2-4caa-84dd-a7243bfe128a\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"b23211a6-6ea2-4caa-84dd-a7243bfe128a\")) {                    Plotly.newPlot(                        \"b23211a6-6ea2-4caa-84dd-a7243bfe128a\",                        [{\"mode\":\"lines\",\"name\":\"IS Estimate\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789,1.358804702758789],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"Train Estimate\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[1.4164025783538818,0.9221543073654175,0.8945554494857788,0.8665988445281982,0.8393106460571289,0.8130905032157898,0.7897789478302002,0.7670372724533081,0.7447301149368286,0.7225669026374817,0.7011421918869019,0.6800812482833862,0.6600592136383057,0.6404150128364563,0.6209288835525513,0.6030488014221191,0.5854542851448059,0.5681960582733154,0.551064670085907,0.5344142913818359,0.5191377997398376,0.5049677491188049,0.4910719096660614,0.47737807035446167,0.46406659483909607,0.4502527415752411,0.43662598729133606,0.4232413172721863,0.4096077084541321,0.3982574939727783,0.38828250765800476,0.3787620961666107,0.36972400546073914,0.3608870804309845,0.3515909016132355,0.34246328473091125,0.3337419033050537,0.3251732885837555,0.3167423903942108,0.3085487484931946,0.3006034791469574,0.29290443658828735,0.28543806076049805,0.27824530005455017,0.271404504776001,0.2647431790828705,0.25828516483306885,0.2520955204963684,0.24612736701965332,0.24036477506160736,0.23479701578617096,0.22938527166843414,0.2241521179676056,0.21907643973827362,0.21401472389698029,0.20909245312213898,0.20437785983085632,0.1998881697654724,0.1953783929347992,0.1910509467124939,0.18686780333518982,0.1828841120004654,0.1790517121553421,0.17539522051811218,0.1715952754020691,0.16763879358768463,0.1638820916414261,0.1602846384048462,0.1568278670310974,0.15352152287960052,0.15036296844482422,0.14734482765197754,0.14446279406547546,0.14171278476715088,0.13908949494361877,0.13658982515335083,0.13420644402503967,0.13193346560001373,0.13004758954048157,0.12835337221622467,0.12675164639949799,0.1252351552248001,0.12380413711071014,0.12245441973209381,0.12117453664541245,0.11997656524181366,0.11886399239301682,0.11782558262348175,0.11682740598917007,0.11586689203977585,0.11496398597955704,0.11411074548959732,0.1133047342300415,0.11254294216632843,0.11181728541851044,0.11112182587385178,0.11045410484075546,0.10981348901987076,0.10917435586452484,0.10854949057102203,0.1079523041844368,0.10737162083387375,0.10679404437541962,0.10619459301233292,0.10560306161642075,0.10502314567565918,0.10443093627691269,0.10384110361337662,0.10327666997909546,0.1026913970708847,0.10211749374866486,0.10154567658901215,0.10094581544399261,0.10034509003162384,0.0997474417090416,0.09915085136890411,0.09855625033378601,0.09796911478042603,0.09739953279495239,0.09683439135551453,0.09626991301774979,0.09570576995611191,0.09513436257839203,0.09456323087215424,0.09399353712797165,0.09342463314533234,0.09285451471805573,0.092282235622406,0.09170469641685486,0.09112511575222015,0.09054483473300934,0.0899643823504448,0.08938334137201309,0.08880924433469772,0.08823675662279129,0.08765852451324463,0.08708109706640244,0.0865292027592659,0.08594150096178055,0.08535639941692352,0.08477476239204407,0.08420439809560776,0.0836351215839386,0.08306761085987091,0.08250259608030319,0.08193835616111755,0.08146236836910248,0.08099397271871567,0.08052553236484528,0.08005449175834656,0.07958393543958664,0.07911423593759537,0.0786542147397995,0.07819202542304993,0.0777311697602272,0.07727143913507462,0.07681220769882202,0.07641694694757462,0.07609333842992783,0.0757499560713768,0.07539286464452744,0.07503701001405716,0.07468196749687195,0.0743279755115509,0.07397840917110443,0.07363051921129227,0.07327727228403091,0.07292910665273666,0.0725829005241394,0.072238028049469,0.07189405709505081,0.07155166566371918,0.07115008682012558,0.07069592922925949,0.07024434953927994,0.06979450583457947,0.06934650242328644,0.06889831274747849,0.06845244020223618,0.06803622096776962,0.06762263178825378,0.06721160560846329,0.06680373847484589,0.06639833748340607,0.06599516421556473,0.0655955895781517,0.06519812345504761,0.0648031085729599,0.06441155076026917,0.06402286887168884,0.063637875020504,0.06325654685497284,0.06287255883216858,0.06248581036925316,0.062101226300001144,0.06175623834133148,0.06143011525273323,0.061105530709028244,0.060780663043260574,0.06049460917711258,0.0602150559425354,0.05994020402431488,0.059744447469711304,0.059567082673311234,0.05939073488116264,0.05921229347586632,0.059032078832387924,0.05885319039225578,0.058675333857536316,0.05849850922822952,0.05832343176007271,0.05814949795603752,0.05797639861702919,0.05782899260520935,0.05768370255827904,0.05753815174102783,0.05739032104611397,0.05724538117647171,0.057090021669864655,0.05692802742123604,0.05676386132836342,0.05659380555152893,0.056419432163238525,0.05624263361096382,0.05606662109494209,0.05589290335774422,0.05572504922747612,0.05556052178144455,0.05539674684405327,0.05523304268717766,0.05506954342126846,0.05490667000412941,0.05474450811743736,0.054570384323596954,0.05439691245555878,0.05422395095229149,0.05405155196785927,0.05390240624547005,0.053756166249513626,0.053616296499967575,0.053486064076423645,0.053355757147073746,0.0532253161072731,0.053095221519470215,0.052962012588977814,0.052820686250925064,0.05268004909157753,0.05254010111093521,0.05240065976977348,0.052262384444475174,0.0521269291639328,0.05199260264635086,0.051859673112630844,0.05172175168991089,0.05158298835158348,0.05144502595067024,0.05130762979388237,0.05117098242044449,0.051035325974226,0.05090364068746567,0.05077316239476204,0.0506429597735405,0.05049687623977661,0.05034598335623741,0.05020596832036972,0.05008381977677345,0.04996278136968613,0.04985272139310837,0.049747154116630554,0.04970186948776245,0.04968665912747383,0.049670539796352386,0.04965420067310333,0.04963747039437294,0.04962412640452385,0.049612853676080704,0.04960118606686592,0.04958892986178398,0.04957611486315727,0.0495651476085186,0.0495547279715538,0.04954373836517334,0.049531158059835434,0.04951778054237366,0.04950374364852905,0.0494869127869606,0.04946088418364525,0.049433983862400055,0.04940663278102875,0.04937856271862984,0.04935039207339287,0.049321066588163376,0.04929094389081001,0.04926075041294098,0.049267835915088654,0.04928022623062134,0.049291547387838364,0.04930312931537628,0.049312371760606766,0.04932050779461861,0.04932868480682373,0.0493357889354229,0.0493430532515049,0.049349721521139145,0.049353256821632385,0.04934544861316681,0.04933644086122513,0.04932695999741554,0.04931947588920593,0.04931293800473213,0.04930517449975014,0.04930168017745018,0.04929769039154053,0.049296244978904724,0.049293939024209976,0.049340322613716125,0.049428269267082214,0.049519989639520645,0.0496101975440979,0.04969901591539383,0.049784258008003235,0.04986586049199104,0.04994334280490875,0.05001948028802872,0.0500914603471756,0.05015862360596657,0.05021078884601593,0.05026537925004959,0.05032280087471008,0.05037911608815193,0.050434328615665436,0.050488293170928955,0.05054255202412605,0.05060150474309921,0.05065933242440224,0.05071578919887543,0.050770923495292664,0.050825610756874084,0.05087730288505554,0.05092555284500122,0.05097321420907974,0.051019053906202316,0.051037296652793884,0.05104140192270279,0.05104171112179756,0.051041148602962494,0.05104020610451698,0.05104105919599533,0.0510469414293766,0.05103817582130432,0.051019489765167236,0.05100468918681145,0.05099049583077431,0.050976332277059555,0.050961192697286606,0.05094514414668083,0.050929225981235504,0.05091356858611107,0.05089730769395828,0.05088089406490326,0.05086451396346092,0.05084812641143799,0.05083168298006058,0.050815582275390625,0.0507996566593647,0.050783589482307434,0.05076755955815315,0.05074971914291382,0.05072448030114174,0.05069916695356369,0.050673674792051315,0.050648052245378494,0.050622254610061646,0.05059627816081047,0.05057047680020332,0.05054440721869469,0.05051816254854202,0.05049163103103638,0.050463322550058365,0.05043361708521843,0.05040349066257477,0.05037382245063782,0.050346896052360535,0.050323039293289185,0.05030402913689613,0.05028623715043068,0.050268493592739105,0.05025314912199974,0.05023842304944992,0.050223805010318756,0.050209175795316696,0.050194352865219116,0.05017935857176781,0.05016430839896202,0.05014907568693161,0.050133999437093735,0.05011950805783272,0.05010474845767021,0.05008973181247711,0.0500742569565773,0.0500582754611969,0.05004167556762695,0.05002461373806,0.05000726133584976,0.049989473074674606,0.04997127503156662,0.04995272308588028,0.04993384703993797,0.04991455748677254,0.04989498108625412,0.049876242876052856,0.049857042729854584,0.049837395548820496,0.049817368388175964,0.04979698359966278,0.04977637156844139,0.0497564896941185,0.04973742365837097,0.04971734806895256,0.04969676956534386,0.04967568814754486,0.049654245376586914,0.04963288456201553,0.049614425748586655,0.04959617555141449,0.04957704246044159,0.04955755174160004,0.049537718296051025,0.04951222240924835,0.049483753740787506,0.04945288598537445,0.04941807687282562,0.04938429594039917,0.049350373446941376,0.049315501004457474,0.04927984997630119,0.04924817010760307,0.04921494796872139,0.04917902871966362,0.04912259802222252,0.049056366086006165,0.04898849129676819,0.04891886189579964,0.04884747043251991,0.048816386610269547,0.04878789559006691,0.048758614808321,0.04872896894812584,0.04868384450674057,0.04862535744905472,0.0485810823738575,0.048534929752349854,0.04849175736308098,0.048474229872226715,0.04845967888832092,0.04845799133181572,0.04846282675862312,0.0484774187207222,0.048501625657081604,0.04852641373872757,0.048550624400377274,0.04857317730784416,0.04859191179275513,0.04865175858139992,0.04871916025876999,0.04878610372543335,0.04885212704539299,0.04891626536846161,0.04900461435317993,0.04912666603922844,0.0492924302816391,0.04952231049537659,0.04977443069219589,0.05003530904650688,0.05045247822999954,0.051144789904356,0.052209608256816864,0.05342314392328262,0.05470595881342888,0.05588189512491226,0.056906506419181824,0.057814013212919235,0.05855363607406616,0.059194572269916534,0.059719715267419815,0.060080546885728836,0.06024929881095886,0.06024543568491936,0.06009858474135399,0.05984015017747879,0.059504393488168716,0.05912383273243904,0.05872881039977074,0.05834446847438812,0.057987406849861145,0.05767213925719261,0.057406604290008545,0.057194117456674576,0.05703616887331009,0.05693301558494568],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"Test Estimate\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[1.9384101629257202,1.9253109693527222,1.9128745794296265,1.900753140449524,1.8889843225479126,1.8853665590286255,1.8859964609146118,1.8866949081420898,1.8873952627182007,1.8880952596664429,1.8887476921081543,1.889148473739624,1.8885685205459595,1.8872829675674438,1.8859912157058716,1.884877324104309,1.8838505744934082,1.8828140497207642,1.8818185329437256,1.880785584449768,1.879708170890808,1.8785969018936157,1.877621054649353,1.877411961555481,1.877151608467102,1.8767468929290771,1.8762953281402588,1.8758028745651245,1.875162124633789,1.874469518661499,1.873749017715454,1.873006820678711,1.872244119644165,1.871464490890503,1.8706732988357544,1.8698722124099731,1.869065761566162,1.8682585954666138,1.8674542903900146,1.8666572570800781,1.8658695220947266,1.8652052879333496,1.8645740747451782,1.863959789276123,1.8633663654327393,1.8627976179122925,1.8622400760650635,1.86171293258667,1.8612219095230103,1.860761284828186,1.8603616952896118,1.8601007461547852,1.859948992729187,1.8598376512527466,1.8597700595855713,1.8597474098205566,1.8597723245620728,1.8598452806472778,1.8599697351455688,1.860109806060791,1.8602925539016724,1.8605289459228516,1.8608183860778809,1.861161470413208,1.8615587949752808,1.862012505531311,1.8625215291976929,1.8630857467651367,1.8637027740478516,1.8643715381622314,1.865090012550354,1.8658578395843506,1.8666725158691406,1.8675310611724854,1.8684320449829102,1.869373083114624,1.8703513145446777,1.8713657855987549,1.8724126815795898,1.8734883069992065,1.874589443206787,1.8757153749465942,1.8768625259399414,1.8780291080474854,1.8792130947113037,1.8804117441177368,1.8816273212432861,1.8828532695770264,1.884089469909668,1.8853331804275513,1.886582374572754,1.8878357410430908,1.889091968536377,1.89034903049469,1.8916056156158447,1.8928589820861816,1.8941080570220947,1.8953514099121094,1.896594524383545,1.8978326320648193,1.8990609645843506,1.9002796411514282,1.901487112045288,1.9026824235916138,1.903864860534668,1.905033826828003,1.906188726425171,1.907328486442566,1.9084539413452148,1.9095630645751953,1.9106571674346924,1.9117343425750732,1.9127953052520752,1.9138398170471191,1.9148668050765991,1.9158775806427002,1.916871428489685,1.9178472757339478,1.9188060760498047,1.9197474718093872,1.9206708669662476,1.9215757846832275,1.9224629402160645,1.9233314990997314,1.9241055250167847,1.9248524904251099,1.925583004951477,1.9262973070144653,1.9269952774047852,1.927678108215332,1.928346037864685,1.9289982318878174,1.9296364784240723,1.9302620887756348,1.9308744668960571,1.9314734935760498,1.9320582151412964,1.932631015777588,1.9331908226013184,1.9337377548217773,1.9342730045318604,1.934796690940857,1.9353082180023193,1.9358093738555908,1.936299204826355,1.9367783069610596,1.9372472763061523,1.9377058744430542,1.938154697418213,1.9385946989059448,1.9383792877197266,1.9376716613769531,1.9369628429412842,1.9362554550170898,1.935550332069397,1.9348466396331787,1.9341450929641724,1.9334383010864258,1.9327120780944824,1.9319887161254883,1.9312677383422852,1.9305498600006104,1.9298349618911743,1.9291234016418457,1.9284168481826782,1.9277148246765137,1.927016019821167,1.9263352155685425,1.925657868385315,1.9249851703643799,1.92431640625,1.9236512184143066,1.9229906797409058,1.9223339557647705,1.9216806888580322,1.921030879020691,1.920384407043457,1.919741153717041,1.9191027879714966,1.9184679985046387,1.9178378582000732,1.9172117710113525,1.9165900945663452,1.9159727096557617,1.9153590202331543,1.9147487878799438,1.9141429662704468,1.9135409593582153,1.9129455089569092,1.9123560190200806,1.911771535873413,1.911192774772644,1.9106181859970093,1.910048007965088,1.9094829559326172,1.9089226722717285,1.9083683490753174,1.907819151878357,1.9072755575180054,1.9067370891571045,1.9062050580978394,1.905678153038025,1.9051578044891357,1.9046406745910645,1.9041285514831543,1.9036204814910889,1.9031153917312622,1.9026148319244385,1.9021188020706177,1.901625156402588,1.9011362791061401,1.900650143623352,1.9001669883728027,1.8996872901916504,1.8992091417312622,1.8987330198287964,1.8983362913131714,1.8979730606079102,1.8976109027862549,1.8972522020339966,1.8969179391860962,1.8966511487960815,1.8963907957077026,1.8961328268051147,1.8958767652511597,1.8956226110458374,1.895370364189148,1.8951207399368286,1.8948724269866943,1.8946266174316406,1.8943819999694824,1.8942111730575562,1.8940843343734741,1.8939584493637085,1.893832802772522,1.8937082290649414,1.8935837745666504,1.8934597969055176,1.8934868574142456,1.893608808517456,1.8937302827835083,1.8938502073287964,1.8939685821533203,1.8940858840942383,1.8942025899887085,1.8943183422088623,1.894432783126831,1.8945461511611938,1.8946584463119507,1.894769549369812,1.8948806524276733,1.894991397857666,1.89510178565979,1.8952113389968872,1.895321249961853,1.8954312801361084,1.8955402374267578,1.8956478834152222,1.895755410194397,1.8958613872528076,1.8959673643112183,1.8960726261138916,1.8961772918701172,1.89628005027771,1.8963816165924072,1.896483063697815,1.8965519666671753,1.8965176343917847,1.8964835405349731,1.8964776992797852,1.8965014219284058,1.8965251445770264,1.8965495824813843,1.8965742588043213,1.8965990543365479,1.896624207496643,1.8966490030288696,1.8966734409332275,1.896697998046875,1.8967223167419434,1.896746039390564,1.8967695236206055,1.8967921733856201,1.8968144655227661,1.896836519241333,1.8968573808670044,1.896878957748413,1.8968992233276367,1.8969193696975708,1.896938681602478,1.8969573974609375,1.8969757556915283,1.8969935178756714,1.8970106840133667,1.8970271348953247,1.89704430103302,1.8970619440078735,1.8970763683319092,1.897091031074524,1.8971056938171387,1.8971197605133057,1.8971339464187622,1.8971474170684814,1.8971611261367798,1.8971742391586304,1.8971867561340332,1.8971987962722778,1.8972097635269165,1.897221326828003,1.8972324132919312,1.897242546081543,1.8972529172897339,1.8972629308700562,1.8972722291946411,1.8972814083099365,1.897290587425232,1.8972996473312378,1.897309422492981,1.8973191976547241,1.8973299264907837,1.8973407745361328,1.8973515033721924,1.897362470626831,1.897373080253601,1.8973838090896606,1.8973942995071411,1.8974043130874634,1.897415041923523,1.897424578666687,1.897434949874878,1.897444486618042,1.8974536657333374,1.8974628448486328,1.8974716663360596,1.8974804878234863,1.8974888324737549,1.897497296333313,1.897505283355713,1.8975129127502441,1.897520661354065,1.897528886795044,1.897537112236023,1.897545337677002,1.8975536823272705,1.8975613117218018,1.897569179534912,1.8975768089294434,1.897584319114685,1.8975915908813477,1.8975988626480103,1.8976062536239624,1.897613286972046,1.8976212739944458,1.897629737854004,1.8976378440856934,1.8976469039916992,1.8976554870605469,1.8976647853851318,1.897674560546875,1.8976837396621704,1.8976939916610718,1.8977042436599731,1.8977144956588745,1.897724986076355,1.8977349996566772,1.8977457284927368,1.8977556228637695,1.8977665901184082,1.8977775573730469,1.897788643836975,1.8977998495101929,1.8978111743927002,1.897822618484497,1.8978345394134521,1.8978461027145386,1.8978582620620728,1.89786958694458,1.8978840112686157,1.8978997468948364,1.8979154825210571,1.8979308605194092,1.8979464769363403,1.8979651927947998,1.8979835510253906,1.8980019092559814,1.8980201482772827,1.8980388641357422,1.8980566263198853,1.898074984550476,1.8980929851531982,1.8981109857559204,1.898128867149353,1.8981462717056274,1.8981645107269287,1.898181438446045,1.8981984853744507,1.8982157707214355,1.8982328176498413,1.8982502222061157,1.898267149925232,1.8982839584350586,1.8983004093170166,1.8983172178268433,1.8983335494995117,1.898349642753601,1.89836585521698,1.8983821868896484,1.89839768409729,1.8984136581420898,1.8984291553497314,1.8984445333480835,1.8984594345092773,1.898473858833313,1.8984886407852173,1.8985029458999634,1.8985167741775513,1.8985310792922974,1.8985449075698853,1.898558259010315,1.8985718488693237,1.8985852003097534,1.8985986709594727,1.8986115455627441,1.8986244201660156,1.898637294769287,1.8986501693725586,1.8986629247665405,1.8986749649047852,1.8986878395080566,1.8987003564834595,1.8987131118774414,1.898726224899292,1.8987394571304321,1.8987526893615723,1.8987669944763184,1.8987810611724854,1.8987927436828613,1.8988046646118164,1.8988159894943237,1.8988282680511475,1.8988412618637085,1.8988547325134277,1.8988687992095947,1.89888334274292,1.8988988399505615,1.8989144563674927,1.8989300727844238,1.8989471197128296,1.898964285850525,1.8989810943603516,1.8989989757537842,1.8990169763565063,1.8990349769592285,1.8990533351898193,1.899071455001831,1.8990906476974487,1.8991093635559082,1.8991286754608154,1.8991469144821167,1.8991658687591553,1.8991845846176147,1.8992036581039429,1.899222493171692,1.8992412090301514,1.899260401725769,1.8992785215377808,1.8992974758148193,1.8993161916732788,1.8993347883224487,1.8993529081344604,1.8993709087371826,1.8993890285491943,1.8994070291519165,1.8994250297546387,1.8994413614273071,1.8994578123092651,1.8994746208190918,1.899490237236023,1.8995062112808228,1.899521827697754,1.8995373249053955,1.8995519876480103,1.8995670080184937,1.8995811939239502,1.8995964527130127,1.8996148109436035,1.8996341228485107,1.8996539115905762,1.8996741771697998,1.899694561958313,1.8997151851654053,1.8997365236282349,1.8997572660446167,1.8997762203216553,1.8997955322265625,1.8998148441314697,1.8998351097106934,1.8998546600341797,1.8998751640319824,1.8998953104019165],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"On-policy Estimate\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959,0.818985692663959],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"IS Variance\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583,1.3015061616897583],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"lines\",\"name\":\"Train Variance\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.3713134825229645,0.2799197733402252,0.26687511801719666,0.2545326054096222,0.24295207858085632,0.23178690671920776,0.2211463749408722,0.2112947404384613,0.20188508927822113,0.1925770789384842,0.18361184000968933,0.1750931292772293,0.16696982085704803,0.15912380814552307,0.1516457498073578,0.1445942223072052,0.13769303262233734,0.13098092377185822,0.12452905625104904,0.11844160407781601,0.1130576878786087,0.10792441666126251,0.10303980112075806,0.09836544096469879,0.0939534455537796,0.08991118520498276,0.08610609173774719,0.08252890408039093,0.07918738573789597,0.07652857899665833,0.07427782565355301,0.07213890552520752,0.07010456174612045,0.06824585050344467,0.06634938716888428,0.06450389325618744,0.06271528452634811,0.06101512536406517,0.059399548918008804,0.057863425463438034,0.05640460550785065,0.05503101274371147,0.05372815206646919,0.05249578133225441,0.05135956034064293,0.050269484519958496,0.049229834228754044,0.04825527220964432,0.047333355993032455,0.04645657539367676,0.04562199115753174,0.044828202575445175,0.04407144710421562,0.04333881661295891,0.042612750083208084,0.04191463440656662,0.04124400392174721,0.04059876874089241,0.03998163715004921,0.03939014673233032,0.038824133574962616,0.03828088194131851,0.03775838762521744,0.037255290895700455,0.0366712287068367,0.03600268065929413,0.03535318002104759,0.03472570329904556,0.03411896154284477,0.033531881868839264,0.03296348825097084,0.03241272270679474,0.03187866881489754,0.0313604436814785,0.030857060104608536,0.030367789790034294,0.029891913756728172,0.029428713023662567,0.029051704332232475,0.028708454221487045,0.028373099863529205,0.02804514393210411,0.027724290266633034,0.027410095557570457,0.027102263644337654,0.026798812672495842,0.026498930528759956,0.026203352957963943,0.02591155283153057,0.025624960660934448,0.025343049317598343,0.025065604597330093,0.0247925017029047,0.02452360838651657,0.024258747696876526,0.023998014628887177,0.023741142824292183,0.023487940430641174,0.02323121763765812,0.02297581173479557,0.022723423317074776,0.022474084049463272,0.022228114306926727,0.02198575995862484,0.02174682356417179,0.021511157974600792,0.02127922885119915,0.02105056680738926,0.020824823528528214,0.020601492375135422,0.020381087437272072,0.020163509994745255,0.019948530942201614,0.01973632723093033,0.019526882097125053,0.019320417195558548,0.019116709008812904,0.0189171452075243,0.018723418936133385,0.018532127141952515,0.018343476578593254,0.018157275393605232,0.01797347143292427,0.01779196411371231,0.01761263981461525,0.01743544451892376,0.017260108143091202,0.017086278647184372,0.016913453117012978,0.01674254797399044,0.01657354086637497,0.01640639454126358,0.016241125762462616,0.01607895828783512,0.015918921679258347,0.015760714188218117,0.01560434140264988,0.015450229868292809,0.015297879464924335,0.015147148631513119,0.014998131431639194,0.014850812032818794,0.014705230481922626,0.014561360701918602,0.014419184997677803,0.014278674498200417,0.014132335782051086,0.013986959122121334,0.01384326908737421,0.01370123028755188,0.013560847379267216,0.013422531075775623,0.013287585228681564,0.013154244981706142,0.013022493571043015,0.01289229467511177,0.012763658538460732,0.012636322528123856,0.01251561101526022,0.012397591024637222,0.012280881404876709,0.01216552872210741,0.012051508761942387,0.011938817799091339,0.011827039532363415,0.011715970933437347,0.011605252511799335,0.011495757848024368,0.011387493461370468,0.011280461214482784,0.011174660176038742,0.011070066131651402,0.010971126146614552,0.010877243243157864,0.010784408077597618,0.0106925955042243,0.010601789690554142,0.0105119738727808,0.01042329240590334,0.010339630767703056,0.010256885550916195,0.010175053030252457,0.010094113647937775,0.010014066472649574,0.009934901259839535,0.009856609627604485,0.009778879582881927,0.009701552800834179,0.009625127539038658,0.009549601003527641,0.00947496946901083,0.009401176124811172,0.009328204207122326,0.009255676530301571,0.009183854795992374,0.009115256369113922,0.009047801606357098,0.008980697020888329,0.00891425646841526,0.00885342713445425,0.00879344530403614,0.008734062314033508,0.008680055849254131,0.008627329021692276,0.008575097657740116,0.008523350581526756,0.008472162298858166,0.00842149369418621,0.00837134663015604,0.008321701548993587,0.008272523060441017,0.008223810233175755,0.008175534196197987,0.008127695880830288,0.0080802533775568,0.008033212274312973,0.007986707612872124,0.007940690964460373,0.007895971648395061,0.007852248847484589,0.007808891125023365,0.007765855640172958,0.007723200134932995,0.007680998183786869,0.0076391734182834625,0.007597740273922682,0.007556724362075329,0.007516071200370789,0.007475773338228464,0.007435834035277367,0.007396237924695015,0.007356977090239525,0.007318052463233471,0.007279495242983103,0.007241255138069391,0.007203321438282728,0.007165694609284401,0.0071312300860881805,0.00709759583696723,0.007064080331474543,0.007030649576336145,0.0069974325597286224,0.006964432541280985,0.006931651849299669,0.006899118423461914,0.006866844370961189,0.006834819912910461,0.006803047377616167,0.006771525833755732,0.006740101147443056,0.006708723027259111,0.00667764013633132,0.006646826397627592,0.0066161444410681725,0.006585733033716679,0.006555573549121618,0.00652565760537982,0.006495985668152571,0.006466551683843136,0.006437439471483231,0.006408563815057278,0.0063798921182751656,0.006351279094815254,0.006322667468339205,0.006294215563684702,0.0062658656388521194,0.006237656809389591,0.006209647748619318,0.006181820295751095,0.006150688976049423,0.006117869168519974,0.006085237953811884,0.006052796263247728,0.006020545028150082,0.005988495424389839,0.005956640932708979,0.005924994125962257,0.005893546622246504,0.005862302612513304,0.005831231363117695,0.005800345912575722,0.005769675597548485,0.005739219952374697,0.005708960350602865,0.005678893998265266,0.005649050697684288,0.005619474686682224,0.005590152461081743,0.005561063066124916,0.005532181356102228,0.005503504071384668,0.0054750447161495686,0.005446784198284149,0.005418720189481974,0.005393959581851959,0.005370051134377718,0.005346375983208418,0.0053228833712637424,0.00529957190155983,0.005276423413306475,0.005253439303487539,0.005230601876974106,0.005207919515669346,0.005185390822589397,0.005162942688912153,0.005140306893736124,0.0051177809946238995,0.005095370579510927,0.005073084495961666,0.005050919950008392,0.005028871353715658,0.005006946623325348,0.004985144827514887,0.004963377956300974,0.004941748920828104,0.004924663808196783,0.004911114927381277,0.004897996783256531,0.004884948022663593,0.004871963057667017,0.0048590414226055145,0.004846176598221064,0.004833372309803963,0.0048206220380961895,0.004807644989341497,0.00479439040645957,0.004780731629580259,0.004767102189362049,0.0047535160556435585,0.004739989526569843,0.004726520273834467,0.004713099449872971,0.00469973124563694,0.004686384927481413,0.0046730851754546165,0.004659805912524462,0.004646556451916695,0.004633334930986166,0.004620138555765152,0.0046069566160440445,0.004593814257532358,0.00458073616027832,0.004565325099974871,0.004549046047031879,0.00453295698389411,0.004516916815191507,0.004500929266214371,0.004485148936510086,0.0044700647704303265,0.0044550709426403046,0.004440175835043192,0.004425361752510071,0.004410625901073217,0.0043959664180874825,0.00438137911260128,0.00436687096953392,0.0043524387292563915,0.0043380833230912685,0.004323803354054689,0.004309593699872494,0.004295459948480129,0.004281393252313137,0.004267397336661816,0.004253465682268143,0.004239601083099842,0.004225802607834339,0.004212066996842623,0.004198276437819004,0.0041840034537017345,0.004169797990471125,0.004155648406594992,0.004141557030379772,0.0041275229305028915,0.004113545175641775,0.004099624697118998,0.004085757303982973,0.0040719457902014256,0.004058184567838907,0.004044482484459877,0.004030852112919092,0.0040172855369746685,0.004003786947578192,0.003990321420133114,0.003976890351623297,0.003963518887758255,0.003950227051973343,0.003937012515962124,0.003923873417079449,0.003910808824002743,0.0038978152442723513,0.0038848950061947107,0.003872040892019868,0.0038592536002397537,0.003846536623314023,0.003833883674815297,0.0038212977815419436,0.0038087747525423765,0.0037963194772601128,0.0037839252036064863,0.0037715681828558445,0.0037592488806694746,0.003746969159692526,0.003734724363312125,0.003722523106262088,0.0037103602662682533,0.0036982372403144836,0.003686155192553997,0.003674115287140012,0.003662117524072528,0.0036501616705209017,0.003638260066509247,0.003626396879553795,0.0036145769990980625,0.0036027978640049696,0.0035910599399358034,0.003579363925382495,0.003567709121853113,0.0035560692194849253,0.0035444474779069424,0.0035328450612723827,0.0035212638322263956,0.003509707050397992,0.003498179605230689,0.003486677072942257,0.003475214121863246,0.0034637893550097942,0.0034523990470916033,0.003441047156229615,0.003429729724302888,0.0034184230025857687,0.003407110460102558,0.003395800245925784,0.003384646959602833,0.003373528830707073,0.003362433286383748,0.00335137196816504,0.003340106224641204,0.003328811377286911,0.003317497903481126,0.0033064286690205336,0.003295496106147766,0.003284553997218609,0.0032736235298216343,0.0032626932952553034,0.0032515141647309065,0.0032402558717876673,0.003228948451578617,0.0032176210079342127,0.0032062504906207323,0.0031946375966072083,0.0031828079372644424,0.0031709775794297457,0.003158960025757551,0.003146827220916748,0.0031346098985522985,0.003122424241155386,0.003110261866822839,0.003098134882748127,0.003086414886638522,0.003074939828366041,0.0030637055169790983,0.0030527140479534864,0.0030419626273214817,0.003031342988833785,0.0030208348762243986,0.003010449931025505,0.0030001942068338394,0.002990101696923375,0.0029802212957292795,0.0029715781565755606,0.0029632740188390017,0.0029551342595368624,0.002946886932477355,0.0029384957160800695,0.0029301235917955637,0.0029219784773886204,0.0029071979224681854,0.002891033422201872,0.0028740577399730682,0.002856191713362932,0.002838223474100232,0.0028221250977367163,0.0028079566545784473,0.0027957011479884386,0.0027851946651935577,0.0027765638660639524,0.002769815968349576,0.0027647106908261776,0.0027609984390437603,0.002758404240012169,0.002756640315055847,0.0027554198168218136,0.0027544477488845587,0.0027534980326890945,0.0027523182798177004,0.00275071756914258,0.002748546889051795,0.002745657227933407,0.002742018783465028,0.0027376709040254354],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"lines\",\"name\":\"Test Variance\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[2.348453998565674,2.3518576622009277,2.3567709922790527,2.3619463443756104,2.367441415786743,2.375441074371338,2.3834590911865234,2.391392707824707,2.3992607593536377,2.407043933868408,2.4147491455078125,2.4226114749908447,2.428246021270752,2.4321179389953613,2.435959577560425,2.4404563903808594,2.4452900886535645,2.450070858001709,2.454859495162964,2.4595584869384766,2.464163064956665,2.468681812286377,2.4733171463012695,2.478846549987793,2.484255790710449,2.489229917526245,2.494081735610962,2.4988229274749756,2.5034515857696533,2.5079736709594727,2.5123894214630127,2.51670241355896,2.5209128856658936,2.5250258445739746,2.5290422439575195,2.5329606533050537,2.5367839336395264,2.5405147075653076,2.5441558361053467,2.547710657119751,2.551179885864258,2.5541939735412598,2.5570669174194336,2.5598700046539307,2.562605619430542,2.5652804374694824,2.5678956508636475,2.57045578956604,2.572965621948242,2.5754261016845703,2.5778396129608154,2.5802884101867676,2.582927703857422,2.585515022277832,2.5880520343780518,2.5905392169952393,2.592982292175293,2.595381498336792,2.597743272781372,2.6001880168914795,2.602625846862793,2.605022668838501,2.6073806285858154,2.6097018718719482,2.6119885444641113,2.6142470836639404,2.6164793968200684,2.618687391281128,2.6208691596984863,2.6230275630950928,2.6251614093780518,2.627274513244629,2.6293656826019287,2.6314361095428467,2.6334848403930664,2.6355130672454834,2.637521743774414,2.6395106315612793,2.6414780616760254,2.643423080444336,2.64534068107605,2.6472384929656982,2.6491098403930664,2.6509594917297363,2.652787208557129,2.6545910835266113,2.6563708782196045,2.658128261566162,2.659864902496338,2.6615800857543945,2.6632721424102783,2.66494083404541,2.6665892601013184,2.66821551322937,2.6698219776153564,2.6714041233062744,2.672963857650757,2.67450213432312,2.6760127544403076,2.6775033473968506,2.6789698600769043,2.6804165840148926,2.681840658187866,2.6832427978515625,2.684624433517456,2.6859846115112305,2.6873226165771484,2.688638925552368,2.6899352073669434,2.691209077835083,2.6924631595611572,2.6936957836151123,2.694908857345581,2.6961019039154053,2.697272777557373,2.6984245777130127,2.6995577812194824,2.700667381286621,2.7017576694488525,2.702828884124756,2.7038791179656982,2.7049055099487305,2.7059133052825928,2.7068984508514404,2.708125352859497,2.7093665599823,2.7105839252471924,2.711779832839966,2.712953805923462,2.714106321334839,2.7152390480041504,2.716348648071289,2.717440128326416,2.7185096740722656,2.71955943107605,2.7205913066864014,2.72160267829895,2.72259783744812,2.7235753536224365,2.7245333194732666,2.7254750728607178,2.726400375366211,2.7273080348968506,2.7281999588012695,2.7290751934051514,2.7299346923828125,2.730778217315674,2.731605052947998,2.7324166297912598,2.733215093612671,2.732149362564087,2.729710817337036,2.7272884845733643,2.724882125854492,2.7224936485290527,2.7201199531555176,2.7177624702453613,2.7153990268707275,2.7129881381988525,2.71059513092041,2.708220958709717,2.705864191055298,2.703526258468628,2.7012076377868652,2.6989049911499023,2.69661808013916,2.694350004196167,2.6921207904815674,2.6899101734161377,2.6877188682556152,2.6855478286743164,2.6833927631378174,2.6812586784362793,2.6791436672210693,2.677046775817871,2.67496657371521,2.6729037761688232,2.670856475830078,2.6688270568847656,2.6668143272399902,2.6648194789886475,2.662841796875,2.6608810424804688,2.65893816947937,2.6570093631744385,2.6550991535186768,2.653205633163452,2.651326894760132,2.649467706680298,2.647627115249634,2.6458024978637695,2.643995761871338,2.6422042846679688,2.640430450439453,2.638671875,2.636928081512451,2.635202407836914,2.633491039276123,2.6317975521087646,2.630120038986206,2.628462076187134,2.626821756362915,2.625201463699341,2.623605489730835,2.6220269203186035,2.6204628944396973,2.6189091205596924,2.6173696517944336,2.6158440113067627,2.6143293380737305,2.6128287315368652,2.6113390922546387,2.609861135482788,2.608395576477051,2.606938362121582,2.6054892539978027,2.604048728942871,2.6026179790496826,2.6011955738067627,2.5997862815856934,2.5984649658203125,2.5973808765411377,2.5963099002838135,2.595248222351074,2.5941953659057617,2.5931508541107178,2.592113971710205,2.5910868644714355,2.590066909790039,2.5890562534332275,2.5880515575408936,2.587278366088867,2.5866453647613525,2.5860164165496826,2.585392475128174,2.5847740173339844,2.5841588973999023,2.583548069000244,2.583402395248413,2.583549976348877,2.5836989879608154,2.5838444232940674,2.5839896202087402,2.5841329097747803,2.5842742919921875,2.5844106674194336,2.5845460891723633,2.5846786499023438,2.584810733795166,2.584940195083618,2.5850701332092285,2.5851988792419434,2.585326910018921,2.5854547023773193,2.5855815410614014,2.585709571838379,2.5858356952667236,2.5859596729278564,2.586085796356201,2.586207151412964,2.586331605911255,2.5864548683166504,2.586578607559204,2.586702823638916,2.5868310928344727,2.586961030960083,2.5869975090026855,2.586728572845459,2.5864596366882324,2.5862767696380615,2.5861847400665283,2.586091995239258,2.586001396179199,2.5859110355377197,2.5858211517333984,2.585732936859131,2.5856449604034424,2.585556745529175,2.585470199584961,2.585383176803589,2.5852973461151123,2.5852115154266357,2.585125684738159,2.585040330886841,2.584955930709839,2.584869623184204,2.5847866535186768,2.5847012996673584,2.584618330001831,2.5845346450805664,2.584451675415039,2.58436918258667,2.584287166595459,2.584205389022827,2.5841245651245117,2.58404541015625,2.5839669704437256,2.583890199661255,2.583815574645996,2.5837433338165283,2.583670139312744,2.583599090576172,2.5835273265838623,2.5834569931030273,2.5833873748779297,2.5833191871643066,2.5832509994506836,2.5831828117370605,2.583116292953491,2.583052158355713,2.58298659324646,2.58292293548584,2.582859992980957,2.582796335220337,2.582735300064087,2.5826756954193115,2.58261775970459,2.582563638687134,2.5825119018554688,2.5824639797210693,2.5824191570281982,2.5823752880096436,2.5823328495025635,2.5822930335998535,2.5822553634643555,2.5822181701660156,2.5821826457977295,2.5821499824523926,2.5821170806884766,2.5820870399475098,2.582056760787964,2.5820276737213135,2.5819995403289795,2.581972599029541,2.5819478034973145,2.5819225311279297,2.5818991661071777,2.581876039505005,2.581853151321411,2.581831932067871,2.5818123817443848,2.5817933082580566,2.581774950027466,2.5817580223083496,2.5817413330078125,2.5817251205444336,2.581709623336792,2.581695795059204,2.5816824436187744,2.581670045852661,2.5816588401794434,2.581646680831909,2.581636667251587,2.5816285610198975,2.581620693206787,2.5816152095794678,2.5816092491149902,2.5816049575805664,2.5816028118133545,2.5815985202789307,2.5815975666046143,2.5815978050231934,2.5815985202789307,2.5816009044647217,2.581601619720459,2.581604480743408,2.5816080570220947,2.5816128253936768,2.581618547439575,2.581625461578369,2.5816328525543213,2.5816409587860107,2.581650733947754,2.5816617012023926,2.581672430038452,2.5816855430603027,2.5816969871520996,2.581719160079956,2.581747055053711,2.5817744731903076,2.5818026065826416,2.5818302631378174,2.5818471908569336,2.5818631649017334,2.5818800926208496,2.5818982124328613,2.5819175243377686,2.581935167312622,2.5819549560546875,2.581974744796753,2.581993579864502,2.582015037536621,2.5820348262786865,2.582056999206543,2.582077980041504,2.582098960876465,2.5821213722229004,2.582143545150757,2.582167863845825,2.5821917057037354,2.5822150707244873,2.5822393894195557,2.5822641849517822,2.582289695739746,2.58231520652771,2.5823416709899902,2.5823683738708496,2.5823943614959717,2.5824227333068848,2.5824499130249023,2.5824778079986572,2.5825047492980957,2.5825326442718506,2.58256196975708,2.582590341567993,2.5826187133789062,2.5826475620269775,2.5826780796051025,2.582706928253174,2.582737445831299,2.582768201828003,2.5827994346618652,2.5828304290771484,2.5828616619110107,2.5828933715820312,2.58292555809021,2.582958459854126,2.5829901695251465,2.5830235481262207,2.5830564498901367,2.583090305328369,2.583124876022339,2.583160638809204,2.583195686340332,2.5832319259643555,2.583268642425537,2.583315372467041,2.5833632946014404,2.5834105014801025,2.5834596157073975,2.583509922027588,2.583562135696411,2.5836141109466553,2.5836682319641113,2.583723545074463,2.5837788581848145,2.583834648132324,2.583893299102783,2.583951711654663,2.5840094089508057,2.5840706825256348,2.5841310024261475,2.5841920375823975,2.5842535495758057,2.5843160152435303,2.5843796730041504,2.5844433307647705,2.584507703781128,2.5845701694488525,2.58463454246521,2.58469820022583,2.5847630500793457,2.584826707839966,2.5848910808563232,2.584956407546997,2.585020065307617,2.585085868835449,2.5851519107818604,2.585216760635376,2.5852816104888916,2.5853469371795654,2.5854134559631348,2.585479497909546,2.5855464935302734,2.585613250732422,2.585679769515991,2.585747480392456,2.5858142375946045,2.5858824253082275,2.5859503746032715,2.586019277572632,2.5860865116119385,2.5861546993255615,2.5862226486206055,2.586292028427124,2.586360216140747,2.5864272117614746,2.586495876312256,2.5865652561187744,2.586634635925293,2.586704969406128,2.586775302886963,2.5868451595306396,2.5869128704071045,2.5869810581207275,2.587048053741455,2.587117910385132,2.5871856212615967,2.5872554779052734,2.5873241424560547],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"lines\",\"name\":\"Train MSE Loss\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[26.2270565032959,24.95638656616211,23.684661865234375,22.46395492553711,21.293073654174805,20.173877716064453,19.11149024963379,18.09649085998535,17.12900161743164,16.206798553466797,15.328935623168945,14.490153312683105,13.69153118133545,12.93274211883545,12.211864471435547,11.529874801635742,10.882454872131348,10.267704963684082,9.683869361877441,9.131093978881836,8.60858154296875,8.11670207977295,7.652352809906006,7.214237689971924,6.801093578338623,6.411799907684326,6.045286655426025,5.700898170471191,5.378142356872559,5.075096607208252,4.7905097007751465,4.523248672485352,4.272597312927246,4.037850856781006,3.8181095123291016,3.612537145614624,3.420454502105713,3.2409298419952393,3.07344126701355,2.9173595905303955,2.772125005722046,2.636732578277588,2.5107674598693848,2.393799304962158,2.28532075881958,2.1847729682922363,2.0916311740875244,2.00545072555542,1.9257789850234985,1.8521924018859863,1.7842819690704346,1.721677303314209,1.6639670133590698,1.610737919807434,1.5616662502288818,1.5164577960968018,1.4748106002807617,1.436424732208252,1.4010365009307861,1.3683868646621704,1.338210105895996,1.3103079795837402,1.2845134735107422,1.2606037855148315,1.238378882408142,1.2176485061645508,1.1982779502868652,1.1801384687423706,1.1630922555923462,1.1470426321029663,1.1318796873092651,1.1175193786621094,1.1038776636123657,1.0908520221710205,1.0783722400665283,1.0663783550262451,1.0548152923583984,1.0436441898345947,1.0328106880187988,1.0222829580307007,1.0120301246643066,1.0020194053649902,0.992232084274292,0.9826483130455017,0.9732508063316345,0.9640355706214905,0.9549840092658997,0.946077287197113,0.9373040795326233,0.928653359413147,0.9201134443283081,0.9116913080215454,0.9033814668655396,0.8951865434646606,0.8871111869812012,0.8791570067405701,0.8713155388832092,0.8635874390602112,0.8559632301330566,0.8484451174736023,0.8410326838493347,0.833721935749054,0.8265193104743958,0.8194257020950317,0.8124387264251709,0.8055562376976013,0.7987653017044067,0.7920694947242737,0.785473644733429,0.7789749503135681,0.772569477558136,0.7662592530250549,0.7600436210632324,0.7539229393005371,0.7478929162025452,0.7419539093971252,0.736099123954773,0.7303364276885986,0.7246636748313904,0.7190761566162109,0.7135849595069885,0.7081745266914368,0.7028438448905945,0.6975898146629333,0.6924059391021729,0.6872966289520264,0.6822603940963745,0.6772962212562561,0.6724036335945129,0.6675803661346436,0.6628256440162659,0.6581329107284546,0.6535029411315918,0.6489330530166626,0.644422709941864,0.6399714946746826,0.6355788111686707,0.6312441229820251,0.6269657015800476,0.6227443814277649,0.61857670545578,0.6144626140594482,0.6103998422622681,0.6063862442970276,0.6024230718612671,0.5985078811645508,0.5945994853973389,0.5907294154167175,0.5869015455245972,0.5831140875816345,0.5793673992156982,0.5756610035896301,0.5719941854476929,0.5683678984642029,0.5647792816162109,0.5612248182296753,0.5577095746994019,0.5542334318161011,0.5507976412773132,0.547396719455719,0.5440283417701721,0.5406997799873352,0.5374071598052979,0.534144401550293,0.5309175848960876,0.5277286767959595,0.524574875831604,0.5214568972587585,0.5183727741241455,0.5153209567070007,0.5123008489608765,0.5093129277229309,0.5063560009002686,0.503430962562561,0.5005320310592651,0.4976579248905182,0.49481192231178284,0.49199509620666504,0.48920246958732605,0.48643818497657776,0.4837006628513336,0.48099109530448914,0.4783079922199249,0.4756515622138977,0.47302067279815674,0.47041600942611694,0.46783697605133057,0.4652687609195709,0.46272537112236023,0.46020689606666565,0.45770883560180664,0.45523396134376526,0.45278361439704895,0.450356662273407,0.44794961810112,0.44556310772895813,0.44318974018096924,0.4408360719680786,0.4385029971599579,0.4361923635005951,0.4339005947113037,0.4316288232803345,0.42937585711479187,0.427143394947052,0.42492976784706116,0.4227316677570343,0.420554518699646,0.418397456407547,0.4162595868110657,0.4141414761543274,0.41204214096069336,0.409959614276886,0.4078948497772217,0.40584123134613037,0.4038046896457672,0.4017854332923889,0.3997862935066223,0.3978060781955719,0.3958403170108795,0.39388972520828247,0.39195480942726135,0.390036404132843,0.38813385367393494,0.3862476050853729,0.38437706232070923,0.38252249360084534,0.3806816637516022,0.37885722517967224,0.3770486116409302,0.3752548396587372,0.37347617745399475,0.3717130720615387,0.3699650764465332,0.3682333827018738,0.3665148913860321,0.3648110330104828,0.36312219500541687,0.3614489436149597,0.35979077219963074,0.3581483066082001,0.3565205931663513,0.35490670800209045,0.35330653190612793,0.35171929001808167,0.35014665126800537,0.3485901355743408,0.3470459282398224,0.34551507234573364,0.3439972698688507,0.3424891531467438,0.34098830819129944,0.33949920535087585,0.3380209803581238,0.3365505337715149,0.33509159088134766,0.333644300699234,0.33220845460891724,0.3307839632034302,0.32937097549438477,0.32796499133110046,0.3265679180622101,0.3251805007457733,0.32379865646362305,0.32242050766944885,0.32105013728141785,0.31967899203300476,0.31831520795822144,0.3169533908367157,0.31559452414512634,0.3142394721508026,0.3128910958766937,0.3115476667881012,0.3102116286754608,0.3088832497596741,0.3075633943080902,0.30625244975090027,0.3049498498439789,0.30365607142448425,0.3023708760738373,0.30109402537345886,0.2998262643814087,0.29856738448143005,0.2973169982433319,0.29607561230659485,0.29484203457832336,0.29361698031425476,0.29240158200263977,0.29119500517845154,0.28999724984169006,0.2888087332248688,0.2876293659210205,0.2864585518836975,0.2852945625782013,0.284138947725296,0.2829817831516266,0.2818257510662079,0.28067633509635925,0.2795334756374359,0.27839863300323486,0.27726492285728455,0.27613821625709534,0.2750147581100464,0.27389585971832275,0.2727847695350647,0.2716769278049469,0.27055656909942627,0.2694411277770996,0.2683301568031311,0.26722225546836853,0.26611849665641785,0.2650177776813507,0.2639221251010895,0.2628326117992401,0.26174962520599365,0.26067352294921875,0.2596029043197632,0.258538156747818,0.2574796676635742,0.2564280331134796,0.2553830146789551,0.2543390095233917,0.25330036878585815,0.2522682845592499,0.25124284625053406,0.25022193789482117,0.24920259416103363,0.2481897473335266,0.24718289077281952,0.24618270993232727,0.24518902599811554,0.2442001849412918,0.24321499466896057,0.24223490059375763,0.24126023054122925,0.2402902990579605,0.2393248975276947,0.23836258053779602,0.23740582168102264,0.23645253479480743,0.23550137877464294,0.2345551997423172,0.2336137890815735,0.23267778754234314,0.23174692690372467,0.23082156479358673,0.22990179061889648,0.22898703813552856,0.22807800769805908,0.2271755188703537,0.22627665102481842,0.22538121044635773,0.22449173033237457,0.22360791265964508,0.22272977232933044,0.2218569666147232,0.2209891527891159,0.22012735903263092,0.21927110850811005,0.21842007339000702,0.21757471561431885,0.21673493087291718,0.21590062975883484,0.21507194638252258,0.2142488658428192,0.21343088150024414,0.21261759102344513,0.21180900931358337,0.21100541949272156,0.21020738780498505,0.20941473543643951,0.20862740278244019,0.20784565806388855,0.2070695012807846,0.2062978893518448,0.20553171634674072,0.20476943254470825,0.20401008427143097,0.2032540738582611,0.20250360667705536,0.20175829529762268,0.20101672410964966,0.20028048753738403,0.1995488554239273,0.19882173836231232,0.19809888303279877,0.19738058745861053,0.1966669261455536,0.19595777988433838,0.19525322318077087,0.19455337524414062,0.19385819137096405,0.19316768646240234,0.1924816370010376,0.19180001318454742,0.1911228597164154,0.19044993817806244,0.18978124856948853,0.1891160011291504,0.1884537786245346,0.18779529631137848,0.18714091181755066,0.18648982048034668,0.18584273755550385,0.185199573636055,0.18456043303012848,0.18392519652843475,0.18329428136348724,0.18266750872135162,0.18204450607299805,0.18142469227313995,0.1808086633682251,0.18019655346870422,0.179588183760643,0.1789836436510086,0.17838293313980103,0.17778603732585907,0.17719274759292603,0.17660297453403473,0.1760168820619583,0.17543454468250275,0.17485596239566803,0.17428067326545715,0.17370863258838654,0.17313925921916962,0.17257162928581238,0.17200574278831482,0.17144295573234558,0.17088326811790466,0.17032627761363983,0.16977210342884064,0.169220969080925,0.16867241263389587,0.16812682151794434,0.16758422553539276,0.16704455018043518,0.16650746762752533,0.16596853733062744,0.1654321700334549,0.16489814221858978,0.16436408460140228,0.16383203864097595,0.16330252587795258,0.16277453303337097,0.16224847733974457,0.1617233008146286,0.16120029985904694,0.16067959368228912,0.16016140580177307,0.1596425175666809,0.15912295877933502,0.15860028564929962,0.15807922184467316,0.15755733847618103,0.15703682601451874,0.15652044117450714,0.1560080498456955,0.15549889206886292,0.15499819815158844,0.15450409054756165,0.1540161371231079,0.15353292226791382,0.15305528044700623,0.1525810956954956,0.15210528671741486,0.1516309380531311,0.15116021037101746,0.1506921648979187,0.15022826194763184,0.14976736903190613,0.14930333197116852,0.14883814752101898,0.14836525917053223,0.14788588881492615,0.14737944304943085,0.14682704210281372,0.1461939811706543,0.14550542831420898,0.14481231570243835,0.14413118362426758,0.1435403674840927,0.14304547011852264,0.1426103711128235,0.14219817519187927,0.14180704951286316,0.14142440259456635,0.14102941751480103,0.14061053097248077,0.1401672214269638,0.139703631401062,0.13922899961471558,0.13875307142734528,0.13828393816947937,0.13782745599746704,0.13738632202148438,0.1369594782590866,0.13654504716396332,0.1361393928527832,0.13573959469795227,0.13534313440322876,0.13494780659675598],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"mode\":\"lines\",\"name\":\"IS MSE\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205,1.5929107253495205],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"mode\":\"lines\",\"name\":\"Train MSE\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[0.7282204178304108,0.2905635363996432,0.27258590616330564,0.2567996176400693,0.24336518231129084,0.23182165997783757,0.2219994088846565,0.21399337880084368,0.20739898010181104,0.20187366200865411,0.19749893068508162,0.19438757394590495,0.19222744659253949,0.19101129583957957,0.1908722494427504,0.19122296330639538,0.1922299509202141,0.1938763644896509,0.19631073059031812,0.19942248650548716,0.2029664467696441,0.20653168552959011,0.21056725020075034,0.215061208584647,0.21992101155459426,0.22587517442357763,0.23230503603038624,0.23914251473461529,0.2467777196935973,0.253540796170584,0.2597830592278263,0.26593572043826763,0.27194062533480423,0.27810018903322187,0.28480727787023385,0.29157749851849746,0.2981768196377378,0.3048658157875354,0.31164788359283047,0.31840929943782614,0.3251247247986369,0.3317925007378679,0.3384012275762603,0.34489595353163205,0.3512047176694302,0.3574542483806416,0.3636149161385929,0.3696197395098449,0.3755000172530299,0.3812587416806642,0.38689840134975245,0.3924568590135454,0.39789842869025793,0.4032299283588129,0.40860262313406487,0.4138843980453825,0.4189867921015503,0.42388051159993456,0.4288677014255434,0.4336921919054614,0.43839715958442077,0.44290610286391363,0.44727388703482035,0.45146398673261456,0.4557855810693607,0.4602554635955725,0.46451390809373766,0.4686127821811123,0.47257194758968396,0.4763744431356248,0.48001983559318806,0.4835141742608375,0.4868598095485977,0.49005903545247687,0.4931158997791846,0.49603190978558986,0.4988145331232111,0.5014694757371896,0.5036874142676078,0.505681456268509,0.5075610746711972,0.509334952129226,0.5110016854480679,0.512565909729655,0.5140426731082781,0.515412572891965,0.516669325719035,0.5178288528699382,0.5189378123776057,0.5200010084521243,0.5209896128004166,0.5219142957513894,0.5227781167991172,0.5235849681171741,0.5243459039029412,0.52506926853593,0.5257581537675622,0.5264131548520534,0.527063351486658,0.527695408979032,0.5282919028497459,0.5288686712760571,0.5294450581988733,0.5300569117011993,0.53066160184448,0.531253676476621,0.5318677287265503,0.5324823500557156,0.5330642286810507,0.533679010274314,0.5342811020533299,0.5348836866603653,0.5355297962202661,0.5361806429826962,0.5368305437338139,0.5374826159378354,0.538135290384977,0.5387820507904051,0.539410005050633,0.5400346291234324,0.5406615747282213,0.5412911219858746,0.5419342194995688,0.5425798672622112,0.5432262654033326,0.5438742956087159,0.5445265957281963,0.5451841931233287,0.5458511006191934,0.5465235673962798,0.547199624369553,0.5478784654324969,0.5485607167731987,0.5492366039825696,0.549912929204557,0.5506001410635615,0.5512886784594727,0.5519427394717966,0.5526516664532245,0.5533590885416579,0.55406382156239,0.5547543628803611,0.5554456928696349,0.5561367838281271,0.5568265365511283,0.5575174507441333,0.5580729896609873,0.5586187378298598,0.559166677436367,0.5597205499593625,0.560275805965757,0.560832303554167,0.5613782824340519,0.561929502405941,0.5624807612962821,0.563032328563022,0.5635851403237572,0.5640446646429282,0.5644046609946415,0.5647969511729555,0.5652111752868128,0.5656251711386319,0.5660395440595452,0.5664539335137272,0.566862891989766,0.5672703055260924,0.567686300737327,0.5680961873787448,0.5685046215754893,0.5689125358216777,0.5693205721130651,0.5697276908494467,0.570229219514428,0.5708148133043165,0.571398006981746,0.5719800299270387,0.5725607052352455,0.5731430513827515,0.5737234554566756,0.574264739808489,0.5748033347994249,0.5753393309983765,0.5758718058556909,0.5764017936503094,0.5769296371928316,0.5774532570552479,0.5779745790767614,0.5784929229470112,0.5790072631687285,0.579518466311926,0.580025295087741,0.5805277179499911,0.5810352753600534,0.5815477484422055,0.5820579502190457,0.5825117028628582,0.5829382544732128,0.5833630369057204,0.5837891234105395,0.5841621508635045,0.5845263244546708,0.5848841161382297,0.585127324253366,0.58534395422182,0.5855595975467883,0.5857789686953556,0.5860016574745229,0.5862229147040272,0.5864431883385073,0.5866624577190025,0.586879598223853,0.587095525410806,0.5873106798220046,0.5874872179251557,0.5876609735164257,0.587835569851892,0.5880142176825957,0.5881889931095146,0.5883809851279364,0.5885841340026746,0.5887910112896125,0.5890072451750253,0.5892305017889857,0.5894579723173078,0.5896846831820143,0.5899083453650619,0.5901235341811493,0.5903340627373672,0.5905438515165835,0.5907539443818333,0.5909641209984757,0.5911737299590399,0.5913826406203041,0.591610258868074,0.5918372579586388,0.592063843024146,0.592289934211765,0.5924836652430039,0.5926738239334436,0.5928543929159075,0.5930203309439908,0.5931866307193185,0.5933533868455184,0.5935198656392268,0.5936913968590791,0.5938756614228455,0.5940591592837923,0.5942418921886808,0.5944241384911353,0.5946047325144728,0.5947810861840482,0.5949560402710902,0.5951291562702924,0.5953100995600958,0.595492643619664,0.5956742486078015,0.5958552658173332,0.5960354149344848,0.5962143173827386,0.5963874780399039,0.5965590554776592,0.5967304473037922,0.596926340063856,0.597129670192998,0.5973164801254899,0.5974759557682738,0.5976338949049087,0.5977751752445465,0.5979097494821809,0.5979482895766352,0.5979388721686901,0.5979310423855209,0.5979237408321239,0.5979172321375226,0.5979057150615611,0.5978912063049767,0.5978775131176147,0.597864925232713,0.5978534010241213,0.5978392065165288,0.5978243553400611,0.5978105966326831,0.5977995007752231,0.5977898281353548,0.5977813638588501,0.5977774229298736,0.5977879055533458,0.5977999849804811,0.5978129924764197,0.597827315818789,0.5978419999865158,0.5978586813485439,0.5978767904872452,0.5978952069128151,0.5978595385799265,0.5978165561917397,0.5977754532555464,0.5977341316941088,0.5976965928119545,0.5976609202132624,0.597625349047086,0.5975915761863191,0.5975577119174382,0.5975249188995408,0.5974970289895052,0.5974864121562992,0.597477751795132,0.5974699353493808,0.5974591697403229,0.5974470692147309,0.5974369713952408,0.5974204257006577,0.5974047656696214,0.5973852238340249,0.5973671445418602,0.5972786594479721,0.5971297428326212,0.5969754649141498,0.5968236005135951,0.5966739540805185,0.5965298884993862,0.5963914928384573,0.5962595081865338,0.5961296578138806,0.5960059854793572,0.5958894525227627,0.5957955843698679,0.5956980224445412,0.5955961572694543,0.5954960590821519,0.5953977194543272,0.5953013524774229,0.5952045916420471,0.5951006451742806,0.5949984810144199,0.5948984504827733,0.5948004880207841,0.5947032463664856,0.5946106370045051,0.5945233349947611,0.5944369813199388,0.5943534944051652,0.5943100640360962,0.594287479729123,0.5942709157707218,0.5942557395682434,0.5942411995932326,0.5942241090087552,0.5941999904181602,0.5941984595674398,0.5942122646298315,0.5942201834542766,0.5942272482599154,0.594234344059982,0.5942430116616585,0.5942531551362555,0.594263174742406,0.5942728711085483,0.5942835704798788,0.5942945753307686,0.5943056051167227,0.5943167139406593,0.5943279799301125,0.5943387841766535,0.5943493869955517,0.5943602739405472,0.5943711670294123,0.5943847874496471,0.5944092938748876,0.5944339835786211,0.5944590052129977,0.5944842867143717,0.5945098958685083,0.5945358374961333,0.5945615686680613,0.5945877664807532,0.5946142906318908,0.5946413073329052,0.5946711158499473,0.5947031449893093,0.5947358867702713,0.5947679939803976,0.5947959210766595,0.5948191650384619,0.594835018730491,0.5948490799587683,0.5948631446638637,0.5948735969175698,0.5948831733637655,0.5948926551530606,0.5949022278948767,0.5949121650415614,0.5949224329405137,0.5949328575264602,0.5949436272794957,0.5949542239593597,0.5949639845833243,0.5949742258408144,0.5949849238173301,0.5949963641444429,0.5950086218067802,0.5950218705879368,0.5950358652661949,0.5950503509541017,0.5950655460088792,0.5950814117668022,0.5950978634906322,0.5951148565448532,0.5951325284867988,0.5951506843056213,0.5951676058195651,0.595185277029012,0.5952036799542155,0.5952227089332212,0.5952423300919344,0.5952623435856097,0.5952812758234692,0.5952989685875785,0.5953182334738486,0.5953382922634994,0.5953591468812716,0.5953805828356806,0.5954019229395766,0.5954188234279074,0.5954354431645378,0.5954534603630085,0.5954720630903292,0.5954912324151065,0.59551915115013,0.5955516570091062,0.5955878510147224,0.5956301155203754,0.595670956798457,0.5957120534169877,0.5957546372155577,0.5957984562356825,0.5958359598558378,0.5958758107659476,0.5959197977565265,0.5959956131603719,0.5960866640309278,0.5961802441105248,0.5962765473791387,0.5963755746370568,0.5964122741519525,0.596444902489264,0.5964786999136137,0.5965130414373836,0.5965711877650471,0.5966496836690269,0.5967060714935076,0.5967653556505104,0.5968198643611913,0.5968347415143719,0.5968449478035271,0.5968353627613521,0.5968157487497951,0.5967811350977342,0.5967321123980969,0.5966824403103537,0.596633899927289,0.5965881578652894,0.59654854023235,0.5964457129879464,0.5963313658197386,0.5962178567320995,0.5961059030992,0.5959970245521388,0.5958510822523594,0.5956544990321532,0.5953909921755778,0.5950290307578509,0.5946328524766697,0.5942231881815069,0.5935734252799899,0.5925016304280708,0.590852761541217,0.5889770494565224,0.5869975693146103,0.5851835975318774,0.5836029095816021,0.5822044506960532,0.5810648693441125,0.5800782477776228,0.5792700190971156,0.5787135841547408,0.5784507313254046,0.5784514882514453,0.5786706410101794,0.5790603589171046,0.5795684841128022,0.5801454659954107,0.5807449747789485,0.5813285699692982,0.5818707092918132,0.58234904416998,0.5827512547375493,0.5830720612847291,0.5833090955882617,0.5834619535473164],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"mode\":\"lines\",\"name\":\"Test MSE\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[3.601565143186498,3.5758132800413955,3.5533638888684838,3.532167155464105,3.5123384837402805,3.512609226519994,3.5219710707493714,3.5313956766416323,3.540759768737127,3.5500392001246466,3.559139880962655,3.567859852990446,3.5722534469708087,3.573377006561573,3.5744603637623698,3.57658136035543,3.579227305207211,3.58180163127989,3.584473141540119,3.586977497134832,3.589295240772373,3.591457727011512,3.5940259759472157,3.5991127166674213,3.6039708960779535,3.6080886743125484,3.611985400881988,3.615685483436496,3.618960241218174,3.622019777901878,3.624915093336698,3.62766295186045,3.6302661996707113,3.6327374652903646,3.6350890649328806,3.637323130688943,3.639452084745182,3.6414883321212166,3.643442236522988,3.645326364005869,3.6471456381878857,3.6487694150669068,3.650321982162655,3.6518408672443385,3.653336609083512,3.654823772760115,3.656275359349266,3.6577358864428744,3.659221953680909,3.6607224861136958,3.662303591805399,3.664208964791973,3.6665322959401117,3.6688878219759467,3.6712841328064725,3.6737241688939886,3.6762191053131126,3.678770180233596,3.681391049482726,3.6841274363878185,3.686945826123531,3.689835017247618,3.692795989651922,3.6958322235992,3.6989472181271648,3.7021520160241663,3.7054464389502275,3.7088323142552095,3.712302939833765,3.7158591290632303,3.7194956574630282,3.7232158052423383,3.7270133621196937,3.730883499363528,3.734822486788618,3.738826737263241,3.742891414647044,3.7470144915667287,3.7511864826518777,3.7553988440842074,3.759639959236135,3.763916114382857,3.7682132347750867,3.7725324473969404,3.7768693526091903,3.7812163462313686,3.785578109009329,3.789942482773043,3.7943109587994144,3.7986770504141187,3.8030348176329465,3.8073812599654824,3.8117167017628537,3.8160349148771746,3.8203354767286655,3.824607965040779,3.8288519559937844,3.833065291590245,3.837253548640358,3.841414066051454,3.8455324530908115,3.849613187050514,3.853649981150458,3.857641402474848,3.861587242397298,3.8654851612324315,3.8693330531967307,3.873128962322191,3.876876272251546,3.8805680819599018,3.884209768389265,3.887795395497675,3.8913283259357456,3.8948074575942213,3.8982281901001383,3.9015963916265797,3.9049108701490782,3.9081641600337025,3.911362545159841,3.914505378552164,3.917589341243162,3.9206104209677894,3.923575341147763,3.926478111043717,3.9294151967190345,3.9323079343728016,3.9351415368091507,3.93791884411549,3.9406390458009994,3.943305193635977,3.945919423508024,3.948476485305487,3.950985296235973,3.9534449026272194,3.955856077339407,3.9582204138646206,3.9605331185930126,3.9628037431409786,3.9650284252011643,3.9672054795583747,3.969340860874247,3.971434559241898,3.9734840154746642,3.9754950936716966,3.97746467786582,3.979395020959959,3.98128718676562,3.9831398980678494,3.984955890993887,3.9867394204708377,3.9851913832159624,3.981169113932366,3.9771613931155727,3.973173847723113,3.9692102424996483,3.965265606126561,3.9613429583232924,3.957403643290367,3.953374599802991,3.9493708611549154,3.9453923078480786,3.9414390891621203,3.937512357411266,3.933613370681536,3.9297424799855025,3.9258983683124726,3.922081210096276,3.918343756358576,3.914633477931977,3.910953712929219,3.907303815070943,3.903678686919109,3.9000856899270486,3.8965210569086466,3.892983030449318,3.8894701664872535,3.885982904205634,3.882519060868261,3.8790846802726593,3.8756756680967275,3.872295560692055,3.868942316037295,3.8656164655559633,3.8623186849279434,3.859043836579588,3.855795914355992,3.852575087096647,3.849378126608266,3.8462157863440027,3.8430857858057252,3.839983396982767,3.8369120720797056,3.8338657851685003,3.8308474263097128,3.827856156196433,3.8248907010289583,3.8219569799267816,3.8190493411809148,3.8161723820528026,3.813323139558994,3.810508024761583,3.8077222597967557,3.804971320206105,3.8022522295139782,3.799561944364899,3.7968955195737695,3.7942463249594534,3.791621763248841,3.789021343999699,3.786437546517996,3.7838786232740214,3.781337076723924,3.778814129673442,3.7763115193759544,3.7738210620364425,3.771343544517413,3.7690464437472837,3.7668317192322975,3.764627917718129,3.762444946814738,3.7604028939125738,3.758743711881593,3.757111656348513,3.7554941709395786,3.7538897481237727,3.752297908133545,3.7507179328045934,3.7491535044404163,3.747599174881679,3.7460596524683005,3.744528775307249,3.7433881997765086,3.7424824541669963,3.741582844196341,3.7406887852369026,3.739802547582145,3.7389199350288456,3.7380426696859432,3.737955148298135,3.7383648174755555,3.738774921952053,3.7391781481797435,3.7395778329036364,3.739973331388203,3.740365668284848,3.740750974596695,3.74113253355742,3.7415089497851257,3.7418826067358184,3.742251101432537,3.742620097654193,3.74298715685135,3.7433527556235324,3.7437163442020482,3.7440797729651694,3.7444446746266395,3.7448053831161605,3.7451611459211653,3.74551882094678,3.7458684130091786,3.74622112697538,3.7465711305252296,3.7469203489595246,3.7472659565853403,3.7476130697321066,3.7479616155449538,3.7481465838718595,3.7478036582891967,3.7474612488548993,3.747265793959061,3.7472248868788203,3.747183265668371,3.7471453328176594,3.7471081534141613,3.747071708988696,3.7470377055099235,3.7470031709100997,3.7469676282988607,3.7469340127587203,3.746899407682599,3.746864711091364,3.7468295016982207,3.7467924946237714,3.746755194489163,3.746718335063367,3.7466769994138867,3.7466405444331015,3.7465988792551936,3.7465593420850336,3.746517291442053,3.7464746717579427,3.7464317585728524,3.7463880378131442,3.746343270996717,3.7462979162927943,3.7462557732348865,3.7462153741554722,3.7461697046234317,3.7461266953553545,3.7460860707030603,3.7460432075701235,3.746002747650703,3.7459600305547953,3.7459192584473318,3.7458779166702216,3.7458367204323055,3.7457944962433665,3.745749958725348,3.745708375734629,3.745668148900689,3.745624435188449,3.7455831431880107,3.745541795414325,3.7454981900836706,3.7454569504445576,3.745417141485431,3.7453787445347757,3.745345704999507,3.745315049841137,3.7452902663486305,3.745268839627741,3.7452481097140686,3.745229324752149,3.745212391312266,3.7451978609748564,3.745183293479468,3.7451693666738635,3.745159843796799,3.745147511531281,3.745139840326292,3.745130131044859,3.7451208426576867,3.745112508113343,3.7451045944369996,3.7450988266835052,3.7450915537075176,3.745086445356619,3.7450805470109128,3.7450741157884613,3.7450696107552384,3.7450678033508673,3.7450664729189707,3.7450658578781266,3.7450669306347066,3.7450666990338206,3.7450674586951367,3.7450684194236152,3.745070792040597,3.745073127288114,3.7450764163157046,3.7450811547051153,3.7450841680347597,3.745091384563744,3.7451015372438405,3.7451111569735227,3.745125218402495,3.745137774458567,3.7451535426543385,3.745172485507881,3.7451879968766857,3.7452091609298583,3.7452315172861335,3.7452543506897733,3.7452793676165967,3.7453016870577285,3.745327695644714,3.7453526193253985,3.745381050106303,3.7454104348020856,3.7454412690379777,3.7454728375661714,3.745505378813261,3.7455398464616625,3.7455765353351036,3.745612214412956,3.7456515640599903,3.7456874444902177,3.745740741967911,3.7458025914706194,3.745863964631389,3.745925281821267,3.7459866371354895,3.7460439525595324,3.7460995432502893,3.7461560882894114,3.746213568833603,3.7462732712010816,3.746329247173694,3.7463886559188317,3.746447293500209,3.746504978055313,3.7465650285750343,3.7466223816362354,3.7466839205623312,3.7467414377556563,3.746799212826443,3.746858933606847,3.7469179019410492,3.746979788573678,3.747040169691752,3.74709981722099,3.7471596470034254,3.7472207261622197,3.7472814917952464,3.747341743280825,3.747403206302976,3.747465165617558,3.7475246087460405,3.747587465963141,3.7476481021599524,3.7477091967297707,3.7477683086316285,3.747827345171525,3.7478885847595675,3.7479478416022003,3.748006069332812,3.748065803817506,3.7481261780934023,3.7481838542608306,3.7482437145015726,3.7483032987370444,3.7483636175659742,3.7484224113245777,3.7484814438332705,3.7485409535106324,3.748600940356664,3.7486613853748176,3.748719094117071,3.7487802740259735,3.748840205156993,3.7489016051297757,3.7489644929741788,3.7490288306887236,3.749092453497715,3.7491595857079485,3.749226680278001,3.7492986398971793,3.749372306779968,3.749443971432856,3.749519603326233,3.7495979723593025,3.7496792789218243,3.7497616347493077,3.7498471666101727,3.749935950756918,3.750024992859057,3.750114512286099,3.750209983016216,3.7503054733958967,3.750399476636158,3.7504993741760972,3.750598576180719,3.750698494089121,3.750799662007175,3.750901269248512,3.7510063868920467,3.75111047518587,3.7512165670664177,3.7513184345685477,3.751423755294259,3.7515278464037354,3.751633902938644,3.751738253011149,3.7518430614959115,3.7519498545855754,3.7520526614238214,3.7521594176500406,3.752265897871586,3.752370929125492,3.752474930752376,3.752579152289151,3.7526848241550788,3.7527897622479696,3.75289565466322,3.7529977028952755,3.753099770846812,3.753203804258283,3.753304308435488,3.7534070164602835,3.753508713717043,3.7536111075122642,3.7537100294674977,3.7538106784188976,3.7539092859639367,3.754011643160917,3.7541195074145888,3.75422824142181,3.7543396757102823,3.754452856662305,3.754566296096774,3.754681205368561,3.7547976615169354,3.7549123533583417,3.7550210350817057,3.755130967416068,3.755239708403434,3.7553533727153967,3.7554633458855635,3.7555775272195184,3.7556897441744717],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.45],\"title\":{\"text\":\"Epoch\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.625,1.0],\"title\":{\"text\":\"Estimate\"}},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.55,1.0],\"title\":{\"text\":\"Epoch\"}},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.625,1.0],\"title\":{\"text\":\"Variance\"}},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.0,0.45],\"title\":{\"text\":\"Epoch\"}},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,0.375],\"title\":{\"text\":\"MSE Loss\"}},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.55,1.0],\"title\":{\"text\":\"Epoch\"}},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.0,0.375],\"title\":{\"text\":\"MSE\"}},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Estimate over Epochs\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Variance over Epochs\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Shaping Train MSE Loss over Epochs\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Total MSE over Epochs\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Metrics over Epochs\"},\"showlegend\":true},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('b23211a6-6ea2-4caa-84dd-a7243bfe128a');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"7a2ce31a-1d89-4ae4-8634-bafecba12ced\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"7a2ce31a-1d89-4ae4-8634-bafecba12ced\")) {                    Plotly.newPlot(                        \"7a2ce31a-1d89-4ae4-8634-bafecba12ced\",                        [{\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"z\":[[0.055717337876558304,0.060102030634880066,0.05524938553571701,0.04466574639081955,0.03397655487060547,0.02328735589981079,0.01259814202785492,0.0019089467823505402,-0.005717672407627106,-0.012927703559398651],[0.04994998127222061,0.05983053520321846,0.06099966913461685,0.05361479893326759,0.04360547661781311,0.033596161752939224,0.023586807772517204,0.013577479869127274,0.0035681575536727905,-0.006441161036491394],[0.045536886900663376,0.04931589961051941,0.05290818214416504,0.05460888519883156,0.04975302889943123,0.04197090119123459,0.03196156769990921,0.02195224165916443,0.011942915618419647,0.0019336044788360596],[0.04378993436694145,0.039628468453884125,0.04667521268129349,0.044816985726356506,0.04721418023109436,0.043362244963645935,0.03850637748837471,0.03032699041068554,0.020317643880844116,0.010308321565389633],[0.03785894438624382,0.03349316120147705,0.03824247419834137,0.03888743743300438,0.038098257035017014,0.039122987538576126,0.03697146475315094,0.03211560100317001,0.02725973166525364,0.018683072179555893],[0.03192796930670738,0.02735784649848938,0.031469136476516724,0.03692450001835823,0.03141523152589798,0.03181520476937294,0.0322151742875576,0.030580703169107437,0.02572483755648136,0.02086898684501648],[0.0259969811886549,0.021222535520792007,0.025333832949399948,0.02944513037800789,0.02940082550048828,0.02513216622173786,0.025532130151987076,0.025932108983397484,0.025184234604239464,0.019334059208631516],[0.020065218210220337,0.015087220817804337,0.019198529422283173,0.023309828713536263,0.027421128004789352,0.021613065153360367,0.01884911209344864,0.019249077886343002,0.019649062305688858,0.020049039274454117],[0.013735104352235794,0.00895192101597786,0.0130632184445858,0.01717451587319374,0.021285809576511383,0.02040918916463852,0.013825282454490662,0.01256602630019188,0.012966003268957138,0.01336599513888359],[0.008737903088331223,0.0028165988624095917,0.006927900016307831,0.011039197444915771,0.015150491148233414,0.019261792302131653,0.012126419693231583,0.006037496030330658,0.006282985210418701,0.00668296217918396]],\"type\":\"heatmap\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"Values\"},\"ticks\":\"outside\",\"tickvals\":[-0.012927703559398651,0.06099966913461685],\"ticktext\":[-0.012927703559398651,0.06099966913461685]}},\"xaxis\":{\"tickvals\":[0,1,2,3,4,5,6,7,8,9],\"ticktext\":[0,1,2,3,4,5,6,7,8,9],\"title\":{\"text\":\"X\"}},\"yaxis\":{\"tickvals\":[9,8,7,6,5,4,3,2,1,0],\"ticktext\":[9,8,7,6,5,4,3,2,1,0],\"title\":{\"text\":\"Y\"},\"autorange\":\"reversed\"},\"title\":{\"text\":\"Heatmap\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('7a2ce31a-1d89-4ae4-8634-bafecba12ced');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"fcb22001-1c44-4bc9-891e-c896d513e66f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"fcb22001-1c44-4bc9-891e-c896d513e66f\")) {                    Plotly.newPlot(                        \"fcb22001-1c44-4bc9-891e-c896d513e66f\",                        [{\"colorbar\":{\"title\":{\"text\":\"Visits\"}},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"x\":[0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9],\"y\":[9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0],\"z\":[0,194,643,1583,3494,3293,3319,2995,2187,2262,0,364,976,2531,2804,0,1166,1641,1428,2261,0,739,1983,2367,1082,0,407,540,872,2349,0,1596,1896,966,424,0,101,170,324,580,0,1588,872,455,210,0,28,49,79,119,443,1070,436,185,74,16,6,16,23,19,108,223,125,68,28,25,6,15,21,17,15,38,32,28,12,23,10,13,15,16,2,6,6,5,3,24,11,10,14,22,0,1,0,1,0,17,6,9,12,14],\"zmax\":3494,\"zmin\":0,\"type\":\"heatmap\"}],                        {\"title\":{\"text\":\"State Visitations Heatmap\"},\"xaxis\":{\"title\":{\"text\":\"X-axis\"}},\"yaxis\":{\"ticktext\":[9,8,7,6,5,4,3,2,1,0],\"tickvals\":[0,1,2,3,4,5,6,7,8,9],\"title\":{\"text\":\"Y-axis\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('fcb22001-1c44-4bc9-891e-c896d513e66f');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_trajectories = [200, 400, 600, 800, 1000]\n",
        "viz_over_num_trajectories(params, num_trajectories)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4LOjy03htSrQ",
        "outputId": "30bff940-62d2-496e-c2de-efbb33632540"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"1e9f4b6b-49df-4ccb-9762-211e8caea888\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"1e9f4b6b-49df-4ccb-9762-211e8caea888\")) {                    Plotly.newPlot(                        \"1e9f4b6b-49df-4ccb-9762-211e8caea888\",                        [{\"mode\":\"lines\",\"name\":\"IS Bias\",\"x\":[200,400,600,800,1000],\"y\":[-0.7803387781426122,-0.7808302329420876,1.106840909866196,0.8782739949647959,0.53981901009483],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Train Bias\",\"x\":[200,400,600,800,1000],\"y\":[-0.6317728115066698,-0.7944354215204549,-0.7567071081720769,-0.7689350607569639,-0.7620526770790134],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Test Bias\",\"x\":[200,400,600,800,1000],\"y\":[-0.795595680345576,-0.7593974792897534,1.8945698155439914,1.5407215667192515,1.0809096177379574],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Bias over Trajectories\"},\"xaxis\":{\"title\":{\"text\":\"Number of Trajectories\"}},\"yaxis\":{\"title\":{\"text\":\"Bias\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('1e9f4b6b-49df-4ccb-9762-211e8caea888');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"e4a99576-9cd8-4373-8ca7-e86126a6fb13\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e4a99576-9cd8-4373-8ca7-e86126a6fb13\")) {                    Plotly.newPlot(                        \"e4a99576-9cd8-4373-8ca7-e86126a6fb13\",                        [{\"mode\":\"lines\",\"name\":\"IS Variance\",\"x\":[200,400,600,800,1000],\"y\":[0.0013326029293239117,0.0006751575274392962,3.5907814502716064,2.087684154510498,1.3015061616897583],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Train Variance\",\"x\":[200,400,600,800,1000],\"y\":[0.01465107873082161,0.0019921800121665,0.004731263965368271,0.0007242661667987704,0.0027376709040254354],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Test Variance\",\"x\":[200,400,600,800,1000],\"y\":[2.7966823836322874e-05,0.0007040593191049993,7.014622688293457,3.987762689590454,2.5873241424560547],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Variance over Trajectories\"},\"xaxis\":{\"title\":{\"text\":\"Number of Trajectories\"}},\"yaxis\":{\"title\":{\"text\":\"Variance\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('e4a99576-9cd8-4373-8ca7-e86126a6fb13');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"cefda53b-ee89-4aec-939a-6e87439a5e6d\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"cefda53b-ee89-4aec-939a-6e87439a5e6d\")) {                    Plotly.newPlot(                        \"cefda53b-ee89-4aec-939a-6e87439a5e6d\",                        [{\"mode\":\"lines\",\"name\":\"IS MSE\",\"x\":[200,400,600,800,1000],\"y\":[0.6102612116024289,0.6103710102038341,4.815878250025035,2.8590493647419204,1.5929107253495205],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Train MSE\",\"x\":[200,400,600,800,1000],\"y\":[0.4137879640898637,0.6331198189785493,0.5773369115235155,0.5919853938281145,0.5834619535473164],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Test MSE\",\"x\":[200,400,600,800,1000],\"y\":[0.6330004534083763,0.5773885908707365,10.60401747426385,6.361585635744279,3.7556897441744717],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"MSE over Trajectories\"},\"xaxis\":{\"title\":{\"text\":\"Number of Trajectories\"}},\"yaxis\":{\"title\":{\"text\":\"MSE\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('cefda53b-ee89-4aec-939a-6e87439a5e6d');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pi_b = test_load.load_pi_b()"
      ],
      "metadata": {
        "id": "ZpVTe8_ovtMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_load = existing_experiments(test_experiment)\n",
        "test_load.plot_metrics()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "YIUqiytfU_td",
        "outputId": "2132af04-3930-43e3-c8e9-7fb89aabbe9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"1cccf456-9e17-4e59-835c-240814c21c9e\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"1cccf456-9e17-4e59-835c-240814c21c9e\")) {                    Plotly.newPlot(                        \"1cccf456-9e17-4e59-835c-240814c21c9e\",                        [{\"mode\":\"lines\",\"name\":\"IS Estimate\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800],\"y\":[0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181,0.04560364410281181],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"Train Estimate\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800],\"y\":[0.1247360110282898,-0.4569704532623291,-0.4511866271495819,-0.4448806047439575,-0.4386078119277954,-0.43249180912971497,-0.426710844039917,-0.421223521232605,-0.4158547818660736,-0.41068392992019653,-0.40569356083869934,-0.40094825625419617,-0.3960804343223572,-0.3909339904785156,-0.3860778212547302,-0.38107460737228394,-0.37590137124061584,-0.37092652916908264,-0.3662880063056946,-0.3619218170642853,-0.3577418923377991,-0.35374119877815247,-0.3499293923377991,-0.3463069200515747,-0.34293314814567566,-0.3397406339645386,-0.3367204964160919,-0.333825021982193,-0.330731064081192,-0.32777297496795654,-0.32514241337776184,-0.32271382212638855,-0.32040002942085266,-0.31819698214530945,-0.3160703480243683,-0.31386393308639526,-0.31170564889907837,-0.3096248209476471,-0.3077695667743683,-0.30601760745048523,-0.30443689227104187,-0.3029312789440155,-0.30124136805534363,-0.2994442284107208,-0.2976619601249695,-0.2959205210208893,-0.29419803619384766,-0.2924935221672058,-0.29081887006759644,-0.28915902972221375,-0.28750085830688477,-0.28583183884620667,-0.28414955735206604,-0.2824626564979553,-0.2808161973953247,-0.2791704535484314,-0.2776133418083191,-0.275944322347641,-0.2741602659225464,-0.27228209376335144,-0.2703138291835785,-0.26814740896224976,-0.2659294605255127,-0.26364782452583313,-0.26131001114845276,-0.2589191496372223,-0.2565077543258667,-0.2541842460632324,-0.2518465518951416,-0.2495012879371643,-0.2471219003200531,-0.2448168694972992,-0.2425445020198822,-0.24026308953762054,-0.23801328241825104,-0.23578312993049622,-0.23358461260795593,-0.2313752919435501,-0.22919026017189026,-0.227043017745018,-0.22484922409057617,-0.22265438735485077,-0.2205246388912201,-0.21845850348472595,-0.21645253896713257,-0.2145031988620758,-0.2126038372516632,-0.21075011789798737,-0.20894281566143036,-0.20717550814151764,-0.20548273622989655,-0.20382460951805115,-0.20218952000141144,-0.20056594908237457,-0.19894738495349884,-0.19724653661251068,-0.19555234909057617,-0.19385136663913727,-0.19215579330921173,-0.19049052894115448,-0.18882516026496887,-0.18714787065982819,-0.1854592114686966,-0.18377259373664856,-0.18208684027194977,-0.18040624260902405,-0.1787329912185669,-0.17706936597824097,-0.17542096972465515,-0.17378266155719757,-0.17214706540107727,-0.17051760852336884,-0.16890160739421844,-0.1674051582813263,-0.16593971848487854,-0.16449253261089325,-0.1630135327577591,-0.1615595668554306,-0.1601450890302658,-0.15877127647399902,-0.15743759274482727,-0.1561439335346222,-0.154889777302742,-0.15366098284721375,-0.15245674550533295,-0.151292085647583,-0.1501709371805191,-0.1490887999534607,-0.1480301320552826,-0.146993488073349,-0.1459902971982956,-0.14501768350601196,-0.1440611034631729,-0.14311586320400238,-0.14219757914543152,-0.1413034200668335,-0.14042004942893982,-0.1395447850227356,-0.13868814706802368,-0.13784778118133545,-0.13700994849205017,-0.13617399334907532,-0.13534194231033325,-0.13452431559562683,-0.13371916115283966,-0.1329137235879898,-0.13210754096508026,-0.13130046427249908,-0.13050395250320435,-0.12971588969230652,-0.12891438603401184,-0.12809135019779205,-0.12727423012256622,-0.12646484375,-0.12567375600337982,-0.12489975243806839,-0.12414156645536423,-0.12338930368423462,-0.12264209240674973,-0.12190072238445282,-0.12116529792547226,-0.12043553590774536,-0.11965588480234146,-0.11881999671459198,-0.11800051480531693,-0.11718711256980896,-0.11638044565916061,-0.11558213829994202,-0.11479225754737854,-0.11401080340147018,-0.11323744058609009,-0.1124725341796875,-0.11171574890613556,-0.11096660047769547,-0.11023436486721039,-0.10951756685972214,-0.10881451517343521,-0.10811599344015121,-0.10742608457803726,-0.106742724776268,-0.10591373592615128,-0.10503356903791428,-0.10415676236152649,-0.10328362137079239,-0.10241518914699554,-0.1015520989894867,-0.10069488734006882,-0.09984347969293594,-0.09899833798408508,-0.09816000610589981,-0.09732864052057266,-0.09650300443172455,-0.0956840068101883,-0.09487168490886688,-0.09406585991382599,-0.09326732158660889,-0.09247682243585587,-0.09169352054595947,-0.09091725945472717,-0.09014779329299927,-0.08938509970903397,-0.0886288434267044,-0.08787872642278671,-0.08713465929031372,-0.08639626204967499,-0.08566363900899887,-0.08493705093860626,-0.08421669155359268,-0.0835026204586029,-0.08279510587453842,-0.0820942148566246,-0.08140023797750473,-0.08068710565567017,-0.07997341454029083,-0.07926514744758606,-0.0785626471042633,-0.07786616683006287,-0.07726409286260605,-0.0766628310084343,-0.07606688886880875,-0.07547685503959656,-0.07489241659641266,-0.07431318610906601,-0.07373899221420288,-0.07306176424026489,-0.07232377678155899,-0.07158970087766647,-0.07085995376110077,-0.07013483345508575,-0.06942392885684967,-0.06871674209833145,-0.06801354885101318,-0.06731336563825607,-0.06658351421356201,-0.06585865467786789,-0.0651390552520752,-0.06442603468894958,-0.06371554732322693,-0.0630037933588028,-0.062301307916641235,-0.06158445402979851,-0.060877732932567596,-0.060382433235645294,-0.05990937352180481,-0.05943809077143669,-0.05890778824687004,-0.05837654322385788,-0.05785071849822998,-0.05733049288392067,-0.05681556463241577,-0.0563063845038414,-0.055863868445158005,-0.055520664900541306,-0.05516333505511284,-0.05480043962597847,-0.05443957448005676,-0.05408147722482681,-0.05372695252299309,-0.053375665098428726,-0.05302982032299042,-0.0526900514960289,-0.05235688015818596,-0.052030049264431,-0.05171041935682297,-0.05139882117509842,-0.05109439417719841,-0.050797175616025925,-0.05050700530409813,-0.0502229668200016,-0.04994546249508858,-0.049674347043037415,-0.049409568309783936,-0.04914373904466629,-0.0488816499710083,-0.04863069951534271,-0.04840073361992836,-0.048173997551202774,-0.0479498989880085,-0.04772880673408508,-0.0475102961063385,-0.0472935289144516,-0.047081273049116135,-0.04688349738717079,-0.04668620601296425,-0.04649551212787628,-0.04630618914961815,-0.04611574858427048,-0.04592371731996536,-0.04572980850934982,-0.04553362354636192,-0.045335255563259125,-0.04513469710946083,-0.04493190348148346,-0.04472695663571358,-0.04452009126543999,-0.04431545361876488,-0.04411175474524498,-0.04390888288617134,-0.043706733733415604,-0.04350494593381882,-0.04330342262983322,-0.04310217127203941,-0.04290108382701874,-0.04270013049244881,-0.04249914735555649,-0.04229806736111641,-0.042096808552742004,-0.04189514368772507,-0.0416928231716156,-0.04149001091718674,-0.04128677025437355,-0.04108436405658722,-0.04090698063373566,-0.040734872221946716,-0.040567412972450256,-0.0404038168489933,-0.040243349969387054,-0.04008530452847481,-0.03992893546819687,-0.03977346047759056,-0.03961826115846634,-0.03946271538734436,-0.03930632770061493,-0.03914865851402283,-0.0389891192317009,-0.038826655596494675,-0.03861529380083084,-0.03839944303035736,-0.03818449378013611,-0.03797049820423126,-0.03775756433606148,-0.03754561021924019,-0.03733457624912262,-0.03712416812777519,-0.03689925745129585,-0.036659251898527145,-0.03641480952501297,-0.0361669659614563,-0.03591664880514145,-0.03566494211554527,-0.0354129858314991,-0.03516180068254471,-0.034912463277578354,-0.034665849059820175,-0.03442270681262016,-0.034183744341135025,-0.03394955024123192,-0.033720627427101135,-0.033496785908937454,-0.03327885642647743,-0.03306705877184868,-0.032859884202480316,-0.032659344375133514,-0.03247355297207832,-0.032300908118486404,-0.03213978186249733,-0.0319884791970253,-0.031837042421102524,-0.03168400749564171,-0.03152921050786972,-0.031372420489788055,-0.031213488429784775,-0.03105245716869831,-0.030889468267560005,-0.0307247806340456,-0.030558764934539795,-0.030391816049814224,-0.03022431582212448,-0.030056821182370186,-0.029888613149523735,-0.02972584217786789,-0.029572274535894394,-0.029424317181110382,-0.029274245724081993,-0.029123837128281593,-0.02897326648235321,-0.028822461143136024,-0.02867167443037033,-0.028521038591861725,-0.028370853513479233,-0.02822001650929451,-0.028076650574803352,-0.027939435094594955,-0.02780095487833023,-0.02766224928200245,-0.02752334624528885,-0.02738436870276928,-0.027245376259088516,-0.02710646577179432,-0.02696716971695423,-0.02682521753013134,-0.02669110707938671,-0.026562392711639404,-0.02643081359565258,-0.02629789337515831,-0.026163537055253983,-0.026027923449873924,-0.025891263037919998,-0.025753751397132874,-0.025615645572543144,-0.025477176532149315,-0.02533862181007862,-0.025198671966791153,-0.02506604976952076,-0.02493767999112606,-0.024808036163449287,-0.02467784471809864,-0.02454717643558979,-0.024416113272309303,-0.02428479678928852,-0.024153346195816994,-0.024021927267313004,-0.023890569806098938,-0.023759424686431885,-0.023628603667020798,-0.02349833957850933,-0.023368969559669495,-0.023240545764565468,-0.023111829534173012,-0.02299027517437935,-0.022872313857078552,-0.022754106670618057,-0.022635607048869133,-0.02251678891479969,-0.02239767648279667,-0.02227807603776455,-0.022158045321702957,-0.022037670016288757,-0.021917100995779037,-0.02179640904068947,-0.02167537808418274,-0.021554142236709595,-0.02143361233174801,-0.021313630044460297,-0.021193502470850945,-0.02107335813343525,-0.02095254696905613,-0.020858321338891983,-0.020768413320183754,-0.020677777007222176,-0.02056390419602394,-0.02041550725698471,-0.020256996154785156,-0.01984170265495777,-0.019371965900063515,-0.018932702019810677,-0.018538057804107666,-0.018244829028844833,-0.018076583743095398,-0.018018081784248352,-0.01804116554558277,-0.01811790280044079,-0.01822221651673317,-0.01832919381558895,-0.01841534674167633,-0.018461080268025398,-0.018454043194651604,-0.018390879034996033,-0.01827598363161087,-0.018118731677532196,-0.017931150272488594,-0.01772647723555565,-0.01751803606748581,-0.01731833815574646,-0.017137862741947174,-0.016984039917588234,-0.016860418021678925,-0.016766676679253578,-0.016699232161045074,-0.016652178019285202,-0.0166181568056345,-0.016589369624853134,-0.016558250412344933,-0.016518225893378258,-0.016464488580822945,-0.01639413833618164,-0.01630634441971779,-0.016202256083488464,-0.016084617003798485,-0.015957321971654892,-0.015824835747480392,-0.015691760927438736,-0.015562310814857483,-0.015439915470778942,-0.015326965600252151,-0.015224618837237358,-0.015132864005863667,-0.015050524845719337,-0.014975662343204021,-0.0149056576192379,-0.01483773160725832,-0.014769140630960464,-0.014697515405714512,-0.014621040783822536,-0.014538592658936977,-0.014449833892285824,-0.014355074614286423,-0.014255279675126076,-0.014151891693472862,-0.014046544209122658,0.029965704306960106,-0.014787321910262108,-0.014507826417684555,-0.013898223638534546,-0.013231332413852215,-0.012500667944550514,-0.011622477322816849,-0.010529650375247002,-0.009198440238833427,-0.00770956976339221,-0.006337789818644524,-0.0050050802528858185,-0.004042705520987511,-0.0032953026238828897,-0.00252252584323287,-0.001694565056823194,-0.0008315247250720859,-4.4306463678367436e-05,0.0007230833289213479,0.001437254948541522,0.0020490868482738733,0.002541051711887121,0.0028657896909862757,0.0030778180807828903,0.003171795979142189,0.003139583859592676,0.0029749879613518715,0.002696163021028042,0.002328170696273446,0.0019023643108084798,0.001458547543734312,0.0010232545901089907,0.0006185980746522546,0.00024965853663161397,-8.262036863015965e-05,-0.00035676435800269246,-0.0005881297402083874,-0.0007871264242567122,-0.0009604102815501392,-0.0011090902844443917,-0.0012295265914872289,-0.0013182718539610505,-0.0013753026723861694,-0.0013983972603455186,-0.001400002627633512,-0.0013910827692598104,-0.0013790937373414636,-0.0013681406853720546,-0.0013611987233161926,-0.0013502977089956403,-0.0013316768454387784,-0.001304444158449769,-0.001271060318686068,-0.0012372008059173822,-0.0012063519097864628,-0.0011981258867308497,-0.0011817571939900517,-0.0011412535095587373,-0.0010906446259468794,-0.0010310661746188998,-0.0009711459861136973,-0.000917646219022572,-0.0008729564724490047,-0.0008372545125894248,-0.0008079382823780179,-0.0007842223276384175,-0.000752967142034322,-0.0009341562399640679,-0.0012588015524670482,-0.0014847551938146353,-0.0016111732693389058,-0.0016632367623969913,-0.0016761396545916796,-0.0016754905227571726,-0.00169307307805866,-0.0016916560707613826,-0.001651678467169404,-0.001552360481582582,-0.0013825553469359875,-0.0011801415821537375,-0.00121578190010041,-0.0014463146217167377,-0.0015914356335997581,-0.001635469845496118,-0.0015927660278975964,-0.0014860773226246238,-0.0013437675079330802,-0.0011816626647487283,-0.0009988705860450864,-0.0010333990212529898,-0.0012139813043177128,-0.001240654499270022,-0.0011537378886714578,-0.0009570196270942688,-0.0007200178224593401,-0.0004837124433834106,-0.0001719558786135167,0.0004890551208518445,0.0012080136220902205,0.0017595762619748712,0.0022199065424501896,0.002758029382675886,0.0033201901242136955,0.003916691057384014,0.004487681668251753,0.005092875100672245,0.0053191520273685455,0.0056102401576936245,0.005861509591341019,0.006357947364449501,0.006961014587432146,0.007289759814739227,0.007482327055186033,0.007215303834527731,0.007133981212973595,0.00727883679792285,0.007350774947553873,0.007245594635605812,0.007272699847817421,0.0074937851168215275,0.0077164978720247746,0.008100070990622044,0.008380785584449768,0.008537685498595238,0.008859977126121521,0.009350869804620743,0.009749693796038628,0.010090714320540428,0.010344131849706173,0.010453475639224052,0.01063546258956194,0.01083442009985447,0.011017898097634315,0.011194467544555664,0.01132058072835207,0.01117396354675293,0.010703403502702713,0.01002538576722145,0.009200824424624443,0.008488365449011326,0.008211762644350529,0.008122834376990795,0.007900390774011612,0.007546005304902792,0.007136232685297728,0.0068094199523329735,0.0065790037624537945,0.006375747732818127,0.006152620539069176,0.005921377334743738,0.005728140473365784,0.005621601361781359,0.005595453083515167,0.00573167996481061,0.005780850071460009,0.005786260589957237,0.0057821436785161495,0.005743683781474829,0.005661056376993656,0.005508878733962774,0.005358120892196894,0.005215981509536505,0.005073139443993568,0.004900503437966108,0.004649400245398283,0.004364689812064171,0.0041070361621677876,0.004049379378557205,0.004150631837546825,0.0041779098100960255,0.004096302203834057,0.0039299349300563335,0.003835190087556839,0.0037346226163208485,0.00359684182330966,0.0034236274659633636,0.003266263520345092,0.0031683032866567373,0.0029577508103102446,0.0027110264636576176,0.002450404455885291,0.0021658455953001976,0.0018317284993827343,0.0016327914781868458,0.0016464912332594395,0.0017258470179513097,0.0016762157902121544,0.0016714601079002023,0.0017980319680646062,0.0019916798919439316,0.002226185752078891,0.002448452403768897,0.0026571229100227356,0.0028468878008425236,0.002956008305773139,0.0030531263910233974,0.0031669961754232645,0.003252748865634203,0.0033021876588463783,0.0033431441988795996,0.00333456345833838,0.0033014656510204077,0.003269883804023266,0.003229452995583415,0.0031755289528518915,0.003053796710446477,0.0028576801996678114,0.002582407323643565,0.0022875654976814985,0.0020853423047810793,0.0019346129847690463,0.0017488411394879222,0.0015046632615849376,0.001200926722958684,0.0009441970614716411,0.0007447371608577669,0.0006178494659252465,0.0005348607082851231,0.00041442690417170525,0.00022969074780121446,3.746259608305991e-05,-0.00010907913383562118,-0.00020904674602206796,-0.0002494261134415865,-0.000214315892662853,-0.0001386015210300684,-6.12291696597822e-05,-2.0752131604240276e-06,2.095296986226458e-05,5.088342368253507e-05,0.00010210115578956902,0.00018092067330144346,0.0002508237666916102,0.00031063627102412283,0.0003650424478109926,0.0004092659510206431,0.00042346277041360736,0.0003941891191061586,0.00032858451595529914,0.0002479550603311509,0.00019914917356800288,0.0002122295554727316,0.00025274328072555363,0.000243305679759942,0.0002326237881788984,0.00018004914454650134,7.25690697436221e-05,-4.081311635673046e-05,-9.017332922667265e-05,-0.0001083771203411743,-0.00014566066965926439,-0.0002706466184463352,-0.00046803418081253767,-0.0006374120130203664,-0.0007272306247614324,-0.0007461105124093592,-0.0007879026816226542,-0.0008723969222046435,-0.0009875250980257988,-0.00105691934004426,-0.0010690370108932257,-0.0010147466091439128,-0.0009791881311684847,-0.0009795587975531816,-0.0010114379692822695,-0.0010071945143863559,-0.0010134207550436258,-0.0010278687113896012,-0.0010179025121033192,-0.0009999530157074332,-0.0009734107297845185,-0.0009427097393199801,-0.0009407397010363638,-0.0009451864170841873,-0.0009339925600215793,-0.0008882855181582272,-0.0008407295099459589,-0.000849870964884758,-0.0009491335949860513,-0.0011251113610342145,-0.0012825154699385166,-0.0013808105140924454,-0.0013888649409636855,-0.0013612089678645134,-0.0013711206847801805,-0.0014313936699181795,-0.001514360075816512,-0.001598387723788619,-0.0016427284572273493,-0.001643845229409635,-0.0015982629265636206,-0.0015678951749578118,-0.0015929321525618434,-0.0016944223316386342,-0.0018163769273087382,-0.001900989911518991,-0.0019160476513206959,-0.0018702885136008263,-0.001829573418945074,-0.001839889562688768],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"Test Estimate\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800],\"y\":[-0.26268917322158813,-0.25489625334739685,-0.2476004809141159,-0.24065400660037994,-0.2338995337486267,-0.22734929621219635,-0.22099272906780243,-0.21484047174453735,-0.20891574025154114,-0.20323069393634796,-0.19780394434928894,-0.19262102246284485,-0.18772195279598236,-0.1832975298166275,-0.17909182608127594,-0.17510023713111877,-0.17131607234477997,-0.16770116984844208,-0.16429471969604492,-0.16108785569667816,-0.15806373953819275,-0.15521128475666046,-0.152523934841156,-0.1499563753604889,-0.14753641188144684,-0.14523212611675262,-0.14294427633285522,-0.14073415100574493,-0.13860662281513214,-0.13656722009181976,-0.13459834456443787,-0.13269157707691193,-0.13084200024604797,-0.12901745736598969,-0.1267842948436737,-0.12440463900566101,-0.12208790332078934,-0.11983110010623932,-0.11763038486242294,-0.11548299342393875,-0.1133851408958435,-0.111332468688488,-0.1093224510550499,-0.10738836973905563,-0.10553070157766342,-0.10370414704084396,-0.10191729664802551,-0.1001635417342186,-0.09843479841947556,-0.09673050791025162,-0.09504978358745575,-0.09339375048875809,-0.09176032990217209,-0.09014969319105148,-0.08857637643814087,-0.08706503361463547,-0.08557770401239395,-0.08405431360006332,-0.08254571259021759,-0.08105982095003128,-0.07957974076271057,-0.07796268165111542,-0.07630092650651932,-0.07465816289186478,-0.0730140283703804,-0.07138977199792862,-0.06969498097896576,-0.06799691170454025,-0.06631859391927719,-0.06447015702724457,-0.06253839284181595,-0.060621410608291626,-0.05872728303074837,-0.056874945759773254,-0.055051930248737335,-0.053280048072338104,-0.05157287046313286,-0.0499359630048275,-0.04828716814517975,-0.04649234563112259,-0.044536054134368896,-0.042636677622795105,-0.040791261941194534,-0.03899919614195824,-0.03725987672805786,-0.035572681576013565,-0.033922821283340454,-0.03231010586023331,-0.030733197927474976,-0.029194796457886696,-0.027698379009962082,-0.026235250756144524,-0.024804476648569107,-0.02340097911655903,-0.022023731842637062,-0.020682429894804955,-0.01936149038374424,-0.018048275262117386,-0.016736743971705437,-0.015422123484313488,-0.01409484539180994,-0.012759383767843246,-0.011422896757721901,-0.010090513154864311,-0.00876875501126051,-0.007461331784725189,-0.006171541754156351,-0.004902941640466452,-0.0036591212265193462,-0.002354591852054,-0.0008682456682436168,0.0005693501443602145,0.0019594470504671335,0.0033012619242072105,0.004593991674482822,0.005840596277266741,0.007044829428195953,0.008200161159038544,0.009306101128458977,0.01036277785897255,0.011371592991054058,0.012337209656834602,0.01325893122702837,0.014102627523243427,0.014911839738488197,0.015688082203269005,0.016433769837021828,0.017150182276964188,0.01783823035657406,0.018498526886105537,0.01913200505077839,0.019739633426070213,0.020315174013376236,0.02086392417550087,0.021390967071056366,0.02189737930893898,0.022385163232684135,0.022855600342154503,0.023309646174311638,0.02374839596450329,0.024173010140657425,0.024585146456956863,0.024986721575260162,0.025379974395036697,0.025768261402845383,0.026147861033678055,0.026519248262047768,0.026882927864789963,0.027239549905061722,0.027594301849603653,0.02794678881764412,0.028298458084464073,0.028649628162384033,0.028999553993344307,0.029347779229283333,0.02969389036297798,0.030037561431527138,0.030378466472029686,0.030716191977262497,0.03105064481496811,0.03138155862689018,0.03170846030116081,0.032031070441007614,0.03235249221324921,0.03267215937376022,0.03298695757985115,0.03329668566584587,0.033601365983486176,0.03390428423881531,0.03420492634177208,0.03450395166873932,0.03480081260204315,0.035094983875751495,0.03538600355386734,0.03567368909716606,0.03595767915248871,0.03623771667480469,0.03651318699121475,0.03678469732403755,0.03705202415585518,0.037315089255571365,0.03757685422897339,0.03783685341477394,0.03809467330574989,0.03834977373480797,0.038602039217948914,0.038850490003824234,0.039095018059015274,0.039335694164037704,0.039572399109601974,0.03980519250035286,0.04003433510661125,0.040262673050165176,0.04048997908830643,0.04072962701320648,0.040972065180540085,0.04121113941073418,0.041447073221206665,0.041679996997117996,0.04191009700298309,0.042137645184993744,0.04236358776688576,0.042589329183101654,0.04281333461403847,0.043035876005887985,0.04325712099671364,0.04347701370716095,0.04369568079710007,0.04391274228692055,0.0441286563873291,0.044346388429403305,0.04457388445734978,0.04479428008198738,0.04500255733728409,0.04521278664469719,0.04542491212487221,0.045640863478183746,0.04585966840386391,0.046080753207206726,0.04630432650446892,0.046529993414878845,0.046737171709537506,0.04689415171742439,0.047035545110702515,0.047174420207738876,0.047315023839473724,0.04745869338512421,0.04760393127799034,0.04775066673755646,0.04789434373378754,0.04803347960114479,0.04817310348153114,0.048314038664102554,0.048454638570547104,0.04859580472111702,0.04873984679579735,0.048886992037296295,0.04890162870287895,0.04872507229447365,0.04856026917695999,0.04840743914246559,0.048271406441926956,0.04815010353922844,0.048043977469205856,0.04795311391353607,0.047875870019197464,0.04781569913029671,0.04777182638645172,0.04774382337927818,0.04773009940981865,0.04772954434156418,0.047741346061229706,0.04776693880558014,0.04780520126223564,0.04785403609275818,0.047911982983350754,0.04797818139195442,0.048051781952381134,0.04813161492347717,0.048217207193374634,0.04830823838710785,0.04840414598584175,0.048504170030355453,0.04860770329833031,0.04871362820267677,0.04882147163152695,0.04893070086836815,0.049040962010622025,0.049151789397001266,0.04926246777176857,0.04937275871634483,0.049481138586997986,0.049587592482566833,0.04969222843647003,0.04979543760418892,0.04989682510495186,0.04999657720327377,0.05009303614497185,0.05018648877739906,0.050278399139642715,0.05036841332912445,0.05045675113797188,0.05054256319999695,0.05062611773610115,0.05070783197879791,0.05078813433647156,0.05086740478873253,0.05094587057828903,0.051023926585912704,0.051088303327560425,0.05115178972482681,0.05121566727757454,0.05128040909767151,0.051353346556425095,0.051428064703941345,0.05150282755494118,0.05157795548439026,0.05165373533964157,0.051730409264564514,0.05180820822715759,0.05188729986548424,0.0519677996635437,0.05204978212714195,0.05213329568505287,0.05221843346953392,0.05230521783232689,0.052393682301044464,0.05248379334807396,0.05257123336195946,0.052657000720500946,0.05274474620819092,0.05283437669277191,0.05292430892586708,0.05301457643508911,0.05311325192451477,0.053217194974422455,0.05332116037607193,0.05342581123113632,0.053530555218458176,0.053635284304618835,0.05374002084136009,0.05384470894932747,0.05394937843084335,0.0540538989007473,0.05415310710668564,0.054251790046691895,0.05435001850128174,0.054446641355752945,0.054541926831007004,0.054637257009744644,0.05475880578160286,0.054880205541849136,0.055001337081193924,0.05512242391705513,0.055247120559215546,0.05537000671029091,0.055491264909505844,0.05561086907982826,0.05572887137532234,0.0558452345430851,0.05595994368195534,0.0560729019343853,0.0561840645968914,0.05629316344857216,0.056400127708911896,0.05650489032268524,0.05660735443234444,0.05670745298266411,0.05680512264370918,0.056900255382061005,0.056992847472429276,0.05708323419094086,0.05717325955629349,0.057261377573013306,0.05734758824110031,0.05743192136287689,0.057514458894729614,0.057595886290073395,0.057675328105688095,0.05775274708867073,0.05782832205295563,0.0579022578895092,0.05797469988465309,0.05804586037993431,0.058115873485803604,0.05818484351038933,0.05825290083885193,0.05832020193338394,0.05838768184185028,0.05845460295677185,0.058521684259176254,0.05858892202377319,0.05865637958049774,0.05872339382767677,0.05879009887576103,0.058856599032878876,0.05892295017838478,0.058989208191633224,0.0590556338429451,0.05912221595644951,0.059188928455114365,0.0592564158141613,0.05932468920946121,0.059393078088760376,0.05946142598986626,0.059529706835746765,0.05959787592291832,0.05966590717434883,0.059733759611845016,0.05980134755373001,0.05986862629652023,0.05993618071079254,0.060003913938999176,0.06007111072540283,0.06013781577348709,0.060203973203897476,0.06026960536837578,0.060334667563438416,0.06039920821785927,0.06046314164996147,0.060526490211486816,0.06058921664953232,0.06065131723880768,0.060713380575180054,0.06077534705400467,0.06083659827709198,0.06089716777205467,0.06095709279179573,0.061016399413347244,0.061075109988451004,0.06113323196768761,0.061190783977508545,0.06124775484204292,0.061304155737161636,0.06135999783873558,0.06141527742147446,0.06146993860602379,0.06152403727173805,0.06157749518752098,0.06163090839982033,0.0616842582821846,0.06173694506287575,0.061789024621248245,0.061840564012527466,0.0618915818631649,0.061942096799612045,0.06199214607477188,0.06204170361161232,0.06209082156419754,0.06213948503136635,0.06218770891427994,0.062235478311777115,0.062282830476760864,0.062329746782779694,0.0623762272298336,0.062422264367341995,0.06246786564588547,0.06251302361488342,0.06255772709846497,0.06260193884372711,0.06264565140008926,0.06268880516290665,0.06273136287927628,0.0627737045288086,0.0628150999546051,0.06285511702299118,0.06289313733577728,0.06292867660522461,0.06296156346797943,0.0629919096827507,0.06302008777856827,0.06304655969142914,0.06307189911603928,0.06309671700000763,0.06312151998281479,0.06314676254987717,0.06317278742790222,0.06319975852966309,0.06322776526212692,0.06325676292181015,0.06328665465116501,0.06331728398799896,0.06334846466779709,0.06337999552488327,0.06341177970170975,0.06344372034072876,0.06347577273845673,0.06350795924663544,0.06354033201932907,0.06357300281524658,0.06360607594251633,0.06363967061042786,0.06367387622594833,0.06370876729488373,0.06374417245388031,0.06378006935119629,0.06381644308567047,0.06385324150323868,0.06389035284519196,0.06392765790224075,0.06396499276161194,0.06400226056575775,0.06403929740190506,0.06407599151134491,0.06411223858594894,0.06414800137281418,0.06418324261903763,0.0642179474234581,0.0642520934343338,0.06428574025630951,0.06431891769170761,0.06435167044401169,0.06438400596380234,0.06441601365804672,0.06444764137268066,0.06447893381118774,0.06450989842414856,0.06454052031040192,0.06457075476646423,0.0646006241440773,0.06463008373975754,0.06625521183013916,0.06716972589492798,0.0677403137087822,0.06797387450933456,0.06798873096704483,0.06790939718484879,0.06783993542194366,0.06783781200647354,0.06790284067392349,0.06798865646123886,0.06807179749011993,0.06807941943407059,0.06802616268396378,0.06794759631156921,0.06785336881875992,0.067725770175457,0.06756008416414261,0.06732886284589767,0.06702934205532074,0.06670784205198288,0.06638200581073761,0.06606785953044891,0.06580591201782227,0.06559333205223083,0.06542208045721054,0.06528215110301971,0.06516335159540176,0.0650625228881836,0.06497997045516968,0.06491196155548096,0.06485976278781891,0.06482378393411636,0.06480155885219574,0.0647657960653305,0.06473549455404282,0.06470366567373276,0.06466712802648544,0.06462514400482178,0.06457961350679398,0.06453578919172287,0.06449731439352036,0.06446590274572372,0.06444697827100754,0.06443904340267181,0.06444017589092255,0.06444859504699707,0.06448416411876678,0.06452953070402145,0.0645812377333641,0.06464114785194397,0.06470733880996704,0.064779132604599,0.06485499441623688,0.06493636220693588,0.06501840800046921,0.06510443985462189,0.06519302725791931,0.0652848407626152,0.06537847965955734,0.06547216325998306,0.06551961600780487,0.06553696095943451,0.06553290784358978,0.06550908088684082,0.06547608971595764,0.0654204785823822,0.06539582461118698,0.06540010124444962,0.06540343910455704,0.06540685892105103,0.0653967410326004,0.0653686374425888,0.06531860679388046,0.06524879485368729,0.06517045944929123,0.06508900970220566,0.06501518934965134,0.06495259702205658,0.06489282846450806,0.06485295295715332,0.06483079493045807,0.06480298936367035,0.0647711306810379,0.0647280290722847,0.06466885656118393,0.06458449363708496,0.06447974592447281,0.06434933841228485,0.06424375623464584,0.06417220830917358,0.06411836296319962,0.06407903879880905,0.06404227018356323,0.06398715078830719,0.06389892846345901,0.06378049403429031,0.06364692747592926,0.0635499507188797,0.06349289417266846,0.06346944719552994,0.06344789266586304,0.06341464817523956,0.06383293122053146,0.06425101310014725,0.06466415524482727,0.06510094553232193,0.06556675583124161,0.0661100521683693,0.06661932170391083,0.06689921021461487,0.06717777997255325,0.06723878532648087,0.06739713996648788,0.06751064211130142,0.06759880483150482,0.06780049949884415,0.06803853064775467,0.06792907416820526,0.0675281509757042,0.0672200471162796,0.06707591563463211,0.06703822314739227,0.06703657656908035,0.06678665429353714,0.06631646305322647,0.06592754274606705,0.06564151495695114,0.06556112319231033,0.06568014621734619,0.06567853689193726,0.06551004201173782,0.06517428159713745,0.06471966207027435,0.06440433114767075,0.0644870325922966,0.06477010250091553,0.06510048359632492,0.0654640793800354,0.06565248221158981,0.06553120911121368,0.06515661627054214,0.06479135900735855,0.06449706107378006,0.0643301010131836,0.06420113146305084,0.06405708938837051,0.06382641941308975,0.0634259432554245,0.06289786100387573,0.06234259158372879,0.06185578554868698,0.061524346470832825,0.06111564859747887,0.060821715742349625,0.060809895396232605,0.061036303639411926,0.06139788776636124,0.061783015727996826,0.06211097538471222,0.06229783222079277,0.06206551566720009,0.061474427580833435,0.06089169904589653,0.060493916273117065,0.06032096594572067,0.06035938858985901,0.06027736887335777,0.06007188558578491,0.060028478503227234,0.060130372643470764,0.06035720929503441,0.06056436896324158,0.06076497212052345,0.06093237176537514,0.060941148549318314,0.060553960502147675,0.060134075582027435,0.05991627648472786,0.05989617854356766,0.06003928184509277,0.060287877917289734,0.06057533621788025,0.06042839214205742,0.059874266386032104,0.05939458683133125,0.05915919318795204,0.059131231158971786,0.05921563878655434,0.05941259115934372,0.0596616268157959,0.059896569699048996,0.060051243752241135,0.06012870371341705,0.0602632574737072,0.060440562665462494,0.0606137216091156,0.060753270983695984,0.06085311993956566,0.06086237356066704,0.06081613153219223,0.06076741963624954,0.06075439974665642,0.060516003519296646,0.060314446687698364,0.06023740395903587,0.060219306498765945,0.06027236208319664,0.06041021645069122,0.06053538993000984,0.06041429564356804,0.06033691391348839,0.06027631834149361,0.06037374958395958,0.06050574779510498,0.060679901391267776,0.06086402013897896,0.06100282073020935,0.06117233261466026,0.061099812388420105,0.06071228161454201,0.06034150347113609,0.060191474854946136,0.0602615587413311,0.060404688119888306,0.060584656894207,0.060757141560316086,0.06089141219854355,0.06074781343340874,0.06060624495148659,0.060489051043987274,0.06042787432670593,0.060519665479660034,0.06071087718009949,0.06103621795773506,0.06108440086245537,0.060969360172748566,0.06079869344830513,0.06066039949655533,0.060590893030166626,0.060683589428663254,0.06087089702486992,0.061034075915813446,0.060920171439647675,0.060808539390563965,0.06070855259895325,0.06063975393772125,0.06064027175307274,0.06071179360151291,0.06081697344779968,0.06090313568711281,0.06082224100828171,0.06073031574487686,0.06066346913576126,0.06065236032009125,0.06059322506189346,0.060578834265470505,0.06058070808649063,0.060592468827962875,0.06060134246945381,0.06053577736020088,0.06052100658416748,0.06053178757429123,0.06054605171084404,0.06046563759446144,0.06033039465546608,0.060257378965616226,0.06024044007062912,0.06026986241340637,0.060232069343328476,0.060209497809410095,0.06020089611411095,0.06021508947014809,0.06026415899395943,0.06035333126783371,0.06036749109625816,0.0602930523455143,0.06013698875904083,0.06000739708542824,0.059932176023721695,0.05994570255279541,0.0600559264421463,0.06023210287094116,0.06030287966132164,0.060234058648347855,0.06012924760580063,0.060035254806280136,0.060016877949237823,0.06012863665819168,0.06033723056316376,0.06058281287550926,0.0607072189450264,0.06067889556288719,0.06052200496196747,0.06039967015385628,0.06038926541805267,0.06050655618309975,0.060620952397584915,0.060670074075460434,0.060697849839925766],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"On-policy Estimate\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800],\"y\":[0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659,0.820534186117659],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"IS Variance\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800],\"y\":[0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743,0.0013421167386695743],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"lines\",\"name\":\"Train Variance\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800],\"y\":[0.034637514501810074,0.14296461641788483,0.13820159435272217,0.13355617225170135,0.12911181151866913,0.12494096159934998,0.12114037573337555,0.11764343827962875,0.11433853209018707,0.1112397089600563,0.10828114300966263,0.10553138703107834,0.10291657596826553,0.10040438175201416,0.09806796908378601,0.09570126980543137,0.09334242343902588,0.09112657606601715,0.08903174847364426,0.08704527467489243,0.08515492081642151,0.08336013555526733,0.0816614031791687,0.08005491644144058,0.07853908836841583,0.07710998505353928,0.0757623091340065,0.0744708925485611,0.07307326048612595,0.07174216210842133,0.07050137966871262,0.06932660937309265,0.06820035725831985,0.06711791455745697,0.06606876105070114,0.06496718525886536,0.06389441341161728,0.06285775452852249,0.06185991317033768,0.06089257448911667,0.05995152145624161,0.05903705954551697,0.05814451351761818,0.05727557837963104,0.05642598867416382,0.055608488619327545,0.05481964722275734,0.05405329167842865,0.0533127523958683,0.05259299278259277,0.05188922956585884,0.05119970068335533,0.0505254864692688,0.04986356571316719,0.04921160638332367,0.04854341223835945,0.04788908362388611,0.04716862365603447,0.046395495533943176,0.04560817778110504,0.04478969797492027,0.04387721046805382,0.042952895164489746,0.04201288893818855,0.04106295108795166,0.04010610282421112,0.039145637303590775,0.03817850723862648,0.037209633737802505,0.03624053671956062,0.03526829928159714,0.034298162907361984,0.03334318473935127,0.0324162058532238,0.03152039274573326,0.030666563659906387,0.029857804998755455,0.029089946299791336,0.028365259990096092,0.027683233842253685,0.027041535824537277,0.026434456929564476,0.02586187981069088,0.02532176300883293,0.024811916053295135,0.024330174550414085,0.023873111233115196,0.023438656702637672,0.02302592433989048,0.02263265661895275,0.022267811000347137,0.02191947028040886,0.02158311940729618,0.021254735067486763,0.02093324437737465,0.020621633157134056,0.020314499735832214,0.020007755607366562,0.01969466172158718,0.019373981282114983,0.019045135006308556,0.018709644675254822,0.01836901158094406,0.01802748255431652,0.017686182633042336,0.017346257343888283,0.017008861526846886,0.016675103455781937,0.01634611375629902,0.01602102816104889,0.015698831528425217,0.015380896627902985,0.015068531967699528,0.014787151478230953,0.014515016227960587,0.01425219140946865,0.013993803411722183,0.013744023628532887,0.01350573543459177,0.013278849422931671,0.013063154183328152,0.012858405709266663,0.01266432460397482,0.012478037737309933,0.01229933649301529,0.01213065441697836,0.011971810832619667,0.011822152882814407,0.011678637005388737,0.011540804989635944,0.011410672217607498,0.011287476867437363,0.011168298311531544,0.011052695102989674,0.010942475870251656,0.01083718053996563,0.010734038427472115,0.010632729157805443,0.010535040870308876,0.010440414771437645,0.010346260853111744,0.010252389125525951,0.010159069672226906,0.010068162344396114,0.009979233145713806,0.009889928624033928,0.009800144471228123,0.009709839709103107,0.00962095521390438,0.009531739167869091,0.009438578970730305,0.009339527226984501,0.00923998560756445,0.009140455164015293,0.009042938239872456,0.008947332389652729,0.008853573352098465,0.008759903721511364,0.00866646971553564,0.008573473431169987,0.008481056429445744,0.008389284834265709,0.008290288038551807,0.008183708414435387,0.008080179803073406,0.007978004403412342,0.007877313531935215,0.0077782971784472466,0.007681061513721943,0.007585665676742792,0.007492092903703451,0.007400337141007185,0.007310341577976942,0.007222045212984085,0.007136857602745295,0.00705453148111701,0.006974812131375074,0.006896082777529955,0.006818901281803846,0.006743074394762516,0.006646160036325455,0.00654224120080471,0.006439453922212124,0.006337938364595175,0.006237787660211325,0.006139057222753763,0.006041775923222303,0.005945997312664986,0.005851783324033022,0.0057592145167291164,0.005668298806995153,0.005579026415944099,0.0054909177124500275,0.0054040034301579,0.005318273324519396,0.005233706906437874,0.0051507847383618355,0.005069480277597904,0.0049897427670657635,0.004911507945507765,0.004834729712456465,0.004759350325912237,0.0046852752566337585,0.004612474702298641,0.004540774971246719,0.00447017652913928,0.004400710109621286,0.004332380834966898,0.004265193827450275,0.004199161659926176,0.004134288523346186,0.004070592112839222,0.004008380696177483,0.00394706055521965,0.0038866063114255667,0.0038270296063274145,0.0037683481350541115,0.0037135391030460596,0.0036596080753952265,0.003606435377150774,0.0035539933014661074,0.003502268809825182,0.0034512383863329887,0.0034008952789008617,0.0033473835792392492,0.003292256034910679,0.0032378043979406357,0.00318403379060328,0.003130944212898612,0.003078693291172385,0.0030271431896835566,0.0029761986806988716,0.0029258232098072767,0.0028744153678417206,0.002823730232194066,0.002773749176412821,0.0027244947850704193,0.0026760182809084654,0.0026284391060471535,0.0025816767010837793,0.0025350418873131275,0.002489339327439666,0.002462409669533372,0.0024366213474422693,0.0024106143973767757,0.00238440977409482,0.0023578586988151073,0.002330965595319867,0.002303759101778269,0.002276296028867364,0.002248648786917329,0.0022209163289517164,0.0021931566298007965,0.0021653727162629366,0.0021377061493694782,0.0021102807950228453,0.002083185128867626,0.002056514611467719,0.002030368894338608,0.0020048117730766535,0.0019799028523266315,0.0019556868355721235,0.0019322108710184693,0.0019095083698630333,0.001887616002932191,0.001866550068370998,0.0018463096348568797,0.0018268811982125044,0.0018089085351675749,0.001791871734894812,0.0017755533335730433,0.0017599430866539478,0.0017448161961510777,0.0017302562482655048,0.001716236351057887,0.0017027065623551607,0.0016896325396373868,0.0016770074144005775,0.001664771232753992,0.0016528770793229342,0.0016412182012572885,0.0016297707334160805,0.001618576585315168,0.0016075089806690812,0.0015965176280587912,0.0015855642268434167,0.0015746160643175244,0.0015636318130418658,0.001552585163153708,0.001541460631415248,0.0015302436659112573,0.0015189270488917828,0.001507511013187468,0.001495998352766037,0.0014844023389741778,0.0014734304277226329,0.0014630205696448684,0.0014531031483784318,0.0014436182100325823,0.0014344897354021668,0.0014256684808060527,0.0014171081129461527,0.0014087633462622762,0.0014005976263433695,0.001392571022734046,0.001384654315188527,0.0013768147910013795,0.0013690374325960875,0.0013612972106784582,0.0013535660691559315,0.0013458365574479103,0.0013381039025261998,0.00133129779715091,0.00132530159316957,0.0013200121466070414,0.0013153222389519215,0.0013111332664266229,0.0013073496520519257,0.0013038842007517815,0.0013006492517888546,0.0012975723948329687,0.001294581568799913,0.0012916189152747393,0.0012886321637779474,0.0012855746317654848,0.0012824159348383546,0.001274977345019579,0.0012674443423748016,0.0012602787464857101,0.0012534274719655514,0.0012468385975807905,0.0012404697481542826,0.0012342818081378937,0.001228237058967352,0.0012220534263178706,0.0012138173915445805,0.0012039104476571083,0.001192555297166109,0.0011799578787758946,0.0011663218028843403,0.001151844160631299,0.0011367034167051315,0.0011210674419999123,0.001105085015296936,0.0010888881515711546,0.001072597922757268,0.0010563157266005874,0.0010401314357295632,0.0010241050040349364,0.0010083155939355493,0.0009928122162818909,0.0009776095394045115,0.000964340113569051,0.0009529219241812825,0.0009431374492123723,0.0009347955929115415,0.0009277184144593775,0.0009216094622388482,0.0009148136014118791,0.0009073865367099643,0.0008993862429633737,0.0008908717427402735,0.0008819057256914675,0.000872549950145185,0.0008628680370748043,0.0008529217448085546,0.0008427725988440216,0.0008324745576828718,0.0008220865274779499,0.0008116405224427581,0.0008025817223824561,0.0007948186830617487,0.0007881688652560115,0.0007811220129951835,0.0007737536798231304,0.0007661149720661342,0.0007582406396977603,0.0007501805084757507,0.00074197439244017,0.0007336653652600944,0.0007252705981954932,0.0007181084947660565,0.0007120303926058114,0.0007056642789393663,0.0006990606198087335,0.0006922560278326273,0.0006852857186459005,0.00067818135721609,0.0006709728040732443,0.000663661805447191,0.0006562453927472234,0.0006499452865682542,0.0006446126499213278,0.000638988392893225,0.0006331162876449525,0.000627020257525146,0.0006207356927916408,0.0006142950733192265,0.0006077290745452046,0.0006010666838847101,0.0005943363648839295,0.0005875644274055958,0.0005807557026855648,0.000574975332710892,0.0005700753536075354,0.0005649679806083441,0.0005596884875558317,0.0005542623111978173,0.0005487122107297182,0.0005430631572380662,0.0005373362801037729,0.0005315532325766981,0.0005257283337414265,0.000519880501087755,0.000514024926815182,0.0005081786075606942,0.0005023609846830368,0.0004965831176377833,0.0004908324917778373,0.00048599488218314946,0.00048193216207437217,0.0004777320136781782,0.0004734103276859969,0.00046898264554329216,0.00046446401393041015,0.0004598607192747295,0.0004551882157102227,0.00045046047307550907,0.00044569294550456107,0.00044089797302149236,0.00043607474071905017,0.00043123585055582225,0.0004264033050276339,0.0004215719527564943,0.00041674289968796074,0.0004119251680094749,0.0004070998402312398,0.0004023141518700868,0.000397523952415213,0.0003927339566871524,0.0003876840928569436,0.00038220029091462493,0.0003766260342672467,0.00037188586429692805,0.0003656672779470682,0.000359599303919822,0.0003540955076459795,0.00034954241709783673,0.0003460762673057616,0.0003435843682382256,0.0003418521664571017,0.00034063824568875134,0.000339693040587008,0.00033876675297506154,0.00033762361272238195,0.00033606853685341775,0.00033397568040527403,0.00033130761585198343,0.0003281041863374412,0.0003244602703489363,0.000320503197144717,0.0003163750225212425,0.0003122153866570443,0.00030815054196864367,0.00030428089667111635,0.0003006755723617971,0.00029736533178947866,0.0002943451690953225,0.00029158141114749014,0.00028901969199068844,0.0002865914721041918,0.00028422559262253344,0.0002818511857185513,0.0002794082392938435,0.0002768531849142164,0.00027416174998506904,0.00027132706600241363,0.00026836167671717703,0.00026529296883381903,0.0002621587773319334,0.0002590007788967341,0.00025586190167814493,0.00025277878739871085,0.0002497806854080409,0.0002468868042342365,0.00024410501646343619,0.00024143447808455676,0.00023886255803517997,0.00023637285630684346,0.0002339412458240986,0.00023154370137490332,0.00022915696899872273,0.0002267615927848965,0.00022434339916799217,0.00022189370065461844,0.00021941175509709865,0.00021690137509722263,0.00021437219402287155,0.00021183854551054537,0.0002093137300107628,0.0004076724871993065,0.00022682965209241956,0.00021683106024283916,0.0001962667447514832,0.00017420548829250038,0.00015173526480793953,0.00012843434524256736,0.00010404294880572706,7.971160812303424e-05,5.7829452998703346e-05,4.171056571067311e-05,2.95344325422775e-05,2.25081093958579e-05,1.8217266188003123e-05,1.5092353351064958e-05,1.3036904420005158e-05,1.2169674846518319e-05,1.2520074051280972e-05,1.3907694665249437e-05,1.5962854376994073e-05,1.8226402971777134e-05,2.034283352259081e-05,2.2038268070900813e-05,2.3197540940600447e-05,2.3683176550548524e-05,2.34430845011957e-05,2.2488748072646558e-05,2.1036923499195836e-05,1.933310522872489e-05,1.7631335140322335e-05,1.6127745766425505e-05,1.489705391577445e-05,1.3957330338598695e-05,1.3264566405268852e-05,1.2811408851121087e-05,1.2574277207022533e-05,1.2507298379205167e-05,1.2579755093611311e-05,1.2764812709065154e-05,1.3029885849391576e-05,1.3331328773347195e-05,1.362656712444732e-05,1.3885898624721449e-05,1.4083994756219909e-05,1.421107299393043e-05,1.428632367606042e-05,1.4331587408378255e-05,1.4371426914294716e-05,1.4412731616175734e-05,1.4446179193328135e-05,1.4460480088018812e-05,1.44517016451573e-05,1.442519533156883e-05,1.4393263882084284e-05,1.4359436136146542e-05,1.4473429473582655e-05,1.4540247320837807e-05,1.4523991012538318e-05,1.447024078515824e-05,1.4408639799512457e-05,1.4360036402649712e-05,1.434093155694427e-05,1.4357538020703942e-05,1.4409207324206363e-05,1.4487755834124982e-05,1.4583436495740898e-05,1.4678301340609323e-05,1.5003287444415037e-05,1.556948700454086e-05,1.6022486306610517e-05,1.627934761927463e-05,1.637718014535494e-05,1.641658673179336e-05,1.6474659787490964e-05,1.6759930076659657e-05,1.7018639482557774e-05,1.7176635083160363e-05,1.718236853776034e-05,1.702920053503476e-05,1.682530273683369e-05,1.707916089799255e-05,1.7751899576978758e-05,1.827428422984667e-05,1.8540667952038348e-05,1.857124334492255e-05,1.8444152374286205e-05,1.827419146138709e-05,1.8113210899173282e-05,1.798052471713163e-05,1.828937092795968e-05,1.8897120753536e-05,1.9154822439304553e-05,1.932271698024124e-05,1.9329685528646223e-05,1.936975786520634e-05,1.9545890609151684e-05,1.9726649043150246e-05,1.9728704501176253e-05,1.9568084098864347e-05,1.9512192011461593e-05,1.943862844200339e-05,1.9228176824981347e-05,1.910922037495766e-05,1.919513670145534e-05,1.9520271962392144e-05,2.0077113731531426e-05,2.0482415493461303e-05,2.0939925889251754e-05,2.116991345246788e-05,2.1489575374289416e-05,2.2163727408042178e-05,2.2681579139316455e-05,2.324955494259484e-05,2.311705975444056e-05,2.3523007257608697e-05,2.4722095986362547e-05,2.5872090191114694e-05,2.646598659339361e-05,2.727654282352887e-05,2.8415397537173703e-05,2.9374885343713686e-05,3.0812097975285724e-05,3.173542791046202e-05,3.200086939614266e-05,3.2787505915621296e-05,3.409859345993027e-05,3.485223351162858e-05,3.514601485221647e-05,3.504726919345558e-05,3.456072954577394e-05,3.458699211478233e-05,3.46533561241813e-05,3.470509545877576e-05,3.495822238619439e-05,3.5952849430032074e-05,3.6156507121631876e-05,3.560980621841736e-05,3.479962470009923e-05,3.40370497724507e-05,3.353516149218194e-05,3.3114130928879604e-05,3.285685306764208e-05,3.298541560070589e-05,3.3818672818597406e-05,3.5108892916468903e-05,3.6643585190176964e-05,3.804060906986706e-05,3.914794433512725e-05,3.996753730461933e-05,4.057542537339032e-05,4.106818596483208e-05,4.157019793638028e-05,4.256618194631301e-05,4.357498255558312e-05,4.469780105864629e-05,4.594002166413702e-05,4.7089757572393864e-05,4.791046376340091e-05,4.813005216419697e-05,4.7932302550179884e-05,4.808072844753042e-05,4.853857171838172e-05,4.919288767268881e-05,5.0456757890060544e-05,5.257280281512067e-05,5.535988020710647e-05,5.805783439427614e-05,5.9326630434952676e-05,5.93922013649717e-05,5.932506246608682e-05,5.9520647482713684e-05,5.997956759529188e-05,6.0200585721759126e-05,6.0248345107538626e-05,6.008041600580327e-05,5.968529512756504e-05,5.9333786339266226e-05,5.97316466155462e-05,6.134466821094975e-05,6.304179987637326e-05,6.446717452490702e-05,6.55081239528954e-05,6.608827243326232e-05,6.559480971191078e-05,6.438413402065635e-05,6.309684977168217e-05,6.175009912112728e-05,6.0007445426890627e-05,5.749549382016994e-05,5.483282438945025e-05,5.271870395517908e-05,5.1524311857065186e-05,5.10181525896769e-05,5.1423889090074226e-05,5.229527596384287e-05,5.301680357661098e-05,5.289755426929332e-05,5.2151550335111097e-05,5.122378934174776e-05,5.0492155423853546e-05,5.021278411732055e-05,5.0520589866209775e-05,5.1305556553415954e-05,5.2600189519580454e-05,5.3972515161149204e-05,5.599129872280173e-05,5.7765282690525055e-05,5.8893296227324754e-05,5.909622632316314e-05,5.8309648011345416e-05,5.713531209039502e-05,5.676636646967381e-05,5.710191180696711e-05,5.8239274949301034e-05,5.97411890339572e-05,6.132377166068181e-05,6.257953646127135e-05,6.342709821183234e-05,6.39665377093479e-05,6.441876030294225e-05,6.470224616350606e-05,6.468286301242188e-05,6.507966463686898e-05,6.524712807731703e-05,6.518079317174852e-05,6.501378811663017e-05,6.487503560492769e-05,6.475847476394847e-05,6.478322029579431e-05,6.461636803578585e-05,6.423061131499708e-05,6.366554589476436e-05,6.302070687524974e-05,6.23570813331753e-05,6.165028753457591e-05,6.104313797550276e-05,6.137153832241893e-05,6.183220830280334e-05,6.240567745408043e-05,6.282110553001985e-05,6.27815315965563e-05,6.214903987711295e-05,6.11591967754066e-05,6.045538975740783e-05,5.9705729654524475e-05,5.9341968153603375e-05,5.9462716308189556e-05,5.975271051283926e-05,5.975199383101426e-05,5.955504093435593e-05,5.939041875535622e-05,5.9629761381074786e-05,6.025681796018034e-05,6.076243516872637e-05,6.0932976339245215e-05,6.078961450839415e-05,6.0891947214258835e-05,6.135773583082482e-05,6.203528755577281e-05,6.234955071704462e-05,6.212478911038488e-05,6.216362089617178e-05,6.21528088231571e-05,6.228969141375273e-05,6.261811358854175e-05,6.270963058341295e-05,6.290835881372914e-05,6.321958790067583e-05,6.34130701655522e-05,6.347826274577528e-05,6.347385351546109e-05,6.34562165942043e-05,6.346381996991113e-05,6.33416639175266e-05,6.298534572124481e-05,6.232454325072467e-05,6.172352004796267e-05,6.155898154247552e-05,6.223276432137936e-05,6.367148307617754e-05,6.487861537607387e-05,6.531092367367819e-05,6.47898341412656e-05,6.380271224770695e-05,6.301211396930739e-05,6.279890658333898e-05,6.312663754215464e-05,6.370755727402866e-05,6.405669410014525e-05,6.39318604953587e-05,6.3447849242948e-05,6.302688416326419e-05,6.304635462583974e-05,6.36308832326904e-05,6.443020538426936e-05,6.489127554232255e-05,6.466146442107856e-05,6.391799252014607e-05,6.326488073682413e-05,6.316091457847506e-05],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"lines\",\"name\":\"Test Variance\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800],\"y\":[0.0229813139885664,0.022179115563631058,0.021404258906841278,0.020663166418671608,0.019953306764364243,0.019274909049272537,0.018625915050506592,0.018006283789873123,0.01741167902946472,0.01684913970530033,0.0163254551589489,0.015838921070098877,0.015381235629320145,0.014962122775614262,0.014565924182534218,0.014191399328410625,0.01383758895099163,0.013512484729290009,0.01320163905620575,0.01290409080684185,0.012621024623513222,0.012351722456514835,0.012095463462173939,0.011849158443510532,0.011621791869401932,0.011406900361180305,0.011196982115507126,0.010998273268342018,0.010810048319399357,0.010630162432789803,0.010456861928105354,0.010289783589541912,0.010129532776772976,0.009973028674721718,0.009809480048716068,0.009658250957727432,0.009514560922980309,0.009377636946737766,0.0092471269890666,0.009122730232775211,0.009004095569252968,0.00889099296182394,0.008783104829490185,0.008680415339767933,0.00858528632670641,0.008494150824844837,0.008405637927353382,0.008320121094584465,0.008238096721470356,0.00815939623862505,0.008083819411695004,0.008011410012841225,0.007942000404000282,0.007875392213463783,0.00780964270234108,0.007741909474134445,0.00767646636813879,0.00761000532656908,0.0075452602468431,0.0074823047034442425,0.007419804111123085,0.007352317217737436,0.00727796321734786,0.007203957531601191,0.0071263560093939304,0.007050564978271723,0.006967745255678892,0.00688453484326601,0.006802333518862724,0.006704599130898714,0.006600724533200264,0.006498303264379501,0.006398974917829037,0.006304262671619654,0.0062139322981238365,0.006129729561507702,0.006052677053958178,0.005981741938740015,0.005911682732403278,0.0058395531959831715,0.005765226669609547,0.005695397034287453,0.005630907136946917,0.0055715162307024,0.005516962613910437,0.005466965958476067,0.005420736502856016,0.005378230940550566,0.00533940689638257,0.005304068326950073,0.005271939095109701,0.005242733750492334,0.0052162348292768,0.005191887263208628,0.005169523414224386,0.00514964247122407,0.005131008569151163,0.005112950224429369,0.005094840656965971,0.0050763580948114395,0.005057311616837978,0.005037847440689802,0.005018090829253197,0.004998160060495138,0.004978139419108629,0.0049581099301576614,0.0049381437711417675,0.004918312653899193,0.004898663144558668,0.004880172200500965,0.004864675458520651,0.004849886987358332,0.004835787229239941,0.004822478163987398,0.004809767939150333,0.004797677975147963,0.004786194767802954,0.004775156732648611,0.004764513578265905,0.00475420942530036,0.004744221922010183,0.004734611138701439,0.004725285805761814,0.004715132061392069,0.004705318249762058,0.004695820156484842,0.0046865553595125675,0.004677509423345327,0.004668612498790026,0.004659820348024368,0.004651101306080818,0.004642408806830645,0.004634100943803787,0.0046259257942438126,0.004617685917764902,0.004609348718076944,0.004600874613970518,0.0045922365970909595,0.004583430010825396,0.004574434366077185,0.004565217532217503,0.004555779043585062,0.00454616267234087,0.004536341410130262,0.004526272416114807,0.004516003653407097,0.00450553186237812,0.004494864493608475,0.004484028555452824,0.004472775384783745,0.004461132921278477,0.004448990803211927,0.004436412826180458,0.004423434846103191,0.004410125780850649,0.004396536387503147,0.004382711835205555,0.004368678200989962,0.004354477860033512,0.00434013269841671,0.004325677175074816,0.0043111457489430904,0.004296578466892242,0.004282113630324602,0.004267766140401363,0.004253463353961706,0.004239228088408709,0.004225065931677818,0.004211109131574631,0.004197360947728157,0.004183842334896326,0.004170544911175966,0.004157456569373608,0.004144566133618355,0.004131878260523081,0.004119378514587879,0.004107053857296705,0.0040948702953755856,0.004082768689841032,0.004070747643709183,0.004058803431689739,0.004046826623380184,0.004034839104861021,0.004022856242954731,0.004010892007499933,0.003998954314738512,0.003987020812928677,0.0039751045405864716,0.003963225055485964,0.003951394464820623,0.0039396206848323345,0.003927925135940313,0.003916165325790644,0.003904349636286497,0.003892536275088787,0.0038809070829302073,0.0038693719543516636,0.003857934381812811,0.003846594365313649,0.00383534817956388,0.003824202809482813,0.0038131526671350002,0.00380219635553658,0.0037913441192358732,0.003780582221224904,0.003769917879253626,0.003759348066523671,0.003748880699276924,0.0037385188043117523,0.003728268900886178,0.0037183398380875587,0.0037093213759362698,0.0036998216528445482,0.0036892658099532127,0.0036788531579077244,0.003668589284643531,0.0036585130728781223,0.0036486180033534765,0.00363889685831964,0.003629351733252406,0.0036199751775711775,0.0036108598578721285,0.0036021359264850616,0.003591724205762148,0.00358105031773448,0.003570596454665065,0.003560354234650731,0.0035503129474818707,0.003540468169376254,0.0035309887025505304,0.003521690610796213,0.0035124607384204865,0.003503314685076475,0.0034941374324262142,0.003484956920146942,0.0034758823458105326,0.003466932801529765,0.003458104794844985,0.0034493959974497557,0.003440841566771269,0.003432449884712696,0.003424205118790269,0.0034161179792135954,0.0034081852063536644,0.003400403307750821,0.0033927750773727894,0.003385284449905157,0.003377928864210844,0.0033707127440720797,0.0033636377193033695,0.003356710309162736,0.0033499333076179028,0.0033432994969189167,0.003336818190291524,0.003330492414534092,0.0033243088982999325,0.003318288130685687,0.0033124317415058613,0.003306751372292638,0.003301246790215373,0.003295915899798274,0.003290758468210697,0.0032857719343155622,0.003280951175838709,0.0032762987539172173,0.003271806752309203,0.003267468884587288,0.0032632790971547365,0.00325922854244709,0.003255311166867614,0.003251518588513136,0.0032478668726980686,0.003244345309212804,0.003240940161049366,0.0032376390881836414,0.0032344311475753784,0.0032313053961843252,0.0032282609026879072,0.0032252913806587458,0.003222497645765543,0.0032198599074035883,0.0032173562794923782,0.003214982571080327,0.003212720388546586,0.0032105494756251574,0.003208465874195099,0.0032064535189419985,0.003204495646059513,0.0032025815453380346,0.0031992653384804726,0.0031958746258169413,0.0031925092916935682,0.0031891604885458946,0.003185645444318652,0.003182151587679982,0.003178709652274847,0.003175321500748396,0.003171986434608698,0.0031686974689364433,0.0031654529739171267,0.0031622499227523804,0.0031590857543051243,0.0031559569761157036,0.0031528612598776817,0.003149796277284622,0.003146760631352663,0.0031437529250979424,0.003140771761536598,0.0031374392565339804,0.003133804304525256,0.003130202181637287,0.003126633120700717,0.003123158821836114,0.0031197690404951572,0.0031165052205324173,0.003113062120974064,0.00310965976677835,0.0031063102651387453,0.0031030059326440096,0.003099739784374833,0.003096509026363492,0.0030933101661503315,0.0030901399441063404,0.003086993470788002,0.003083616029471159,0.003080266760662198,0.0030769421719014645,0.0030736573971807957,0.003070410341024399,0.003067196346819401,0.0030639132019132376,0.003060664515942335,0.0030574502889066935,0.0030542684253305197,0.0030510069336742163,0.0030477801337838173,0.003044589888304472,0.0030414348002523184,0.003038317197933793,0.00303523987531662,0.0030322049278765917,0.003029212122783065,0.003026262391358614,0.0030233552679419518,0.0030204933136701584,0.0030176762957125902,0.0030149046797305346,0.003012178698554635,0.0030094969552010298,0.0030068582855165005,0.003004262689501047,0.003001693170517683,0.002999141113832593,0.002996640047058463,0.0029941892717033625,0.0029917790088802576,0.0029894050676375628,0.0029870448634028435,0.002984679536893964,0.0029823267832398415,0.0029799840413033962,0.0029776515439152718,0.0029753264971077442,0.0029730095993727446,0.002970703411847353,0.002968407468870282,0.0029661234002560377,0.0029638537671417,0.0029615755192935467,0.0029593114741146564,0.0029570837505161762,0.0029548928141593933,0.0029527354054152966,0.0029505917336791754,0.002948465058580041,0.002946354914456606,0.002944261534139514,0.0029421867802739143,0.0029401301871985197,0.002938092453405261,0.002936074510216713,0.002934093587100506,0.0029321603942662477,0.002930266549810767,0.0029283887706696987,0.0029265263583511114,0.002924679545685649,0.002922848565503955,0.002921032952144742,0.002919235732406378,0.0029174562077969313,0.00291570951230824,0.002913995645940304,0.002912293653935194,0.0029106060974299908,0.002908930880948901,0.002907270099967718,0.0029056225903332233,0.0029039878863841295,0.002902369014918804,0.002900762250646949,0.0028991715516895056,0.0028975948225706816,0.0028960485942661762,0.0028945300728082657,0.002893023658543825,0.002891527721658349,0.0028900434263050556,0.002888571238145232,0.002887110458686948,0.0028856629505753517,0.0028842261526733637,0.0028828035574406385,0.0028813928365707397,0.00287999608553946,0.0028786128386855125,0.002877243096008897,0.002875887556001544,0.0028745445888489485,0.002873229095712304,0.002871938981115818,0.002870658878237009,0.0028693873900920153,0.002868125680834055,0.002866874448955059,0.0028656302019953728,0.0028643961995840073,0.002863169414922595,0.002861951943486929,0.0028607433196157217,0.00285954587161541,0.002858357038348913,0.0028571791481226683,0.002856012200936675,0.0028548557311296463,0.0028537120670080185,0.002852578414604068,0.0028514573350548744,0.0028503485955297947,0.002849251264706254,0.00284816836938262,0.0028470982797443867,0.0028460435569286346,0.00284501607529819,0.0028439995367079973,0.0028429972007870674,0.0028420144226402044,0.002841051435098052,0.00284010823816061,0.0028391845989972353,0.0028382742311805487,0.002837373875081539,0.002836477244272828,0.002835581311956048,0.002834680723026395,0.0028337729163467884,0.0028328564949333668,0.0028319295961409807,0.002830995013937354,0.002830054145306349,0.0028291111811995506,0.0028281693812459707,0.002827231539413333,0.0028263023123145103,0.002825382864102721,0.0028244780842214823,0.002823587041348219,0.002822711132466793,0.0028218505904078484,0.002821005182340741,0.0028201728127896786,0.0028193541802465916,0.0028185464907437563,0.0028177478816360235,0.002816959982737899,0.002816180931404233,0.0028154104948043823,0.002814647974446416,0.0028138933703303337,0.002813146449625492,0.0028124062810093164,0.0028116758912801743,0.002810954349115491,0.002810240490362048,0.0028095345478504896,0.002808836055919528,0.0028081464115530252,0.002807463053613901,0.0028067855164408684,0.0028061140328645706,0.002805447904393077,0.0028047857340425253,0.002804127288982272,0.0028034732677042484,0.0028028220403939486,0.00280217407271266,0.0028015305288136005,0.0028008909430354834,0.0028002560138702393,0.0027996255084872246,0.002799000358209014,0.002795611508190632,0.0027904442977160215,0.002784048207104206,0.0027772183530032635,0.002770330524072051,0.002763507654890418,0.0027568317018449306,0.0027503594756126404,0.0027442520949989557,0.0027386106085032225,0.002733236877247691,0.002728510880842805,0.0027243695221841335,0.002720779972150922,0.002717655384913087,0.0027149878442287445,0.0027127990033477545,0.0027111403178423643,0.002710046013817191,0.0027095165569335222,0.0027095177210867405,0.0027100013103336096,0.0027108953800052404,0.002712174318730831,0.002713824389502406,0.0027158416341990232,0.0027181992772966623,0.0027208321262151003,0.002723648911342025,0.002726536011323333,0.0027294177561998367,0.0027322033420205116,0.00273484387435019,0.0027373337652534246,0.0027396392542868853,0.002741767093539238,0.0027437261305749416,0.002745513105764985,0.002747113583609462,0.0027484982274472713,0.0027496435213834047,0.0027505431789904833,0.0027512116357684135,0.002751691034063697,0.0027520323637872934,0.002752299653366208,0.0027525813784450293,0.002752861939370632,0.002753138542175293,0.002753417007625103,0.0027537066489458084,0.0027540288865566254,0.002754414454102516,0.002754853805527091,0.002755409339442849,0.0027560421731323004,0.0027567485813051462,0.0027575306594371796,0.0027583912014961243,0.0027593430131673813,0.0027603304479271173,0.0027613972779363394,0.0027626974042505026,0.0027641961351037025,0.0027657838072627783,0.0027673514559865,0.0027685295790433884,0.0027693253941833973,0.002770481165498495,0.002772283973172307,0.0027741005178540945,0.0027759436052292585,0.002777731278911233,0.0027794749476015568,0.0027810833416879177,0.002782604657113552,0.002784015843644738,0.0027853907085955143,0.00278668780811131,0.0027875001542270184,0.002787842880934477,0.002788259880617261,0.0027886528987437487,0.0027891083154827356,0.002789698075503111,0.0027904745656996965,0.0027914957609027624,0.0027927171904593706,0.0027934247627854347,0.0027935286052525043,0.0027936582919210196,0.0027938643470406532,0.0027942799497395754,0.0027949875220656395,0.0027960841543972492,0.002797498134896159,0.002799021312966943,0.002800306538119912,0.0028006145730614662,0.002799896989017725,0.002799001056700945,0.0027980145532637835,0.002797354245558381,0.002797241322696209,0.0027980601880699396,0.0027987423818558455,0.0027994955889880657,0.0027999680023640394,0.002800252055749297,0.002801493974402547,0.0028020611498504877,0.002803464885801077,0.002804219489917159,0.002805681899189949,0.002807862125337124,0.00280925165861845,0.0028099610935896635,0.002811893355101347,0.0028151606675237417,0.0028177278582006693,0.0028207001741975546,0.0028232389595359564,0.002825790550559759,0.0028307910542935133,0.0028378174174576998,0.0028439376037567854,0.002849180018529296,0.0028532836586236954,0.002855931641533971,0.002860202919691801,0.0028660462703555822,0.002873196266591549,0.0028813222888857126,0.002889845287427306,0.002895645098760724,0.002899587620049715,0.002902508480474353,0.002904236549511552,0.0029066402930766344,0.0029115008655935526,0.002918428974226117,0.002925217617303133,0.0029318761080503464,0.002937427954748273,0.0029428228735923767,0.0029480131343007088,0.002953160088509321,0.0029591170605272055,0.00296599674038589,0.002973334863781929,0.0029807183891534805,0.0029876527842134237,0.0029950342141091824,0.00299994763918221,0.0030018503312021494,0.0030006607994437218,0.0029971087351441383,0.002992113819345832,0.002986787585541606,0.0029833903536200523,0.002985974308103323,0.0029940311796963215,0.0030033534858375788,0.003011277411133051,0.0030170998070389032,0.003020291682332754,0.0030238006729632616,0.0030275299213826656,0.0030284645035862923,0.003027109196409583,0.003023506375029683,0.003020452568307519,0.003017981071025133,0.0030163386836647987,0.0030158658046275377,0.0030208074022084475,0.003026725957170129,0.0030301357619464397,0.0030308880377560854,0.0030292775481939316,0.0030256935860961676,0.0030201664194464684,0.003020231844857335,0.0030254016164690256,0.003028187435120344,0.0030285739339888096,0.00302606332115829,0.0030237219762057066,0.0030212178826332092,0.003019485855475068,0.0030191855039447546,0.0030205773655325174,0.003023536643013358,0.0030249683186411858,0.003024374833330512,0.003021649783477187,0.003017413429915905,0.0030123917385935783,0.003008289961144328,0.0030056366231292486,0.003004370955750346,0.0030040021520107985,0.0030083628371357918,0.0030126895289868116,0.0030167782679200172,0.0030201973859220743,0.0030204192735254765,0.0030174690764397383,0.003014021087437868,0.003014644607901573,0.003015819238498807,0.0030181293841451406,0.0030192371923476458,0.0030213247518986464,0.0030237871687859297,0.003026193007826805,0.0030287750996649265,0.0030293711461126804,0.0030323758255690336,0.003039679955691099,0.0030463985167443752,0.003049892606213689,0.0030501224100589752,0.0030498437117785215,0.0030493687372654676,0.0030490427743643522,0.0030489845667034388,0.0030532556120306253,0.0030571739189326763,0.003060587914660573,0.0030631348490715027,0.003062912030145526,0.003061042632907629,0.003056785324588418,0.0030573320109397173,0.003062418196350336,0.0030678038019686937,0.003071803832426667,0.003074247855693102,0.003075077896937728,0.003073884639889002,0.003072624560445547,0.0030757468193769455,0.0030780767556279898,0.0030803370755165815,0.00308254174888134,0.003084269119426608,0.003085531061515212,0.0030865806620568037,0.0030878554098308086,0.003091290593147278,0.0030946312472224236,0.003097647801041603,0.003099971916526556,0.0031035449355840683,0.0031063812784850597,0.003108629025518894,0.003110199235379696,0.00311111519113183,0.003113077487796545,0.0031143936794251204,0.003114779246971011,0.0031144716776907444,0.0031154106836766005,0.0031176006887108088,0.0031189967412501574,0.0031196405179798603,0.0031198232900351286,0.0031215150374919176,0.003122814930975437,0.003123778849840164,0.0031242147088050842,0.0031240328680723906,0.0031232379842549562,0.003124050097540021,0.003126688301563263,0.003131260396912694,0.0031355777755379677,0.003139222739264369,0.0031415687408298254,0.0031422378960996866,0.0031415836419910192,0.003142188536003232,0.0031445955391973257,0.0031471613328903913,0.0031496945302933455,0.0031514873262494802,0.00315202958881855,0.00315138790756464,0.0031501862686127424,0.0031507634557783604,0.0031533779110759497,0.003157657803967595,0.0031610934529453516,0.003163031069561839,0.0031632808968424797,0.0031641714740544558,0.0031662594992667437,0.0031681694090366364],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"lines\",\"name\":\"Train MSE Loss\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800],\"y\":[2.5778491497039795,2.478677988052368,2.402203321456909,2.330552101135254,2.263279676437378,2.199873685836792,2.140063762664795,2.083498477935791,2.030719757080078,1.980937123298645,1.9343607425689697,1.889923334121704,1.8478236198425293,1.8079057931900024,1.7698155641555786,1.733275055885315,1.6982227563858032,1.6644285917282104,1.6317410469055176,1.6000674962997437,1.569252848625183,1.5392132997512817,1.509922742843628,1.481296181678772,1.4533597230911255,1.4260581731796265,1.3993757963180542,1.3731672763824463,1.3475406169891357,1.3224942684173584,1.2980111837387085,1.2741057872772217,1.2508007287979126,1.2280875444412231,1.2059072256088257,1.184241771697998,1.1631089448928833,1.1424397230148315,1.122186303138733,1.10244882106781,1.0831767320632935,1.0643675327301025,1.046053171157837,1.0282021760940552,1.010785460472107,0.9937359690666199,0.9770578145980835,0.9607400298118591,0.9448161721229553,0.9292651414871216,0.9140425324440002,0.899151623249054,0.884559690952301,0.8702940344810486,0.8563042283058167,0.8425891995429993,0.8291711807250977,0.8160192966461182,0.8031862378120422,0.7907499074935913,0.7785989046096802,0.7667353749275208,0.7551268935203552,0.7438095211982727,0.7327809929847717,0.7219922542572021,0.711449384689331,0.7011011242866516,0.6910035014152527,0.6811574697494507,0.6715195178985596,0.6620639562606812,0.6528074145317078,0.6437766551971436,0.6349983811378479,0.6264103651046753,0.6180093288421631,0.6097530126571655,0.6016321778297424,0.593641459941864,0.5857179760932922,0.577928900718689,0.5702707767486572,0.5627460479736328,0.5553524494171143,0.5480800867080688,0.5408791899681091,0.5338070392608643,0.5268616676330566,0.5200604200363159,0.5133556723594666,0.5067774653434753,0.5003324747085571,0.4940192401409149,0.4878372550010681,0.4817799925804138,0.47582489252090454,0.4700128734111786,0.464340478181839,0.4587836265563965,0.45331457257270813,0.4479724168777466,0.4427597224712372,0.4376569390296936,0.43265992403030396,0.42776381969451904,0.4229644238948822,0.41825658082962036,0.41363534331321716,0.4090937376022339,0.40463370084762573,0.40024933218955994,0.3959413468837738,0.3916628658771515,0.38745325803756714,0.38329780101776123,0.3791954815387726,0.37514936923980713,0.3711545765399933,0.36720818281173706,0.3633056581020355,0.35944852232933044,0.3556348979473114,0.3518558442592621,0.348122239112854,0.3444226086139679,0.34076157212257385,0.3371402621269226,0.3335610628128052,0.3300238847732544,0.3265257179737091,0.32306739687919617,0.3196510970592499,0.3162798583507538,0.31294575333595276,0.30965015292167664,0.30639398097991943,0.30317777395248413,0.29999956488609314,0.29685914516448975,0.29375821352005005,0.2906975746154785,0.2876764237880707,0.28469139337539673,0.2817424237728119,0.27883145213127136,0.27595800161361694,0.2731216847896576,0.27032139897346497,0.2675597369670868,0.26483431458473206,0.26213890314102173,0.2594756782054901,0.25684401392936707,0.25424179434776306,0.251668781042099,0.24912486970424652,0.2466105818748474,0.24412481486797333,0.24166777729988098,0.23923970758914948,0.2368408888578415,0.23446696996688843,0.2321140468120575,0.22978419065475464,0.22748006880283356,0.22520188987255096,0.22294791042804718,0.22071954607963562,0.21851688623428345,0.2163396179676056,0.2141878455877304,0.21206146478652954,0.20996037125587463,0.20788265764713287,0.20582866668701172,0.2037993222475052,0.20179139077663422,0.19980277121067047,0.19783808290958405,0.19589656591415405,0.1939745843410492,0.19207291305065155,0.19019250571727753,0.1883334219455719,0.18649333715438843,0.18467184901237488,0.1828719973564148,0.18109355866909027,0.17933565378189087,0.17759840190410614,0.1758420318365097,0.1740923672914505,0.17235465347766876,0.17062968015670776,0.16891784965991974,0.1672210395336151,0.16554050147533417,0.16387754678726196,0.16223223507404327,0.16060547530651093,0.15899737179279327,0.1574060469865799,0.15583540499210358,0.1542869210243225,0.15275897085666656,0.15125112235546112,0.14976398646831512,0.14829738438129425,0.1468508541584015,0.1454247683286667,0.14401623606681824,0.14258350431919098,0.14114722609519958,0.13972680270671844,0.13832201063632965,0.13693438470363617,0.13555756211280823,0.13418824970722198,0.13282926380634308,0.1314864158630371,0.13016100227832794,0.12885358929634094,0.1275637298822403,0.12629084289073944,0.12503330409526825,0.12379308044910431,0.12257234752178192,0.12137101590633392,0.12017644196748734,0.11899472028017044,0.11782964318990707,0.11667930334806442,0.11555901169776917,0.11445670574903488,0.11337112635374069,0.11230441927909851,0.11126039177179337,0.1102437749505043,0.10924569517374039,0.10828609764575958,0.10733747482299805,0.10638859868049622,0.10545752197504044,0.10454153269529343,0.10365085303783417,0.10277821123600006,0.10192175954580307,0.10107938200235367,0.10025133937597275,0.09943646937608719,0.09863785654306412,0.09785682708024979,0.09708618372678757,0.09632693976163864,0.09557873755693436,0.09484221041202545,0.09411738067865372,0.09340188652276993,0.09269765019416809,0.09200476109981537,0.09132247418165207,0.09065023809671402,0.08998718857765198,0.08933286368846893,0.0886879488825798,0.08805201202630997,0.08742482215166092,0.08680509030818939,0.08619362860918045,0.08558691293001175,0.08498754352331161,0.08439595252275467,0.08381220698356628,0.08323685824871063,0.08266814053058624,0.08210691809654236,0.08155037462711334,0.08100089430809021,0.08045801520347595,0.07992161810398102,0.07939185202121735,0.07886680960655212,0.07834863662719727,0.07783737033605576,0.07733293622732162,0.0768355280160904,0.07634516060352325,0.07586170732975006,0.07538464665412903,0.07491467893123627,0.07445146888494492,0.07399548590183258,0.07354605942964554,0.07310310006141663,0.07266482710838318,0.07223182171583176,0.0718042403459549,0.07138220220804214,0.07096545398235321,0.07055407017469406,0.07014815509319305,0.06974753737449646,0.0693521797657013,0.0689619705080986,0.0685768574476242,0.06819695979356766,0.06782212108373642,0.067452572286129,0.06708799302577972,0.06672811508178711,0.06637275218963623,0.06601715832948685,0.06566473841667175,0.06531550735235214,0.06496955454349518,0.06462692469358444,0.0642879530787468,0.06395279616117477,0.063621886074543,0.0632949098944664,0.06297195702791214,0.06265303492546082,0.06233811378479004,0.06202719733119011,0.06171990558505058,0.06141751632094383,0.06111787259578705,0.06082100793719292,0.0605270154774189,0.06023603305220604,0.05994812399148941,0.05966319143772125,0.05938149243593216,0.05912201851606369,0.05887703597545624,0.05863456055521965,0.05839450657367706,0.05815688148140907,0.05792172625660896,0.057689119130373,0.05745904892683029,0.05723150447010994,0.057006530463695526,0.05678417533636093,0.056564461439847946,0.05634739622473717,0.056132972240448,0.055921271443367004,0.05571223422884941,0.05550580099225044,0.05530402436852455,0.05511147528886795,0.05491636320948601,0.05471907556056976,0.05452004447579384,0.05431969463825226,0.05412972718477249,0.05394282191991806,0.05375843495130539,0.05357637256383896,0.05339664965867996,0.05321924015879631,0.053044117987155914,0.052871234714984894,0.052700575441122055,0.05253211781382561,0.052365828305482864,0.05220165103673935,0.05204102024435997,0.05188331753015518,0.05172313004732132,0.051564447581768036,0.051409848034381866,0.05125717446208,0.051106322556734085,0.05095728859305382,0.05081009119749069,0.05066471919417381,0.050521109253168106,0.0503808967769146,0.05024022236466408,0.05010001361370087,0.04996282979846001,0.04982730373740196,0.049693431705236435,0.04956117644906044,0.04943051561713219,0.04930112510919571,0.049172837287187576,0.049049194902181625,0.04892277717590332,0.048796117305755615,0.04867321252822876,0.04855171963572502,0.04843146353960037,0.04831266403198242,0.04819530248641968,0.04807937145233154,0.04796483740210533,0.04785170406103134,0.047739919275045395,0.047631461173295975,0.047520775347948074,0.04741133004426956,0.047304075211286545,0.04719812422990799,0.04709354788064957,0.0469902828335762,0.04688826575875282,0.04678746685385704,0.04668787494301796,0.04658937826752663,0.0464920736849308,0.04639590531587601,0.04630087688565254,0.04620702192187309,0.046114131808280945,0.046023424714803696,0.04593057930469513,0.04583965241909027,0.045749910175800323,0.045661259442567825,0.04557371512055397,0.045487139374017715,0.04540131613612175,0.045316509902477264,0.04523272439837456,0.04514993727207184,0.04506721347570419,0.04498530179262161,0.044904325157403946,0.044823870062828064,0.04474334418773651,0.0446636825799942,0.04458286985754967,0.04450207203626633,0.04442014917731285,0.04433887451887131,0.044254086911678314,0.044165365397930145,0.04407012462615967,0.04396779090166092,0.04384259507060051,0.04377567768096924,0.04370250552892685,0.04364544898271561,0.043593354523181915,0.04353441670536995,0.04346562922000885,0.04339044168591499,0.04331408441066742,0.04324089735746384,0.04317323490977287,0.04311106353998184,0.04305233806371689,0.04299439117312431,0.04293537512421608,0.04287488013505936,0.042813703417778015,0.04275312274694443,0.04269428923726082,0.04263773187994957,0.04258330911397934,0.042530275881290436,0.04247767850756645,0.04242479428648949,0.04237131401896477,0.04231741279363632,0.04226357862353325,0.042210355401039124,0.042158160358667374,0.04210715368390083,0.042057279497385025,0.042008280754089355,0.041959866881370544,0.041911862790584564,0.04186422750353813,0.041817035526037216,0.04177040979266167,0.041724465787410736,0.04167923703789711,0.04163467884063721,0.04159069061279297,0.04154711961746216,0.04150386527180672,0.04146089032292366,0.04141821339726448,0.04137588292360306,0.04133398458361626,0.041292596608400345,0.04125174507498741,0.04121142625808716,0.04117162153124809,0.04113228991627693,0.04109339788556099,0.04105493798851967,0.04101690277457237,0.040979284793138504,0.04094211012125015,0.04099327698349953,0.04038221389055252,0.03997678682208061,0.03962117061018944,0.03929553180932999,0.039000432938337326,0.03873952105641365,0.03851454332470894,0.038323599845170975,0.03815700113773346,0.038013357669115067,0.03790459781885147,0.037782613188028336,0.037692055106163025,0.03761797770857811,0.03755699470639229,0.0375041700899601,0.03745846450328827,0.037414781749248505,0.03737529739737511,0.037335578352212906,0.03729720413684845,0.03726392611861229,0.03723273426294327,0.037201233208179474,0.037169087678194046,0.037136852741241455,0.03710571303963661,0.0370764322578907,0.03704961761832237,0.03702929988503456,0.03701149672269821,0.036995019763708115,0.036979448050260544,0.03696564957499504,0.03695379197597504,0.03694244474172592,0.03693114221096039,0.03691951557993889,0.036907393485307693,0.0368947759270668,0.036881666630506516,0.03686822950839996,0.036855220794677734,0.036842070519924164,0.036828331649303436,0.03681468591094017,0.036802250891923904,0.03679046407341957,0.03677881881594658,0.03676765039563179,0.03675680235028267,0.03674604371190071,0.03673546761274338,0.03672676905989647,0.03671509772539139,0.03670484945178032,0.03669361397624016,0.03668222203850746,0.03667096793651581,0.03665931522846222,0.036647386848926544,0.03663526102900505,0.03662272170186043,0.036609161645174026,0.03659581020474434,0.03659415617585182,0.036580126732587814,0.036559540778398514,0.036548417061567307,0.036536701023578644,0.036524638533592224,0.03651287406682968,0.036502398550510406,0.036487944424152374,0.036475203931331635,0.03646271303296089,0.036448802798986435,0.03643367439508438,0.036423955112695694,0.03640592098236084,0.03638698160648346,0.036371033638715744,0.036353662610054016,0.03633532300591469,0.0363147109746933,0.03629271313548088,0.036272041499614716,0.036237142980098724,0.036198344081640244,0.03615817055106163,0.03611932322382927,0.03606884181499481,0.036013949662446976,0.03595679625868797,0.03589824587106705,0.03584812581539154,0.03578228875994682,0.035723112523555756,0.035643380135297775,0.035555340349674225,0.035464655607938766,0.03536123409867287,0.03525938093662262,0.035144124180078506,0.03502427414059639,0.03488721325993538,0.034747056663036346,0.034595146775245667,0.0344310998916626,0.034268636256456375,0.03412047401070595,0.033968329429626465,0.03381985425949097,0.033678989857435226,0.033544182777404785,0.033414412289857864,0.03329838067293167,0.03320332244038582,0.033116940408945084,0.03303118795156479,0.03294157236814499,0.032849155366420746,0.03275713697075844,0.032658856362104416,0.032556578516960144,0.0324559211730957,0.03235027566552162,0.032254911959171295,0.03217465803027153,0.032090213149785995,0.03200108930468559,0.03191037103533745,0.031829483807086945,0.03177352994680405,0.031698111444711685,0.031632669270038605,0.031565334647893906,0.031510986387729645,0.03147667273879051,0.03144397214055061,0.03140067309141159,0.03137459233403206,0.03134485334157944,0.031313974410295486,0.03128254413604736,0.0312514491379261,0.031219568103551865,0.031184373423457146,0.031146813184022903,0.031108766794204712,0.03107612021267414,0.031043924391269684,0.03101818449795246,0.0309983529150486,0.030975012108683586,0.030947422608733177,0.030918611213564873,0.030889064073562622,0.03087577410042286,0.03086288832128048,0.030836382880806923,0.03080383688211441,0.03077789768576622,0.030754053965210915,0.030722320079803467,0.030692312866449356,0.030662069097161293,0.030631454661488533,0.030587906017899513,0.03053523786365986,0.03048863261938095,0.030429791659116745,0.03037160634994507,0.030313482508063316,0.030232567340135574,0.03015149012207985,0.030080324038863182,0.029973942786455154,0.029865380376577377,0.029726527631282806,0.02956479787826538,0.029422814026474953,0.02931847609579563,0.029245197772979736,0.029194090515375137,0.02915250137448311,0.029125360772013664,0.02909848652780056,0.02906966209411621,0.029037734493613243,0.029002035036683083,0.028970370069146156,0.028944307938218117,0.028909673914313316,0.02887086197733879,0.028830328956246376,0.028783312067389488,0.02874632366001606,0.028711527585983276,0.028678059577941895,0.028642280027270317,0.028608301654458046,0.028564244508743286,0.028530623763799667,0.028492450714111328,0.028460662811994553,0.028427867218852043,0.028395215049386024,0.028363971039652824,0.028334463015198708,0.02830060012638569,0.028271310031414032,0.028239335864782333,0.028206756338477135,0.028174249455332756,0.028142912313342094,0.028117651119828224,0.028089893981814384,0.028059687465429306,0.028024962171912193,0.02800610288977623,0.027971656993031502,0.02794482558965683,0.02791799232363701,0.027890177443623543,0.027861740440130234,0.027835430577397346,0.02780243381857872,0.027771927416324615,0.027741214260458946,0.027721518650650978,0.027693770825862885,0.027658618986606598,0.02763376757502556,0.027612963691353798,0.02757284976541996,0.027545489370822906,0.02752203494310379,0.02749517746269703,0.027468377724289894,0.027443643659353256,0.027418721467256546,0.027393877506256104,0.027366645634174347,0.027341393753886223,0.027316216379404068,0.027288446202874184,0.027262529358267784,0.02723623253405094,0.027209483087062836,0.027184749022126198,0.027157310396432877,0.02713196910917759,0.027106009423732758,0.027084894478321075,0.027061371132731438,0.02703228034079075,0.02699945494532585,0.02697649784386158,0.02694726549088955,0.0269259475171566,0.026900624856352806,0.026871856302022934,0.026842545717954636,0.02681446634232998,0.02678433619439602,0.026757914572954178,0.026732532307505608,0.026702161878347397,0.026672841981053352,0.026648811995983124,0.026623619720339775,0.0265928003937006,0.026576371863484383,0.02655198983848095,0.026518594473600388,0.026500405743718147,0.026480309665203094,0.026454083621501923,0.026423953473567963,0.026397597044706345,0.026377903297543526,0.026355750858783722,0.026332922279834747,0.026308631524443626,0.02629358321428299,0.026274146512150764,0.0262489952147007,0.02622050978243351,0.026207052171230316,0.026188259944319725,0.026163961738348007,0.026147978380322456,0.026128875091671944,0.02610565908253193,0.0260862335562706,0.026068655773997307,0.026050707325339317,0.026032112538814545],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"mode\":\"lines\",\"name\":\"IS MSE\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800],\"y\":[0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945,0.6018594616860945],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"mode\":\"lines\",\"name\":\"Train MSE\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800],\"y\":[0.5187726149595067,1.7749827200552781,1.7554754212498147,1.73483076518305,1.7145503827605681,1.6950151063650218,1.6767605409861481,1.6596056420434124,1.6429962122420663,1.6271377582198625,1.6119156304153293,1.5975507440537906,1.58306771063667,1.5680595246572742,1.5539805054190126,1.5395649623977876,1.5248004663502315,1.510705212137611,1.4975786649022198,1.4852474741359105,1.4734894378767942,1.4622828151274734,1.4516463916699247,1.4415730834876814,1.4321953262662457,1.4233476431703151,1.415000709380299,1.4070160738734783,1.3984849368015488,1.390351498308927,1.3830762503001035,1.3763426177270743,1.3699312414447986,1.3638265881310019,1.3579386280829158,1.351826278112561,1.3458614574103458,1.3401171357793609,1.3349292719605705,1.3300115180807193,1.325511448667278,1.3212117107317614,1.3165249074577652,1.3116272273891343,1.3067886101460295,1.3020796017111491,1.2974475746823075,1.2928839710882867,1.2884183678881758,1.284012026063631,1.2796308892387593,1.2752454818777001,1.270851659555554,1.2664656005331814,1.2621842736475197,1.257893706741485,1.2538170767138228,1.2494337431823233,1.2447514388615486,1.2398555993540759,1.234739090461569,1.229104825933788,1.2233561506416684,1.2174635211411537,1.2114498182463092,1.2053256068965514,1.1991649787779457,1.1931982157079797,1.1872100809986812,1.1812164524552908,1.1751578181890883,1.1692710346072677,1.1634794819115868,1.1577070658908868,1.1520431358895167,1.1464728358430845,1.1410242468254888,1.1356034963347965,1.1302866731279968,1.1251012318949982,1.1198680101631364,1.1146768567531742,1.1096653569395587,1.1048275720560305,1.100153384055376,1.0956325628561017,1.0912472865645853,1.0869859724116737,1.0828488215319536,1.078819872293243,1.0749785359438968,1.0712304124766514,1.0675468984652228,1.0639002211730135,1.0602759181310908,1.0564992327182805,1.0527463467673082,1.0489858052490775,1.0452356561531828,1.04154495574187,1.0378514251362743,1.0341327722265616,1.0303917275682832,1.026659590615645,1.0229351051915947,1.0192279992034443,1.0155437532283553,1.011887950610139,1.0082727862051875,1.004687021731113,1.0011148986452298,0.9975645562891051,0.9940517214501782,0.9908112996897279,0.987645780689737,0.9845298280186071,0.9813599187167608,0.9782521632573009,0.9752375761392511,0.972318038484793,0.969491954434784,0.9667585551167824,0.9641162330187387,0.9615342649718069,0.9590106895135931,0.9565769569101085,0.9542402472299509,0.9519908880002893,0.9497954754432041,0.9476506053150974,0.9455802490667806,0.9435778898012039,0.9416123709930606,0.9396741126606302,0.9377949277168381,0.9359687612106806,0.9341670812424203,0.9323843599838042,0.9306425253524938,0.9289364100153286,0.9272370305785687,0.9255429297840791,0.9238582425707146,0.9222049040392226,0.9205786839226648,0.9189528451461051,0.9173264046504125,0.9156990413924576,0.914094496325341,0.9125069457447144,0.9108911701315769,0.9092299353767618,0.9075807795033686,0.9059476177343027,0.9043524079728037,0.9027926645626477,0.9012658508515063,0.899751458321297,0.8982479620866888,0.896757030194554,0.8952789746765455,0.8938133026028325,0.8922476574951074,0.8905699892188815,0.8889275646396534,0.8872992384155239,0.8856863407694288,0.8840920700195666,0.8825166177328087,0.8809600031120521,0.8794215437406693,0.8779018772610182,0.8764002829298462,0.8749157606407483,0.8734669531052188,0.8720507946974166,0.8706638207228187,0.8692872387702832,0.8679291652714338,0.8665855438717465,0.8649519122956195,0.863217910584532,0.8614928041215479,0.8597772797973647,0.8580733369616276,0.8563821744054503,0.854704781707006,0.8530410450356243,0.8513918462049577,0.8497582333420264,0.8481404673313198,0.8465362352666506,0.8449466947644201,0.8433719121399905,0.8418115175253139,0.8402669023890311,0.8387398864782684,0.8372288690823627,0.8357334804030583,0.8342531755688225,0.8327878364318155,0.8313367646161973,0.8298992949268493,0.828475207626541,0.8270636127842481,0.8256646747934242,0.8242788712458247,0.8229065314818672,0.8215477414720559,0.8202029714310509,0.8188723187687383,0.817556297480714,0.8162081974417656,0.8148609993979574,0.8135254469958848,0.8122021451160166,0.8108915423116454,0.809755288842972,0.8086220956153547,0.8074999230440404,0.8063897791771754,0.8052910696578892,0.804203057967408,0.803125412762671,0.8018611060753205,0.8004875979474521,0.7991228341455889,0.7977675464007973,0.7964222466395731,0.7951041397001533,0.7937943565226843,0.7924932759986567,0.7911990983687797,0.7898522296087959,0.7885159984457585,0.7871908396547843,0.7858790871951519,0.7845736093711864,0.7832678002833958,0.7819801862278708,0.7806683371829128,0.779376310371243,0.7784764999223879,0.7776174830580524,0.7767618224907562,0.7758025960482758,0.7748419288504523,0.7738910062523844,0.7729501537403248,0.7720188811700858,0.7710980350747558,0.7702944663704422,0.769665258622322,0.7690115213044002,0.7683484131751235,0.7676893625295318,0.7670357436928842,0.7663890531487173,0.7657487969468633,0.7651188851217157,0.7645004720083332,0.7638945004197537,0.76330055573895,0.7627201601491979,0.7621547852095241,0.7616029320551998,0.7610646515755346,0.7605396383516467,0.7600269279272681,0.7595266903838674,0.7590384445192639,0.7585620789539692,0.7580845097107982,0.757614152290022,0.7571638347684869,0.7567506013017227,0.7563435409128904,0.755941613496229,0.7555453959886219,0.755154100198851,0.7547661611791115,0.7543863557185903,0.7540320142422003,0.7536787175078611,0.7533370152678028,0.7529978004203574,0.7526567253831762,0.7523129302425655,0.7519658935502962,0.7516149115676501,0.7512601337027363,0.7509015424365807,0.7505390632592185,0.7501728435116383,0.7498033051577698,0.7494383297799448,0.7490756236203414,0.7487149226971395,0.7483559857550642,0.7479981114516734,0.7476410827673916,0.7472848659182931,0.7469292287307009,0.7465740829996633,0.7462191057086245,0.7458641519584503,0.7455090477570468,0.7451533863411601,0.7447967127586054,0.7444392823427266,0.7440811973994528,0.7437246299068964,0.7434121815711551,0.7431096924463608,0.7428159761021503,0.7425295671911594,0.7422490998985126,0.7419732573320628,0.7417006678100272,0.7414298960420458,0.7411598049499406,0.7408892521670064,0.7406173281185482,0.7403432255177984,0.7400658870704545,0.7397834722064971,0.7394128061892312,0.7390344236237569,0.7386580499518977,0.7382837204745941,0.7379115674944925,0.7375414066297288,0.7371730952528516,0.7368060896659541,0.7364141635768341,0.7359944075695538,0.7355654915806414,0.7351294192708496,0.734687990518738,0.7342432689901834,0.733797405328393,0.7333523252426796,0.7329100374035381,0.7324721851828586,0.7320401769205681,0.7316153385705212,0.7311987714284512,0.7307914179001226,0.7303930061847282,0.730005027212411,0.7296278974931992,0.7292590487969794,0.7289035405883248,0.7285751248711667,0.7282708354099875,0.7279876912639363,0.7277226132897127,0.7274583207029166,0.7271906631269293,0.7269194184057431,0.726644252624379,0.7263649728397186,0.7260817167494171,0.7257947891968262,0.7255046965122546,0.7252121330755491,0.7249178337635628,0.7246225031805075,0.7243271482271564,0.7240305780358738,0.7237446974394928,0.7234758131279734,0.7232176261951403,0.7229554928423142,0.7226925101460225,0.7224290269950282,0.7221649548857965,0.7219007740975949,0.721636748998975,0.7213734316764046,0.7211089670751112,0.7208584606466472,0.7206195162856412,0.7203781757276244,0.7201362536445008,0.719893834225365,0.7196511613274096,0.7194083677409258,0.7191656475396507,0.718922209946955,0.7186742043430862,0.7184406427193885,0.7182172265142232,0.7179886991322632,0.7177576871457743,0.71752405468372,0.7172881410482234,0.717050336051543,0.7168110022575855,0.7165706043532422,0.7163295620974695,0.716088371618961,0.7158448229463783,0.715614734265165,0.715392751735079,0.7151684407517711,0.7149430655570617,0.7147167716460534,0.7144897206499269,0.7142621770371674,0.7140343635259334,0.7138065818885064,0.7135788967506397,0.7133515817456976,0.7131248405838687,0.7128990830406138,0.7126748971468364,0.7124523812805577,0.7122294322169891,0.7120195116802067,0.7118164563617114,0.7116128767674451,0.7114087104361719,0.7112039291487227,0.710998589001004,0.7107923699588172,0.7105853851439615,0.7103777932220815,0.710169864104593,0.7099617295128391,0.7097530247737753,0.7095439886012108,0.709336176930769,0.709129317529686,0.7089222446362436,0.7087151837083672,0.7085070218011839,0.7083436657558924,0.7081875877732866,0.7080303008611036,0.7078336816221814,0.707578587077822,0.7073064382213617,0.7066035202946626,0.7058080114751647,0.7050642555831269,0.7043963260275548,0.7038997786672369,0.703614099593753,0.7035134903716705,0.7035504725835868,0.7036779644923812,0.7038519960007736,0.7040305369460078,0.7041739422976194,0.704249125554439,0.7042352246050116,0.7041265725572385,0.7039306050611365,0.7036631767967367,0.7033446235249882,0.7029973147478927,0.7026437424961165,0.7023050029732862,0.7019987423373216,0.7017374545135894,0.701527088373468,0.7013670800095496,0.701251378093791,0.7011700279888269,0.7011106367340638,0.7010600731716095,0.7010055984814573,0.7009361486927892,0.7008436346319294,0.7007231820230982,0.7005734006160808,0.7003962353841514,0.7001963147052139,0.6999802018828667,0.6997554142341095,0.6995296964131489,0.6993101309702243,0.6991024792120041,0.6989107517554272,0.6987368850761,0.6985808531402348,0.6984406717537878,0.6983130797314012,0.6981936737489549,0.698077784624781,0.6979608046463097,0.6978387568224147,0.6977085964200331,0.6975684395543204,0.6974177254270651,0.6972569790606317,0.6970878243926264,0.6969126870372415,0.6967343091627951,0.6254061969196727,0.6979888514261328,0.6975119937593198,0.6964737131962796,0.6953391453804123,0.6940988033472547,0.6926131468536281,0.6907711432751134,0.6885359428485658,0.6860455486089492,0.6837589751545177,0.6815446147521597,0.6799495583338482,0.6787132437863383,0.6774374434572257,0.6760731561623686,0.6746538006230315,0.6733615825611113,0.6721041519503514,0.6709357455050431,0.6699360841289871,0.6691331107685018,0.6686036447830374,0.6682581111849814,0.6681049599894996,0.6681573788851237,0.6684255312380566,0.6688800689461047,0.6694804167769695,0.6701756910099435,0.670901029451049,0.6716130639470687,0.6722755288462482,0.6728799707552346,0.673424754496607,0.6738745268500423,0.6742543648981666,0.6745812781906689,0.6748661367258086,0.6751107035426327,0.6753089308542937,0.6754550892411181,0.6755490936617382,0.6755872556131967,0.6755900217013762,0.6755754339585099,0.6755557711894128,0.6755378062311508,0.6755264363545109,0.6755085509341999,0.6754779571841655,0.6754331859157559,0.6753782882656335,0.6753226056301804,0.6752718712737718,0.6752584660215536,0.6752316317398741,0.6751650520775941,0.6750818327352442,0.6749838724138738,0.6748853707113326,0.6747974537808487,0.6747240514360668,0.674665452690334,0.6746173730698001,0.6745785114876122,0.6745272664107517,0.6748252407832255,0.6753592840707966,0.6757311623611426,0.6759392713091953,0.676024979370751,0.6760462363932425,0.6760452270209253,0.6760744256945787,0.6760723542019398,0.676006772558185,0.6758434724680048,0.675564159100313,0.6752312616498921,0.6752900890980866,0.675669695495332,0.6759088122241237,0.675981483854525,0.6759112966874873,0.6757357576588077,0.6755016448472524,0.675235049351092,0.6749345437816486,0.6749915863219115,0.6752889477821307,0.6753330434934185,0.6751903671748134,0.6748671308014973,0.6744778372471828,0.6740899356481993,0.673578298159449,0.6724937455760719,0.6713149450203375,0.6704113739363393,0.669657698785135,0.6687770707010647,0.6678578244679498,0.6668833283752198,0.6659514176960589,0.6649646088268337,0.6645960342223269,0.6641219776248499,0.6637127397920073,0.6629044373256976,0.6619234691611601,0.6613891784919045,0.661076575079886,0.6615107213380365,0.6616434163462419,0.6614089852931525,0.6612931322924395,0.6614647990214555,0.6614215215926553,0.6610631090571398,0.6607019692103209,0.6600800035202269,0.659624881425566,0.6593703178870014,0.6588478090479538,0.6580524712580786,0.6574063452227394,0.6568537669934192,0.6564429713039018,0.6562653182187917,0.6559705293645559,0.6556483644454116,0.6553513256651784,0.6550657382823764,0.654862611996591,0.6551001263871483,0.655861506276971,0.6569593150702057,0.658295860845893,0.6594519500269097,0.6599008338084781,0.6600450612901675,0.6604066707502217,0.6609836008140535,0.6616513395408703,0.6621846386560047,0.6625610794919653,0.662893110737578,0.6632573018915396,0.663634603658564,0.663949960204455,0.6641240909914419,0.664167704781242,0.6639466990155182,0.6638676963994692,0.6638601221733577,0.6638679804163273,0.6639314731610149,0.6640663476255115,0.6643141839784388,0.6645600980449144,0.6647923133371307,0.6650259115297827,0.6653087610795281,0.6657205566206399,0.6661880065799356,0.6666113490188404,0.6667067662662235,0.6665414999003939,0.6664968949292163,0.666630338937167,0.6669024826252606,0.6670574507022987,0.6672217752810842,0.6674467049187102,0.6677293503552137,0.6679861910928684,0.6681467180627193,0.6684925722380824,0.6688977622663307,0.6693255409925536,0.6697922488932724,0.6703398023826388,0.6706650889521845,0.6706414409671062,0.6705101930289936,0.670590125667907,0.6705961714935603,0.6703863856054887,0.6700666673226643,0.6696807021662695,0.669315792018051,0.6689739086737376,0.6686639417177446,0.6684863721101676,0.6683282998153599,0.6681420207483363,0.6680010992270705,0.6679193630943265,0.6678516911477242,0.6678654360586534,0.6679198399911693,0.6679722453927472,0.6680396269732669,0.6681291469574179,0.6683301783640907,0.6686526336129452,0.6691040057285214,0.6695866283823366,0.6699168195866481,0.6701623964454401,0.6704662075174924,0.6708664612216554,0.6713652292252926,0.6717874913501554,0.6721160643925566,0.6723253786448605,0.6724623207700401,0.6726603859900978,0.6729638838843001,0.673279575555805,0.6735200516656474,0.6736845339561636,0.673750985235211,0.6736932843453591,0.6735688381587736,0.6734417106261722,0.6733445146335229,0.6733067489909466,0.6732574663676513,0.6731730366461952,0.6730431456711155,0.6729278152566838,0.6728290288043484,0.6727390745156664,0.6726659278163105,0.6726429700874645,0.6726914468850892,0.6727996345762669,0.672932321967766,0.6730123543696598,0.6729902614578906,0.6729228046594168,0.6729375839193411,0.6729543588898406,0.6730402520170539,0.6732167277651884,0.6734030820784178,0.6734840913114425,0.6735137716387696,0.6735748013416116,0.673780203204327,0.6741049025529803,0.6743835560116628,0.6745312476061069,0.6745621152472816,0.6746308654968295,0.6747701323970553,0.6749599572863029,0.675074294117928,0.675093981044336,0.6750048124854452,0.6749463768785173,0.6749471227760302,0.6749998305699905,0.6749929497213907,0.6750033787170786,0.6750274295228295,0.6750112474020905,0.6749818200243474,0.6749382055315774,0.6748877466434122,0.6748845175688011,0.674891701163993,0.6748729539257471,0.6747972014515458,0.6747184755423032,0.674733328210922,0.6748970773304293,0.6751876726162559,0.6754475696236945,0.6756095726118457,0.6756222916956566,0.6755758431750366,0.675591345463981,0.6756902132621113,0.6758269389363489,0.6759656765284374,0.6760389355539802,0.6760406470902368,0.6759652116206943,0.6759148589498157,0.6759560449499236,0.6761235154357012,0.6763248787457599,0.6764645100456874,0.6764890484910705,0.6764130378860387,0.6763454178799144,0.6763622812656849],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"mode\":\"lines\",\"name\":\"Test MSE\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800],\"y\":[1.19635416020677,1.1787297456916341,1.1623159258219218,1.1467835467828493,1.1317837763554168,1.1173347015890167,1.1034042301062499,1.090006965933133,1.077178829931016,1.0649436693372956,1.0533380031218675,1.0423223977439031,1.031961677286364,1.0226402366911882,1.0138180884472794,1.0054793040863372,0.9976045241629987,0.9901216035107366,0.9830896127824231,0.9764859237825902,0.9702749247214493,0.9644309463882623,0.9589375702260738,0.9537010883616813,0.9487824745797484,0.9441114702080354,0.9394877297215142,0.9350350892243363,0.9307611396796485,0.9266732642009515,0.9227350130952922,0.9189291392074143,0.9152461807567239,0.9116213523172201,0.907221784419603,0.9025676341831679,0.8980509644202865,0.8936645084816921,0.8893998892313079,0.8852508906297829,0.8812094049386064,0.8772664553014228,0.873416470523629,0.8697206850074257,0.8661814625488566,0.8627106473044528,0.8593223759839634,0.8560044271661946,0.8527420912626827,0.8495339151487417,0.8463778249926716,0.8432756833225045,0.8402232843638582,0.8372205202462258,0.8342916576528641,0.8314782531328042,0.8287152238031961,0.8258903591481289,0.8230985636970718,0.8203540582838187,0.8176248854751225,0.814648938608036,0.8115911824529706,0.8085732992567903,0.8055547676241572,0.8025789120388483,0.7994757152052292,0.7963720466403887,0.7933101869781052,0.7899372865162411,0.7864179042433385,0.7829334889058457,0.7794997060468448,0.776151047373529,0.7728649794717125,0.7696810454345588,0.7666233951919708,0.763700022452064,0.7607622283555165,0.7575745599523043,0.7541117472393108,0.7507593370447291,0.7475124346107318,0.7443691514493598,0.7413276168672722,0.7383859348707476,0.7355175139995277,0.7327216172998231,0.7299955660354283,0.7273434121558222,0.7247704236380937,0.7222612129740708,0.7198136895966716,0.7174184503821156,0.7150733685318135,0.7127950375266854,0.7105557559749011,0.7083334947581936,0.7061174510296755,0.7038993096581604,0.7016629318552722,0.6994160210532143,0.6971706785757666,0.694935551102065,0.6927215075841848,0.6905346875965952,0.6883805042672099,0.6862647645354832,0.684193271015494,0.6820261131089886,0.6795666304023151,0.6771922192200772,0.6749003906681613,0.6726921305497676,0.6705681688471186,0.6685233233021733,0.6665511282148394,0.6646617248381212,0.6628555194535107,0.6611319201851636,0.6594883240373819,0.6579169638991199,0.6564186229644945,0.6550469907584104,0.6537326832352428,0.652473071142658,0.6512640348222066,0.6501033670504509,0.6489894098939918,0.647921019027017,0.6468965571248342,0.6459143244273525,0.6449845682769582,0.6440984536288837,0.6432475704659313,0.6424300979077058,0.6416427373462107,0.6408833628019,0.6401503970987074,0.6394420297560659,0.6387563401356905,0.6380906527803791,0.6374419310121803,0.6368065618303552,0.6361791475039077,0.6355656371338394,0.6349652534002284,0.6343771842199708,0.63380040839913,0.6332264354478209,0.6326559152800902,0.6320864395754984,0.6315175659542017,0.6309505086982775,0.630386056225789,0.6298249097768546,0.6292676254753728,0.6287147394896924,0.628166941727993,0.6276243946862544,0.627087546650659,0.6265571714588684,0.626033741898679,0.6255124962363494,0.6249943393254053,0.6244841005315439,0.6239821102060272,0.6234883293360003,0.622997711661494,0.6225110657274225,0.62202737180272,0.6215474791674064,0.6210721969877777,0.6206022347168435,0.6201378780437784,0.6196796737962559,0.6192280058378229,0.6187837973666036,0.618346029874104,0.6179150457560515,0.617490957121154,0.6170690101816296,0.6166499537250718,0.6162344474522925,0.615823346982206,0.6154168366699284,0.6150164215831148,0.6146222779167718,0.6142343088860982,0.6138527072316385,0.6134773821595241,0.6131079425642081,0.6127397994304269,0.612373314556338,0.6119876866751784,0.6115980074829095,0.6112137830829155,0.6108346638631423,0.6104604422759292,0.6100908203292227,0.6097253777454213,0.6093626328047356,0.6090003967864656,0.6086410669827526,0.6082842044478847,0.6079295538422841,0.6075771972611222,0.6072269440479571,0.6068793858220527,0.6065338154967205,0.6061858371182322,0.6058237111286945,0.6054722234690773,0.6051385730486946,0.6048021256386198,0.6044629759142687,0.6041181745441241,0.6037692263984545,0.6034170166051042,0.6030612272499125,0.6027024654990537,0.6023726793647948,0.6021210387532813,0.6018918718453707,0.601666377845981,0.6014384693688437,0.6012060716983023,0.6009714917939971,0.6007348359948737,0.6005033147415243,0.6002790321793099,0.6000541027092721,0.599827270818269,0.5996009651729793,0.5993738215932601,0.5991423845550795,0.5989063249336268,0.5988749084573188,0.5991387041779805,0.5993845700035366,0.5996121632792071,0.5998140059912785,0.5999932889997375,0.6001493076640844,0.6002819164358231,0.600393648513483,0.6004791445819436,0.6005395934815547,0.6005756574853903,0.6005897941516427,0.600583724659841,0.6005587069500999,0.6005125180152067,0.6004469022259847,0.6003651066570375,0.6002693776744122,0.6001610685684287,0.6000414964864736,0.5999124833596758,0.5997747627249489,0.5996288302481463,0.5994755573421725,0.5993161176740778,0.5991514460536581,0.5989832723741118,0.5988123204518636,0.59863940733344,0.5984650739402256,0.5982900305129534,0.5981153746870902,0.5979414657001455,0.597770668979018,0.5976029955467648,0.5974382638828174,0.5972758575482938,0.5971163733362049,0.5969595121476825,0.5968078264739246,0.5966608661780995,0.5965164750188888,0.5963751774823642,0.5962366121443867,0.5961020819344555,0.5959711541475682,0.5958431650023563,0.5957174501069217,0.5955934078001716,0.5954706710607844,0.5953486210699537,0.5952462318811147,0.5951451465049942,0.5950434927219951,0.5949405339480626,0.5948248093924434,0.5947063775837322,0.5945879401050944,0.5944690061304733,0.5943491340232161,0.5942279447725192,0.5941050820576249,0.5939802856679162,0.5938533761414417,0.593724236152776,0.5935927896774997,0.5934588920445396,0.5933225083440985,0.5931835865287405,0.5930421775950505,0.5929045360617868,0.5927691761579867,0.592630826218132,0.5924896305117088,0.5923480823842341,0.5922061202877796,0.5920513954584107,0.5918884270180839,0.5917254866343395,0.5915615690861806,0.5913975757452016,0.591233665386422,0.5910698009281395,0.5909060645668,0.5907424073203386,0.5905790241629075,0.5904235742954951,0.5902689772889248,0.5901151208779024,0.5899637836365063,0.5898145516280939,0.589665302363753,0.5894758463307448,0.589286682487525,0.589097993242794,0.5889094341403643,0.5887152996447276,0.5885240015819349,0.588335261179009,0.5881491157484101,0.5879654866560585,0.5877844325355377,0.5876059771240069,0.5874302671379231,0.5872573706601709,0.5870876959982337,0.5869213525338928,0.5867584411286761,0.5865991088484935,0.5864434569502334,0.5862915793499975,0.5861436384562166,0.5859996385096505,0.5858590491683299,0.5857190453144592,0.5855820203106898,0.5854479724500995,0.5853168454827579,0.5851885091989912,0.5850618942072098,0.5849383167842224,0.584817850510374,0.5847002191199893,0.5845851094969011,0.5844722965410537,0.5843614564856914,0.584252386848253,0.5841449276426066,0.5840388812865661,0.5839340114532081,0.5838288694991289,0.5837246025447862,0.5836201367391404,0.5835154782892609,0.5834105274992915,0.5833062749831697,0.5832025195065724,0.5830991015817495,0.5829959362430884,0.5828929401846251,0.5827897157615928,0.5826862807581799,0.5825826758754633,0.5824779371453656,0.5823720585774979,0.5822660528812703,0.5821601349792065,0.5820543438454856,0.5819487477184724,0.5818433864676589,0.5817383219235733,0.5816336874019393,0.5815295501058034,0.5814250353412119,0.5813202905460868,0.5812163826889836,0.5811132461300211,0.5810109635504349,0.5809095028418512,0.5808089306004021,0.5807091725131133,0.5806103616531355,0.5805124600872558,0.5804155281716016,0.5803195692381243,0.5802237051294878,0.5801280236081602,0.5800334486293199,0.5799399273626584,0.5798474041316724,0.5797558395583617,0.5796651987737171,0.5795754721144624,0.5794866285264517,0.5793986882767016,0.5793116318681417,0.5792254442345018,0.5791401303787718,0.579055774946414,0.5789722936071087,0.5788898032964741,0.5788074140265913,0.5787251519570206,0.578643911910588,0.5785636074843066,0.5784841379038382,0.5784054754389961,0.5783275881779152,0.578250422712009,0.5781740154331082,0.5780982891786618,0.578023265955383,0.5779489253583906,0.5778752872984192,0.5778022974793825,0.5777299840280554,0.5776583463560833,0.5775873979669669,0.5775171246482178,0.5774475401371142,0.5773786610228058,0.577310542722419,0.5772431994257275,0.5771767197141981,0.5771111624649923,0.5770459635330648,0.5769822130724815,0.5769205689449496,0.57686197322195,0.5768071594786934,0.5767563868264745,0.5767094851851803,0.5766658834136662,0.5766248780639252,0.5765855934739971,0.5765471009353091,0.5765086275445195,0.5764694822949894,0.5764291447202382,0.5763873648061785,0.5763440100829537,0.5762991498274512,0.5762529350932984,0.5762056062520852,0.5761574483069613,0.5761087706445159,0.5760597211611806,0.5760104514545508,0.5759610283095834,0.5759114193030453,0.5758615457330516,0.5758112382089292,0.5757603367861027,0.5757086617851729,0.5756560751801202,0.5756024624579053,0.5755480847639604,0.5754929741743934,0.575437153114231,0.5753806999170179,0.5753237837995833,0.575266584987814,0.5752093506164291,0.5751522302705477,0.5750954710021765,0.5750392406774063,0.5749836972555157,0.5749288965287821,0.5748748961428078,0.5748217159661575,0.5747693892299106,0.5747178259005711,0.5746669801049269,0.5746167827445685,0.5745672222356922,0.5745181639913683,0.5744696851847941,0.5744217186129147,0.5743742541112935,0.5743273136837302,0.5742809655541429,0.5742351756265541,0.57419001234995,0.5717323825604237,0.570348454224403,0.5694826625434566,0.5691242409610217,0.5690949925919172,0.5692075805710476,0.5693054667322294,0.5693021910757383,0.5691981942394465,0.5690633848143652,0.5689328831763094,0.5689166867856964,0.568992694854271,0.5691073551281106,0.5692460681146518,0.5694354989576362,0.5696827972160523,0.5700293993227609,0.5704795960392259,0.5709636735643567,0.5714550287827701,0.5719294392643325,0.5723256631057236,0.572647867455769,0.5729081165044587,0.573121478027953,0.573303296924148,0.573458266068925,0.5735858217167015,0.573691482263618,0.5737732518310863,0.5738304153104323,0.5738666477879099,0.573923193167542,0.5739713014235612,0.5740215427280757,0.5740787356379805,0.5741439930537122,0.5742144294348851,0.5742820743820326,0.5743413949278051,0.5743897922999756,0.574419077505114,0.5744315558712606,0.5744301846645357,0.5744177206780385,0.5743642171429705,0.5742959009464635,0.5742179987130838,0.5741277023061989,0.574027929760031,0.5739197297970848,0.5738054552246172,0.5736829253041473,0.5735595003234657,0.573430143712169,0.5732970148488797,0.5731591043186595,0.5730185321977308,0.572878001375093,0.572807331526095,0.5727822072745551,0.5727896275997291,0.5728271056639118,0.5728785127490238,0.5729640627636581,0.5730024745977227,0.5729968115314829,0.5729929262500639,0.5729895642522654,0.5730066614874441,0.5730509495109491,0.5731283025322618,0.5732354972043725,0.5733554429080127,0.5734800192264891,0.5735929703209816,0.5736889284888314,0.5737805492040086,0.5738416263052096,0.5738754583327702,0.5739179016278333,0.573966448861641,0.5740320553431798,0.5741220945010218,0.5742504121271742,0.574409812296735,0.5746082410896594,0.5747686390954183,0.5748769700796164,0.5749585558103595,0.5750182542522237,0.5750742988233787,0.5751584041876973,0.575292997279835,0.5754736486167062,0.5756773436071597,0.5758254391803945,0.5759121322828019,0.5759469159082492,0.57597865678928,0.5760280092874066,0.5753941434084461,0.5747614791121319,0.5741375637597657,0.5734781233631197,0.5727753163822646,0.5719557418875,0.5711878748397496,0.5707671708787845,0.5703479358297201,0.5702574257389429,0.5700196297752285,0.5698501397270848,0.5697195505178636,0.5694172546293707,0.5690596725946707,0.5692263478875512,0.5698332496277307,0.5702999198775903,0.5705200655334718,0.5705794051720255,0.5705844381459821,0.5709661327852492,0.5716821912019548,0.5722751238242978,0.572712124990678,0.5728376094015063,0.5726605531953571,0.5726672540876777,0.5729275044532345,0.5734417816238431,0.5741369170498604,0.5746222028643628,0.5745029434525637,0.5740789377051058,0.5735825873855659,0.573035102638278,0.572753027185207,0.5729409961541886,0.5735137020023621,0.5740724383459727,0.5745240105526642,0.574782046283445,0.5749825124367629,0.5752056110102741,0.5755598042795262,0.5761720084704676,0.5769787978723042,0.5778278288856856,0.5785736338790471,0.5790835894649142,0.5797115493433985,0.5801629852829376,0.5801828482433766,0.579837694288385,0.5792850282096548,0.578695452387028,0.5781925541640135,0.5779057587244338,0.5782606983629902,0.5791657482096804,0.5800600616504105,0.5806724891964973,0.5809412399312269,0.5808860144787645,0.5810142288393981,0.5813304404516131,0.581397395817714,0.5812410687424977,0.5808925424662149,0.5805745755540263,0.5802672396088504,0.5800112550509464,0.5799974485269263,0.580590750728812,0.5812350540597709,0.5815697402163164,0.5816010666040397,0.5813817769727336,0.5810001427183871,0.580557619960441,0.5807810498801371,0.5816289151025942,0.582361677036872,0.5827204537927002,0.582760523140979,0.5826296524865492,0.5823273001945231,0.5819465373540423,0.5815887690149293,0.581354882994296,0.5812400343134413,0.5810368532597782,0.5807666912460201,0.5805007621623576,0.5802844524317183,0.5801277140480783,0.5801095527547699,0.5801771590862556,0.580249910405367,0.5802693259299772,0.5806360007172535,0.5809467417479441,0.5810679752286769,0.581098913555814,0.5810184603577334,0.5808059183387092,0.5806121912941138,0.5807968925022456,0.5809157119051608,0.5810101548997066,0.5808631264634522,0.580664551810919,0.5804023211858417,0.5801249540859021,0.5799166701069886,0.5796597957016225,0.5797729438270904,0.580369006518435,0.5809393132660615,0.581170931176547,0.5810645903477638,0.5808466974381215,0.5805726557042119,0.580310200210655,0.5801061285342318,0.5803285877287211,0.5805476496839903,0.5807291952638165,0.5808247400735171,0.5806849836107529,0.5803925034377297,0.5798939489636413,0.5798213083351147,0.5800011430090725,0.5802658226235146,0.5804799754263213,0.5805880565643555,0.5804480071855607,0.5801621974351635,0.5799130419570612,0.580089198114623,0.5802611350505309,0.5804153304276192,0.5805220898069514,0.5805230302077599,0.5804155992304757,0.5802568238889171,0.5801271881880459,0.5802535301350209,0.580396552680682,0.5805011543276251,0.5805203610939718,0.5806138092259447,0.5806385180872687,0.5806379177971884,0.5806216129125922,0.5806090420463794,0.5807106588016651,0.5807344267440324,0.5807184250386431,0.5806964361168419,0.580819609137837,0.5810274052422042,0.5811398202345547,0.5811662207962055,0.5811216651875198,0.5811808238090197,0.5812164465820113,0.5812304907374597,0.5812093434356922,0.5811345470107433,0.5809981700644662,0.5809774543172995,0.5810932697807194,0.581335158147754,0.5815365746112133,0.5816546404982024,0.5816364100723287,0.5814694213351963,0.5812008414312901,0.5810938278523128,0.5812008793690482,0.5813628318461136,0.5815083190560427,0.5815380633499908,0.581368629237573,0.581050799141888,0.580676275961242,0.5804877834985394,0.5805334404951528,0.5807761733089993,0.5809655758124701,0.5809833315349727,0.580805279160786,0.5806322942569545,0.5805597282689458,0.5805194273370052],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.45],\"title\":{\"text\":\"Epoch\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.625,1.0],\"title\":{\"text\":\"Estimate\"}},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.55,1.0],\"title\":{\"text\":\"Epoch\"}},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.625,1.0],\"title\":{\"text\":\"Variance\"}},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.0,0.45],\"title\":{\"text\":\"Epoch\"}},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,0.375],\"title\":{\"text\":\"MSE Loss\"}},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.55,1.0],\"title\":{\"text\":\"Epoch\"}},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.0,0.375],\"title\":{\"text\":\"MSE\"}},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Estimate over Epochs\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Variance over Epochs\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Shaping Train MSE Loss over Epochs\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Total MSE over Epochs\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Metrics over Epochs\"},\"showlegend\":true},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('1cccf456-9e17-4e59-835c-240814c21c9e');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_load.get_state_visitation_heatmap()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "zx9Jrq6NY33P",
        "outputId": "21b63c2b-d403-4134-a727-3240455032b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"ff0a98bf-d481-4852-887b-6ed95fbb8101\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"ff0a98bf-d481-4852-887b-6ed95fbb8101\")) {                    Plotly.newPlot(                        \"ff0a98bf-d481-4852-887b-6ed95fbb8101\",                        [{\"colorbar\":{\"title\":{\"text\":\"Visits\"}},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"x\":[0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9],\"y\":[9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0],\"z\":[0,250,629,1282,2484,2652,2955,3060,2315,2065,0,363,806,1715,1991,0,1504,2038,1770,2047,0,440,1091,1411,853,0,688,876,1257,2411,0,741,972,675,352,0,266,353,543,770,0,729,503,336,149,0,84,124,189,244,158,435,256,129,62,16,25,26,53,51,41,117,78,42,26,14,18,31,53,56,10,34,14,5,10,17,23,27,49,53,4,12,4,2,4,17,22,28,46,51,0,1,2,0,1,12,15,20,33,36],\"zmax\":3060,\"zmin\":0,\"type\":\"heatmap\"}],                        {\"title\":{\"text\":\"State Visitations Heatmap\"},\"xaxis\":{\"title\":{\"text\":\"X-axis\"}},\"yaxis\":{\"ticktext\":[9,8,7,6,5,4,3,2,1,0],\"tickvals\":[0,1,2,3,4,5,6,7,8,9],\"title\":{\"text\":\"Y-axis\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('ff0a98bf-d481-4852-887b-6ed95fbb8101');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_load.get_heatmap()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "9L5OZf4YYoRC",
        "outputId": "68791ae6-824f-4e7b-ada7-ed8df2a1a746"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"a175c8f8-558f-4fca-b4c7-fc6ea8a159a8\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a175c8f8-558f-4fca-b4c7-fc6ea8a159a8\")) {                    Plotly.newPlot(                        \"a175c8f8-558f-4fca-b4c7-fc6ea8a159a8\",                        [{\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"z\":[[0.01781342551112175,0.014779575169086456,0.02318766713142395,0.03713291883468628,0.042919836938381195,0.04870675131678581,0.05449366569519043,0.06014891713857651,0.057889554649591446,0.0529584176838398],[0.009799063205718994,0.008403109386563301,0.009277001023292542,0.01254216581583023,0.020927051082253456,0.030564315617084503,0.03635123372077942,0.042138151824474335,0.03996752202510834,0.03478328138589859],[0.01316029392182827,0.009909146465361118,0.010461593046784401,0.011380893178284168,0.012300195172429085,0.013219496235251427,0.020505020394921303,0.022038327530026436,0.021792389452457428,0.01660814695060253],[0.018282441422343254,0.012658724561333656,0.011646184138953686,0.012565484270453453,0.013484787195920944,0.014796560630202293,0.013786385767161846,0.012557713314890862,0.00872790813446045,0.00017821043729782104],[0.02340458706021309,0.01672130823135376,0.013733518309891224,0.01381766889244318,0.014737725257873535,0.01340048760175705,0.012134426273405552,0.004763301461935043,-0.0036423206329345703,-0.012047946453094482],[0.02490410767495632,0.021843452006578445,0.016483094543218613,0.014351828955113888,0.013014591298997402,0.010189507156610489,0.0023376308381557465,-0.006067998707294464,-0.014473620802164078,-0.02287924662232399],[0.024848900735378265,0.022380013018846512,0.0179440937936306,0.013816306367516518,0.008244575932621956,-8.806213736534119e-05,-0.008493674919009209,-0.016899295151233673,-0.02530493587255478,-0.0337105467915535],[0.024102110415697098,0.019448276609182358,0.01435687206685543,0.011004646308720112,-0.0009310655295848846,-0.0109193604439497,-0.01932496577501297,-0.027730606496334076,-0.036136213690042496,-0.0445418581366539],[0.019008148461580276,0.01586105115711689,0.010769646614789963,0.007518736645579338,-0.005714338272809982,-0.021750658750534058,-0.030156277120113373,-0.03856190666556358,-0.0469675287604332,-0.05537314713001251],[0.013914180919528008,0.012273825705051422,0.0071824220940470695,0.003986716270446777,-0.010497616603970528,-0.02892831340432167,-0.040987592190504074,-0.049393199384212494,-0.0577988401055336,-0.06620445102453232]],\"type\":\"heatmap\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"Values\"},\"ticks\":\"outside\",\"tickvals\":[-0.06620445102453232,0.06014891713857651],\"ticktext\":[-0.06620445102453232,0.06014891713857651]}},\"xaxis\":{\"tickvals\":[0,1,2,3,4,5,6,7,8,9],\"ticktext\":[0,1,2,3,4,5,6,7,8,9],\"title\":{\"text\":\"X\"}},\"yaxis\":{\"tickvals\":[9,8,7,6,5,4,3,2,1,0],\"ticktext\":[9,8,7,6,5,4,3,2,1,0],\"title\":{\"text\":\"Y\"},\"autorange\":\"reversed\"},\"title\":{\"text\":\"Heatmap\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('a175c8f8-558f-4fca-b4c7-fc6ea8a159a8');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_load = existing_experiments(test_experiment)\n",
        "test_load.plot_metrics()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "J1CN24G-nAZq",
        "outputId": "cdf1d0f0-aea8-423d-c5a3-81f3b4bb0bd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"b94f1868-43d0-45f2-9742-2e4081bee23a\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"b94f1868-43d0-45f2-9742-2e4081bee23a\")) {                    Plotly.newPlot(                        \"b94f1868-43d0-45f2-9742-2e4081bee23a\",                        [{\"mode\":\"lines\",\"name\":\"IS Estimate\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600],\"y\":[1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918,1.1025996208190918],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"Train Estimate\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600],\"y\":[0.14776988327503204,0.33671918511390686,0.35601502656936646,0.3750842213630676,0.39392897486686707,0.4125460386276245,0.43097442388534546,0.4489583373069763,0.4666912257671356,0.483719140291214,0.5004819631576538,0.5169813632965088,0.5333804488182068,0.5496383905410767,0.5656126737594604,0.5810834169387817,0.5962068438529968,0.6109862923622131,0.625407338142395,0.6393949389457703,0.6530917286872864,0.6665080785751343,0.6796185374259949,0.6924272179603577,0.7049397230148315,0.7171967029571533,0.729162871837616,0.7408280968666077,0.7521339654922485,0.7630676031112671,0.7737365365028381,0.7842660546302795,0.7943917512893677,0.804170548915863,0.8135103583335876,0.8225392699241638,0.8315634727478027,0.8403502106666565,0.848831057548523,0.8571020364761353,0.865172266960144,0.8730718493461609,0.8807736039161682,0.8882529139518738,0.8955168724060059,0.9025732278823853,0.909430742263794,0.9161043763160706,0.9226231575012207,0.9289693236351013,0.9351678490638733,0.941281259059906,0.9472663998603821,0.9531263709068298,0.9589008092880249,0.9643866419792175,0.9695256948471069,0.9744557738304138,0.9792675971984863,0.9839538931846619,0.9884403347969055,0.9930080771446228,0.9980894327163696,1.0030022859573364,1.0078115463256836,1.0125633478164673,1.0172467231750488,1.021920919418335,1.02681565284729,1.0318396091461182,1.0368473529815674,1.0417985916137695,1.0467138290405273,1.0515987873077393,1.0564663410186768,1.0613058805465698,1.0661096572875977,1.0709733963012695,1.0759427547454834,1.0807276964187622,1.0854332447052002,1.0901049375534058,1.0947141647338867,1.0992684364318848,1.1037659645080566,1.108212947845459,1.1126136779785156,1.1170023679733276,1.121321439743042,1.1255764961242676,1.1297606229782104,1.133881688117981,1.137934923171997,1.1419129371643066,1.1459007263183594,1.1498125791549683,1.1536470651626587,1.1574064493179321,1.1610841751098633,1.1646791696548462,1.1681909561157227,1.1716182231903076,1.1749707460403442,1.1782472133636475,1.1814615726470947,1.1845966577529907,1.1876435279846191,1.1905300617218018,1.1933135986328125,1.1960344314575195,1.1987063884735107,1.2012969255447388,1.20379638671875,1.2062067985534668,1.208536148071289,1.2107853889465332,1.2129526138305664,1.2150425910949707,1.2170573472976685,1.2190006971359253,1.2208768129348755,1.2226861715316772,1.224429965019226,1.2261101007461548,1.227741003036499,1.2293206453323364,1.2308862209320068,1.232391357421875,1.2338173389434814,1.2351882457733154,1.236548662185669,1.2378615140914917,1.2391984462738037,1.2406517267227173,1.2424635887145996,1.244322419166565,1.246180534362793,1.2481240034103394,1.2500615119934082,1.2519675493240356,1.2538384199142456,1.255676507949829,1.2574783563613892,1.2592381238937378,1.2609697580337524,1.262651801109314,1.2643029689788818,1.2659568786621094,1.2675275802612305,1.2690638303756714,1.2706269025802612,1.2721644639968872,1.2736327648162842,1.2751283645629883,1.2766658067703247,1.2781459093093872,1.279565691947937,1.2809412479400635,1.2823127508163452,1.2836158275604248,1.2848409414291382,1.2859883308410645,1.2870500087738037,1.2880274057388306,1.2889264822006226,1.2897450923919678,1.2904846668243408,1.2911487817764282,1.2917405366897583,1.292264699935913,1.2927000522613525,1.2930607795715332,1.2933588027954102,1.2935950756072998,1.2937870025634766,1.2939401865005493,1.2940486669540405,1.2941457033157349,1.2942274808883667,1.2942785024642944,1.2943040132522583,1.2943063974380493,1.2942970991134644,1.2942622900009155,1.2942146062850952,1.2941601276397705,1.2940970659255981,1.2940291166305542,1.2939584255218506,1.2938865423202515,1.2938164472579956,1.293745756149292,1.2936763763427734,1.2936100959777832,1.2935478687286377,1.2934902906417847,1.2934414148330688,1.2934082746505737,1.2933818101882935,1.2933586835861206,1.2933473587036133,1.2933530807495117,1.293370246887207,1.2933951616287231,1.2934271097183228,1.2934669256210327,1.2935283184051514,1.2936010360717773,1.2936939001083374,1.2938096523284912,1.2939331531524658,1.2940682172775269,1.2942113876342773,1.2943599224090576,1.2945127487182617,1.2946645021438599,1.2947490215301514,1.2948352098464966,1.2949402332305908,1.2950958013534546,1.2952570915222168,1.2954187393188477,1.2955800294876099,1.2957403659820557,1.2958991527557373,1.2960861921310425,1.29634428024292,1.2966232299804688,1.2969927787780762,1.2979353666305542,1.2989000082015991,1.2998740673065186,1.3008525371551514,1.3018271923065186,1.3027931451797485,1.3037512302398682,1.3046892881393433,1.3056024312973022,1.3064944744110107,1.3073835372924805,1.3082482814788818,1.3090877532958984,1.3099212646484375,1.3107578754425049,1.311568021774292,1.312341332435608,1.3130824565887451,1.3137812614440918,1.3144232034683228,1.315004825592041,1.315523624420166,1.315979242324829,1.3163708448410034,1.3166985511779785,1.3169682025909424,1.3171827793121338,1.3173474073410034,1.3174667358398438,1.3175488710403442,1.3176006078720093,1.3176320791244507,1.317642331123352,1.3176360130310059,1.3176169395446777,1.3175888061523438,1.3175548315048218,1.317517876625061,1.317480206489563,1.3174444437026978,1.3174093961715698,1.3173718452453613,1.3173367977142334,1.3173012733459473,1.3172656297683716,1.3172369003295898,1.3172286748886108,1.3172216415405273,1.3172118663787842,1.317181944847107,1.3171488046646118,1.3171072006225586,1.317051887512207,1.3169862031936646,1.3169115781784058,1.316827654838562,1.3166495561599731,1.3164352178573608,1.3162736892700195,1.315772294998169,1.3149868249893188,1.3140918016433716,1.313018798828125,1.3122565746307373,1.3115243911743164,1.3107763528823853,1.310130000114441,1.3096266984939575,1.30941903591156,1.3092600107192993,1.3089723587036133,1.3088784217834473,1.3088401556015015,1.3088105916976929,1.3086938858032227,1.3085410594940186,1.308347225189209,1.3081245422363281,1.3078858852386475,1.3076450824737549,1.3074076175689697,1.3071799278259277,1.3069654703140259,1.3067667484283447,1.3065954446792603,1.3064699172973633,1.3064274787902832,1.3065258264541626,1.3068498373031616,1.3073476552963257,1.30778169631958,1.308030605316162,1.3083871603012085,1.3088356256484985,1.3093231916427612,1.309853434562683,1.3102045059204102,1.3105417490005493,1.3108724355697632,1.311196208000183,1.311511516571045,1.3118752241134644,1.312380313873291,1.3129682540893555,1.313398838043213,1.3138536214828491,1.3143336772918701,1.315048098564148,1.3158001899719238,1.3164788484573364,1.3170479536056519,1.317534327507019,1.317914605140686,1.318155288696289,1.3182716369628906,1.3182742595672607,1.3181073665618896,1.3177704811096191,1.3170894384384155,1.3183573484420776,1.3212692737579346,1.3240036964416504,1.3269532918930054,1.3298988342285156,1.3327207565307617,1.3352404832839966,1.3375529050827026,1.3395965099334717,1.341671347618103,1.343808889389038,1.3458157777786255,1.3473806381225586,1.348318338394165,1.349581003189087,1.3511595726013184,1.3525488376617432,1.353729248046875,1.354371190071106,1.3549888134002686,1.3550773859024048,1.3549675941467285,1.3546198606491089,1.3542002439498901,1.3535138368606567,1.3526127338409424,1.351796269416809,1.3510762453079224,1.3502593040466309,1.3495256900787354,1.3488690853118896,1.3485755920410156,1.3490170240402222,1.3494994640350342,1.3497806787490845,1.3499629497528076,1.3499774932861328,1.3498305082321167,1.3495023250579834,1.3490480184555054,1.348522424697876,1.3479982614517212,1.3474781513214111,1.3470078706741333,1.3465964794158936,1.3462413549423218,1.3459253311157227,1.3456379175186157,1.3453599214553833,1.3450771570205688,1.3447726964950562,1.34446120262146,1.3440861701965332,1.3436492681503296,1.3431257009506226,1.342512845993042,1.341816782951355,1.3410606384277344,1.3402663469314575,1.3395094871520996,1.338728666305542,1.337937355041504,1.3371449708938599,1.3363771438598633,1.335646152496338,1.3349170684814453,1.3342317342758179,1.33356773853302,1.3329168558120728,1.3322906494140625,1.3317089080810547,1.3311558961868286,1.3306405544281006,1.3302603960037231,1.3298499584197998,1.3294416666030884,1.3290482759475708,1.3286281824111938,1.3281911611557007,1.3277223110198975,1.3272039890289307,1.3266360759735107,1.3260676860809326,1.32550048828125,1.3249558210372925,1.324472188949585,1.3240338563919067,1.3236441612243652,1.323305368423462,1.323034405708313,1.3228033781051636,1.3226391077041626,1.3224979639053345,1.3223828077316284,1.3222696781158447,1.3221606016159058,1.32205069065094,1.321934700012207,1.3218052387237549,1.3216776847839355,1.3215250968933105,1.3213714361190796,1.3211790323257446,1.3209679126739502,1.3207532167434692,1.320536732673645,1.3203190565109253,1.3200961351394653,1.3198802471160889,1.3196688890457153,1.3194606304168701,1.3192462921142578,1.319031000137329,1.3188072443008423,1.3185855150222778,1.318356990814209,1.3181232213974,1.3178930282592773,1.3176658153533936,1.3174114227294922,1.3171591758728027,1.3169169425964355,1.3166862726211548,1.316451072692871,1.3162477016448975,1.3160604238510132,1.3159241676330566,1.3157929182052612,1.315682053565979,1.315584421157837,1.3154997825622559,1.3154034614562988,1.3152316808700562,1.3150684833526611,1.314834475517273,1.3146216869354248,1.3144261837005615,1.3142451047897339,1.314018726348877,1.3137773275375366,1.3135730028152466,1.3134536743164062,1.3133972883224487,1.3133050203323364,1.3131840229034424,1.3129557371139526,1.3127318620681763,1.3125057220458984,1.3122854232788086,1.3120776414871216,1.311880111694336,1.3116910457611084,1.311530590057373,1.3113503456115723,1.3111634254455566,1.3109995126724243,1.31087064743042,1.3107531070709229,1.310643196105957,1.310550570487976,1.3104634284973145,1.3103721141815186,1.3102856874465942,1.310186505317688,1.3100535869598389,1.3098818063735962,1.3094767332077026,1.3090890645980835,1.3086824417114258,1.308348298072815,1.3080668449401855,1.3078668117523193,1.3076533079147339,1.3074259757995605,1.3071833848953247,1.3069084882736206,1.3066132068634033,1.3062891960144043,1.3059346675872803,1.3056374788284302,1.305330514907837,1.3050276041030884,1.30470609664917,1.3043818473815918,1.304086685180664,1.3038246631622314,1.303582787513733,1.303390622138977,1.3031742572784424,1.3029221296310425,1.3026477098464966,1.3023451566696167,1.301981806755066,1.3015806674957275,1.3011596202850342,1.300737738609314,1.30031156539917,1.2998814582824707,1.2994749546051025,1.2991422414779663,1.2987959384918213,1.2984304428100586,1.2980607748031616,1.2977625131607056,1.29746675491333,1.2971471548080444,1.2968083620071411,1.296466588973999,1.2960940599441528,1.2957836389541626,1.2955065965652466,1.2952204942703247,1.2948912382125854,1.2945683002471924,1.2943536043167114,1.294328212738037,1.2943434715270996,1.2944241762161255,1.2945764064788818,1.294802188873291,1.2950270175933838,1.2951711416244507,1.2952502965927124,1.2953299283981323,1.2953990697860718,1.29558265209198,1.2956804037094116,1.2957086563110352,1.295702576637268,1.2956079244613647,1.2954442501068115,1.2952007055282593,1.2948912382125854,1.2944973707199097,1.29407799243927,1.2937151193618774,1.2934448719024658,1.2932230234146118,1.2930244207382202,1.2928109169006348,1.292573094367981,1.2923171520233154,1.2920315265655518,1.2916978597640991,1.2913241386413574,1.2909256219863892,1.2905948162078857,1.290222406387329,1.2898056507110596,1.289364218711853,1.288917899131775,1.2884740829467773],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"Test Estimate\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600],\"y\":[-0.02805250510573387,-0.007275775074958801,0.013326769694685936,0.03373977169394493,0.053956471383571625,0.07324148714542389,0.09229418635368347,0.11111002415418625,0.1296861320734024,0.14799878001213074,0.16603119671344757,0.18377749621868134,0.20123325288295746,0.21838603913784027,0.2352289855480194,0.2517586052417755,0.2679746150970459,0.28387507796287537,0.29947805404663086,0.3148266077041626,0.32985883951187134,0.34456759691238403,0.3589543402194977,0.3730207681655884,0.38676899671554565,0.4002000391483307,0.41335225105285645,0.42619788646698,0.4387320280075073,0.45095205307006836,0.46286141872406006,0.47444799542427063,0.485683411359787,0.4965898096561432,0.5071806907653809,0.5174598097801208,0.5274387001991272,0.5371292233467102,0.5465376973152161,0.5556609630584717,0.5645051002502441,0.5730862617492676,0.5814166069030762,0.5895137786865234,0.5973851084709167,0.6050400733947754,0.6124860644340515,0.6197943091392517,0.6269092559814453,0.6338398456573486,0.6405957937240601,0.647185742855072,0.6536164879798889,0.6598979234695435,0.6660371422767639,0.6720436811447144,0.6779159903526306,0.683661699295044,0.6892894506454468,0.6948119401931763,0.7002246379852295,0.7055351734161377,0.7107574939727783,0.7159116268157959,0.7209844589233398,0.7259813547134399,0.7309045195579529,0.735760509967804,0.7405585646629333,0.7452991008758545,0.7499834299087524,0.7546140551567078,0.7591950297355652,0.7637277841567993,0.7682124376296997,0.772649884223938,0.7770422697067261,0.7813885807991028,0.785681962966919,0.7899205088615417,0.7941012978553772,0.7982248663902283,0.802288830280304,0.8063244819641113,0.810322105884552,0.8142588138580322,0.8181325793266296,0.8219406008720398,0.8256840109825134,0.829364538192749,0.8329831957817078,0.8365393280982971,0.8400306701660156,0.8434566259384155,0.8468137979507446,0.8501020669937134,0.853321373462677,0.8564699292182922,0.8595486283302307,0.8625572323799133,0.8654956817626953,0.8683640360832214,0.8711621165275574,0.8738851547241211,0.8765344619750977,0.8791074156761169,0.8816051483154297,0.8840284943580627,0.8863756656646729,0.8886478543281555,0.8908452987670898,0.8929686546325684,0.8950191140174866,0.8969968557357788,0.8989031314849854,0.9007396697998047,0.9025090932846069,0.9042111039161682,0.9058478474617004,0.907421886920929,0.9089349508285522,0.9103947281837463,0.9118014574050903,0.9131529331207275,0.9144502878189087,0.9156947135925293,0.9168877005577087,0.9180310368537903,0.9191250801086426,0.9201722741127014,0.9211720824241638,0.9221258759498596,0.9230332970619202,0.9238966703414917,0.9247191548347473,0.9254959225654602,0.9262288808822632,0.927954912185669,0.9296673536300659,0.93135666847229,0.9330222606658936,0.9346641898155212,0.9363206028938293,0.9380109310150146,0.9396855235099792,0.9413031935691833,0.9429168105125427,0.944517195224762,0.9460983276367188,0.9476965069770813,0.9493044018745422,0.9508917927742004,0.9524479508399963,0.9539686441421509,0.9554532170295715,0.9568935632705688,0.9582797884941101,0.9596037864685059,0.9608548879623413,0.9620265364646912,0.9631128907203674,0.9641128182411194,0.9650244116783142,0.9658482670783997,0.9665857553482056,0.9672377109527588,0.9678070545196533,0.9682978391647339,0.9687140583992004,0.9690601825714111,0.9693413376808167,0.9695616364479065,0.9697263836860657,0.9698405265808105,0.9699093699455261,0.9699391722679138,0.9699288010597229,0.9698871374130249,0.9698176980018616,0.9697244167327881,0.9696207046508789,0.9695062637329102,0.9693814516067505,0.9692496061325073,0.9691108465194702,0.9689695239067078,0.9688277244567871,0.968687891960144,0.9685524702072144,0.968422532081604,0.9683002233505249,0.9681863188743591,0.9680812358856201,0.9679859280586243,0.9679010510444641,0.9678271412849426,0.9677647352218628,0.9677163362503052,0.9676810503005981,0.9676623344421387,0.9676586985588074,0.9676695466041565,0.9676900506019592,0.9677200317382812,0.9677581787109375,0.9678049683570862,0.9678612351417542,0.9679263830184937,0.9679989218711853,0.96807861328125,0.9681650400161743,0.9682566523551941,0.9683533906936646,0.9684544205665588,0.968559205532074,0.9686664938926697,0.9687792062759399,0.9688959121704102,0.9690155982971191,0.9691374897956848,0.969261109828949,0.9693850874900818,0.9695093035697937,0.9696332216262817,0.9697566628456116,0.969878613948822,0.9699980616569519,0.9701142311096191,0.9702272415161133,0.9703361392021179,0.9704402089118958,0.9705384969711304,0.9706440567970276,0.9715559482574463,0.9727438688278198,0.973930835723877,0.9751213788986206,0.9762946367263794,0.9774435758590698,0.9785648584365845,0.9796353578567505,0.9806625247001648,0.981658399105072,0.9826502799987793,0.9836218953132629,0.9845604300498962,0.9854613542556763,0.9863337874412537,0.9871527552604675,0.9879112243652344,0.9886027574539185,0.9892235398292542,0.9897732138633728,0.9902522563934326,0.9906644821166992,0.9910160303115845,0.9913125038146973,0.9915595650672913,0.9917677640914917,0.9919429421424866,0.9920925498008728,0.9922217726707458,0.992335855960846,0.9924394488334656,0.9925370216369629,0.9926318526268005,0.992727518081665,0.9928258657455444,0.992928147315979,0.993035078048706,0.993148148059845,0.9932656288146973,0.9933875203132629,0.9935140609741211,0.9936427474021912,0.993771493434906,0.9939013719558716,0.9940305948257446,0.9941485524177551,0.9942631125450134,0.9943712949752808,0.9944701194763184,0.994560718536377,0.9946420192718506,0.9947127103805542,0.9947549104690552,0.9947713613510132,0.9947935342788696,0.9949022531509399,0.9950255155563354,0.9951781034469604,0.9953899383544922,0.9955890774726868,0.9957693219184875,0.9959308505058289,0.996067464351654,0.9961733222007751,0.9962445497512817,0.9962785840034485,0.9962941408157349,0.9963200092315674,0.996311604976654,0.9962624311447144,0.9962202310562134,0.9961581826210022,0.9960698485374451,0.9959523677825928,0.9958077073097229,0.9956421852111816,0.9952308535575867,0.9947699308395386,0.9943241477012634,0.9939054846763611,0.9935255646705627,0.9932336211204529,0.9930519461631775,0.9930661916732788,0.993172287940979,0.9933500289916992,0.9935495257377625,0.9936570525169373,0.9937087893486023,0.9936783313751221,0.993593156337738,0.9934784173965454,0.9933393597602844,0.9932634830474854,0.993261992931366,0.9933373928070068,0.9934839606285095,0.9937034249305725,0.9940702319145203,0.9945351481437683,0.9950142502784729,0.995444118976593,0.9958086013793945,0.9961362481117249,0.996375560760498,0.9964884519577026,0.9964229464530945,0.9962363243103027,0.9959082007408142,0.9954386949539185,0.994784951210022,0.9939450025558472,0.9929967522621155,0.9919478297233582,0.9908081889152527,0.9917590618133545,0.9945874214172363,0.9973254203796387,0.9998679757118225,1.002192735671997,1.0042965412139893,1.006213903427124,1.007940649986267,1.0095155239105225,1.010984182357788,1.0123188495635986,1.0135973691940308,1.0145336389541626,1.0145264863967896,1.0144706964492798,1.014469027519226,1.0145142078399658,1.0147103071212769,1.015475869178772,1.0162822008132935,1.0170433521270752,1.0178985595703125,1.0188288688659668,1.0198451280593872,1.0209376811981201,1.0221179723739624,1.0232864618301392,1.0244426727294922,1.0255796909332275,1.026663899421692,1.0276687145233154,1.0285636186599731,1.0293585062026978,1.030030608177185,1.0305386781692505,1.030889868736267,1.0310941934585571,1.031166911125183,1.031123399734497,1.0321776866912842,1.0331759452819824,1.034081220626831,1.034920573234558,1.0357565879821777,1.0366168022155762,1.0375452041625977,1.0385236740112305,1.0395267009735107,1.0405234098434448,1.0414795875549316,1.0423918962478638,1.0432499647140503,1.0439985990524292,1.0446105003356934,1.045090675354004,1.0454368591308594,1.0456582307815552,1.0457793474197388,1.0458310842514038,1.045835256576538,1.0457788705825806,1.0456897020339966,1.0455918312072754,1.0455152988433838,1.0455204248428345,1.0456050634384155,1.045767068862915,1.0459966659545898,1.0462796688079834,1.0465971231460571,1.0469887256622314,1.0474154949188232,1.0478391647338867,1.0482515096664429,1.048628568649292,1.0489726066589355,1.049272894859314,1.0495247840881348,1.0497262477874756,1.0498703718185425,1.04995858669281,1.05000638961792,1.050031065940857,1.0500203371047974,1.0499956607818604,1.0499658584594727,1.0499476194381714,1.0499552488327026,1.0499967336654663,1.0500730276107788,1.050182580947876,1.0503114461898804,1.0504525899887085,1.0505998134613037,1.0507526397705078,1.0509023666381836,1.0510412454605103,1.0511645078659058,1.0512652397155762,1.0513405799865723,1.0513861179351807,1.0514161586761475,1.0514435768127441,1.0514625310897827,1.0514730215072632,1.051474928855896,1.051476001739502,1.0514791011810303,1.051484227180481,1.0514883995056152,1.0514949560165405,1.0515000820159912,1.051497220993042,1.0514885187149048,1.0514756441116333,1.0514600276947021,1.0514439344406128,1.0514291524887085,1.051413655281067,1.0513997077941895,1.0513725280761719,1.0513535737991333,1.0513430833816528,1.0513395071029663,1.0513733625411987,1.051435947418213,1.0515316724777222,1.0516407489776611,1.0517749786376953,1.0519194602966309,1.0520600080490112,1.0521849393844604,1.0522829294204712,1.0524060726165771,1.0525380373001099,1.052764892578125,1.0530636310577393,1.0534112453460693,1.0537714958190918,1.0541515350341797,1.054527759552002,1.0549156665802002,1.0552585124969482,1.0555541515350342,1.0558161735534668,1.0560492277145386,1.0562617778778076,1.056464433670044,1.0566664934158325,1.0568792819976807,1.0571051836013794,1.0573426485061646,1.0575824975967407,1.0578205585479736,1.0580710172653198,1.0583274364471436,1.0586111545562744,1.0589262247085571,1.0592683553695679,1.0596240758895874,1.0599827766418457,1.0603671073913574,1.060765266418457,1.0611544847488403,1.0615313053131104,1.0617738962173462,1.0615984201431274,1.0614395141601562,1.0613019466400146,1.0612308979034424,1.0612128973007202,1.061248779296875,1.0612629652023315,1.061248779296875,1.0612092018127441,1.061141014099121,1.0610432624816895,1.0609174966812134,1.0607448816299438,1.0605272054672241,1.0603103637695312,1.0600990056991577,1.059904932975769,1.0597294569015503,1.0595744848251343,1.0594452619552612,1.059341549873352,1.0592519044876099,1.0591093301773071,1.058937668800354,1.0587354898452759,1.0585135221481323,1.0582820177078247,1.0580813884735107,1.0579166412353516,1.0577927827835083,1.0577044486999512,1.0576448440551758,1.0576270818710327,1.0576385259628296,1.05766761302948,1.0577000379562378,1.057739496231079,1.0577894449234009,1.0578306913375854,1.0578560829162598,1.0578573942184448,1.0578300952911377,1.0577518939971924,1.05763840675354,1.0575056076049805,1.0573619604110718,1.0571781396865845,1.0570178031921387,1.0568866729736328,1.056787371635437,1.0567219257354736,1.0566835403442383,1.0566805601119995,1.0566974878311157,1.0566662549972534,1.0565794706344604,1.0565731525421143,1.0566396713256836,1.0567429065704346,1.0568686723709106,1.0570032596588135,1.057151198387146,1.0572906732559204,1.0574339628219604,1.0575767755508423,1.0574233531951904,1.0567220449447632,1.056017518043518,1.0555330514907837,1.0552313327789307,1.0550663471221924,1.0549907684326172,1.0549514293670654,1.054897665977478,1.054781198501587,1.0537960529327393,1.0527528524398804,1.0516995191574097,1.0506463050842285,1.0496050119400024,1.0485788583755493,1.0475690364837646,1.046588659286499,1.0456510782241821,1.0447635650634766,1.0439397096633911],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"On-policy Estimate\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600],\"y\":[0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855,0.8517364622345855],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"IS Variance\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600],\"y\":[0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806,0.030542027205228806],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"lines\",\"name\":\"Train Variance\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600],\"y\":[0.16321882605552673,0.15478327870368958,0.1537313014268875,0.15269817411899567,0.15167370438575745,0.15066799521446228,0.14969827234745026,0.14873553812503815,0.1477915197610855,0.14680655300617218,0.14583136141300201,0.1448679268360138,0.14396658539772034,0.14312146604061127,0.1423044502735138,0.14147920906543732,0.14066016674041748,0.13985471427440643,0.1390560418367386,0.13824665546417236,0.1374628245830536,0.13673622906208038,0.13602368533611298,0.13532571494579315,0.1346404254436493,0.13396352529525757,0.13330352306365967,0.13265863060951233,0.13202187418937683,0.1314232349395752,0.13083912432193756,0.13036099076271057,0.1298927217721939,0.12942154705524445,0.1289297342300415,0.12844467163085938,0.12801769375801086,0.12760011851787567,0.1271975338459015,0.12681366503238678,0.12643979489803314,0.1260998547077179,0.12582185864448547,0.12555459141731262,0.12529724836349487,0.12504999339580536,0.12481319904327393,0.12458675354719162,0.12437140941619873,0.12416673451662064,0.12397336214780807,0.12379086017608643,0.1236184686422348,0.12345913052558899,0.12331846356391907,0.12319250404834747,0.12305763363838196,0.12293687462806702,0.12283015996217728,0.12272556126117706,0.12260337918996811,0.12252740561962128,0.12258115410804749,0.12264245003461838,0.12271418422460556,0.12280005216598511,0.12289942055940628,0.12301594763994217,0.12315336614847183,0.12330331653356552,0.12346776574850082,0.12364249676465988,0.12382610142230988,0.1240188330411911,0.12422149628400803,0.124432273209095,0.12465039640665054,0.12488187849521637,0.12513068318367004,0.12537319958209991,0.12561331689357758,0.12585750222206116,0.1261054426431656,0.12635649740695953,0.12661004066467285,0.12686468660831451,0.12712018191814423,0.12737815082073212,0.12763643264770508,0.12789450585842133,0.12815174460411072,0.12840791046619415,0.12866255640983582,0.12891532480716705,0.12916558980941772,0.12941330671310425,0.1296583116054535,0.1299016773700714,0.13014142215251923,0.13037727773189545,0.13060905039310455,0.13083645701408386,0.13106226921081543,0.1312863826751709,0.13150520622730255,0.13171857595443726,0.13192635774612427,0.13212841749191284,0.13232479989528656,0.13251766562461853,0.13270822167396545,0.1328933835029602,0.13307243585586548,0.13324561715126038,0.13341303169727325,0.13357464969158173,0.13373099267482758,0.1338820606470108,0.13402770459651947,0.13416799902915955,0.13430312275886536,0.1344331055879593,0.1345580369234085,0.13467803597450256,0.1347937434911728,0.1349053829908371,0.13501305878162384,0.13511629402637482,0.13521385192871094,0.1353088617324829,0.1354026198387146,0.13549423217773438,0.13558200001716614,0.1356666386127472,0.13575007021427155,0.1358312964439392,0.13591007888317108,0.1359863430261612,0.1360601931810379,0.13613146543502808,0.13620026409626007,0.1362665295600891,0.13633017241954803,0.13639116287231445,0.13644979894161224,0.13650614023208618,0.13655561208724976,0.13660456240177155,0.13665612041950226,0.13670800626277924,0.13676334917545319,0.1368200033903122,0.13687291741371155,0.1369227021932602,0.13697093725204468,0.1370171159505844,0.1370605230331421,0.1371029019355774,0.1371493637561798,0.1371927112340927,0.13723322749137878,0.1372714340686798,0.1373063176870346,0.1373380720615387,0.1373669058084488,0.1373927742242813,0.13741569221019745,0.13743577897548676,0.13745316863059998,0.13746799528598785,0.13747698068618774,0.1374817043542862,0.13748368620872498,0.13748270273208618,0.1374799907207489,0.13747574388980865,0.1374698430299759,0.1374625265598297,0.13745367527008057,0.1374433934688568,0.13743183016777039,0.13741907477378845,0.13740511238574982,0.13738997280597687,0.13737377524375916,0.13736020028591156,0.13735449314117432,0.13734778761863708,0.13734008371829987,0.13733142614364624,0.13732190430164337,0.13731160759925842,0.13730056583881378,0.1372888684272766,0.1372765153646469,0.13726353645324707,0.1372501403093338,0.13723745942115784,0.13722477853298187,0.13721171021461487,0.1371982991695404,0.13718460500240326,0.13717098534107208,0.13715708255767822,0.13714297115802765,0.13712859153747559,0.1371140033006668,0.1370992362499237,0.13708636164665222,0.13707366585731506,0.1370611935853958,0.13704894483089447,0.13703688979148865,0.13702498376369476,0.13701318204402924,0.13700169324874878,0.1369924694299698,0.1369834691286087,0.13697493076324463,0.13697022199630737,0.13696563243865967,0.13696123659610748,0.13695687055587769,0.13695256412029266,0.13694825768470764,0.13694283366203308,0.13693539798259735,0.1369285136461258,0.1369219720363617,0.13691717386245728,0.1369125097990036,0.13690799474716187,0.13690336048603058,0.13689854741096497,0.13689351081848145,0.1368883103132248,0.13688205182552338,0.1368747353553772,0.1368669867515564,0.13685892522335052,0.13685043156147003,0.13684161007404327,0.136837899684906,0.13683973252773285,0.13684000074863434,0.1368386149406433,0.13683541119098663,0.13683024048805237,0.13682307302951813,0.13681381940841675,0.13680249452590942,0.136789008975029,0.13677336275577545,0.13675563037395477,0.13673585653305054,0.1367141455411911,0.13669057190418243,0.13666518032550812,0.13663817942142487,0.13660967350006104,0.13657982647418976,0.136548712849617,0.13651636242866516,0.13648289442062378,0.13644832372665405,0.13641278445720673,0.13637632131576538,0.13633903861045837,0.13630066812038422,0.1362612396478653,0.13622039556503296,0.13617819547653198,0.13613465428352356,0.13608990609645844,0.13604401051998138,0.13599711656570435,0.13594940304756165,0.13590079545974731,0.13585132360458374,0.13580112159252167,0.13575027883052826,0.1356988400220871,0.1356467753648758,0.1355939507484436,0.13554033637046814,0.13559818267822266,0.13580510020256042,0.13594192266464233,0.13603582978248596,0.13617639243602753,0.13634571433067322,0.13657110929489136,0.13686305284500122,0.1371546983718872,0.13743436336517334,0.13767597079277039,0.13786771893501282,0.1380155384540558,0.13810990750789642,0.13815629482269287,0.13815610110759735,0.13813364505767822,0.13808251917362213,0.13807262480258942,0.13808979094028473,0.13812196254730225,0.13815973699092865,0.13819678127765656,0.13822990655899048,0.13825805485248566,0.13828273117542267,0.13830679655075073,0.13833364844322205,0.13836658000946045,0.13844317197799683,0.13856354355812073,0.13878442347049713,0.13909976184368134,0.13946816325187683,0.13983963429927826,0.14014022052288055,0.1402905285358429,0.14031223952770233,0.14024226367473602,0.14011278748512268,0.1400013118982315,0.1399271935224533,0.13989710807800293,0.13991336524486542,0.13997295498847961,0.140070378780365,0.14025089144706726,0.14050184190273285,0.14084024727344513,0.1411474645137787,0.14139150083065033,0.1416037231683731,0.14178802073001862,0.14192286133766174,0.1420491635799408,0.14215275645256042,0.14222635328769684,0.1422790288925171,0.14230501651763916,0.14234773814678192,0.14239446818828583,0.1424468606710434,0.14248459041118622,0.1425275355577469,0.142645925283432,0.14281602203845978,0.14305156469345093,0.14332488179206848,0.1435621976852417,0.14379453659057617,0.14399278163909912,0.1441659927368164,0.14436182379722595,0.14457429945468903,0.14477907121181488,0.14495664834976196,0.14506128430366516,0.14519590139389038,0.14533200860023499,0.14545175433158875,0.14557039737701416,0.14556805789470673,0.1455460637807846,0.14548642933368683,0.14539803564548492,0.14529949426651,0.14519917964935303,0.1450488418340683,0.1448708027601242,0.14473232626914978,0.14459064602851868,0.1444271355867386,0.14425811171531677,0.14408855140209198,0.14390841126441956,0.14371897280216217,0.14353345334529877,0.14333809912204742,0.1431347280740738,0.1429266482591629,0.14271439611911774,0.14249344170093536,0.14227135479450226,0.14204658567905426,0.1418232023715973,0.141601100564003,0.14137859642505646,0.14115972816944122,0.14094603061676025,0.1407366394996643,0.1405308097600937,0.14032790064811707,0.1401270478963852,0.1399276703596115,0.13972905278205872,0.13952872157096863,0.1393275111913681,0.13912390172481537,0.1389176994562149,0.13870926201343536,0.13849951326847076,0.13828881084918976,0.13809947669506073,0.13791070878505707,0.1377226561307907,0.13753657042980194,0.13735325634479523,0.13717316091060638,0.13699659705162048,0.1368231326341629,0.1366506963968277,0.13647904992103577,0.13630639016628265,0.13612483441829681,0.13594576716423035,0.13577842712402344,0.13562481105327606,0.1354723423719406,0.13532105088233948,0.13517288863658905,0.1350242644548416,0.13487553596496582,0.13472680747509003,0.13457787036895752,0.1344289630651474,0.13428089022636414,0.13413408398628235,0.1339896321296692,0.13385866582393646,0.133735790848732,0.133613720536232,0.1334930658340454,0.13337604701519012,0.13326184451580048,0.13315580785274506,0.13305239379405975,0.1329442709684372,0.13283555209636688,0.1327279508113861,0.13262169063091278,0.13251660764217377,0.13241241872310638,0.13230912387371063,0.13220687210559845,0.13210761547088623,0.1320149153470993,0.13192401826381683,0.1318342089653015,0.13174645602703094,0.13166141510009766,0.13157707452774048,0.13149385154247284,0.13141165673732758,0.13133059442043304,0.13125112652778625,0.1311728060245514,0.13109441101551056,0.13101673126220703,0.1309383660554886,0.13086174428462982,0.1307864487171173,0.13071201741695404,0.13063812255859375,0.13056126236915588,0.13048437237739563,0.13040868937969208,0.13032832741737366,0.13024592399597168,0.13016271591186523,0.13008084893226624,0.12999743223190308,0.12991303205490112,0.1298278272151947,0.12974193692207336,0.12965531647205353,0.1295514702796936,0.12944243848323822,0.12930826842784882,0.12916097044944763,0.1290031522512436,0.1288401186466217,0.12867094576358795,0.1285024881362915,0.12835879623889923,0.12822362780570984,0.12812331318855286,0.12802116572856903,0.1279159039258957,0.12780927121639252,0.12770353257656097,0.1275986284017563,0.12749475240707397,0.1273920089006424,0.12729015946388245,0.1271892935037613,0.12708812952041626,0.12699075043201447,0.12689542770385742,0.12680168449878693,0.12670934200286865,0.12661892175674438,0.12652860581874847,0.12643957138061523,0.12635214626789093,0.12626594305038452,0.1261812299489975,0.12609778344631195,0.12601794302463531,0.1259404420852661,0.12586243450641632,0.12578456103801727,0.12570272386074066,0.12562325596809387,0.1255439668893814,0.12547528743743896,0.12541627883911133,0.12535710632801056,0.12529857456684113,0.12523865699768066,0.12517759203910828,0.12511591613292694,0.12505488097667694,0.1250137984752655,0.12497767806053162,0.12493707239627838,0.12490051984786987,0.12486670166254044,0.12483226507902145,0.1247972697019577,0.12476184219121933,0.12473379820585251,0.12470907717943192,0.1246800422668457,0.12464853376150131,0.12461478263139725,0.12457100301980972,0.12451494485139847,0.12445006519556046,0.12437987327575684,0.1243034079670906,0.12422171235084534,0.1241406723856926,0.12405642867088318,0.12396574020385742,0.12387168407440186,0.12377713620662689,0.12369678914546967,0.12361851334571838,0.12354245036840439,0.123472198843956,0.12340404093265533,0.12333761155605316,0.12327305972576141,0.12321048229932785,0.12315037101507187,0.12309509515762329,0.12304270267486572,0.12301380932331085,0.12301943451166153,0.12301939725875854,0.12302138656377792,0.12302575260400772,0.12303484231233597,0.12304479628801346,0.12305524945259094,0.12306725978851318,0.12308094650506973,0.12309561669826508,0.1231471449136734,0.12318957597017288,0.12322382628917694,0.12325821816921234,0.12328049540519714,0.12329191714525223,0.12329345941543579,0.12328606098890305,0.12327040731906891,0.12325170636177063,0.12323065102100372,0.12322650104761124,0.12323806434869766,0.12325412780046463,0.12327241152524948,0.12329281121492386,0.12331512570381165,0.12333957105875015,0.12336447089910507,0.12338892370462418,0.12341228127479553,0.12345659732818604,0.1234879121184349,0.12350714206695557,0.12351565808057785,0.12351463735103607,0.12350516021251678],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"lines\",\"name\":\"Test Variance\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600],\"y\":[0.030249623581767082,0.030280420556664467,0.03031168319284916,0.03034328855574131,0.030375251546502113,0.03035864420235157,0.030341025441884995,0.030322646722197533,0.030303608626127243,0.030305413529276848,0.030305316671729088,0.030303221195936203,0.03029913827776909,0.030292455106973648,0.030283188447356224,0.030271373689174652,0.030257025733590126,0.030240194872021675,0.030222369357943535,0.030224040150642395,0.030224677175283432,0.030223019421100616,0.03021913208067417,0.03021310456097126,0.030205003917217255,0.0301948394626379,0.03018549084663391,0.030174721032381058,0.030161965638399124,0.03014700673520565,0.03012995608150959,0.03012789972126484,0.030132735148072243,0.030133957043290138,0.030129462480545044,0.030122803524136543,0.030114218592643738,0.03010392375290394,0.030091973021626472,0.030080074444413185,0.030070481821894646,0.0300595723092556,0.030047643929719925,0.03003503754734993,0.030021894723176956,0.030008414760231972,0.029994767159223557,0.02998601458966732,0.029977483674883842,0.029969314113259315,0.029961707070469856,0.02995483949780464,0.02994888462126255,0.02994406782090664,0.02994055300951004,0.02993856370449066,0.02993808314204216,0.029939288273453712,0.029942359775304794,0.02994750440120697,0.029954582452774048,0.029963791370391846,0.02997775189578533,0.02999980002641678,0.03002425655722618,0.030051207169890404,0.030080623924732208,0.030112629756331444,0.030147435143589973,0.030185028910636902,0.030225301161408424,0.030268242582678795,0.030313828960061073,0.030361993238329887,0.030412668362259865,0.03046576678752899,0.030521145090460777,0.030578693374991417,0.030638257041573524,0.030699683353304863,0.030762840062379837,0.030827602371573448,0.03089379146695137,0.030963467434048653,0.031035825610160828,0.0311091598123312,0.03118322417140007,0.03125763311982155,0.03133263811469078,0.03140871599316597,0.031485263258218765,0.03156210854649544,0.03163910657167435,0.03171616047620773,0.031793080270290375,0.0318698026239872,0.03194623440504074,0.03202226012945175,0.03209781274199486,0.0321727879345417,0.032247141003608704,0.032320793718099594,0.0323936752974987,0.03246551379561424,0.03253628686070442,0.03260590881109238,0.03267434611916542,0.03274157643318176,0.032807596027851105,0.03287239745259285,0.03293593227863312,0.03299819678068161,0.03305915370583534,0.03311878442764282,0.03317706286907196,0.033233996480703354,0.033289600163698196,0.0333438515663147,0.03339677304029465,0.03344839811325073,0.03349873796105385,0.033548206090927124,0.03359672799706459,0.033644020557403564,0.03369007259607315,0.0337350107729435,0.03377886489033699,0.03382164239883423,0.03386334329843521,0.033904001116752625,0.033943600952625275,0.03398216515779495,0.03401966020464897,0.0340564101934433,0.0340927429497242,0.03412814810872078,0.03416264429688454,0.03419644758105278,0.03422939032316208,0.03426146134734154,0.034292686730623245,0.03432310372591019,0.03435559570789337,0.03439042717218399,0.034424640238285065,0.03445854038000107,0.034491878002882004,0.034524597227573395,0.034556709229946136,0.03458867594599724,0.03462393209338188,0.034660063683986664,0.034695565700531006,0.03473037853837013,0.03476449102163315,0.034797850996255875,0.03483034670352936,0.034861981868743896,0.03489264100790024,0.034922294318675995,0.03495093807578087,0.034978628158569336,0.03500532731413841,0.035031065344810486,0.03505588695406914,0.035079825669527054,0.03510292246937752,0.035125236958265305,0.0351468026638031,0.03516767919063568,0.03518790379166603,0.03520752489566803,0.035226572304964066,0.03524509444832802,0.035263124853372574,0.03528071567416191,0.035297833383083344,0.03531455993652344,0.03533089905977249,0.03534688428044319,0.03536325320601463,0.03537963703274727,0.035395730286836624,0.03541154786944389,0.035427093505859375,0.03544239327311516,0.03545745462179184,0.03547229245305061,0.03548693284392357,0.0355013944208622,0.0355156846344471,0.03552984818816185,0.03554388880729675,0.035557813942432404,0.035571638494729996,0.03558538481593132,0.03559906408190727,0.03561270236968994,0.035626303404569626,0.03563990816473961,0.03565352037549019,0.035667143762111664,0.03568075969815254,0.03569437935948372,0.035707987844944,0.03572162613272667,0.03573529049754143,0.035749003291130066,0.035762760788202286,0.035776522010564804,0.03579032048583031,0.035804130136966705,0.03581798076629639,0.03583185002207756,0.035845763981342316,0.035859715193510056,0.03587377443909645,0.035887911915779114,0.03590214625000954,0.03591646999120712,0.035930879414081573,0.03594536334276199,0.03595993295311928,0.03597458451986313,0.03598930314183235,0.03600407764315605,0.03601894527673721,0.03603389486670494,0.03604893013834953,0.03606405481696129,0.03607925772666931,0.036094531416893005,0.03611087054014206,0.03612750396132469,0.03614423796534538,0.036161161959171295,0.03617914021015167,0.036197125911712646,0.036215100437402725,0.03623303771018982,0.03625117242336273,0.03626934066414833,0.03628746420145035,0.03630584850907326,0.03632442653179169,0.03634314611554146,0.03636233136057854,0.036382537335157394,0.03640352934598923,0.03642507642507553,0.03644658997654915,0.03646858409047127,0.036490216851234436,0.036511462181806564,0.036532290279865265,0.036552704870700836,0.03657269850373268,0.0365922637283802,0.036611441522836685,0.036630239337682724,0.03664868697524071,0.036666758358478546,0.03668449446558952,0.03670188784599304,0.036718957126140594,0.03673570603132248,0.03675216808915138,0.03676833584904671,0.036784183233976364,0.036799706518650055,0.03681495785713196,0.03682984784245491,0.03684442117810249,0.036858685314655304,0.03687264025211334,0.0368863046169281,0.036899715662002563,0.03691286966204643,0.03692580759525299,0.036938514560461044,0.03695104643702507,0.036963410675525665,0.03697560355067253,0.03698764368891716,0.03699951618909836,0.03702295944094658,0.03706052526831627,0.03709101304411888,0.03712582215666771,0.03717025741934776,0.03722101449966431,0.03728311508893967,0.03735492378473282,0.03742661699652672,0.037497129291296005,0.03756314143538475,0.037622325122356415,0.03767377883195877,0.03771756961941719,0.03775629773736,0.03778853267431259,0.03781622275710106,0.03783812001347542,0.03786613792181015,0.0378970131278038,0.037928786128759384,0.03795973211526871,0.03798877075314522,0.038015395402908325,0.03802194818854332,0.038024552166461945,0.038026317954063416,0.0380280576646328,0.03803059086203575,0.03804207965731621,0.038063615560531616,0.03810812160372734,0.03816331550478935,0.03822411224246025,0.03828992694616318,0.03835361450910568,0.03838220238685608,0.038378141820430756,0.03835147246718407,0.03831002116203308,0.038283344358205795,0.03826501965522766,0.03825673088431358,0.03825908899307251,0.03827134147286415,0.03829248249530792,0.03833332657814026,0.038389600813388824,0.03847627341747284,0.03855758532881737,0.03862791880965233,0.03869267553091049,0.03874904289841652,0.038792211562395096,0.038834914565086365,0.038871560245752335,0.03890001028776169,0.03892213851213455,0.03893690183758736,0.038956016302108765,0.03897707536816597,0.039000142365694046,0.03902525454759598,0.03905633091926575,0.039110541343688965,0.039178043603897095,0.03925212100148201,0.039331648498773575,0.039415065199136734,0.039504293352365494,0.03959716111421585,0.03969470039010048,0.03979656845331192,0.03989862650632858,0.04000336676836014,0.04008285701274872,0.040093544870615005,0.04010193794965744,0.04011501371860504,0.040130551904439926,0.04015602543950081,0.04022391140460968,0.0402921661734581,0.040353186428546906,0.040418095886707306,0.040484458208084106,0.040551651269197464,0.04061891511082649,0.04068923369050026,0.040754396468400955,0.04081865772604942,0.0408795028924942,0.04093484207987785,0.040984079241752625,0.04102563485503197,0.04106193408370018,0.04109235852956772,0.04111423343420029,0.04112823307514191,0.04113483428955078,0.04113435745239258,0.04112725332379341,0.04111684858798981,0.0411042720079422,0.04109027981758118,0.04107563942670822,0.04106147214770317,0.041048675775527954,0.041038062423467636,0.04102940484881401,0.04102228209376335,0.04101625829935074,0.04101067781448364,0.04100533202290535,0.04099973663687706,0.040992747992277145,0.04098423942923546,0.04097387567162514,0.040961600840091705,0.04094760864973068,0.04093685746192932,0.04093020409345627,0.04092032089829445,0.04090237244963646,0.040883466601371765,0.04086463525891304,0.04084651544690132,0.040829963982105255,0.0408148393034935,0.040801141411066055,0.040788743644952774,0.04077744111418724,0.04076690971851349,0.04075843468308449,0.04075118154287338,0.04074523225426674,0.04073970019817352,0.040734123438596725,0.040728610008955,0.040719714015722275,0.04071030393242836,0.04070046544075012,0.04068991169333458,0.04067857563495636,0.04066672548651695,0.04065461456775665,0.04064323380589485,0.04063742607831955,0.040631648153066635,0.04062608256936073,0.04062098637223244,0.0406164787709713,0.040612563490867615,0.040609076619148254,0.04060541093349457,0.04060190171003342,0.040596190840005875,0.04058811068534851,0.04058026149868965,0.040572524070739746,0.04056481271982193,0.04055701196193695,0.04054909944534302,0.04054099693894386,0.040532827377319336,0.04052472114562988,0.04051658511161804,0.04050841182470322,0.0405002161860466,0.04049205780029297,0.0404839850962162,0.04047596827149391,0.04046797752380371,0.04046005755662918,0.04045215621590614,0.04044425114989281,0.04043632373213768,0.04042841121554375,0.04042050614953041,0.040412627160549164,0.040404826402664185,0.04039709270000458,0.04038940742611885,0.040383901447057724,0.0403783954679966,0.04037304222583771,0.040367819368839264,0.04036325961351395,0.04035923629999161,0.04035588726401329,0.040352776646614075,0.04035000503063202,0.04034747928380966,0.04034503549337387,0.04034243896603584,0.040338531136512756,0.040334999561309814,0.040331535041332245,0.040329016745090485,0.040327221155166626,0.04032590240240097,0.04032442346215248,0.040323033928871155,0.04032145440578461,0.040319859981536865,0.04031772539019585,0.04031137377023697,0.04030369594693184,0.04029695317149162,0.040290139615535736,0.04028341919183731,0.04027682542800903,0.04027043655514717,0.04026428982615471,0.04025835916399956,0.04025211185216904,0.040245071053504944,0.040238119661808014,0.04023091867566109,0.040223680436611176,0.04021667316555977,0.04020985960960388,0.04020316153764725,0.04019651189446449,0.04019232839345932,0.0401899479329586,0.0401875339448452,0.04018498584628105,0.0401812307536602,0.04017755761742592,0.040174052119255066,0.04017075151205063,0.040167950093746185,0.040163882076740265,0.040159933269023895,0.0401562824845314,0.040152836591005325,0.040149588137865067,0.04014644771814346,0.04014340415596962,0.040140409022569656,0.040137313306331635,0.04013408347964287,0.040130615234375,0.04012695327401161,0.040123119950294495,0.040119197219610214,0.04011518508195877,0.04011116176843643,0.0401071198284626,0.04010302200913429,0.04009898379445076,0.040096089243888855,0.040093209594488144,0.04009035602211952,0.04008762910962105,0.04008498042821884,0.04008238762617111,0.040079910308122635,0.040077585726976395,0.040075354278087616,0.04007333517074585,0.040071744471788406,0.04007050022482872,0.040069494396448135,0.04006880149245262,0.04006817936897278,0.04006723314523697,0.040066417306661606,0.04006549343466759,0.04006444662809372,0.04006316512823105,0.04006168618798256,0.040060047060251236,0.04005831107497215,0.04005638137459755,0.040054548531770706,0.040052834898233414,0.04005122184753418,0.04004966840147972,0.04004818573594093,0.040046777576208115,0.040045417845249176,0.04004376009106636,0.040041811764240265,0.04004049301147461,0.04004024341702461,0.04004010930657387,0.04004004970192909,0.0400400310754776,0.04004004970192909,0.04004010558128357,0.0400402657687664,0.040040481835603714,0.04004066810011864,0.040040723979473114,0.0400407575070858,0.04004189744591713,0.04004335030913353,0.040045201778411865,0.040047939866781235,0.04005119949579239,0.040054697543382645,0.04005842283368111,0.04006225988268852,0.04006558656692505,0.04006801173090935,0.04006950184702873,0.04007014259696007,0.040070317685604095,0.04006980359554291,0.04006895050406456,0.040068142116069794,0.04006745293736458,0.04006679356098175],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"lines\",\"name\":\"Train MSE Loss\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600],\"y\":[30.950471878051758,29.713825225830078,28.60778045654297,27.53249168395996,26.487804412841797,25.473758697509766,24.490184783935547,23.536109924316406,22.612071990966797,21.71661376953125,20.850502014160156,20.013669967651367,19.205280303955078,18.424930572509766,17.6722412109375,16.946956634521484,16.248634338378906,15.5767240524292,14.930543899536133,14.309427261352539,13.712915420532227,13.14012622833252,12.590810775756836,12.064261436462402,11.559792518615723,11.076677322387695,10.61428165435791,10.171923637390137,9.74886417388916,9.34418773651123,8.95768928527832,8.588057518005371,8.235040664672852,7.898352146148682,7.577559947967529,7.271812438964844,6.980554103851318,6.703089237213135,6.438821792602539,6.187091827392578,5.947668075561523,5.7200398445129395,5.50337553024292,5.297511577606201,5.1020073890686035,4.916422367095947,4.740311622619629,4.5732855796813965,4.4149580001831055,4.264925003051758,4.1228203773498535,3.9882328510284424,3.8607900142669678,3.7401673793792725,3.625943422317505,3.5177760124206543,3.415339946746826,3.318467140197754,3.2269325256347656,3.140460968017578,3.0587472915649414,2.9815735816955566,2.9086074829101562,2.840027093887329,2.7753360271453857,2.714350700378418,2.6570444107055664,2.6029763221740723,2.551870107650757,2.5036370754241943,2.4582343101501465,2.4153249263763428,2.374746561050415,2.336378335952759,2.300074815750122,2.265766143798828,2.233396053314209,2.202747344970703,2.1735782623291016,2.1458144187927246,2.119443416595459,2.094430923461914,2.070695161819458,2.048173427581787,2.0267882347106934,2.0064523220062256,1.987088680267334,1.968675971031189,1.9510875940322876,1.9342652559280396,1.9181652069091797,1.9027174711227417,1.887872338294983,1.8735957145690918,1.8597840070724487,1.8464568853378296,1.8335744142532349,1.821095585823059,1.8089938163757324,1.7972371578216553,1.785796046257019,1.774646520614624,1.7637624740600586,1.7531251907348633,1.7426881790161133,1.7324423789978027,1.7223879098892212,1.7124687433242798,1.70270574092865,1.6930879354476929,1.6835706233978271,1.6741842031478882,1.6649174690246582,1.6557526588439941,1.6466795206069946,1.6377108097076416,1.6287920475006104,1.6199290752410889,1.6111481189727783,1.6024482250213623,1.593826174736023,1.5852688550949097,1.5767841339111328,1.568375825881958,1.5600097179412842,1.5516985654830933,1.5434404611587524,1.5352396965026855,1.5270795822143555,1.5189648866653442,1.5108543634414673,1.5027724504470825,1.4945420026779175,1.486154317855835,1.4776384830474854,1.4691365957260132,1.4606624841690063,1.4521631002426147,1.4436954259872437,1.43528413772583,1.4269049167633057,1.4185799360275269,1.4102978706359863,1.402006983757019,1.3937827348709106,1.3856005668640137,1.3773987293243408,1.3692150115966797,1.3609817028045654,1.3527090549468994,1.3445079326629639,1.336421251296997,1.3285071849822998,1.3206602334976196,1.3127611875534058,1.3049954175949097,1.2973670959472656,1.2898951768875122,1.2825422286987305,1.275312066078186,1.268201231956482,1.2612069845199585,1.2543132305145264,1.247512936592102,1.2408004999160767,1.234169363975525,1.2276148796081543,1.221132755279541,1.2147186994552612,1.208369493484497,1.2020801305770874,1.1958484649658203,1.1896755695343018,1.1835600137710571,1.177501916885376,1.1715022325515747,1.1655651330947876,1.1596816778182983,1.1538548469543457,1.1480845212936401,1.142371416091919,1.136752724647522,1.131189227104187,1.125684380531311,1.1202318668365479,1.114827275276184,1.1094608306884766,1.1041440963745117,1.0988819599151611,1.0936670303344727,1.0884895324707031,1.0833543539047241,1.0782625675201416,1.073212742805481,1.0682036876678467,1.0632356405258179,1.0582900047302246,1.053362250328064,1.0484646558761597,1.043592095375061,1.0387521982192993,1.0339312553405762,1.029119610786438,1.0243393182754517,1.0195900201797485,1.014868140220642,1.010162591934204,1.0054845809936523,1.00083327293396,0.9961974024772644,0.9915899038314819,0.9870051145553589,0.9824469685554504,0.9779188632965088,0.9734211564064026,0.9689477682113647,0.9644774794578552,0.9600348472595215,0.9556113481521606,0.9512043595314026,0.9468231797218323,0.9424707889556885,0.9381458163261414,0.9338494539260864,0.9295825958251953,0.9253337383270264,0.9210816025733948,0.9168477654457092,0.9126359820365906,0.9084271788597107,0.904245138168335,0.9000890851020813,0.8959603905677795,0.8918487429618835,0.8877597451210022,0.8836939930915833,0.8796634674072266,0.8756722211837769,0.8717156648635864,0.8677883148193359,0.8638958930969238,0.8600285649299622,0.8561525344848633,0.8522596955299377,0.8484051823616028,0.8445911407470703,0.840822160243988,0.8370954394340515,0.8334035873413086,0.829745352268219,0.8261188864707947,0.8225194215774536,0.8189474940299988,0.8154017925262451,0.8118796348571777,0.8083834648132324,0.804913341999054,0.8014686703681946,0.7980456352233887,0.7946430444717407,0.7912632822990417,0.7879089117050171,0.7845800518989563,0.7812758088111877,0.7779959440231323,0.7747389078140259,0.7715053558349609,0.7682942748069763,0.7651030421257019,0.7619330883026123,0.7587810754776001,0.7556474804878235,0.7525339126586914,0.7494402527809143,0.7463539242744446,0.7432547807693481,0.7401728630065918,0.7371048331260681,0.7339960336685181,0.7309064269065857,0.7278121709823608,0.7246865034103394,0.7215772867202759,0.7184869647026062,0.7154222130775452,0.7123092412948608,0.7091568112373352,0.7061001062393188,0.7029621005058289,0.6997460722923279,0.6964100003242493,0.6928701400756836,0.688851535320282,0.6849570870399475,0.6811588406562805,0.6774959564208984,0.6739739775657654,0.6705812811851501,0.6673111915588379,0.6642932891845703,0.6613913178443909,0.6585308909416199,0.655733048915863,0.6528944373130798,0.6500514149665833,0.6472157835960388,0.6443880200386047,0.6415662169456482,0.6387502551078796,0.6359416246414185,0.6331430077552795,0.6303562521934509,0.6275833249092102,0.6248183846473694,0.621988832950592,0.619073212146759,0.6159583926200867,0.6127892136573792,0.6096429228782654,0.606581449508667,0.6037041544914246,0.6009277105331421,0.5982244610786438,0.5955780148506165,0.5930009484291077,0.5905009508132935,0.5879871845245361,0.5854369401931763,0.5828371047973633,0.5801880359649658,0.5773792862892151,0.5742283463478088,0.5709280967712402,0.5676339268684387,0.5643994808197021,0.5612009167671204,0.557516872882843,0.5538681745529175,0.550233006477356,0.5455796122550964,0.5409778356552124,0.5363408327102661,0.5316163897514343,0.5266759395599365,0.5211375951766968,0.5155528783798218,0.5099462270736694,0.5042434930801392,0.4979894161224365,0.49113109707832336,0.4842163622379303,0.477234423160553,0.4702098071575165,0.463111937046051,0.4560605585575104,0.4490566551685333,0.4419664442539215,0.43489664793014526,0.42798277735710144,0.4212453067302704,0.4146755039691925,0.4083286225795746,0.4020816385746002,0.39593562483787537,0.38996705412864685,0.3841477334499359,0.37852269411087036,0.3731054961681366,0.36776307225227356,0.36248263716697693,0.3571680784225464,0.3518476188182831,0.34661829471588135,0.34159064292907715,0.33692899346351624,0.33250606060028076,0.3283175826072693,0.3243280053138733,0.3206072449684143,0.31703299283981323,0.31355294585227966,0.31023237109184265,0.3071361482143402,0.3041648268699646,0.3013191223144531,0.29857581853866577,0.29592686891555786,0.29337209463119507,0.2908948063850403,0.28848251700401306,0.28614017367362976,0.2838391065597534,0.2815592586994171,0.2793214023113251,0.2771247625350952,0.27496984601020813,0.2728564441204071,0.2707807719707489,0.26873084902763367,0.2667112946510315,0.2647315561771393,0.26279178261756897,0.2608889043331146,0.2590213119983673,0.25718697905540466,0.2553846836090088,0.2536129057407379,0.25187352299690247,0.2501697242259979,0.24850013852119446,0.2468634843826294,0.2452525496482849,0.24365290999412537,0.24207159876823425,0.24051275849342346,0.23897621035575867,0.23746488988399506,0.23597420752048492,0.2345043271780014,0.23305737972259521,0.23162813484668732,0.23021340370178223,0.22881974279880524,0.22744044661521912,0.2260802686214447,0.22474117577075958,0.22342003881931305,0.22211666405200958,0.22083476185798645,0.21957308053970337,0.2183297574520111,0.2171010971069336,0.21589115262031555,0.21470141410827637,0.213531494140625,0.21238338947296143,0.21125571429729462,0.2101462334394455,0.209053635597229,0.20797835290431976,0.20691943168640137,0.20587961375713348,0.20485474169254303,0.20384444296360016,0.20284895598888397,0.20186838507652283,0.2009032815694809,0.199951171875,0.19901159405708313,0.1980825960636139,0.19716206192970276,0.19625583291053772,0.19536273181438446,0.19448000192642212,0.19360490143299103,0.1927400678396225,0.19188639521598816,0.191043421626091,0.19020876288414001,0.18938401341438293,0.18857207894325256,0.1877698302268982,0.1869782656431198,0.18619869649410248,0.18542952835559845,0.18466947972774506,0.1839180737733841,0.18317773938179016,0.18244682252407074,0.18172462284564972,0.18101082742214203,0.18030692636966705,0.17960938811302185,0.17891858518123627,0.17823413014411926,0.17755676805973053,0.17688529193401337,0.1762218177318573,0.1755647510290146,0.17491628229618073,0.1742767095565796,0.17364570498466492,0.17300324141979218,0.17236511409282684,0.17173175513744354,0.1711050570011139,0.1704758256673813,0.16985049843788147,0.16922247409820557,0.16859854757785797,0.16797848045825958,0.16736820340156555,0.16676802933216095,0.16617020964622498,0.16557645797729492,0.16498906910419464,0.1644037514925003,0.16382405161857605,0.16325171291828156,0.16268794238567352,0.1621333360671997,0.16157828271389008,0.16102492809295654,0.16046783328056335,0.1598934829235077,0.15931791067123413,0.15873578190803528,0.15815754234790802,0.15758463740348816,0.1570170372724533,0.15645138919353485,0.15588998794555664,0.15532717108726501,0.15475693345069885,0.15413658320903778,0.15351025760173798,0.1528768390417099,0.15224012732505798,0.15161024034023285,0.15099062025547028,0.15037880837917328,0.14976724982261658,0.14914606511592865,0.14852862060070038,0.14791591465473175,0.14730574190616608,0.14669698476791382,0.14608529210090637,0.1454833745956421,0.14488881826400757,0.1442953646183014,0.14371122419834137,0.14312569797039032,0.1425439417362213,0.1419709026813507,0.14140573143959045,0.14084863662719727,0.1402927190065384,0.13973817229270935,0.13918611407279968,0.1386425793170929,0.13810786604881287,0.13756665587425232,0.1370319426059723,0.1365060955286026,0.13598884642124176,0.1354721337556839,0.13495534658432007,0.13444450497627258,0.13393795490264893,0.13342024385929108,0.13290412724018097,0.1323935091495514,0.13188551366329193,0.13136796653270721,0.13085485994815826,0.13035908341407776,0.12986350059509277,0.12937791645526886,0.1288997381925583,0.128424733877182,0.12795397639274597,0.12749198079109192,0.12702737748622894,0.12655819952487946,0.12608294188976288,0.1255916804075241,0.12509922683238983,0.1245993822813034,0.12408935278654099,0.12355444580316544,0.12300875037908554,0.12246041744947433,0.12191177159547806,0.1213744506239891,0.12084942311048508,0.12033379822969437,0.11982665210962296,0.11932707577943802,0.11884450167417526,0.11837943643331528,0.11792813986539841,0.11746037006378174,0.11699026823043823,0.11649138480424881,0.11596787720918655,0.11544691771268845,0.1149192675948143,0.11439920216798782,0.11389379948377609,0.11340541392564774,0.11293015629053116,0.11246376484632492,0.11199861764907837,0.11150764673948288,0.1110093966126442,0.11053043603897095,0.11007130891084671,0.10963144898414612,0.10921358317136765],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"mode\":\"lines\",\"name\":\"IS MSE\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600],\"y\":[0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393,0.09347435154022393],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"mode\":\"lines\",\"name\":\"Train MSE\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600],\"y\":[0.658787770347544,0.42002607443648754,0.3994710432048735,0.3798955328468352,0.36126139987570116,0.3435562234025241,0.32673896526325763,0.3109657560452389,0.2960513538873599,0.28224330225654337,0.26921108453478826,0.2569289031010553,0.24531713667608987,0.2343847109615477,0.2241712726048719,0.21473227999332975,0.20595555261065784,0.1978153585679826,0.19028091424907675,0.18333557797678685,0.17692255474913107,0.17104578317517327,0.16564826537652866,0.16070515025701876,0.15618970808920174,0.15206447212168697,0.14832780812646373,0.1449592961181092,0.1419425315466841,0.13928540151780608,0.13692311273609567,0.13491324666500176,0.1331811376455845,0.13168406316508868,0.1303909692494914,0.12929714766967113,0.12842464326284472,0.12772976524264384,0.1272059752222913,0.12684245441932837,0.12662031574665647,0.12655505345091866,0.12666501424152177,0.12688804266333367,0.12721397267827267,0.12763437013733467,0.12814182899136264,0.12872998191039306,0.12939633298202352,0.1301316493967319,0.13093415845606632,0.13180913081457435,0.1327444376250234,0.13373904410615503,0.13480266084330905,0.13588256704484536,0.13693193695782863,0.13799690406662102,0.13909435034735795,0.14020701030821525,0.14129132796350313,0.14248507479891115,0.14400034607688944,0.14552379946114072,0.14707361609864888,0.1486653392919528,0.15029306703598652,0.15197869710686962,0.15380608913407154,0.15574046006100262,0.15773380762164185,0.15976610978880956,0.16184227498888865,0.16396378202483808,0.16613581955095671,0.16835161430071846,0.17060626316388733,0.17294671175417592,0.17539914478515234,0.17781018491529235,0.18022750303069535,0.18267703224788015,0.1851436065550045,0.18762857565697194,0.19012891068088644,0.19264487427961907,0.19517710361244928,0.1977441515681273,0.20031249274594004,0.20288287001912353,0.20544917856130768,0.20801383895498637,0.21057211545277887,0.21311771140980612,0.21569820407336596,0.2182626781914379,0.22080832376584614,0.22333581837360467,0.2258374296136845,0.2283104158594183,0.2307524970906712,0.23316079800621758,0.2355426714382372,0.2378956532780351,0.24022385466384394,0.24251448571498818,0.24475991456692164,0.2469095205454171,0.2489997400052995,0.25105875723565496,0.2530963513882106,0.25508590101256917,0.25701862628366107,0.2588948364812812,0.2607190475104436,0.26249078146458327,0.2642081008486382,0.2658734039145296,0.2674870536597937,0.269051017266826,0.2705677212739984,0.2720367924155561,0.27345848394129335,0.2748336571868937,0.27617315819483057,0.27747519831643297,0.27876759830193665,0.2800144432564211,0.28119964827534943,0.28234413203151587,0.2834830490699072,0.28458678784923286,0.28570878909277353,0.28692172156462065,0.2884177575816005,0.2899550300241372,0.2914962049202536,0.29310942582552113,0.29472303844640646,0.29631638850783104,0.2978862484660752,0.2994340900925222,0.3009566570691543,0.30244876712728463,0.3039216893322607,0.3053575559546191,0.30676673457444126,0.3081831157871628,0.3095383742493496,0.3108701384623446,0.31223255018844726,0.3135797080561541,0.31486940754581977,0.3161834051505239,0.3175358850996176,0.31884213250522253,0.32009837283026177,0.3213196500080626,0.3225453040450226,0.3237124974283424,0.3248127173897635,0.32584611945689845,0.32680420148758665,0.32768785944536305,0.3285020193663526,0.32924433431662775,0.32991567924093124,0.3305189655406292,0.33105675416775315,0.33153312349822517,0.3319258684154824,0.3322488574272091,0.3325139778911459,0.33272173694374396,0.3328886709258134,0.33301987764449714,0.33310992947376095,0.3331884631538282,0.3332519768593415,0.3332868508395301,0.33329786738155076,0.3332872223197866,0.3332650297003886,0.3332190810462524,0.3331606832061428,0.3330988999964706,0.3330373968390514,0.33297057975126887,0.33290034853194306,0.33282811946340707,0.33275661745994184,0.33268382350623577,0.33261145352076626,0.3325411766246942,0.3324738342728995,0.3324099813656642,0.3323534054593622,0.3323114493039817,0.3322753919021336,0.33224189660607906,0.33221848304971874,0.3322098427509611,0.3322113850876701,0.33221948930819944,0.3322335992326306,0.3322543938210809,0.3322940474793007,0.3323435378622468,0.33241273853858344,0.3325023712571175,0.33259910704411916,0.3327063263502631,0.33282094939895146,0.33294051126051727,0.3330640219163037,0.33318694178662045,0.333252597123577,0.33331996926385277,0.3334045133883241,0.3335377255802277,0.3336761810423561,0.33381519959478345,0.3339539827477676,0.3340920306632854,0.33422875333569607,0.3343895161210873,0.33461150981672955,0.33485274976150525,0.33517515945823884,0.3360106361466201,0.3368677466407971,0.33773530782676964,0.3386086092380859,0.3394802127076506,0.34034564204797474,0.3412056608080942,0.3420483143206291,0.3428690532286161,0.3436718363902101,0.34447318223216544,0.3452534726712071,0.346011813509493,0.34677121284792656,0.34754039031112827,0.3482850638973529,0.348995461393544,0.34967553769761484,0.3503156369646053,0.3509020935430134,0.3514313958963121,0.35190102633406334,0.35231036784094727,0.3526584722558226,0.35294537452855845,0.35317642876805516,0.3533544196222447,0.3534841241070741,0.3535698680779368,0.35361937961884815,0.35363907569054776,0.35363855231137775,0.35361699151461345,0.3535787538609714,0.3535275135593031,0.35346673006032336,0.3533995376067889,0.35332864730735725,0.3532562739231042,0.35318459212348774,0.3531125210493442,0.3530367054766248,0.3529618678752926,0.35288524762868145,0.3528073119211583,0.3527346683866223,0.35268011660724463,0.35262585520104645,0.3525681473229524,0.3524908208889867,0.3524097700787257,0.35232020297829547,0.35221728502338084,0.3521040968273659,0.35198183924179016,0.35185015380825724,0.3517423675814989,0.35175003367991625,0.3517367579664127,0.35136508387107834,0.35077729102841954,0.35011817421048697,0.34935250334808676,0.3489418267663655,0.3485596379705742,0.3481519845711173,0.34780060636278076,0.3475311873966763,0.347488876701635,0.3474377049259406,0.3472209598425283,0.3471348722877705,0.3470774315473537,0.34699927899807953,0.34688271175707625,0.34676023101763753,0.34661535139330557,0.3464498165586056,0.34626907738459517,0.3460825765673736,0.34589425665625817,0.34571148152527476,0.3455402463477419,0.34538620979679646,0.34526327392006534,0.3452256871313281,0.34530746409457447,0.3456177892777442,0.34622794600999174,0.3470497224950191,0.34781688983091574,0.34834456553343085,0.34882038858057696,0.34925188472140145,0.34962787860520705,0.3499839478201856,0.3501942589793387,0.35042948468685153,0.3507029500884439,0.35101662322385296,0.3513660555785738,0.3517980589637925,0.35244364949960894,0.35323660772029464,0.3539723965107114,0.3546997333854637,0.3553876842094059,0.3562613955267498,0.35714316413149305,0.3579083468896783,0.3585639475819067,0.3591204077449165,0.3595484142110775,0.35982555057042975,0.3599600857764093,0.3600052544868062,0.35989628859135325,0.35963456741985855,0.3590379828729486,0.36026258700281216,0.3631069863804528,0.3658523625440504,0.36888259988405053,0.3719641357829301,0.3749080890448323,0.3775706749615255,0.38001039778069695,0.38217341887757583,0.3843980157129864,0.386709573020363,0.38889344126028186,0.39061979744142994,0.3916548440338331,0.39304508835208857,0.39475545176861676,0.396264789712581,0.3975671543845973,0.3982097275219997,0.39880899273457254,0.39883851477246024,0.39863960777106155,0.3981912066674502,0.3976690315849983,0.3968293755207009,0.39574784221840914,0.39479213702827237,0.39393086498824575,0.39295215939509615,0.3920522270729917,0.3912293963298129,0.3907575321712302,0.3910069299518918,0.3913014593066922,0.3913861407255885,0.3913643609388189,0.3911707732824718,0.3908120747773084,0.39026429589325706,0.38959013874537535,0.38884287817963203,0.38809897573382596,0.3873609228626618,0.38667236444274977,0.3860461647741257,0.38548111952864994,0.38495927762568205,0.38446945729177656,0.3839920201412237,0.3835120890283019,0.3830123986533571,0.3825067225713715,0.38193695650118376,0.38130571981526856,0.3805872856507418,0.37977915831124265,0.37888798276728697,0.3779376626755745,0.3769502590911288,0.37602200053224255,0.37507211561094517,0.37411396429703525,0.37315799070862277,0.37222984663100905,0.3713417492398315,0.3704600953047034,0.3696248201763057,0.368812075216206,0.36801362108442126,0.36723871698201044,0.36649838319013855,0.3657887608153195,0.3651275566437182,0.36460996624316605,0.3640648576063895,0.3635233131630925,0.3629994561465686,0.3624499772278461,0.36188461608897626,0.3612893357189638,0.36064723940488885,0.35995860619452774,0.3592710001419376,0.35858643636222687,0.3579261936753143,0.35733773313669503,0.356800619376528,0.3563105969020605,0.35587029911821866,0.35549779853775487,0.3551658837436187,0.35490510936299124,0.3546687852493583,0.354452253498159,0.3542370593439266,0.3540268217240419,0.35381716408178354,0.35360299045135446,0.353377073353131,0.35315387652488833,0.35290823336010746,0.3526646241663757,0.3523912419608921,0.35210217234524677,0.351810924975348,0.3515201495907663,0.35123106275884247,0.3509378577313065,0.3506524548656521,0.3503724127986809,0.35009649192224307,0.3498165675619064,0.34953699117829,0.34924952647549523,0.34896476935097254,0.3486730837474158,0.34837835340702283,0.34808839276505016,0.34780217951466497,0.3474912913905266,0.34717956473951783,0.34687725168707717,0.34658701555819876,0.3462879965907697,0.3460166155344758,0.345759457243039,0.34555107477536406,0.3453458265599667,0.3451585437707375,0.344982756212461,0.3448183542034187,0.3446424026393218,0.3443792879776363,0.34411900027659903,0.3437680383342209,0.34342370169579406,0.343084930601506,0.34275436308482765,0.3423758374782234,0.3419842493461913,0.3416517864544118,0.34140641173831887,0.3412540315326811,0.34106669955300584,0.340849755173134,0.3405324907366417,0.34022029124429315,0.3399069391888214,0.3396000979259872,0.33930601021625795,0.3390223376020201,0.33874751241081835,0.3384987695007341,0.3382356722248888,0.3379685622291124,0.33772423399625573,0.3375135420183114,0.3373152019935526,0.33712399621123823,0.3369499573129692,0.3367825758444978,0.33661260428717277,0.33644862189153096,0.33627422544921043,0.33607252984105873,0.3358375984415186,0.335388590176959,0.33495596392668114,0.3345023520207896,0.33411762459565203,0.33378138506962074,0.33353018318860894,0.3332764490140475,0.33301003910109406,0.33273047392797844,0.33242023028616063,0.332090444843219,0.33173410391963376,0.33135089072228563,0.33103993134019116,0.33072524268107595,0.33040993169272953,0.33008200954955214,0.3297545463574221,0.3294529892783884,0.32918101111995324,0.3289269438594884,0.32872527836479415,0.32850515997349117,0.328248548730832,0.32796948698443146,0.32766297813184053,0.3272918732821758,0.3268747538584269,0.32643124018759895,0.3259820194618921,0.3255230311462081,0.32505564983360435,0.3246104299359161,0.3242283599712599,0.32382791551525136,0.32340719635676296,0.3229825281964389,0.32263602725021945,0.32229400715719764,0.3219331354271727,0.32156119481110773,0.32118892656231013,0.3207912861982708,0.3204509548783887,0.3201424144231808,0.3198284576857484,0.31948125062973454,0.3191427394324894,0.31892374378825966,0.31890689212537104,0.31892036193362217,0.31899379867397964,0.31913296882229913,0.3193420804342201,0.31955131275832527,0.3196895643381834,0.31977178105556114,0.31985610972805945,0.3199321260376492,0.3201465851645996,0.3202757991423767,0.3203351354022336,0.32036412890702815,0.32030237038453624,0.3201685181637165,0.31995399449546646,0.3196722164610143,0.31930762940181845,0.31891773570559245,0.318575784377048,0.31833282021893916,0.31814844805126274,0.3179891901207702,0.3178190860842022,0.31762974744563843,0.3174264699185247,0.3171993147329598,0.3169305022152278,0.31662624895332897,0.3162993993182908,0.3160532521803405,0.31575783533795787,0.3154117559593921,0.3150337113199044,0.3146422461185272,0.3142449095578631],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"mode\":\"lines\",\"name\":\"Test MSE\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600],\"y\":[0.8042782506355127,0.7681824444042133,0.7332424957376982,0.6994618742911819,0.666828165348746,0.636413070441426,0.6070935958370491,0.578850167505857,0.5516602879120008,0.5255521389091096,0.5004970278351435,0.47647240147697206,0.45345356365453715,0.4314252135437999,0.4103646572577931,0.3902448025708595,0.3710349199070223,0.3527067466190046,0.3352117187722371,0.3184962320425223,0.3025809302739951,0.28744327737331,0.2730533518583671,0.259381820308933,0.24639974790841682,0.23407998083616724,0.22236620746006078,0.21125780049870324,0.2007346283296281,0.19077514936455678,0.18135375554682268,0.17247448690934294,0.1641275712028201,0.15626310188096298,0.14884814213328385,0.14186368390029952,0.13528325705385053,0.12908163851355658,0.12323825912993502,0.11774077565679819,0.1125723371292744,0.1077055065397635,0.10312046811616808,0.09879577331449706,0.09471650588458795,0.09086752302683479,0.08723552000693734,0.0837831769721666,0.0805247563464759,0.07744824962906671,0.07454208896954147,0.07179583629648113,0.06920040881994421,0.06674609277641319,0.06442479044230745,0.06222805928030303,0.06015163958730764,0.05818841421063682,0.05633139134954658,0.054572810019131716,0.052910415340141806,0.05133860822256705,0.049852821387948984,0.04844818594295808,0.04712034292713019,0.04586555423754529,0.04468098229574125,0.043563051260518244,0.042507960052042756,0.041513940803645996,0.04057898074891046,0.0397010045392798,0.038877745689031816,0.0381075206553293,0.03738893104845744,0.036720453608963234,0.03610036748784971,0.035527517797452154,0.03500145391507569,0.034520895444723185,0.0340846522353982,0.03369109326138328,0.03333885977283746,0.033025715386134594,0.03275097452204839,0.032513733940167766,0.03231244511789168,0.03214542647415759,0.03201136833093238,0.03190921897849967,0.0318369482608714,0.03179306143245178,0.03177613213962694,0.031784716165299105,0.031817312893941775,0.03187247387179058,0.03194874634864167,0.03204466583913759,0.03215884268110081,0.03228987700107972,0.032436457125631424,0.032597269930191436,0.03277103134220876,0.03295607837461025,0.03315122765183486,0.03335507790339086,0.03356648452736143,0.033784351771845446,0.03400747044212208,0.03423484831887811,0.034465433373559264,0.034698290470625885,0.034932541651195206,0.03516728764752568,0.03540175755724857,0.035635310832383305,0.03586746022743979,0.03609743958592519,0.03632481505149188,0.03654926463574916,0.036770405058487984,0.0369889982550896,0.037204531641897354,0.03741600345351189,0.03762309651549406,0.03782566868970941,0.038023548745373385,0.038216613022775535,0.03840456911741089,0.03858746146416949,0.03876490630373664,0.038936834720974964,0.039102898861045204,0.0392635058274753,0.03941921636889391,0.03956860609702265,0.03971176473286541,0.040005699693998586,0.04030261415685624,0.040600838588676136,0.04090006775723848,0.04120011172764807,0.04151007255895611,0.04183371113552923,0.04215967761750802,0.04248073974196509,0.04280573391497157,0.04313286164176781,0.04346087087211644,0.04379700613297902,0.044143434938968114,0.04449184325840695,0.0448383696376488,0.04518179755595166,0.0455216562468364,0.045855866894547875,0.04618182707397285,0.04649734150612959,0.04679947184120399,0.047086194792358205,0.047355646898029354,0.04760707354787657,0.04783948680330323,0.048052569349523205,0.04824624708276734,0.04842036412498437,0.048575304862783955,0.04871179155011742,0.04883056066825482,0.04893253454430935,0.04901881052038956,0.049090296574067466,0.049148193869090515,0.049193664463425275,0.04922796097023105,0.049252596333384996,0.04926726234003941,0.04927414198164452,0.04927407730009952,0.0492680416871131,0.04925994781607805,0.04924936317770205,0.04923607381121343,0.049220886858217565,0.049203839592115155,0.04918598402213477,0.0491678183105802,0.04914992936790286,0.04913291256258485,0.04911703331720547,0.049102795039940875,0.04909041729958567,0.04907999516320722,0.04907175224680675,0.049065850188098156,0.04906243057830434,0.0490616242143174,0.04906403354639214,0.049069450906366975,0.049078716011821545,0.049091485249898925,0.04910762381355372,0.04912599435342288,0.04914656775430233,0.049169026539063,0.04919352424623564,0.04922025338028291,0.049249100982900904,0.04927972030895428,0.04931201812072969,0.04934593421007377,0.04938108484270946,0.04941748876952634,0.04945493181926181,0.049493317332893194,0.04953234749707061,0.04957277837182645,0.049614248625044106,0.04965654200558381,0.049699471263609116,0.049742922206260885,0.04978656236727018,0.049830375109287395,0.04987423039492663,0.04991807089409918,0.04996164565482572,0.050004751174673456,0.050047191030535815,0.05008899491309325,0.050129938193764316,0.050169837201900346,0.05020845487443621,0.05024988658476816,0.05048421319210721,0.050787030415765703,0.051092626871611736,0.05140297787034255,0.05171186474444081,0.05201737885320173,0.05231847979336103,0.05260929992473218,0.05289127024702678,0.05316717388162902,0.053444276190669784,0.05371819399014198,0.05398535254174415,0.05424467810663091,0.054498977287946976,0.05474110176286076,0.05496864226641432,0.05517897274361474,0.055371280595993694,0.05554436165146194,0.055698087413262654,0.05583328498823024,0.05595150295441621,0.05605416988690576,0.056142763814145596,0.05622020702257666,0.056288096345847374,0.05634851829215601,0.056402880806822875,0.05645268398178152,0.05649921828383765,0.05654375465416299,0.056587217065097145,0.05663064591802567,0.05667455563212488,0.05671927517009975,0.05676500534963648,0.05681222274507383,0.056860352835315923,0.05690944343291133,0.05695957281900406,0.057010034022183145,0.05706025470500411,0.05711057721806397,0.057160489831916794,0.05720701102559222,0.057252360609172034,0.05729574194799117,0.05733630758512613,0.057374371738832336,0.05740964192104817,0.05744172372299596,0.057477235976342245,0.0575195076335629,0.05755633890600237,0.057622265845373014,0.05770201022119105,0.057796518933364,0.057919436290272255,0.05804849869557401,0.05817208166524932,0.058289150900214075,0.05839457960750198,0.05848433163924908,0.0585563661896919,0.05860999458486199,0.058653220174130875,0.058692934736541046,0.05871819465599054,0.05872587570288694,0.05874169737471174,0.058754646447176116,0.05876091253040986,0.05875795952830045,0.05874529441064551,0.058724252508325143,0.0586125885297019,0.05848312530762603,0.05835756600080768,0.05824008860668287,0.05813474043163579,0.0580635256300886,0.05803368155850375,0.05808221402694158,0.05816740829803866,0.058278514532131745,0.058400871926319264,0.05849506845519682,0.05853834405302545,0.05852563603553995,0.05847479412905945,0.05840080301516812,0.05833472494587937,0.05829491727540263,0.058286206723318926,0.05830991253204819,0.05836369477379963,0.05844710099243168,0.05859222856944096,0.05878106551077826,0.05900479796422195,0.05920947593509601,0.05938470008741353,0.05954397369227417,0.059669511720805146,0.05974535009119649,0.0597690932805992,0.05975177038565363,0.05968550047167007,0.05957247020065587,0.05939977203574291,0.05917928524241266,0.05893154490682784,0.058659369938765686,0.05836619970953816,0.058662659312062014,0.05951693788309233,0.060374188337659125,0.06119506628653885,0.06196873871544672,0.06268964289733864,0.06336757318975968,0.06399690938537843,0.06458893269343959,0.06515640481774977,0.06568532962661376,0.06620231997009432,0.06658577776061392,0.06659413683734597,0.0665843689351004,0.06659690152272484,0.06662714636880983,0.06671649955665213,0.06703450479104356,0.06736746625787059,0.0676795542744746,0.0680279384777149,0.06840433056195097,0.0688121747945923,0.06924796760957247,0.06971909268787484,0.07018379882963541,0.07064609286956042,0.07110097105686254,0.07153445036072689,0.07193623663713793,0.07229347810452047,0.07261152458711018,0.0728811610069687,0.07308446585734683,0.07322417613629865,0.07330403003936121,0.07332964344147391,0.07330692666939057,0.0736758840714225,0.07402455801644882,0.07433989073070757,0.07463205794955849,0.0749248788278628,0.07522941588701464,0.07556295100033825,0.0759188673321072,0.07628745585938587,0.07665676988682091,0.0770131314208162,0.07735482654169684,0.07767715826882901,0.07795747724604038,0.07818463400266304,0.0783597274026546,0.07848144459786571,0.07855326096611515,0.07858949875290788,0.07860292638930783,0.07859466286329403,0.07855482868712652,0.07850132583005962,0.07844453933845076,0.07839675296436065,0.07838218814626047,0.07839987383622317,0.07844901771962359,0.07852577039429035,0.078624500338047,0.078737586889369,0.07888188105670332,0.07904146537511235,0.07920150218179617,0.07935786406531867,0.07950062500701682,0.07963070667633806,0.07974035622982614,0.07983052419407154,0.07990042062402951,0.07994695782035821,0.07997058625968821,0.07997768959110964,0.07997536442678388,0.07995972883944066,0.07994413588692728,0.07992654168074992,0.07991374540934534,0.07991167373266232,0.07992361399881781,0.0799499566560926,0.07998993865151761,0.08003743518634016,0.08009000113962633,0.08014282330112694,0.08019554960635825,0.08024731897559281,0.08029492068747258,0.08033635810414987,0.08036874500499562,0.080390903268892,0.08040098196031004,0.08040480854831365,0.08040765275876365,0.080407087691969,0.08040310493479108,0.08039567123427896,0.08038794144192904,0.08038110690950598,0.0803751378723746,0.08036881396733309,0.08036351339466452,0.08035766000407615,0.08034861188964704,0.08033720780025433,0.0803241519924561,0.0803100087496319,0.08029570161547031,0.08028199694359328,0.08026807412292636,0.08025481905351353,0.08023846023176393,0.0802253866973697,0.08021584543158655,0.0802091948895681,0.08021815157754655,0.0802391206825974,0.08027401330011245,0.08031450050487186,0.08036541307538923,0.0804207119969185,0.08047455850103818,0.08052203095773977,0.08055741663725227,0.08060329209217013,0.08065280759012763,0.08074144655147777,0.08085985006151326,0.080998620545465,0.08114257825764505,0.08129489562533615,0.08144576467346538,0.0816016490600539,0.08173895033319153,0.08185302424201119,0.08195222451892975,0.08204065930955791,0.08212074435449535,0.08219696147991518,0.08227314310795589,0.0823540130555009,0.08244060154198651,0.08253226299714281,0.08262470212648668,0.08271572580681076,0.08281206826153913,0.0829107493017549,0.0830208187598046,0.08314427083958054,0.0832793462777936,0.08342042144881856,0.08356303935867194,0.08371907449199018,0.0838829889114979,0.08404344209862613,0.0841988620286239,0.08429695442772274,0.08421959899463252,0.08414942210615367,0.08408844376613278,0.08405586866995898,0.08404425892475681,0.0840553442698332,0.08405763793042428,0.08404824759181463,0.08402841676424411,0.08399671405973042,0.08395274078565068,0.08389711419473095,0.08382183268447763,0.08372765793928047,0.08363368763588422,0.08354190279303733,0.08345723216101747,0.08338028305014224,0.08331182871630821,0.0832541072498402,0.08320699224196251,0.08316568078260256,0.0831024901532402,0.0830284292461991,0.08294180702625947,0.08284710852861003,0.08274869559536996,0.08266320901276633,0.08259265383895903,0.08253911754628304,0.08250039717557343,0.0824736159820616,0.08246428242502601,0.08246740431933827,0.08247813909253826,0.08249048892049692,0.08250605150821311,0.08252601104393001,0.08254206441479678,0.08255171533661887,0.08255133203656233,0.08253903221454248,0.08250552325256436,0.08245729694466918,0.08240098824671396,0.0823401565753003,0.08226266420888871,0.08219497747710189,0.08213944386450892,0.08209709729365038,0.08206870864815365,0.08205149056162503,0.08204886083099515,0.08205443985883068,0.08203998005281636,0.08200246985455148,0.08199856270761705,0.08202556851285486,0.08206775152580142,0.08211927333734254,0.08217448920027662,0.08223526353055512,0.08229263924988703,0.0823517275166595,0.08241071642173846,0.0823477652131584,0.08205981309850419,0.081771507269498,0.08157494723837666,0.0814535126469933,0.08138824386681931,0.08136025285482444,0.08134752236244727,0.08132917224964371,0.08128558775941724,0.08089033807579393,0.0804731756980924,0.08005323586482996,0.0796346274294984,0.07922210555948511,0.0788172466041202,0.07842020073260315,0.07803632920002228,0.0776710204104625,0.07732691536387984,0.07700888188316041],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.45],\"title\":{\"text\":\"Epoch\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.625,1.0],\"title\":{\"text\":\"Estimate\"}},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.55,1.0],\"title\":{\"text\":\"Epoch\"}},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.625,1.0],\"title\":{\"text\":\"Variance\"}},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.0,0.45],\"title\":{\"text\":\"Epoch\"}},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,0.375],\"title\":{\"text\":\"MSE Loss\"}},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.55,1.0],\"title\":{\"text\":\"Epoch\"}},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.0,0.375],\"title\":{\"text\":\"MSE\"}},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Estimate over Epochs\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Variance over Epochs\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Shaping Train MSE Loss over Epochs\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Total MSE over Epochs\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Metrics over Epochs\"},\"showlegend\":true},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('b94f1868-43d0-45f2-9742-2e4081bee23a');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_experiment.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQtxOCXyWSj2",
        "outputId": "1299c052-c37c-4f0d-80e0-2d98a07a43c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_load.get_heatmap()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "-_M47PfUVtQ2",
        "outputId": "87c98e68-940a-4833-dcd5-56889fbfd318"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"2f4c1861-43f1-4a33-9f63-9001d46c8d03\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"2f4c1861-43f1-4a33-9f63-9001d46c8d03\")) {                    Plotly.newPlot(                        \"2f4c1861-43f1-4a33-9f63-9001d46c8d03\",                        [{\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"z\":[[0.043932318687438965,0.04034421592950821,0.0371919684112072,0.034453511238098145,0.03171506151556969,0.02897660806775093,0.026238152757287025,0.02349969930946827,0.020761245861649513,0.018022790551185608],[0.03963206335902214,0.03901221230626106,0.03491516038775444,0.03209323063492775,0.029354779049754143,0.026616321876645088,0.023877868428826332,0.021139413118362427,0.01840095967054367,0.015662509948015213],[0.03790057450532913,0.03823233023285866,0.03486841544508934,0.029873277992010117,0.0269944928586483,0.024256039410829544,0.02151758223772049,0.018779126927256584,0.01604067161679268,0.013302221894264221],[0.03798581659793854,0.036414287984371185,0.03571975976228714,0.030724620446562767,0.025729481130838394,0.02189575508236885,0.019157299771904945,0.01641884632408619,0.013680387288331985,0.010941941291093826],[0.03961024433374405,0.03459453955292702,0.034008365124464035,0.03157596290111542,0.026580825448036194,0.02158568799495697,0.016884498298168182,0.014058560132980347,0.01132010668516159,0.008581653237342834],[0.03824303299188614,0.032772619277238846,0.032221462577581406,0.030423248186707497,0.027432169765233994,0.02243703231215477,0.01744687184691429,0.012762818485498428,0.008959822356700897,0.006221365183591843],[0.0322859026491642,0.02585388906300068,0.03043455444276333,0.02863634191453457,0.026838131248950958,0.02328837290406227,0.018293235450983047,0.013325188308954239,0.008641142398118973,0.003957081586122513],[0.030648421496152878,0.017666008323431015,0.022390063852071762,0.02684943750500679,0.02505122683942318,0.02325301617383957,0.019144579768180847,0.014149438589811325,0.009203512221574783,0.004519455134868622],[0.029010899364948273,0.010357324033975601,0.010504115372896194,0.018119532614946365,0.0232643261551857,0.02146610990166664,0.019667891785502434,0.015000786632299423,0.0100056491792202,0.005081828683614731],[0.027373386546969414,0.0030486322939395905,-0.0013818256556987762,0.006170656532049179,0.01387636736035347,0.019679207354784012,0.017880985513329506,0.015852127224206924,0.010856986045837402,0.005861852318048477]],\"type\":\"heatmap\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"Values\"},\"ticks\":\"outside\",\"tickvals\":[-0.0013818256556987762,0.043932318687438965],\"ticktext\":[-0.0013818256556987762,0.043932318687438965]}},\"xaxis\":{\"tickvals\":[0,1,2,3,4,5,6,7,8,9],\"ticktext\":[0,1,2,3,4,5,6,7,8,9],\"title\":{\"text\":\"X\"}},\"yaxis\":{\"tickvals\":[9,8,7,6,5,4,3,2,1,0],\"ticktext\":[9,8,7,6,5,4,3,2,1,0],\"title\":{\"text\":\"Y\"},\"autorange\":\"reversed\"},\"title\":{\"text\":\"Heatmap\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('2f4c1861-43f1-4a33-9f63-9001d46c8d03');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regional shaping around bottleneck v2"
      ],
      "metadata": {
        "id": "Q0OWDE3G7aJs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Differ folder path with names incorporating policy parameters num top actions and epsilon of $\\pi_e$ and $\\pi_b$"
      ],
      "metadata": {
        "id": "iMEaLT5z7yMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    # Parameters related to policy generation\n",
        "    \"pi_b_top_k\": 1,\n",
        "    \"pi_b_epsilon\": 0.6,\n",
        "    \"pi_e_top_k\": 1,\n",
        "    \"pi_e_epsilon\": 0.1,\n",
        "    \"q_table\": q_table,\n",
        "    \"gamma\": 0.99,\n",
        "    \"num_trajectories\": 800,\n",
        "    \"num_bootstraps\": 10000,\n",
        "    \"percent_to_estimate_phi\": 0.3,\n",
        "\n",
        "    # Parameters related to shaping\n",
        "    \"shaping_feature\": bottleneck_four_regions_k_p9_a_1,\n",
        "    \"shaping_coefficient\": 0.1,\n",
        "\n",
        "    # Parameters related to neural network architecture and training\n",
        "    \"hidden_dims\": [8,8],\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"dropout_prob\": 0.2,\n",
        "    \"l1_reg\": 0.00001,\n",
        "    \"l2_reg\": 0.00001,\n",
        "    \"scope_weight\": 1.0,\n",
        "    \"mse_weight\": 1.0,\n",
        "    \"num_epochs\": 500,\n",
        "\n",
        "    # Parameters related to environment\n",
        "    \"max_length\": 50,\n",
        "    \"death_drag\": 0.0,\n",
        "    # Other general parameters\n",
        "    \"dtype\": torch.float32,\n",
        "    \"experiment_type\": \"test\",\n",
        "    \"folder_path\": \"/content/drive/MyDrive/Lifegate_experiments_v2\"\n",
        "    # \"folder_path\": \"/content\"\n",
        "}"
      ],
      "metadata": {
        "id": "RV9wHvCq7eUO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_trajectories = [200, 400, 600, 800, 1000]\n",
        "\n",
        "for i in list_trajectories:\n",
        "  params[\"num_trajectories\"] = i\n",
        "  test_experiment = SCOPE_experiment(**params)\n",
        "  print(f\"{i} trajectories:\")\n",
        "\n",
        "  # test_load = existing_experiments(test_experiment)\n",
        "  # test_load.plot_metrics()\n",
        "  # test_load.get_heatmap()\n",
        "  # test_load.get_state_visitation_heatmap()\n",
        "\n",
        "  test_experiment.run_experiment()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAaBtnne7ttI",
        "outputId": "801a68dc-5aea-4cea-b02f-d62b59390ff5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200 trajectories:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/Shaping/SCOPE_straight.py:115: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  padded_timestep_tensors = torch.tensor(padded_timesteps, dtype = self.dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 351\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0151, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.12636297941207886\n",
            "SCOPE mean: 0.07641627639532089, SCOPE var: 0.000325129134580493\n",
            "Total Loss: 0.1415061354637146\n",
            "----------------------------------------\n",
            "Epoch 352\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0150, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.12595312297344208\n",
            "SCOPE mean: 0.07636675238609314, SCOPE var: 0.00032408753759227693\n",
            "Total Loss: 0.1409413367509842\n",
            "----------------------------------------\n",
            "Epoch 353\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0148, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.12554620206356049\n",
            "SCOPE mean: 0.07631754130125046, SCOPE var: 0.00032306142384186387\n",
            "Total Loss: 0.14038123190402985\n",
            "----------------------------------------\n",
            "Epoch 354\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0147, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1251421570777893\n",
            "SCOPE mean: 0.07626864314079285, SCOPE var: 0.00032205067691393197\n",
            "Total Loss: 0.1398257315158844\n",
            "----------------------------------------\n",
            "Epoch 355\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0145, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.12474136054515839\n",
            "SCOPE mean: 0.07621999084949493, SCOPE var: 0.0003210549766663462\n",
            "Total Loss: 0.13927523791790009\n",
            "----------------------------------------\n",
            "Epoch 356\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0144, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.12434354424476624\n",
            "SCOPE mean: 0.0761716440320015, SCOPE var: 0.0003200744395144284\n",
            "Total Loss: 0.13872943818569183\n",
            "----------------------------------------\n",
            "Epoch 357\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0142, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.12394876033067703\n",
            "SCOPE mean: 0.07612347602844238, SCOPE var: 0.0003191082796547562\n",
            "Total Loss: 0.1381884217262268\n",
            "----------------------------------------\n",
            "Epoch 358\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0141, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.12355662882328033\n",
            "SCOPE mean: 0.076075479388237, SCOPE var: 0.00031815646798349917\n",
            "Total Loss: 0.1376517415046692\n",
            "----------------------------------------\n",
            "Epoch 359\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0140, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.12316737323999405\n",
            "SCOPE mean: 0.07602772116661072, SCOPE var: 0.00031721897539682686\n",
            "Total Loss: 0.1371196061372757\n",
            "----------------------------------------\n",
            "Epoch 360\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0138, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.12278103828430176\n",
            "SCOPE mean: 0.07598014175891876, SCOPE var: 0.0003162957145832479\n",
            "Total Loss: 0.13659203052520752\n",
            "----------------------------------------\n",
            "Epoch 361\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0137, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1223984807729721\n",
            "SCOPE mean: 0.07593272626399994, SCOPE var: 0.00031538621988147497\n",
            "Total Loss: 0.13606983423233032\n",
            "----------------------------------------\n",
            "Epoch 362\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0135, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.12201930582523346\n",
            "SCOPE mean: 0.07588540017604828, SCOPE var: 0.00031449110247194767\n",
            "Total Loss: 0.13555265963077545\n",
            "----------------------------------------\n",
            "Epoch 363\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0134, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.12164308875799179\n",
            "SCOPE mean: 0.0758398249745369, SCOPE var: 0.00031361161381937563\n",
            "Total Loss: 0.1350400745868683\n",
            "----------------------------------------\n",
            "Epoch 364\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0133, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.121269591152668\n",
            "SCOPE mean: 0.07579450309276581, SCOPE var: 0.00031274594948627055\n",
            "Total Loss: 0.13453194499015808\n",
            "----------------------------------------\n",
            "Epoch 365\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0131, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.12089409679174423\n",
            "SCOPE mean: 0.07574924826622009, SCOPE var: 0.0003118941094726324\n",
            "Total Loss: 0.13402332365512848\n",
            "----------------------------------------\n",
            "Epoch 366\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0130, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.12052073329687119\n",
            "SCOPE mean: 0.07570444047451019, SCOPE var: 0.0003110537363681942\n",
            "Total Loss: 0.13351815938949585\n",
            "----------------------------------------\n",
            "Epoch 367\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0129, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.12015029788017273\n",
            "SCOPE mean: 0.07566002011299133, SCOPE var: 0.00031022500479593873\n",
            "Total Loss: 0.13301733136177063\n",
            "----------------------------------------\n",
            "Epoch 368\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0127, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11978267878293991\n",
            "SCOPE mean: 0.07561598718166351, SCOPE var: 0.00030940817669034004\n",
            "Total Loss: 0.13252070546150208\n",
            "----------------------------------------\n",
            "Epoch 369\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0126, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11941781640052795\n",
            "SCOPE mean: 0.07557225972414017, SCOPE var: 0.0003086030192207545\n",
            "Total Loss: 0.1320282369852066\n",
            "----------------------------------------\n",
            "Epoch 370\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0125, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11905559152364731\n",
            "SCOPE mean: 0.0755288302898407, SCOPE var: 0.0003078094741795212\n",
            "Total Loss: 0.13153979182243347\n",
            "----------------------------------------\n",
            "Epoch 371\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0124, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1186959445476532\n",
            "SCOPE mean: 0.0754857212305069, SCOPE var: 0.0003070275706704706\n",
            "Total Loss: 0.1310552954673767\n",
            "----------------------------------------\n",
            "Epoch 372\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0122, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11833877861499786\n",
            "SCOPE mean: 0.07544286549091339, SCOPE var: 0.00030625725048594177\n",
            "Total Loss: 0.13057464361190796\n",
            "----------------------------------------\n",
            "Epoch 373\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0121, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11798429489135742\n",
            "SCOPE mean: 0.07540033012628555, SCOPE var: 0.00030549828079529107\n",
            "Total Loss: 0.13009802997112274\n",
            "----------------------------------------\n",
            "Epoch 374\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0120, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11763239651918411\n",
            "SCOPE mean: 0.07535804808139801, SCOPE var: 0.0003047506033908576\n",
            "Total Loss: 0.1296253353357315\n",
            "----------------------------------------\n",
            "Epoch 375\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0119, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.117281474173069\n",
            "SCOPE mean: 0.07532992213964462, SCOPE var: 0.00030405091820284724\n",
            "Total Loss: 0.129154771566391\n",
            "----------------------------------------\n",
            "Epoch 376\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0118, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11693229526281357\n",
            "SCOPE mean: 0.07533050328493118, SCOPE var: 0.0003034351975657046\n",
            "Total Loss: 0.1286870539188385\n",
            "----------------------------------------\n",
            "Epoch 377\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0116, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11658476293087006\n",
            "SCOPE mean: 0.07533138990402222, SCOPE var: 0.00030282800435088575\n",
            "Total Loss: 0.12822221219539642\n",
            "----------------------------------------\n",
            "Epoch 378\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0115, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11623942106962204\n",
            "SCOPE mean: 0.07518227398395538, SCOPE var: 0.0003022050077561289\n",
            "Total Loss: 0.12776070833206177\n",
            "----------------------------------------\n",
            "Epoch 379\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0114, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11589638143777847\n",
            "SCOPE mean: 0.07498085498809814, SCOPE var: 0.00030158221488818526\n",
            "Total Loss: 0.12730270624160767\n",
            "----------------------------------------\n",
            "Epoch 380\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0113, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11555799096822739\n",
            "SCOPE mean: 0.07478058338165283, SCOPE var: 0.0003009680367540568\n",
            "Total Loss: 0.12683387100696564\n",
            "----------------------------------------\n",
            "Epoch 381\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0111, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11522164940834045\n",
            "SCOPE mean: 0.07457990944385529, SCOPE var: 0.00030035589588806033\n",
            "Total Loss: 0.12636175751686096\n",
            "----------------------------------------\n",
            "Epoch 382\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0110, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11488673835992813\n",
            "SCOPE mean: 0.07437900453805923, SCOPE var: 0.00029974678182043135\n",
            "Total Loss: 0.12589150667190552\n",
            "----------------------------------------\n",
            "Epoch 383\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0109, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11455299705266953\n",
            "SCOPE mean: 0.0741780549287796, SCOPE var: 0.0002991414803545922\n",
            "Total Loss: 0.12542301416397095\n",
            "----------------------------------------\n",
            "Epoch 384\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0107, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11422022432088852\n",
            "SCOPE mean: 0.07397717237472534, SCOPE var: 0.0002985405153594911\n",
            "Total Loss: 0.1249561607837677\n",
            "----------------------------------------\n",
            "Epoch 385\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0106, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11388853192329407\n",
            "SCOPE mean: 0.07377646118402481, SCOPE var: 0.0002979444107040763\n",
            "Total Loss: 0.1244911327958107\n",
            "----------------------------------------\n",
            "Epoch 386\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0105, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11355812847614288\n",
            "SCOPE mean: 0.07357603311538696, SCOPE var: 0.0002973536029458046\n",
            "Total Loss: 0.12402825057506561\n",
            "----------------------------------------\n",
            "Epoch 387\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0103, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11322962492704391\n",
            "SCOPE mean: 0.07337598502635956, SCOPE var: 0.00029676867416128516\n",
            "Total Loss: 0.12356822937726974\n",
            "----------------------------------------\n",
            "Epoch 388\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0102, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11290324479341507\n",
            "SCOPE mean: 0.07317648828029633, SCOPE var: 0.00029619011911563575\n",
            "Total Loss: 0.12311137467622757\n",
            "----------------------------------------\n",
            "Epoch 389\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0101, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11257883906364441\n",
            "SCOPE mean: 0.07297760248184204, SCOPE var: 0.00029561834526248276\n",
            "Total Loss: 0.12265761196613312\n",
            "----------------------------------------\n",
            "Epoch 390\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0100, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11225666850805283\n",
            "SCOPE mean: 0.07277942448854446, SCOPE var: 0.0002950536145363003\n",
            "Total Loss: 0.12220725417137146\n",
            "----------------------------------------\n",
            "Epoch 391\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0098, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11193645745515823\n",
            "SCOPE mean: 0.07258199155330658, SCOPE var: 0.0002944951702374965\n",
            "Total Loss: 0.12176012247800827\n",
            "----------------------------------------\n",
            "Epoch 392\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0097, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11161863803863525\n",
            "SCOPE mean: 0.07238543033599854, SCOPE var: 0.00029394414741545916\n",
            "Total Loss: 0.12131672352552414\n",
            "----------------------------------------\n",
            "Epoch 393\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0096, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11130262911319733\n",
            "SCOPE mean: 0.0721898004412651, SCOPE var: 0.00029340089531615376\n",
            "Total Loss: 0.1208764985203743\n",
            "----------------------------------------\n",
            "Epoch 394\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0095, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1109885647892952\n",
            "SCOPE mean: 0.07199511677026749, SCOPE var: 0.00029286553035490215\n",
            "Total Loss: 0.12043961882591248\n",
            "----------------------------------------\n",
            "Epoch 395\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0093, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11067614704370499\n",
            "SCOPE mean: 0.07180144637823105, SCOPE var: 0.0002923381980508566\n",
            "Total Loss: 0.12000580132007599\n",
            "----------------------------------------\n",
            "Epoch 396\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0092, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1103651225566864\n",
            "SCOPE mean: 0.07160881906747818, SCOPE var: 0.0002918188984040171\n",
            "Total Loss: 0.11957481503486633\n",
            "----------------------------------------\n",
            "Epoch 397\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0091, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11005616188049316\n",
            "SCOPE mean: 0.07141722738742828, SCOPE var: 0.0002913075149990618\n",
            "Total Loss: 0.11914737522602081\n",
            "----------------------------------------\n",
            "Epoch 398\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0090, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10974880307912827\n",
            "SCOPE mean: 0.07122670859098434, SCOPE var: 0.00029080419335514307\n",
            "Total Loss: 0.11872301250696182\n",
            "----------------------------------------\n",
            "Epoch 399\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0089, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10944287478923798\n",
            "SCOPE mean: 0.07103734463453293, SCOPE var: 0.0002903090789914131\n",
            "Total Loss: 0.11830151081085205\n",
            "----------------------------------------\n",
            "Epoch 400\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0087, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10913879424333572\n",
            "SCOPE mean: 0.07084916532039642, SCOPE var: 0.0002898221428040415\n",
            "Total Loss: 0.11788329482078552\n",
            "----------------------------------------\n",
            "Epoch 401\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0086, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10883653163909912\n",
            "SCOPE mean: 0.07066211849451065, SCOPE var: 0.0002893431228585541\n",
            "Total Loss: 0.11746834218502045\n",
            "----------------------------------------\n",
            "Epoch 402\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0085, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10853592306375504\n",
            "SCOPE mean: 0.0704762265086174, SCOPE var: 0.00028887216467410326\n",
            "Total Loss: 0.11705644428730011\n",
            "----------------------------------------\n",
            "Epoch 403\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0084, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1082366332411766\n",
            "SCOPE mean: 0.07029330730438232, SCOPE var: 0.00028841421590186656\n",
            "Total Loss: 0.11664728820323944\n",
            "----------------------------------------\n",
            "Epoch 404\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0083, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10793877393007278\n",
            "SCOPE mean: 0.07011205703020096, SCOPE var: 0.0002879654348362237\n",
            "Total Loss: 0.1162409856915474\n",
            "----------------------------------------\n",
            "Epoch 405\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0082, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10764294117689133\n",
            "SCOPE mean: 0.06996510177850723, SCOPE var: 0.0002876577200368047\n",
            "Total Loss: 0.11583814024925232\n",
            "----------------------------------------\n",
            "Epoch 406\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0081, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10734900087118149\n",
            "SCOPE mean: 0.06984410434961319, SCOPE var: 0.00028745451709255576\n",
            "Total Loss: 0.11543861776590347\n",
            "----------------------------------------\n",
            "Epoch 407\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0080, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10705680400133133\n",
            "SCOPE mean: 0.069723941385746, SCOPE var: 0.00028725358424708247\n",
            "Total Loss: 0.11504224687814713\n",
            "----------------------------------------\n",
            "Epoch 408\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0079, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10676650702953339\n",
            "SCOPE mean: 0.0696045309305191, SCOPE var: 0.0002870549215003848\n",
            "Total Loss: 0.11464917659759521\n",
            "----------------------------------------\n",
            "Epoch 409\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0078, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10647789388895035\n",
            "SCOPE mean: 0.06948589533567429, SCOPE var: 0.0002868584997486323\n",
            "Total Loss: 0.11425918340682983\n",
            "----------------------------------------\n",
            "Epoch 410\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0077, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10619033873081207\n",
            "SCOPE mean: 0.06936798989772797, SCOPE var: 0.0002866642316803336\n",
            "Total Loss: 0.11387157440185547\n",
            "----------------------------------------\n",
            "Epoch 411\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0076, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10590507835149765\n",
            "SCOPE mean: 0.06925079226493835, SCOPE var: 0.0002864721172954887\n",
            "Total Loss: 0.11348757147789001\n",
            "----------------------------------------\n",
            "Epoch 412\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0075, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10562167316675186\n",
            "SCOPE mean: 0.06913434714078903, SCOPE var: 0.00028628206928260624\n",
            "Total Loss: 0.11310675740242004\n",
            "----------------------------------------\n",
            "Epoch 413\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0074, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10533996671438217\n",
            "SCOPE mean: 0.06901852786540985, SCOPE var: 0.0002860939421225339\n",
            "Total Loss: 0.11272898316383362\n",
            "----------------------------------------\n",
            "Epoch 414\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0073, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10505998879671097\n",
            "SCOPE mean: 0.06890345364809036, SCOPE var: 0.00028590738656930625\n",
            "Total Loss: 0.11235423386096954\n",
            "----------------------------------------\n",
            "Epoch 415\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0072, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10478170216083527\n",
            "SCOPE mean: 0.06878906488418579, SCOPE var: 0.0002857226354535669\n",
            "Total Loss: 0.11198247969150543\n",
            "----------------------------------------\n",
            "Epoch 416\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0071, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10450444370508194\n",
            "SCOPE mean: 0.06867533922195435, SCOPE var: 0.0002855398051906377\n",
            "Total Loss: 0.11161299794912338\n",
            "----------------------------------------\n",
            "Epoch 417\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0070, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10422823578119278\n",
            "SCOPE mean: 0.06856220215559006, SCOPE var: 0.0002853587211575359\n",
            "Total Loss: 0.11124575138092041\n",
            "----------------------------------------\n",
            "Epoch 418\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0069, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1039537563920021\n",
            "SCOPE mean: 0.06844969838857651, SCOPE var: 0.00028517955797724426\n",
            "Total Loss: 0.11088141053915024\n",
            "----------------------------------------\n",
            "Epoch 419\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0069, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10368185490369797\n",
            "SCOPE mean: 0.0683378204703331, SCOPE var: 0.00028500217013061047\n",
            "Total Loss: 0.11054141819477081\n",
            "----------------------------------------\n",
            "Epoch 420\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0068, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10341440886259079\n",
            "SCOPE mean: 0.0682276114821434, SCOPE var: 0.00028482713969424367\n",
            "Total Loss: 0.11022808402776718\n",
            "----------------------------------------\n",
            "Epoch 421\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0068, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10315043479204178\n",
            "SCOPE mean: 0.06811899691820145, SCOPE var: 0.00028465426294133067\n",
            "Total Loss: 0.10991883277893066\n",
            "----------------------------------------\n",
            "Epoch 422\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0067, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10288947075605392\n",
            "SCOPE mean: 0.06801162660121918, SCOPE var: 0.00028448217199184\n",
            "Total Loss: 0.10961315780878067\n",
            "----------------------------------------\n",
            "Epoch 423\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0067, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10263148695230484\n",
            "SCOPE mean: 0.06790561974048615, SCOPE var: 0.0002843118563760072\n",
            "Total Loss: 0.10931099206209183\n",
            "----------------------------------------\n",
            "Epoch 424\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0066, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10237577557563782\n",
            "SCOPE mean: 0.06780090928077698, SCOPE var: 0.00028414366533979774\n",
            "Total Loss: 0.10901161283254623\n",
            "----------------------------------------\n",
            "Epoch 425\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0066, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10212071239948273\n",
            "SCOPE mean: 0.0676974430680275, SCOPE var: 0.0002839774824678898\n",
            "Total Loss: 0.10871335864067078\n",
            "----------------------------------------\n",
            "Epoch 426\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0065, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10186775773763657\n",
            "SCOPE mean: 0.06759516894817352, SCOPE var: 0.000283813220448792\n",
            "Total Loss: 0.10841767489910126\n",
            "----------------------------------------\n",
            "Epoch 427\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0065, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10161688923835754\n",
            "SCOPE mean: 0.06749400496482849, SCOPE var: 0.00028365085017867386\n",
            "Total Loss: 0.1081245169043541\n",
            "----------------------------------------\n",
            "Epoch 428\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0065, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10136832296848297\n",
            "SCOPE mean: 0.06739392876625061, SCOPE var: 0.00028349028434604406\n",
            "Total Loss: 0.10783407837152481\n",
            "----------------------------------------\n",
            "Epoch 429\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0064, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.101121686398983\n",
            "SCOPE mean: 0.06729485839605331, SCOPE var: 0.00028333161026239395\n",
            "Total Loss: 0.10754597187042236\n",
            "----------------------------------------\n",
            "Epoch 430\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0064, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10087697207927704\n",
            "SCOPE mean: 0.06719668954610825, SCOPE var: 0.0002831745077855885\n",
            "Total Loss: 0.10726016014814377\n",
            "----------------------------------------\n",
            "Epoch 431\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0063, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1006341204047203\n",
            "SCOPE mean: 0.0670994371175766, SCOPE var: 0.00028301915153861046\n",
            "Total Loss: 0.10697655379772186\n",
            "----------------------------------------\n",
            "Epoch 432\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0063, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10039295256137848\n",
            "SCOPE mean: 0.06700306385755539, SCOPE var: 0.000282865425106138\n",
            "Total Loss: 0.10669499635696411\n",
            "----------------------------------------\n",
            "Epoch 433\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0063, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10015349090099335\n",
            "SCOPE mean: 0.06690753996372223, SCOPE var: 0.00028271329938434064\n",
            "Total Loss: 0.10641548037528992\n",
            "----------------------------------------\n",
            "Epoch 434\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0062, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.099915511906147\n",
            "SCOPE mean: 0.06681279093027115, SCOPE var: 0.00028256289078854024\n",
            "Total Loss: 0.10613779723644257\n",
            "----------------------------------------\n",
            "Epoch 435\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0062, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.09967752546072006\n",
            "SCOPE mean: 0.06671836227178574, SCOPE var: 0.0002824151888489723\n",
            "Total Loss: 0.10586059093475342\n",
            "----------------------------------------\n",
            "Epoch 436\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0061, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.09944119304418564\n",
            "SCOPE mean: 0.06662479043006897, SCOPE var: 0.00028226911672391\n",
            "Total Loss: 0.10558533668518066\n",
            "----------------------------------------\n",
            "Epoch 437\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0061, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.09920629113912582\n",
            "SCOPE mean: 0.06653208285570145, SCOPE var: 0.0002821246744133532\n",
            "Total Loss: 0.10531178116798401\n",
            "----------------------------------------\n",
            "Epoch 438\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0061, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.09897276014089584\n",
            "SCOPE mean: 0.0664401575922966, SCOPE var: 0.00028198183281347156\n",
            "Total Loss: 0.10503987222909927\n",
            "----------------------------------------\n",
            "Epoch 439\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0060, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.09874061495065689\n",
            "SCOPE mean: 0.06634901463985443, SCOPE var: 0.0002818406210280955\n",
            "Total Loss: 0.10476962476968765\n",
            "----------------------------------------\n",
            "Epoch 440\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0060, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.09850964695215225\n",
            "SCOPE mean: 0.06625859439373016, SCOPE var: 0.0002817008935380727\n",
            "Total Loss: 0.10450077801942825\n",
            "----------------------------------------\n",
            "Epoch 441\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0060, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.09827995300292969\n",
            "SCOPE mean: 0.0661688968539238, SCOPE var: 0.0002815626794472337\n",
            "Total Loss: 0.10423346608877182\n",
            "----------------------------------------\n",
            "Epoch 442\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0059, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0980515331029892\n",
            "SCOPE mean: 0.06607986986637115, SCOPE var: 0.00028142589144408703\n",
            "Total Loss: 0.10396769642829895\n",
            "----------------------------------------\n",
            "Epoch 443\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0059, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.09782423824071884\n",
            "SCOPE mean: 0.06599154323339462, SCOPE var: 0.00028129061684012413\n",
            "Total Loss: 0.10370329767465591\n",
            "----------------------------------------\n",
            "Epoch 444\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0058, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.09759783744812012\n",
            "SCOPE mean: 0.06590384244918823, SCOPE var: 0.00028115679742768407\n",
            "Total Loss: 0.10344003885984421\n",
            "----------------------------------------\n",
            "Epoch 445\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0058, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.09737242013216019\n",
            "SCOPE mean: 0.06581676006317139, SCOPE var: 0.00028102428768761456\n",
            "Total Loss: 0.10317797213792801\n",
            "----------------------------------------\n",
            "Epoch 446\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0058, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.09714816510677338\n",
            "SCOPE mean: 0.06573032587766647, SCOPE var: 0.0002808932331390679\n",
            "Total Loss: 0.10291729122400284\n",
            "----------------------------------------\n",
            "Epoch 447\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0057, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.096924789249897\n",
            "SCOPE mean: 0.06564447283744812, SCOPE var: 0.00028076348826289177\n",
            "Total Loss: 0.10265770554542542\n",
            "----------------------------------------\n",
            "Epoch 448\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0057, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.09670209884643555\n",
            "SCOPE mean: 0.06555917859077454, SCOPE var: 0.00028063502395525575\n",
            "Total Loss: 0.10239902883768082\n",
            "----------------------------------------\n",
            "Epoch 449\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0057, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.09648045152425766\n",
            "SCOPE mean: 0.06547447293996811, SCOPE var: 0.00028050789842382073\n",
            "Total Loss: 0.10214163362979889\n",
            "----------------------------------------\n",
            "Epoch 450\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0056, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.09625967592000961\n",
            "SCOPE mean: 0.06539031863212585, SCOPE var: 0.0002803820825647563\n",
            "Total Loss: 0.1018853560090065\n",
            "----------------------------------------\n",
            "Epoch 451\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0056, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.09603996574878693\n",
            "SCOPE mean: 0.06530672311782837, SCOPE var: 0.00028025757637806237\n",
            "Total Loss: 0.10163037478923798\n",
            "----------------------------------------\n",
            "Epoch 452\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0056, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.09582124650478363\n",
            "SCOPE mean: 0.06522363424301147, SCOPE var: 0.0002801343216560781\n",
            "Total Loss: 0.10137661546468735\n",
            "----------------------------------------\n",
            "Epoch 453\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0055, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0956035777926445\n",
            "SCOPE mean: 0.06514106690883636, SCOPE var: 0.000280012289294973\n",
            "Total Loss: 0.10112413763999939\n",
            "----------------------------------------\n",
            "Epoch 454\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0055, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.09538691490888596\n",
            "SCOPE mean: 0.06505899876356125, SCOPE var: 0.00027989150839857757\n",
            "Total Loss: 0.10087289661169052\n",
            "----------------------------------------\n",
            "Epoch 455\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0055, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.095171257853508\n",
            "SCOPE mean: 0.06497740745544434, SCOPE var: 0.00027977186255156994\n",
            "Total Loss: 0.10062288492918015\n",
            "----------------------------------------\n",
            "Epoch 456\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0054, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.09495655447244644\n",
            "SCOPE mean: 0.06489631533622742, SCOPE var: 0.00027965346816927195\n",
            "Total Loss: 0.10037405043840408\n",
            "----------------------------------------\n",
            "Epoch 457\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0054, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.09474276006221771\n",
            "SCOPE mean: 0.0648156926035881, SCOPE var: 0.0002795361797325313\n",
            "Total Loss: 0.10012635588645935\n",
            "----------------------------------------\n",
            "Epoch 458\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0053, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.09452994912862778\n",
            "SCOPE mean: 0.0647355318069458, SCOPE var: 0.0002794201427605003\n",
            "Total Loss: 0.09987986087799072\n",
            "----------------------------------------\n",
            "Epoch 459\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0053, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.09431808441877365\n",
            "SCOPE mean: 0.06465582549571991, SCOPE var: 0.0002793050662148744\n",
            "Total Loss: 0.09963452816009521\n",
            "----------------------------------------\n",
            "Epoch 460\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0053, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.09410721808671951\n",
            "SCOPE mean: 0.06457655131816864, SCOPE var: 0.0002791911829262972\n",
            "Total Loss: 0.099390409886837\n",
            "----------------------------------------\n",
            "Epoch 461\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0053, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.09389721602201462\n",
            "SCOPE mean: 0.06449773162603378, SCOPE var: 0.00027907840558327734\n",
            "Total Loss: 0.09914737194776535\n",
            "----------------------------------------\n",
            "Epoch 462\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0052, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0936882495880127\n",
            "SCOPE mean: 0.06441932171583176, SCOPE var: 0.0002789666468743235\n",
            "Total Loss: 0.09890559315681458\n",
            "----------------------------------------\n",
            "Epoch 463\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0052, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.09348046034574509\n",
            "SCOPE mean: 0.06434136629104614, SCOPE var: 0.0002788560523185879\n",
            "Total Loss: 0.09866521507501602\n",
            "----------------------------------------\n",
            "Epoch 464\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0052, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0932736024260521\n",
            "SCOPE mean: 0.06426382064819336, SCOPE var: 0.0002787464763969183\n",
            "Total Loss: 0.0984259843826294\n",
            "----------------------------------------\n",
            "Epoch 465\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0051, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.09306767582893372\n",
            "SCOPE mean: 0.06418668478727341, SCOPE var: 0.0002786379773169756\n",
            "Total Loss: 0.0981879010796547\n",
            "----------------------------------------\n",
            "Epoch 466\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0051, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.09286268800497055\n",
            "SCOPE mean: 0.06410999596118927, SCOPE var: 0.00027853052597492933\n",
            "Total Loss: 0.09795095026493073\n",
            "----------------------------------------\n",
            "Epoch 467\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0051, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0926586240530014\n",
            "SCOPE mean: 0.06403370201587677, SCOPE var: 0.0002784240059554577\n",
            "Total Loss: 0.09771513938903809\n",
            "----------------------------------------\n",
            "Epoch 468\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0050, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.09245549142360687\n",
            "SCOPE mean: 0.06395784020423889, SCOPE var: 0.00027831856277771294\n",
            "Total Loss: 0.09748045355081558\n",
            "----------------------------------------\n",
            "Epoch 469\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0050, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.09225325286388397\n",
            "SCOPE mean: 0.06388236582279205, SCOPE var: 0.00027821408002637327\n",
            "Total Loss: 0.09724687039852142\n",
            "----------------------------------------\n",
            "Epoch 470\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0050, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.09205195307731628\n",
            "SCOPE mean: 0.06380727887153625, SCOPE var: 0.0002781106159090996\n",
            "Total Loss: 0.0970144271850586\n",
            "----------------------------------------\n",
            "Epoch 471\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0049, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.09185154736042023\n",
            "SCOPE mean: 0.0637325718998909, SCOPE var: 0.00027800805401057005\n",
            "Total Loss: 0.09678307920694351\n",
            "----------------------------------------\n",
            "Epoch 472\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0049, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.091652050614357\n",
            "SCOPE mean: 0.06365825235843658, SCOPE var: 0.00027790642343461514\n",
            "Total Loss: 0.09655283391475677\n",
            "----------------------------------------\n",
            "Epoch 473\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0049, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.09145336598157883\n",
            "SCOPE mean: 0.06358426809310913, SCOPE var: 0.0002778057532850653\n",
            "Total Loss: 0.09632360935211182\n",
            "----------------------------------------\n",
            "Epoch 474\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0048, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.09125547111034393\n",
            "SCOPE mean: 0.06351066380739212, SCOPE var: 0.0002777059853542596\n",
            "Total Loss: 0.09609536826610565\n",
            "----------------------------------------\n",
            "Epoch 475\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0048, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.09105835109949112\n",
            "SCOPE mean: 0.06343740224838257, SCOPE var: 0.000277607177849859\n",
            "Total Loss: 0.09586809575557709\n",
            "----------------------------------------\n",
            "Epoch 476\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0048, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.09086211770772934\n",
            "SCOPE mean: 0.06336427479982376, SCOPE var: 0.00027750784647651017\n",
            "Total Loss: 0.09564191102981567\n",
            "----------------------------------------\n",
            "Epoch 477\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0048, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.09066669642925262\n",
            "SCOPE mean: 0.06329049170017242, SCOPE var: 0.0002774022286757827\n",
            "Total Loss: 0.09541673213243484\n",
            "----------------------------------------\n",
            "Epoch 478\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0047, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.09047212451696396\n",
            "SCOPE mean: 0.06321703642606735, SCOPE var: 0.0002772976295091212\n",
            "Total Loss: 0.09519261121749878\n",
            "----------------------------------------\n",
            "Epoch 479\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0047, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.09027822315692902\n",
            "SCOPE mean: 0.06314390897750854, SCOPE var: 0.00027719384524971247\n",
            "Total Loss: 0.09496934711933136\n",
            "----------------------------------------\n",
            "Epoch 480\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0047, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.09008490294218063\n",
            "SCOPE mean: 0.06307107955217361, SCOPE var: 0.0002770909632090479\n",
            "Total Loss: 0.09474686533212662\n",
            "----------------------------------------\n",
            "Epoch 481\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0046, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0898922011256218\n",
            "SCOPE mean: 0.06299851834774017, SCOPE var: 0.00027698883786797523\n",
            "Total Loss: 0.09452519565820694\n",
            "----------------------------------------\n",
            "Epoch 482\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0046, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.08970042318105698\n",
            "SCOPE mean: 0.0629262700676918, SCOPE var: 0.0002768877020571381\n",
            "Total Loss: 0.0943046435713768\n",
            "----------------------------------------\n",
            "Epoch 483\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0046, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.08950936049222946\n",
            "SCOPE mean: 0.06285427510738373, SCOPE var: 0.00027678723563440144\n",
            "Total Loss: 0.09408499300479889\n",
            "----------------------------------------\n",
            "Epoch 484\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0045, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.08931894600391388\n",
            "SCOPE mean: 0.06278255581855774, SCOPE var: 0.0002766875841189176\n",
            "Total Loss: 0.09386618435382843\n",
            "----------------------------------------\n",
            "Epoch 485\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0045, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0891292542219162\n",
            "SCOPE mean: 0.06271110475063324, SCOPE var: 0.00027658880571834743\n",
            "Total Loss: 0.0936482846736908\n",
            "----------------------------------------\n",
            "Epoch 486\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0045, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.08894024044275284\n",
            "SCOPE mean: 0.06263992935419083, SCOPE var: 0.0002764907549135387\n",
            "Total Loss: 0.0934312641620636\n",
            "----------------------------------------\n",
            "Epoch 487\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0045, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.08875192701816559\n",
            "SCOPE mean: 0.06256897747516632, SCOPE var: 0.0002763934317044914\n",
            "Total Loss: 0.09321511536836624\n",
            "----------------------------------------\n",
            "Epoch 488\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0044, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.08856436610221863\n",
            "SCOPE mean: 0.0624983049929142, SCOPE var: 0.00027629692340269685\n",
            "Total Loss: 0.09299992024898529\n",
            "----------------------------------------\n",
            "Epoch 489\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0044, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.08837755024433136\n",
            "SCOPE mean: 0.06242785602807999, SCOPE var: 0.00027620114269666374\n",
            "Total Loss: 0.09278564900159836\n",
            "----------------------------------------\n",
            "Epoch 490\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0044, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.08819147944450378\n",
            "SCOPE mean: 0.06235767900943756, SCOPE var: 0.00027610608958639205\n",
            "Total Loss: 0.09257231652736664\n",
            "----------------------------------------\n",
            "Epoch 491\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0044, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.08800620585680008\n",
            "SCOPE mean: 0.06228770688176155, SCOPE var: 0.00027601170586422086\n",
            "Total Loss: 0.09235996752977371\n",
            "----------------------------------------\n",
            "Epoch 492\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0043, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.08782172948122025\n",
            "SCOPE mean: 0.06221800670027733, SCOPE var: 0.0002759181661531329\n",
            "Total Loss: 0.09214859455823898\n",
            "----------------------------------------\n",
            "Epoch 493\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0043, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.08763815462589264\n",
            "SCOPE mean: 0.06214854121208191, SCOPE var: 0.00027582532493397593\n",
            "Total Loss: 0.09193892776966095\n",
            "----------------------------------------\n",
            "Epoch 494\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0043, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.08745559304952621\n",
            "SCOPE mean: 0.062079377472400665, SCOPE var: 0.0002757331822067499\n",
            "Total Loss: 0.09173057973384857\n",
            "----------------------------------------\n",
            "Epoch 495\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0042, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.08727382123470306\n",
            "SCOPE mean: 0.0620105043053627, SCOPE var: 0.00027564188349060714\n",
            "Total Loss: 0.09152321517467499\n",
            "----------------------------------------\n",
            "Epoch 496\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0042, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.08709278702735901\n",
            "SCOPE mean: 0.06194194406270981, SCOPE var: 0.00027555134147405624\n",
            "Total Loss: 0.09131676703691483\n",
            "----------------------------------------\n",
            "Epoch 497\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0042, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.08691254258155823\n",
            "SCOPE mean: 0.06187363341450691, SCOPE var: 0.00027546146884560585\n",
            "Total Loss: 0.09111128747463226\n",
            "----------------------------------------\n",
            "Epoch 498\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0042, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.08673306554555893\n",
            "SCOPE mean: 0.061805617064237595, SCOPE var: 0.0002753724402282387\n",
            "Total Loss: 0.0909067690372467\n",
            "----------------------------------------\n",
            "Epoch 499\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0041, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.08655436336994171\n",
            "SCOPE mean: 0.06173785403370857, SCOPE var: 0.00027528408099897206\n",
            "Total Loss: 0.09070319682359695\n",
            "----------------------------------------\n",
            "Epoch 500\n",
            "IS mean: 0.024885760620236397,IS variance: 0.00014304844080470502\n",
            "SCOPE Var loss:  tensor(0.0041, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.08637641370296478\n",
            "SCOPE mean: 0.061670344322919846, SCOPE var: 0.0002751964202616364\n",
            "Total Loss: 0.09050055593252182\n",
            "----------------------------------------\n",
            "600 trajectories:\n",
            "Epoch 1\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(3.8783, grad_fn=<VarBackward0>)\n",
            "MSE loss:  18.967439651489258\n",
            "SCOPE mean: 0.25434502959251404, SCOPE var: 0.0022254956420511007\n",
            "Total Loss: 22.845699310302734\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0766, grad_fn=<VarBackward0>)\n",
            "MSE loss:  18.039165496826172\n",
            "SCOPE mean: 0.24100059270858765, SCOPE var: 0.002136430935934186\n",
            "Total Loss: 18.115747451782227\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0744, grad_fn=<VarBackward0>)\n",
            "MSE loss:  17.13142967224121\n",
            "SCOPE mean: 0.22792500257492065, SCOPE var: 0.002059929072856903\n",
            "Total Loss: 17.205867767333984\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0724, grad_fn=<VarBackward0>)\n",
            "MSE loss:  16.260696411132812\n",
            "SCOPE mean: 0.21507799625396729, SCOPE var: 0.0019927688408643007\n",
            "Total Loss: 16.333145141601562\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0706, grad_fn=<VarBackward0>)\n",
            "MSE loss:  15.424640655517578\n",
            "SCOPE mean: 0.20215344429016113, SCOPE var: 0.0019231640035286546\n",
            "Total Loss: 15.495210647583008\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0689, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.624088287353516\n",
            "SCOPE mean: 0.19557617604732513, SCOPE var: 0.0018744112458080053\n",
            "Total Loss: 14.692974090576172\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0674, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.866300582885742\n",
            "SCOPE mean: 0.1930779069662094, SCOPE var: 0.0018298585200682282\n",
            "Total Loss: 13.933658599853516\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0660, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.14267349243164\n",
            "SCOPE mean: 0.19064489006996155, SCOPE var: 0.0017863911343738437\n",
            "Total Loss: 13.208662033081055\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0647, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.452549934387207\n",
            "SCOPE mean: 0.1881679892539978, SCOPE var: 0.0017441983800381422\n",
            "Total Loss: 12.517281532287598\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0637, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.794170379638672\n",
            "SCOPE mean: 0.1856665164232254, SCOPE var: 0.001706250011920929\n",
            "Total Loss: 11.857831001281738\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0627, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.166275024414062\n",
            "SCOPE mean: 0.18315500020980835, SCOPE var: 0.0016735474346205592\n",
            "Total Loss: 11.22900390625\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0620, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.565858840942383\n",
            "SCOPE mean: 0.17966167628765106, SCOPE var: 0.001616666209883988\n",
            "Total Loss: 10.627813339233398\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0613, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.993165016174316\n",
            "SCOPE mean: 0.17527979612350464, SCOPE var: 0.0015399097464978695\n",
            "Total Loss: 10.054489135742188\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0606, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.448724746704102\n",
            "SCOPE mean: 0.1708914041519165, SCOPE var: 0.0014699083985760808\n",
            "Total Loss: 9.509325981140137\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0597, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.93120002746582\n",
            "SCOPE mean: 0.16650934517383575, SCOPE var: 0.0014029867015779018\n",
            "Total Loss: 8.990883827209473\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0596, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.441018104553223\n",
            "SCOPE mean: 0.1620716005563736, SCOPE var: 0.0013388906372711062\n",
            "Total Loss: 8.500639915466309\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0599, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.975257873535156\n",
            "SCOPE mean: 0.15767131745815277, SCOPE var: 0.001277774223126471\n",
            "Total Loss: 8.035112380981445\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0605, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.53255558013916\n",
            "SCOPE mean: 0.1533099114894867, SCOPE var: 0.0012195190647616982\n",
            "Total Loss: 7.593051433563232\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0615, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.111456871032715\n",
            "SCOPE mean: 0.14902155101299286, SCOPE var: 0.0011633282992988825\n",
            "Total Loss: 7.1729960441589355\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0631, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.712251663208008\n",
            "SCOPE mean: 0.1447715014219284, SCOPE var: 0.0011099177645519376\n",
            "Total Loss: 6.775373935699463\n",
            "----------------------------------------\n",
            "Epoch 21\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0650, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.334855079650879\n",
            "SCOPE mean: 0.14055702090263367, SCOPE var: 0.0010592172620818019\n",
            "Total Loss: 6.399844646453857\n",
            "----------------------------------------\n",
            "Epoch 22\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0672, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.979077339172363\n",
            "SCOPE mean: 0.1363856941461563, SCOPE var: 0.0010111461160704494\n",
            "Total Loss: 6.046241760253906\n",
            "----------------------------------------\n",
            "Epoch 23\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0696, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.643281936645508\n",
            "SCOPE mean: 0.13225990533828735, SCOPE var: 0.0009655941976234317\n",
            "Total Loss: 5.712903022766113\n",
            "----------------------------------------\n",
            "Epoch 24\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0723, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.326506614685059\n",
            "SCOPE mean: 0.12834011018276215, SCOPE var: 0.0009133331477642059\n",
            "Total Loss: 5.398838996887207\n",
            "----------------------------------------\n",
            "Epoch 25\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0753, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.027537822723389\n",
            "SCOPE mean: 0.12448366731405258, SCOPE var: 0.0008631786331534386\n",
            "Total Loss: 5.102827072143555\n",
            "----------------------------------------\n",
            "Epoch 26\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0766, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.745476722717285\n",
            "SCOPE mean: 0.1207098513841629, SCOPE var: 0.0008162735030055046\n",
            "Total Loss: 4.822107791900635\n",
            "----------------------------------------\n",
            "Epoch 27\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0773, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.479754447937012\n",
            "SCOPE mean: 0.11699428409337997, SCOPE var: 0.0007722266600467265\n",
            "Total Loss: 4.557098865509033\n",
            "----------------------------------------\n",
            "Epoch 28\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0781, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.229468822479248\n",
            "SCOPE mean: 0.11333093047142029, SCOPE var: 0.0007308379863388836\n",
            "Total Loss: 4.307548522949219\n",
            "----------------------------------------\n",
            "Epoch 29\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0788, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.9948208332061768\n",
            "SCOPE mean: 0.10972225666046143, SCOPE var: 0.0006919783190824091\n",
            "Total Loss: 4.073607921600342\n",
            "----------------------------------------\n",
            "Epoch 30\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0795, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.7745556831359863\n",
            "SCOPE mean: 0.10616881400346756, SCOPE var: 0.000655519834253937\n",
            "Total Loss: 3.8540804386138916\n",
            "----------------------------------------\n",
            "Epoch 31\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0803, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.567455291748047\n",
            "SCOPE mean: 0.10267110913991928, SCOPE var: 0.0006213280721567571\n",
            "Total Loss: 3.6477413177490234\n",
            "----------------------------------------\n",
            "Epoch 32\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0811, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.3727569580078125\n",
            "SCOPE mean: 0.09923087805509567, SCOPE var: 0.0005892793997190893\n",
            "Total Loss: 3.453845739364624\n",
            "----------------------------------------\n",
            "Epoch 33\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0820, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.189908266067505\n",
            "SCOPE mean: 0.09584993869066238, SCOPE var: 0.0005592560628429055\n",
            "Total Loss: 3.2718636989593506\n",
            "----------------------------------------\n",
            "Epoch 34\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0829, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.018345832824707\n",
            "SCOPE mean: 0.09252981841564178, SCOPE var: 0.0005311425193212926\n",
            "Total Loss: 3.1012332439422607\n",
            "----------------------------------------\n",
            "Epoch 35\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0839, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.8576009273529053\n",
            "SCOPE mean: 0.08926767110824585, SCOPE var: 0.0005048318998888135\n",
            "Total Loss: 2.9414639472961426\n",
            "----------------------------------------\n",
            "Epoch 36\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0849, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.70696759223938\n",
            "SCOPE mean: 0.08601045608520508, SCOPE var: 0.0004802003677468747\n",
            "Total Loss: 2.7918460369110107\n",
            "----------------------------------------\n",
            "Epoch 37\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0859, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.566045045852661\n",
            "SCOPE mean: 0.08282389491796494, SCOPE var: 0.00045717525063082576\n",
            "Total Loss: 2.651978015899658\n",
            "----------------------------------------\n",
            "Epoch 38\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0870, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.4342663288116455\n",
            "SCOPE mean: 0.07971015572547913, SCOPE var: 0.0004356678109616041\n",
            "Total Loss: 2.521284818649292\n",
            "----------------------------------------\n",
            "Epoch 39\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0881, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.311220169067383\n",
            "SCOPE mean: 0.07666989415884018, SCOPE var: 0.0004155951028224081\n",
            "Total Loss: 2.3993489742279053\n",
            "----------------------------------------\n",
            "Epoch 40\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0893, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.196420431137085\n",
            "SCOPE mean: 0.07370470464229584, SCOPE var: 0.0003968773817177862\n",
            "Total Loss: 2.2856791019439697\n",
            "----------------------------------------\n",
            "Epoch 41\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0904, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.0894157886505127\n",
            "SCOPE mean: 0.07081691175699234, SCOPE var: 0.00037943912320770323\n",
            "Total Loss: 2.179823637008667\n",
            "----------------------------------------\n",
            "Epoch 42\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0914, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.9895565509796143\n",
            "SCOPE mean: 0.06810812652111053, SCOPE var: 0.0003619342460297048\n",
            "Total Loss: 2.0809948444366455\n",
            "----------------------------------------\n",
            "Epoch 43\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0924, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.8965650796890259\n",
            "SCOPE mean: 0.06550285965204239, SCOPE var: 0.00034540516207925975\n",
            "Total Loss: 1.9890036582946777\n",
            "----------------------------------------\n",
            "Epoch 44\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0934, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.810124158859253\n",
            "SCOPE mean: 0.06297596544027328, SCOPE var: 0.00033013938809745014\n",
            "Total Loss: 1.9035595655441284\n",
            "----------------------------------------\n",
            "Epoch 45\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0944, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.729835033416748\n",
            "SCOPE mean: 0.06052907556295395, SCOPE var: 0.00031606797710992396\n",
            "Total Loss: 1.8242584466934204\n",
            "----------------------------------------\n",
            "Epoch 46\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0954, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6553348302841187\n",
            "SCOPE mean: 0.05816371366381645, SCOPE var: 0.0003031245432794094\n",
            "Total Loss: 1.7507388591766357\n",
            "----------------------------------------\n",
            "Epoch 47\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0964, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.586249828338623\n",
            "SCOPE mean: 0.05588321015238762, SCOPE var: 0.0002912478521466255\n",
            "Total Loss: 1.6826205253601074\n",
            "----------------------------------------\n",
            "Epoch 48\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0973, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.522197961807251\n",
            "SCOPE mean: 0.05369048938155174, SCOPE var: 0.0002803777751978487\n",
            "Total Loss: 1.6195259094238281\n",
            "----------------------------------------\n",
            "Epoch 49\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0983, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4628955125808716\n",
            "SCOPE mean: 0.05158226191997528, SCOPE var: 0.0002704506041482091\n",
            "Total Loss: 1.561147928237915\n",
            "----------------------------------------\n",
            "Epoch 50\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0992, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4080235958099365\n",
            "SCOPE mean: 0.04955961927771568, SCOPE var: 0.00026140979025512934\n",
            "Total Loss: 1.507173776626587\n",
            "----------------------------------------\n",
            "Epoch 51\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.1000, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.3572981357574463\n",
            "SCOPE mean: 0.04762386158108711, SCOPE var: 0.00025320271379314363\n",
            "Total Loss: 1.4573148488998413\n",
            "----------------------------------------\n",
            "Epoch 52\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.1008, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.310457468032837\n",
            "SCOPE mean: 0.04577047750353813, SCOPE var: 0.00024577611475251615\n",
            "Total Loss: 1.4113062620162964\n",
            "----------------------------------------\n",
            "Epoch 53\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.1016, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.267170786857605\n",
            "SCOPE mean: 0.04400670528411865, SCOPE var: 0.00023907377908471972\n",
            "Total Loss: 1.3688125610351562\n",
            "----------------------------------------\n",
            "Epoch 54\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.1024, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.2271835803985596\n",
            "SCOPE mean: 0.04233749210834503, SCOPE var: 0.00023304024944081903\n",
            "Total Loss: 1.3295773267745972\n",
            "----------------------------------------\n",
            "Epoch 55\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.1031, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1902215480804443\n",
            "SCOPE mean: 0.040757741779088974, SCOPE var: 0.00022766370966564864\n",
            "Total Loss: 1.293321132659912\n",
            "----------------------------------------\n",
            "Epoch 56\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.1038, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1560254096984863\n",
            "SCOPE mean: 0.03926806151866913, SCOPE var: 0.00022290096967481077\n",
            "Total Loss: 1.2597813606262207\n",
            "----------------------------------------\n",
            "Epoch 57\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.1043, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1244200468063354\n",
            "SCOPE mean: 0.03785346448421478, SCOPE var: 0.00021869648480787873\n",
            "Total Loss: 1.2287620306015015\n",
            "----------------------------------------\n",
            "Epoch 58\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.1049, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0951875448226929\n",
            "SCOPE mean: 0.036521345376968384, SCOPE var: 0.0002150225336663425\n",
            "Total Loss: 1.2000586986541748\n",
            "----------------------------------------\n",
            "Epoch 59\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.1053, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0681356191635132\n",
            "SCOPE mean: 0.03527981415390968, SCOPE var: 0.0002118525153491646\n",
            "Total Loss: 1.1734790802001953\n",
            "----------------------------------------\n",
            "Epoch 60\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.1058, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0430675745010376\n",
            "SCOPE mean: 0.03412797674536705, SCOPE var: 0.00020915268396493047\n",
            "Total Loss: 1.148826003074646\n",
            "----------------------------------------\n",
            "Epoch 61\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.1061, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0198312997817993\n",
            "SCOPE mean: 0.033065080642700195, SCOPE var: 0.00020689131633844227\n",
            "Total Loss: 1.1259456872940063\n",
            "----------------------------------------\n",
            "Epoch 62\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.1064, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9982534050941467\n",
            "SCOPE mean: 0.03208979219198227, SCOPE var: 0.00020503845007624477\n",
            "Total Loss: 1.1046638488769531\n",
            "----------------------------------------\n",
            "Epoch 63\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.1066, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.978157103061676\n",
            "SCOPE mean: 0.031200988218188286, SCOPE var: 0.00020356583991087973\n",
            "Total Loss: 1.0847715139389038\n",
            "----------------------------------------\n",
            "Epoch 64\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.1067, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9594162702560425\n",
            "SCOPE mean: 0.030394433066248894, SCOPE var: 0.00020243994367774576\n",
            "Total Loss: 1.0661653280258179\n",
            "----------------------------------------\n",
            "Epoch 65\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.1068, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9419056177139282\n",
            "SCOPE mean: 0.029668347910046577, SCOPE var: 0.00020163548470009118\n",
            "Total Loss: 1.048732042312622\n",
            "----------------------------------------\n",
            "Epoch 66\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.1069, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9255117774009705\n",
            "SCOPE mean: 0.029020901769399643, SCOPE var: 0.00020112910715397447\n",
            "Total Loss: 1.032367467880249\n",
            "----------------------------------------\n",
            "Epoch 67\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.1068, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9101089239120483\n",
            "SCOPE mean: 0.028421057388186455, SCOPE var: 0.00020082734408788383\n",
            "Total Loss: 1.0169501304626465\n",
            "----------------------------------------\n",
            "Epoch 68\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.1068, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8956131935119629\n",
            "SCOPE mean: 0.027896666899323463, SCOPE var: 0.0002007618750212714\n",
            "Total Loss: 1.002387285232544\n",
            "----------------------------------------\n",
            "Epoch 69\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.1067, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8819388747215271\n",
            "SCOPE mean: 0.027445713058114052, SCOPE var: 0.00020091733313165605\n",
            "Total Loss: 0.9885943531990051\n",
            "----------------------------------------\n",
            "Epoch 70\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.1064, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8690440654754639\n",
            "SCOPE mean: 0.027066247537732124, SCOPE var: 0.0002012795739574358\n",
            "Total Loss: 0.9754679799079895\n",
            "----------------------------------------\n",
            "Epoch 71\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.1061, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8568077683448792\n",
            "SCOPE mean: 0.026755649596452713, SCOPE var: 0.00020183398737572134\n",
            "Total Loss: 0.9629523754119873\n",
            "----------------------------------------\n",
            "Epoch 72\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.1058, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8451672792434692\n",
            "SCOPE mean: 0.026511410251259804, SCOPE var: 0.00020256746211089194\n",
            "Total Loss: 0.9509862661361694\n",
            "----------------------------------------\n",
            "Epoch 73\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.1054, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8340514898300171\n",
            "SCOPE mean: 0.02633066661655903, SCOPE var: 0.0002034668723354116\n",
            "Total Loss: 0.9395001530647278\n",
            "----------------------------------------\n",
            "Epoch 74\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.1050, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8234038352966309\n",
            "SCOPE mean: 0.02621065452694893, SCOPE var: 0.00020452066382858902\n",
            "Total Loss: 0.9284393787384033\n",
            "----------------------------------------\n",
            "Epoch 75\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.1046, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8131787776947021\n",
            "SCOPE mean: 0.02614866942167282, SCOPE var: 0.00020571789355017245\n",
            "Total Loss: 0.9177603125572205\n",
            "----------------------------------------\n",
            "Epoch 76\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.1041, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8033345341682434\n",
            "SCOPE mean: 0.026141777634620667, SCOPE var: 0.0002070480986731127\n",
            "Total Loss: 0.9074230790138245\n",
            "----------------------------------------\n",
            "Epoch 77\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.1036, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7938330769538879\n",
            "SCOPE mean: 0.0261871088296175, SCOPE var: 0.00020850148575846106\n",
            "Total Loss: 0.8973916172981262\n",
            "----------------------------------------\n",
            "Epoch 78\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.1030, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7846397161483765\n",
            "SCOPE mean: 0.02628200128674507, SCOPE var: 0.0002100699784932658\n",
            "Total Loss: 0.8876340389251709\n",
            "----------------------------------------\n",
            "Epoch 79\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.1024, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7757397294044495\n",
            "SCOPE mean: 0.026423761621117592, SCOPE var: 0.00021174528228584677\n",
            "Total Loss: 0.8781504034996033\n",
            "----------------------------------------\n",
            "Epoch 80\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.1018, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7670958042144775\n",
            "SCOPE mean: 0.02661176398396492, SCOPE var: 0.00021352457406464964\n",
            "Total Loss: 0.8689069747924805\n",
            "----------------------------------------\n",
            "Epoch 81\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.1012, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7586848139762878\n",
            "SCOPE mean: 0.026842962950468063, SCOPE var: 0.00021540017041843385\n",
            "Total Loss: 0.8598644137382507\n",
            "----------------------------------------\n",
            "Epoch 82\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.1005, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7504768371582031\n",
            "SCOPE mean: 0.027114270254969597, SCOPE var: 0.00021736447524745017\n",
            "Total Loss: 0.8509676456451416\n",
            "----------------------------------------\n",
            "Epoch 83\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0998, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7424591779708862\n",
            "SCOPE mean: 0.02742515318095684, SCOPE var: 0.00021941817249171436\n",
            "Total Loss: 0.8422300815582275\n",
            "----------------------------------------\n",
            "Epoch 84\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0990, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7346162796020508\n",
            "SCOPE mean: 0.02777225337922573, SCOPE var: 0.00022155359329190105\n",
            "Total Loss: 0.8336397409439087\n",
            "----------------------------------------\n",
            "Epoch 85\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0983, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7269362807273865\n",
            "SCOPE mean: 0.0281524695456028, SCOPE var: 0.0002237636363133788\n",
            "Total Loss: 0.825187623500824\n",
            "----------------------------------------\n",
            "Epoch 86\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0975, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7194127440452576\n",
            "SCOPE mean: 0.028562646359205246, SCOPE var: 0.00022604173864237964\n",
            "Total Loss: 0.8168702125549316\n",
            "----------------------------------------\n",
            "Epoch 87\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0966, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7120335698127747\n",
            "SCOPE mean: 0.028999831527471542, SCOPE var: 0.00022838097356725484\n",
            "Total Loss: 0.8086780309677124\n",
            "----------------------------------------\n",
            "Epoch 88\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0958, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7047838568687439\n",
            "SCOPE mean: 0.02946130931377411, SCOPE var: 0.00023077648074831814\n",
            "Total Loss: 0.8005988001823425\n",
            "----------------------------------------\n",
            "Epoch 89\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0950, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6976662874221802\n",
            "SCOPE mean: 0.029944317415356636, SCOPE var: 0.0002332225558348\n",
            "Total Loss: 0.7926375269889832\n",
            "----------------------------------------\n",
            "Epoch 90\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0941, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.690678596496582\n",
            "SCOPE mean: 0.030446166172623634, SCOPE var: 0.00023571314522996545\n",
            "Total Loss: 0.7847945094108582\n",
            "----------------------------------------\n",
            "Epoch 91\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0933, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6838147640228271\n",
            "SCOPE mean: 0.030964355915784836, SCOPE var: 0.00023824266099836677\n",
            "Total Loss: 0.7770658731460571\n",
            "----------------------------------------\n",
            "Epoch 92\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0924, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6770497560501099\n",
            "SCOPE mean: 0.031494464725255966, SCOPE var: 0.0002407860301900655\n",
            "Total Loss: 0.7694284319877625\n",
            "----------------------------------------\n",
            "Epoch 93\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0915, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6704028844833374\n",
            "SCOPE mean: 0.032036326825618744, SCOPE var: 0.00024336419301107526\n",
            "Total Loss: 0.7619032859802246\n",
            "----------------------------------------\n",
            "Epoch 94\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0906, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6638695597648621\n",
            "SCOPE mean: 0.03258780390024185, SCOPE var: 0.0002459718962199986\n",
            "Total Loss: 0.7544862031936646\n",
            "----------------------------------------\n",
            "Epoch 95\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0897, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.657446563243866\n",
            "SCOPE mean: 0.033141735941171646, SCOPE var: 0.00024854153161868453\n",
            "Total Loss: 0.7471785545349121\n",
            "----------------------------------------\n",
            "Epoch 96\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0888, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6511408686637878\n",
            "SCOPE mean: 0.03369694575667381, SCOPE var: 0.0002510736812837422\n",
            "Total Loss: 0.7399886846542358\n",
            "----------------------------------------\n",
            "Epoch 97\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0880, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.644942045211792\n",
            "SCOPE mean: 0.034256428480148315, SCOPE var: 0.0002536205283831805\n",
            "Total Loss: 0.7329065203666687\n",
            "----------------------------------------\n",
            "Epoch 98\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0871, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6388380527496338\n",
            "SCOPE mean: 0.03481880947947502, SCOPE var: 0.00025618021027185023\n",
            "Total Loss: 0.7259212136268616\n",
            "----------------------------------------\n",
            "Epoch 99\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0862, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6328356266021729\n",
            "SCOPE mean: 0.035382505506277084, SCOPE var: 0.0002587492926977575\n",
            "Total Loss: 0.7190408110618591\n",
            "----------------------------------------\n",
            "Epoch 100\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0853, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6269290447235107\n",
            "SCOPE mean: 0.03594626858830452, SCOPE var: 0.00026132530183531344\n",
            "Total Loss: 0.7122606039047241\n",
            "----------------------------------------\n",
            "Epoch 101\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0845, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6211196780204773\n",
            "SCOPE mean: 0.03650875389575958, SCOPE var: 0.0002639046579133719\n",
            "Total Loss: 0.7055829763412476\n",
            "----------------------------------------\n",
            "Epoch 102\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0836, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6154018640518188\n",
            "SCOPE mean: 0.03706915304064751, SCOPE var: 0.0002664853527676314\n",
            "Total Loss: 0.6990030407905579\n",
            "----------------------------------------\n",
            "Epoch 103\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0827, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6097792983055115\n",
            "SCOPE mean: 0.03762630745768547, SCOPE var: 0.0002690640394575894\n",
            "Total Loss: 0.6925253868103027\n",
            "----------------------------------------\n",
            "Epoch 104\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0819, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6042501926422119\n",
            "SCOPE mean: 0.038179319351911545, SCOPE var: 0.000271637924015522\n",
            "Total Loss: 0.6861487627029419\n",
            "----------------------------------------\n",
            "Epoch 105\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0811, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5988123416900635\n",
            "SCOPE mean: 0.038727227598428726, SCOPE var: 0.00027420406695455313\n",
            "Total Loss: 0.6798718571662903\n",
            "----------------------------------------\n",
            "Epoch 106\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0802, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5934611558914185\n",
            "SCOPE mean: 0.0392693467438221, SCOPE var: 0.0002767607511486858\n",
            "Total Loss: 0.6736905574798584\n",
            "----------------------------------------\n",
            "Epoch 107\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0794, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5881898999214172\n",
            "SCOPE mean: 0.039805006235837936, SCOPE var: 0.00027930623036809266\n",
            "Total Loss: 0.6675986647605896\n",
            "----------------------------------------\n",
            "Epoch 108\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0786, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5830060243606567\n",
            "SCOPE mean: 0.040333665907382965, SCOPE var: 0.00028183896210975945\n",
            "Total Loss: 0.6616037487983704\n",
            "----------------------------------------\n",
            "Epoch 109\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0778, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5779064893722534\n",
            "SCOPE mean: 0.040854692459106445, SCOPE var: 0.00028435688000172377\n",
            "Total Loss: 0.655703067779541\n",
            "----------------------------------------\n",
            "Epoch 110\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0770, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5728839635848999\n",
            "SCOPE mean: 0.04136765003204346, SCOPE var: 0.00028685759752988815\n",
            "Total Loss: 0.6498895883560181\n",
            "----------------------------------------\n",
            "Epoch 111\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0762, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5679380893707275\n",
            "SCOPE mean: 0.04187217354774475, SCOPE var: 0.00028933989233337343\n",
            "Total Loss: 0.644163191318512\n",
            "----------------------------------------\n",
            "Epoch 112\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0755, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5630708336830139\n",
            "SCOPE mean: 0.04236786812543869, SCOPE var: 0.00029180195997469127\n",
            "Total Loss: 0.6385261416435242\n",
            "----------------------------------------\n",
            "Epoch 113\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0747, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5582840442657471\n",
            "SCOPE mean: 0.042854346334934235, SCOPE var: 0.0002942415594588965\n",
            "Total Loss: 0.6329814195632935\n",
            "----------------------------------------\n",
            "Epoch 114\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0740, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5535754561424255\n",
            "SCOPE mean: 0.04321557655930519, SCOPE var: 0.0002949559420812875\n",
            "Total Loss: 0.6275266408920288\n",
            "----------------------------------------\n",
            "Epoch 115\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0732, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5489420890808105\n",
            "SCOPE mean: 0.04356759041547775, SCOPE var: 0.00029562905547209084\n",
            "Total Loss: 0.6221579313278198\n",
            "----------------------------------------\n",
            "Epoch 116\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0725, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5443799495697021\n",
            "SCOPE mean: 0.04391095042228699, SCOPE var: 0.00029627245385199785\n",
            "Total Loss: 0.6168712973594666\n",
            "----------------------------------------\n",
            "Epoch 117\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0718, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5398926734924316\n",
            "SCOPE mean: 0.044245533645153046, SCOPE var: 0.00029688567155972123\n",
            "Total Loss: 0.6116702556610107\n",
            "----------------------------------------\n",
            "Epoch 118\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0711, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5354738235473633\n",
            "SCOPE mean: 0.04457123577594757, SCOPE var: 0.0002974684757646173\n",
            "Total Loss: 0.6065483689308167\n",
            "----------------------------------------\n",
            "Epoch 119\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0704, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5311223268508911\n",
            "SCOPE mean: 0.04488786682486534, SCOPE var: 0.0002980202261824161\n",
            "Total Loss: 0.6015046238899231\n",
            "----------------------------------------\n",
            "Epoch 120\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0697, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5268344879150391\n",
            "SCOPE mean: 0.045195404440164566, SCOPE var: 0.00029854095191694796\n",
            "Total Loss: 0.5965352654457092\n",
            "----------------------------------------\n",
            "Epoch 121\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0690, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5226109027862549\n",
            "SCOPE mean: 0.045493971556425095, SCOPE var: 0.00029903059476055205\n",
            "Total Loss: 0.5916406512260437\n",
            "----------------------------------------\n",
            "Epoch 122\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0684, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5184561610221863\n",
            "SCOPE mean: 0.04578350856900215, SCOPE var: 0.00029948889277875423\n",
            "Total Loss: 0.5868253111839294\n",
            "----------------------------------------\n",
            "Epoch 123\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0677, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5143622159957886\n",
            "SCOPE mean: 0.04606400802731514, SCOPE var: 0.0002999159332830459\n",
            "Total Loss: 0.5820391178131104\n",
            "----------------------------------------\n",
            "Epoch 124\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0670, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.510322630405426\n",
            "SCOPE mean: 0.04633602127432823, SCOPE var: 0.0003003132587764412\n",
            "Total Loss: 0.5773053765296936\n",
            "----------------------------------------\n",
            "Epoch 125\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0663, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.50633704662323\n",
            "SCOPE mean: 0.04659965634346008, SCOPE var: 0.00030068113119341433\n",
            "Total Loss: 0.5726362466812134\n",
            "----------------------------------------\n",
            "Epoch 126\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0656, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5024049282073975\n",
            "SCOPE mean: 0.04685495048761368, SCOPE var: 0.00030101975426077843\n",
            "Total Loss: 0.5680310726165771\n",
            "----------------------------------------\n",
            "Epoch 127\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0650, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.49852481484413147\n",
            "SCOPE mean: 0.04710207134485245, SCOPE var: 0.000301329797366634\n",
            "Total Loss: 0.5634881258010864\n",
            "----------------------------------------\n",
            "Epoch 128\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0643, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4946949779987335\n",
            "SCOPE mean: 0.04734117537736893, SCOPE var: 0.0003016112605109811\n",
            "Total Loss: 0.5590054392814636\n",
            "----------------------------------------\n",
            "Epoch 129\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0636, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4908771216869354\n",
            "SCOPE mean: 0.04757236689329147, SCOPE var: 0.0003018648421857506\n",
            "Total Loss: 0.554519534111023\n",
            "----------------------------------------\n",
            "Epoch 130\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0630, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4870988726615906\n",
            "SCOPE mean: 0.04779478907585144, SCOPE var: 0.0003020414151251316\n",
            "Total Loss: 0.5500805974006653\n",
            "----------------------------------------\n",
            "Epoch 131\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0623, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.48336389660835266\n",
            "SCOPE mean: 0.048009321093559265, SCOPE var: 0.0003021734592039138\n",
            "Total Loss: 0.5456939935684204\n",
            "----------------------------------------\n",
            "Epoch 132\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0617, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.47967198491096497\n",
            "SCOPE mean: 0.04821684956550598, SCOPE var: 0.00030227971728891134\n",
            "Total Loss: 0.5413594245910645\n",
            "----------------------------------------\n",
            "Epoch 133\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0611, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4760240912437439\n",
            "SCOPE mean: 0.04841752350330353, SCOPE var: 0.00030236117891035974\n",
            "Total Loss: 0.5370775461196899\n",
            "----------------------------------------\n",
            "Epoch 134\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0604, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.47242024540901184\n",
            "SCOPE mean: 0.04861152172088623, SCOPE var: 0.0003024180477950722\n",
            "Total Loss: 0.5328484177589417\n",
            "----------------------------------------\n",
            "Epoch 135\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0598, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4688599109649658\n",
            "SCOPE mean: 0.048798903822898865, SCOPE var: 0.0003024509933311492\n",
            "Total Loss: 0.5286715030670166\n",
            "----------------------------------------\n",
            "Epoch 136\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0592, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.465343177318573\n",
            "SCOPE mean: 0.04897984862327576, SCOPE var: 0.00030246053938753903\n",
            "Total Loss: 0.5245466232299805\n",
            "----------------------------------------\n",
            "Epoch 137\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0586, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4618690013885498\n",
            "SCOPE mean: 0.049154505133628845, SCOPE var: 0.00030244726804085076\n",
            "Total Loss: 0.5204726457595825\n",
            "----------------------------------------\n",
            "Epoch 138\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0580, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.45843788981437683\n",
            "SCOPE mean: 0.04932302236557007, SCOPE var: 0.0003024119941983372\n",
            "Total Loss: 0.5164499282836914\n",
            "----------------------------------------\n",
            "Epoch 139\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0574, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.45505061745643616\n",
            "SCOPE mean: 0.04948551952838898, SCOPE var: 0.0003023543977178633\n",
            "Total Loss: 0.5124791860580444\n",
            "----------------------------------------\n",
            "Epoch 140\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0569, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.45170435309410095\n",
            "SCOPE mean: 0.04964224994182587, SCOPE var: 0.00030227593379095197\n",
            "Total Loss: 0.5085574388504028\n",
            "----------------------------------------\n",
            "Epoch 141\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0563, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4484008252620697\n",
            "SCOPE mean: 0.049793414771556854, SCOPE var: 0.00030217706807889044\n",
            "Total Loss: 0.504686176776886\n",
            "----------------------------------------\n",
            "Epoch 142\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0557, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4451402425765991\n",
            "SCOPE mean: 0.04993916675448418, SCOPE var: 0.0003020584408659488\n",
            "Total Loss: 0.5008655190467834\n",
            "----------------------------------------\n",
            "Epoch 143\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0552, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.44192054867744446\n",
            "SCOPE mean: 0.050079572945833206, SCOPE var: 0.0003019194700755179\n",
            "Total Loss: 0.4970932900905609\n",
            "----------------------------------------\n",
            "Epoch 144\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0546, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4387412965297699\n",
            "SCOPE mean: 0.050214819610118866, SCOPE var: 0.00030176114523783326\n",
            "Total Loss: 0.49336880445480347\n",
            "----------------------------------------\n",
            "Epoch 145\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0541, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4356051981449127\n",
            "SCOPE mean: 0.05034511908888817, SCOPE var: 0.0003015843976754695\n",
            "Total Loss: 0.489694744348526\n",
            "----------------------------------------\n",
            "Epoch 146\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0536, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.43250879645347595\n",
            "SCOPE mean: 0.050470709800720215, SCOPE var: 0.0003013900713995099\n",
            "Total Loss: 0.48606744408607483\n",
            "----------------------------------------\n",
            "Epoch 147\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0530, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4294516146183014\n",
            "SCOPE mean: 0.05059180408716202, SCOPE var: 0.0003011791850440204\n",
            "Total Loss: 0.48248618841171265\n",
            "----------------------------------------\n",
            "Epoch 148\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0525, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4264334440231323\n",
            "SCOPE mean: 0.05070864409208298, SCOPE var: 0.00030095252441242337\n",
            "Total Loss: 0.47895073890686035\n",
            "----------------------------------------\n",
            "Epoch 149\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0520, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.42345350980758667\n",
            "SCOPE mean: 0.050821349024772644, SCOPE var: 0.0003007104096468538\n",
            "Total Loss: 0.4754600524902344\n",
            "----------------------------------------\n",
            "Epoch 150\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0515, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4205113351345062\n",
            "SCOPE mean: 0.05091776326298714, SCOPE var: 0.00030030542984604836\n",
            "Total Loss: 0.4720135033130646\n",
            "----------------------------------------\n",
            "Epoch 151\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0510, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4176071882247925\n",
            "SCOPE mean: 0.051008373498916626, SCOPE var: 0.00029986226581968367\n",
            "Total Loss: 0.46861129999160767\n",
            "----------------------------------------\n",
            "Epoch 152\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0505, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4147411286830902\n",
            "SCOPE mean: 0.05109553039073944, SCOPE var: 0.00029940748936496675\n",
            "Total Loss: 0.4652533531188965\n",
            "----------------------------------------\n",
            "Epoch 153\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0500, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.41191110014915466\n",
            "SCOPE mean: 0.05117923766374588, SCOPE var: 0.00029894118779338896\n",
            "Total Loss: 0.4619375467300415\n",
            "----------------------------------------\n",
            "Epoch 154\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0496, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.40911391377449036\n",
            "SCOPE mean: 0.05125973001122475, SCOPE var: 0.0002984642924275249\n",
            "Total Loss: 0.4586658775806427\n",
            "----------------------------------------\n",
            "Epoch 155\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0491, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4063540995121002\n",
            "SCOPE mean: 0.051336951553821564, SCOPE var: 0.0002979763667099178\n",
            "Total Loss: 0.4554465711116791\n",
            "----------------------------------------\n",
            "Epoch 156\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0487, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4036310911178589\n",
            "SCOPE mean: 0.05141096189618111, SCOPE var: 0.00029747741064056754\n",
            "Total Loss: 0.4523056745529175\n",
            "----------------------------------------\n",
            "Epoch 157\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0483, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4009423851966858\n",
            "SCOPE mean: 0.05148063972592354, SCOPE var: 0.00029696704586967826\n",
            "Total Loss: 0.4492500126361847\n",
            "----------------------------------------\n",
            "Epoch 158\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0479, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3982941508293152\n",
            "SCOPE mean: 0.0515461191534996, SCOPE var: 0.00029644559253938496\n",
            "Total Loss: 0.44623956084251404\n",
            "----------------------------------------\n",
            "Epoch 159\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0476, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3956839144229889\n",
            "SCOPE mean: 0.05160750821232796, SCOPE var: 0.00029591339989565313\n",
            "Total Loss: 0.44327083230018616\n",
            "----------------------------------------\n",
            "Epoch 160\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0472, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3931015431880951\n",
            "SCOPE mean: 0.05166510120034218, SCOPE var: 0.00029537128284573555\n",
            "Total Loss: 0.44033148884773254\n",
            "----------------------------------------\n",
            "Epoch 161\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0469, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3905489146709442\n",
            "SCOPE mean: 0.051720403134822845, SCOPE var: 0.0002948243054561317\n",
            "Total Loss: 0.43742358684539795\n",
            "----------------------------------------\n",
            "Epoch 162\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0465, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3880304992198944\n",
            "SCOPE mean: 0.051775526255369186, SCOPE var: 0.00029425506363622844\n",
            "Total Loss: 0.4345529079437256\n",
            "----------------------------------------\n",
            "Epoch 163\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0462, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3855472207069397\n",
            "SCOPE mean: 0.0518295094370842, SCOPE var: 0.0002936725504696369\n",
            "Total Loss: 0.43172022700309753\n",
            "----------------------------------------\n",
            "Epoch 164\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0458, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.38309982419013977\n",
            "SCOPE mean: 0.051881346851587296, SCOPE var: 0.00029308535158634186\n",
            "Total Loss: 0.4289262294769287\n",
            "----------------------------------------\n",
            "Epoch 165\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0455, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.38068386912345886\n",
            "SCOPE mean: 0.05193116515874863, SCOPE var: 0.00029249434010125697\n",
            "Total Loss: 0.42616647481918335\n",
            "----------------------------------------\n",
            "Epoch 166\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0451, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.37829798460006714\n",
            "SCOPE mean: 0.05197903513908386, SCOPE var: 0.0002918993995990604\n",
            "Total Loss: 0.42343947291374207\n",
            "----------------------------------------\n",
            "Epoch 167\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0448, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.37593793869018555\n",
            "SCOPE mean: 0.05202537775039673, SCOPE var: 0.00029130210168659687\n",
            "Total Loss: 0.42074090242385864\n",
            "----------------------------------------\n",
            "Epoch 168\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0445, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3736063539981842\n",
            "SCOPE mean: 0.05207017809152603, SCOPE var: 0.00029070267919451\n",
            "Total Loss: 0.4180734157562256\n",
            "----------------------------------------\n",
            "Epoch 169\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0441, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3713029623031616\n",
            "SCOPE mean: 0.05211356282234192, SCOPE var: 0.00029010098660364747\n",
            "Total Loss: 0.415436714887619\n",
            "----------------------------------------\n",
            "Epoch 170\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0438, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.36902737617492676\n",
            "SCOPE mean: 0.05215552821755409, SCOPE var: 0.00028949775150977075\n",
            "Total Loss: 0.4128304719924927\n",
            "----------------------------------------\n",
            "Epoch 171\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0435, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.36678165197372437\n",
            "SCOPE mean: 0.05219603329896927, SCOPE var: 0.0002888925955630839\n",
            "Total Loss: 0.4102571904659271\n",
            "----------------------------------------\n",
            "Epoch 172\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0432, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.36456602811813354\n",
            "SCOPE mean: 0.05223504453897476, SCOPE var: 0.0002882856933865696\n",
            "Total Loss: 0.407717227935791\n",
            "----------------------------------------\n",
            "Epoch 173\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0428, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3623741567134857\n",
            "SCOPE mean: 0.05227266997098923, SCOPE var: 0.0002876772196032107\n",
            "Total Loss: 0.40520012378692627\n",
            "----------------------------------------\n",
            "Epoch 174\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0425, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.36020568013191223\n",
            "SCOPE mean: 0.052309077233076096, SCOPE var: 0.0002870676398742944\n",
            "Total Loss: 0.4027082622051239\n",
            "----------------------------------------\n",
            "Epoch 175\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0422, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.35806190967559814\n",
            "SCOPE mean: 0.052344389259815216, SCOPE var: 0.00028645721613429487\n",
            "Total Loss: 0.400243878364563\n",
            "----------------------------------------\n",
            "Epoch 176\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0419, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3559425473213196\n",
            "SCOPE mean: 0.05237848684191704, SCOPE var: 0.00028584597748704255\n",
            "Total Loss: 0.39780670404434204\n",
            "----------------------------------------\n",
            "Epoch 177\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0415, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.35384660959243774\n",
            "SCOPE mean: 0.05241145193576813, SCOPE var: 0.00028523392393253744\n",
            "Total Loss: 0.3953954577445984\n",
            "----------------------------------------\n",
            "Epoch 178\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0412, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.35177311301231384\n",
            "SCOPE mean: 0.052443090826272964, SCOPE var: 0.00028462070622481406\n",
            "Total Loss: 0.3930090367794037\n",
            "----------------------------------------\n",
            "Epoch 179\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0409, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.34971264004707336\n",
            "SCOPE mean: 0.05247429013252258, SCOPE var: 0.0002840096422005445\n",
            "Total Loss: 0.3906380236148834\n",
            "----------------------------------------\n",
            "Epoch 180\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0406, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3476731479167938\n",
            "SCOPE mean: 0.05250502750277519, SCOPE var: 0.0002834008482750505\n",
            "Total Loss: 0.3882903754711151\n",
            "----------------------------------------\n",
            "Epoch 181\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0403, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3456539213657379\n",
            "SCOPE mean: 0.05253530293703079, SCOPE var: 0.0002827943244483322\n",
            "Total Loss: 0.38596537709236145\n",
            "----------------------------------------\n",
            "Epoch 182\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0400, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3436536490917206\n",
            "SCOPE mean: 0.052565112709999084, SCOPE var: 0.00028219004161655903\n",
            "Total Loss: 0.3836617171764374\n",
            "----------------------------------------\n",
            "Epoch 183\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0397, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3416733145713806\n",
            "SCOPE mean: 0.052594397217035294, SCOPE var: 0.0002815877378452569\n",
            "Total Loss: 0.3813803493976593\n",
            "----------------------------------------\n",
            "Epoch 184\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0394, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3397129774093628\n",
            "SCOPE mean: 0.052623212337493896, SCOPE var: 0.0002809877914842218\n",
            "Total Loss: 0.379121333360672\n",
            "----------------------------------------\n",
            "Epoch 185\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0391, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3377734422683716\n",
            "SCOPE mean: 0.052651550620794296, SCOPE var: 0.0002803901443257928\n",
            "Total Loss: 0.3768855035305023\n",
            "----------------------------------------\n",
            "Epoch 186\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0388, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.33585482835769653\n",
            "SCOPE mean: 0.052679333835840225, SCOPE var: 0.000279794679954648\n",
            "Total Loss: 0.3746730089187622\n",
            "----------------------------------------\n",
            "Epoch 187\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0385, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3339576721191406\n",
            "SCOPE mean: 0.05270655080676079, SCOPE var: 0.0002792013401631266\n",
            "Total Loss: 0.37248435616493225\n",
            "----------------------------------------\n",
            "Epoch 188\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0382, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.33208101987838745\n",
            "SCOPE mean: 0.05273301899433136, SCOPE var: 0.00027860933914780617\n",
            "Total Loss: 0.3703186511993408\n",
            "----------------------------------------\n",
            "Epoch 189\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0380, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.33022862672805786\n",
            "SCOPE mean: 0.05275886133313179, SCOPE var: 0.0002780189970508218\n",
            "Total Loss: 0.36817967891693115\n",
            "----------------------------------------\n",
            "Epoch 190\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0377, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.32840049266815186\n",
            "SCOPE mean: 0.05278369039297104, SCOPE var: 0.000277417158940807\n",
            "Total Loss: 0.366067498922348\n",
            "----------------------------------------\n",
            "Epoch 191\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0374, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.32659003138542175\n",
            "SCOPE mean: 0.0528080090880394, SCOPE var: 0.0002768007980193943\n",
            "Total Loss: 0.3639755845069885\n",
            "----------------------------------------\n",
            "Epoch 192\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0371, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3247999846935272\n",
            "SCOPE mean: 0.05283175781369209, SCOPE var: 0.00027617847081273794\n",
            "Total Loss: 0.36190661787986755\n",
            "----------------------------------------\n",
            "Epoch 193\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0368, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.32303041219711304\n",
            "SCOPE mean: 0.05285485088825226, SCOPE var: 0.00027555867563933134\n",
            "Total Loss: 0.3598604202270508\n",
            "----------------------------------------\n",
            "Epoch 194\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0366, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.32127949595451355\n",
            "SCOPE mean: 0.05287732556462288, SCOPE var: 0.0002749415289144963\n",
            "Total Loss: 0.35783523321151733\n",
            "----------------------------------------\n",
            "Epoch 195\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0363, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3195458650588989\n",
            "SCOPE mean: 0.0528990775346756, SCOPE var: 0.00027432668139226735\n",
            "Total Loss: 0.3558296859264374\n",
            "----------------------------------------\n",
            "Epoch 196\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0360, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.31783053278923035\n",
            "SCOPE mean: 0.052920106798410416, SCOPE var: 0.00027371416217647493\n",
            "Total Loss: 0.3538447916507721\n",
            "----------------------------------------\n",
            "Epoch 197\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0357, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3161318004131317\n",
            "SCOPE mean: 0.05294036120176315, SCOPE var: 0.00027310370933264494\n",
            "Total Loss: 0.35187891125679016\n",
            "----------------------------------------\n",
            "Epoch 198\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0355, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3144497573375702\n",
            "SCOPE mean: 0.052960027009248734, SCOPE var: 0.00027249607956036925\n",
            "Total Loss: 0.3499319851398468\n",
            "----------------------------------------\n",
            "Epoch 199\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0352, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.31278476119041443\n",
            "SCOPE mean: 0.05297907814383507, SCOPE var: 0.00027189127285964787\n",
            "Total Loss: 0.34800437092781067\n",
            "----------------------------------------\n",
            "Epoch 200\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0350, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.311136394739151\n",
            "SCOPE mean: 0.052997395396232605, SCOPE var: 0.0002712887362577021\n",
            "Total Loss: 0.34609562158584595\n",
            "----------------------------------------\n",
            "Epoch 201\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0347, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.30950507521629333\n",
            "SCOPE mean: 0.053014978766441345, SCOPE var: 0.0002706885279621929\n",
            "Total Loss: 0.34420621395111084\n",
            "----------------------------------------\n",
            "Epoch 202\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0344, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.30789071321487427\n",
            "SCOPE mean: 0.053031813353300095, SCOPE var: 0.00027009047335013747\n",
            "Total Loss: 0.3423360586166382\n",
            "----------------------------------------\n",
            "Epoch 203\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0342, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3062918782234192\n",
            "SCOPE mean: 0.05304794758558273, SCOPE var: 0.0002694949507713318\n",
            "Total Loss: 0.3404836058616638\n",
            "----------------------------------------\n",
            "Epoch 204\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0339, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3047012984752655\n",
            "SCOPE mean: 0.05306340381503105, SCOPE var: 0.0002689020475372672\n",
            "Total Loss: 0.33864182233810425\n",
            "----------------------------------------\n",
            "Epoch 205\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0337, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.30312129855155945\n",
            "SCOPE mean: 0.053078874945640564, SCOPE var: 0.0002683143538888544\n",
            "Total Loss: 0.3368123769760132\n",
            "----------------------------------------\n",
            "Epoch 206\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0334, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.30155715346336365\n",
            "SCOPE mean: 0.053094297647476196, SCOPE var: 0.00026773111312650144\n",
            "Total Loss: 0.33500081300735474\n",
            "----------------------------------------\n",
            "Epoch 207\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0332, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3000088334083557\n",
            "SCOPE mean: 0.05309809744358063, SCOPE var: 0.00026710086967796087\n",
            "Total Loss: 0.3332071006298065\n",
            "----------------------------------------\n",
            "Epoch 208\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0330, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.29847419261932373\n",
            "SCOPE mean: 0.05308504030108452, SCOPE var: 0.00026640662690624595\n",
            "Total Loss: 0.33142903447151184\n",
            "----------------------------------------\n",
            "Epoch 209\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0327, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.29695141315460205\n",
            "SCOPE mean: 0.05307183787226677, SCOPE var: 0.0002657177101355046\n",
            "Total Loss: 0.32966479659080505\n",
            "----------------------------------------\n",
            "Epoch 210\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0325, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2954428791999817\n",
            "SCOPE mean: 0.05305841192603111, SCOPE var: 0.0002650334208738059\n",
            "Total Loss: 0.32791680097579956\n",
            "----------------------------------------\n",
            "Epoch 211\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0322, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2939487099647522\n",
            "SCOPE mean: 0.05304469168186188, SCOPE var: 0.00026435358449816704\n",
            "Total Loss: 0.3261851668357849\n",
            "----------------------------------------\n",
            "Epoch 212\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0320, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.29246729612350464\n",
            "SCOPE mean: 0.05303063988685608, SCOPE var: 0.00026367808459326625\n",
            "Total Loss: 0.32446831464767456\n",
            "----------------------------------------\n",
            "Epoch 213\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0318, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2909986674785614\n",
            "SCOPE mean: 0.05301623418927193, SCOPE var: 0.00026300642639398575\n",
            "Total Loss: 0.3227662742137909\n",
            "----------------------------------------\n",
            "Epoch 214\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0315, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2895435094833374\n",
            "SCOPE mean: 0.05300145223736763, SCOPE var: 0.000262338639004156\n",
            "Total Loss: 0.3210797905921936\n",
            "----------------------------------------\n",
            "Epoch 215\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0313, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.28810080885887146\n",
            "SCOPE mean: 0.05298631638288498, SCOPE var: 0.0002616748388390988\n",
            "Total Loss: 0.31940779089927673\n",
            "----------------------------------------\n",
            "Epoch 216\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0311, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.28667086362838745\n",
            "SCOPE mean: 0.05297080799937248, SCOPE var: 0.0002610149094834924\n",
            "Total Loss: 0.31775057315826416\n",
            "----------------------------------------\n",
            "Epoch 217\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0309, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2852542996406555\n",
            "SCOPE mean: 0.05295493081212044, SCOPE var: 0.00026034709298983216\n",
            "Total Loss: 0.3161090314388275\n",
            "----------------------------------------\n",
            "Epoch 218\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0306, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.28385129570961\n",
            "SCOPE mean: 0.0529385544359684, SCOPE var: 0.0002596724661998451\n",
            "Total Loss: 0.31448331475257874\n",
            "----------------------------------------\n",
            "Epoch 219\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0304, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2824607491493225\n",
            "SCOPE mean: 0.05292161926627159, SCOPE var: 0.00025900176842696965\n",
            "Total Loss: 0.31287211179733276\n",
            "----------------------------------------\n",
            "Epoch 220\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0302, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2810830771923065\n",
            "SCOPE mean: 0.052904192358255386, SCOPE var: 0.00025833502877503633\n",
            "Total Loss: 0.31127575039863586\n",
            "----------------------------------------\n",
            "Epoch 221\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0300, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.27971747517585754\n",
            "SCOPE mean: 0.0528862364590168, SCOPE var: 0.00025767178158275783\n",
            "Total Loss: 0.3096839189529419\n",
            "----------------------------------------\n",
            "Epoch 222\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0297, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2783622443675995\n",
            "SCOPE mean: 0.052859704941511154, SCOPE var: 0.00025694482610560954\n",
            "Total Loss: 0.30810365080833435\n",
            "----------------------------------------\n",
            "Epoch 223\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0295, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2770181894302368\n",
            "SCOPE mean: 0.052826929837465286, SCOPE var: 0.0002561756409704685\n",
            "Total Loss: 0.3065369129180908\n",
            "----------------------------------------\n",
            "Epoch 224\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0293, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2756851613521576\n",
            "SCOPE mean: 0.052792515605688095, SCOPE var: 0.00025540642673149705\n",
            "Total Loss: 0.3049834668636322\n",
            "----------------------------------------\n",
            "Epoch 225\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0291, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2743628919124603\n",
            "SCOPE mean: 0.0527566522359848, SCOPE var: 0.00025463782367296517\n",
            "Total Loss: 0.303443044424057\n",
            "----------------------------------------\n",
            "Epoch 226\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0289, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2730506360530853\n",
            "SCOPE mean: 0.05271940305829048, SCOPE var: 0.000253870093729347\n",
            "Total Loss: 0.30191487073898315\n",
            "----------------------------------------\n",
            "Epoch 227\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0287, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2717474102973938\n",
            "SCOPE mean: 0.0526808425784111, SCOPE var: 0.0002531031786929816\n",
            "Total Loss: 0.3003979027271271\n",
            "----------------------------------------\n",
            "Epoch 228\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0284, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.27045443654060364\n",
            "SCOPE mean: 0.05264117568731308, SCOPE var: 0.00025233766064047813\n",
            "Total Loss: 0.2988933026790619\n",
            "----------------------------------------\n",
            "Epoch 229\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0282, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.26917213201522827\n",
            "SCOPE mean: 0.05260039493441582, SCOPE var: 0.00025157356867566705\n",
            "Total Loss: 0.29740145802497864\n",
            "----------------------------------------\n",
            "Epoch 230\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0280, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2678951621055603\n",
            "SCOPE mean: 0.05255855619907379, SCOPE var: 0.0002508112811483443\n",
            "Total Loss: 0.295916885137558\n",
            "----------------------------------------\n",
            "Epoch 231\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0278, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2666279077529907\n",
            "SCOPE mean: 0.0525192990899086, SCOPE var: 0.00025009887758642435\n",
            "Total Loss: 0.29444384574890137\n",
            "----------------------------------------\n",
            "Epoch 232\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0276, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.26537102460861206\n",
            "SCOPE mean: 0.05248255655169487, SCOPE var: 0.00024943784228526056\n",
            "Total Loss: 0.29298296570777893\n",
            "----------------------------------------\n",
            "Epoch 233\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0274, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.26412492990493774\n",
            "SCOPE mean: 0.05244237184524536, SCOPE var: 0.0002487468591425568\n",
            "Total Loss: 0.2915346920490265\n",
            "----------------------------------------\n",
            "Epoch 234\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0272, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.26288941502571106\n",
            "SCOPE mean: 0.05240180715918541, SCOPE var: 0.0002480589901097119\n",
            "Total Loss: 0.29009878635406494\n",
            "----------------------------------------\n",
            "Epoch 235\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0270, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.26166442036628723\n",
            "SCOPE mean: 0.052360888570547104, SCOPE var: 0.00024737438070587814\n",
            "Total Loss: 0.28867530822753906\n",
            "----------------------------------------\n",
            "Epoch 236\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0268, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2604498267173767\n",
            "SCOPE mean: 0.05231964588165283, SCOPE var: 0.0002466929436195642\n",
            "Total Loss: 0.2872641682624817\n",
            "----------------------------------------\n",
            "Epoch 237\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0266, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.25924524664878845\n",
            "SCOPE mean: 0.05227813869714737, SCOPE var: 0.00024601496988907456\n",
            "Total Loss: 0.28586477041244507\n",
            "----------------------------------------\n",
            "Epoch 238\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0264, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.25804805755615234\n",
            "SCOPE mean: 0.05223635956645012, SCOPE var: 0.00024534037220291793\n",
            "Total Loss: 0.2844744622707367\n",
            "----------------------------------------\n",
            "Epoch 239\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0262, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2568580210208893\n",
            "SCOPE mean: 0.05219448357820511, SCOPE var: 0.0002446697617415339\n",
            "Total Loss: 0.28309375047683716\n",
            "----------------------------------------\n",
            "Epoch 240\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0260, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2556738257408142\n",
            "SCOPE mean: 0.05215251445770264, SCOPE var: 0.000244020382524468\n",
            "Total Loss: 0.2817208468914032\n",
            "----------------------------------------\n",
            "Epoch 241\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0259, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.25449976325035095\n",
            "SCOPE mean: 0.05211048573255539, SCOPE var: 0.00024339019728358835\n",
            "Total Loss: 0.28035950660705566\n",
            "----------------------------------------\n",
            "Epoch 242\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0257, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2533354163169861\n",
            "SCOPE mean: 0.05206870660185814, SCOPE var: 0.00024276479962281883\n",
            "Total Loss: 0.27900931239128113\n",
            "----------------------------------------\n",
            "Epoch 243\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0255, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.25217923521995544\n",
            "SCOPE mean: 0.05202721059322357, SCOPE var: 0.00024214440782088786\n",
            "Total Loss: 0.27765172719955444\n",
            "----------------------------------------\n",
            "Epoch 244\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0253, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.25103065371513367\n",
            "SCOPE mean: 0.05198371410369873, SCOPE var: 0.00024151997058652341\n",
            "Total Loss: 0.27630308270454407\n",
            "----------------------------------------\n",
            "Epoch 245\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0251, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.24988818168640137\n",
            "SCOPE mean: 0.051938414573669434, SCOPE var: 0.00024089223006740212\n",
            "Total Loss: 0.27496200799942017\n",
            "----------------------------------------\n",
            "Epoch 246\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0249, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2487500011920929\n",
            "SCOPE mean: 0.051891859620809555, SCOPE var: 0.0002402629907010123\n",
            "Total Loss: 0.27362650632858276\n",
            "----------------------------------------\n",
            "Epoch 247\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0247, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.24761956930160522\n",
            "SCOPE mean: 0.05184417590498924, SCOPE var: 0.0002396328200120479\n",
            "Total Loss: 0.2723000943660736\n",
            "----------------------------------------\n",
            "Epoch 248\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0245, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2464972585439682\n",
            "SCOPE mean: 0.05179548263549805, SCOPE var: 0.00023900219821371138\n",
            "Total Loss: 0.27098318934440613\n",
            "----------------------------------------\n",
            "Epoch 249\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0243, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.24538305401802063\n",
            "SCOPE mean: 0.05174587294459343, SCOPE var: 0.00023837166372686625\n",
            "Total Loss: 0.2696758508682251\n",
            "----------------------------------------\n",
            "Epoch 250\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0241, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.24427734315395355\n",
            "SCOPE mean: 0.051695436239242554, SCOPE var: 0.0002377416822127998\n",
            "Total Loss: 0.26837846636772156\n",
            "----------------------------------------\n",
            "Epoch 251\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0239, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.243179589509964\n",
            "SCOPE mean: 0.05164424329996109, SCOPE var: 0.00023711258836556226\n",
            "Total Loss: 0.2670903503894806\n",
            "----------------------------------------\n",
            "Epoch 252\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0237, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.24208961427211761\n",
            "SCOPE mean: 0.05159240588545799, SCOPE var: 0.00023648483329452574\n",
            "Total Loss: 0.2658115029335022\n",
            "----------------------------------------\n",
            "Epoch 253\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0235, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.24100786447525024\n",
            "SCOPE mean: 0.05154148116707802, SCOPE var: 0.00023589377815369517\n",
            "Total Loss: 0.26454249024391174\n",
            "----------------------------------------\n",
            "Epoch 254\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0233, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2399316132068634\n",
            "SCOPE mean: 0.051490794867277145, SCOPE var: 0.00023532200430054218\n",
            "Total Loss: 0.26328057050704956\n",
            "----------------------------------------\n",
            "Epoch 255\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0232, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.23885098099708557\n",
            "SCOPE mean: 0.05143985524773598, SCOPE var: 0.00023475231137126684\n",
            "Total Loss: 0.26201626658439636\n",
            "----------------------------------------\n",
            "Epoch 256\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0230, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.23777766525745392\n",
            "SCOPE mean: 0.0513886958360672, SCOPE var: 0.00023418475757353008\n",
            "Total Loss: 0.26076099276542664\n",
            "----------------------------------------\n",
            "Epoch 257\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0228, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.23671235144138336\n",
            "SCOPE mean: 0.05133741348981857, SCOPE var: 0.00023361977946478873\n",
            "Total Loss: 0.2595154047012329\n",
            "----------------------------------------\n",
            "Epoch 258\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0226, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.23565492033958435\n",
            "SCOPE mean: 0.05128607898950577, SCOPE var: 0.000233057580771856\n",
            "Total Loss: 0.25827938318252563\n",
            "----------------------------------------\n",
            "Epoch 259\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0224, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.23460371792316437\n",
            "SCOPE mean: 0.051234666258096695, SCOPE var: 0.00023249835066962987\n",
            "Total Loss: 0.25705114006996155\n",
            "----------------------------------------\n",
            "Epoch 260\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0223, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2335595041513443\n",
            "SCOPE mean: 0.05118320509791374, SCOPE var: 0.00023194216191768646\n",
            "Total Loss: 0.25583139061927795\n",
            "----------------------------------------\n",
            "Epoch 261\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0221, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.23252300918102264\n",
            "SCOPE mean: 0.0511317104101181, SCOPE var: 0.0002313892327947542\n",
            "Total Loss: 0.2546210289001465\n",
            "----------------------------------------\n",
            "Epoch 262\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0219, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.23149439692497253\n",
            "SCOPE mean: 0.05108020454645157, SCOPE var: 0.00023083943233359605\n",
            "Total Loss: 0.2534202039241791\n",
            "----------------------------------------\n",
            "Epoch 263\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0218, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.23047351837158203\n",
            "SCOPE mean: 0.05102863907814026, SCOPE var: 0.00023029283329378814\n",
            "Total Loss: 0.2522287368774414\n",
            "----------------------------------------\n",
            "Epoch 264\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0216, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.22946061193943024\n",
            "SCOPE mean: 0.050977107137441635, SCOPE var: 0.00022974959574639797\n",
            "Total Loss: 0.25104689598083496\n",
            "----------------------------------------\n",
            "Epoch 265\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0214, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2284555584192276\n",
            "SCOPE mean: 0.05092551186680794, SCOPE var: 0.00022920961782801896\n",
            "Total Loss: 0.24987444281578064\n",
            "----------------------------------------\n",
            "Epoch 266\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0213, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.22745352983474731\n",
            "SCOPE mean: 0.05087392032146454, SCOPE var: 0.00022867301595397294\n",
            "Total Loss: 0.24870659410953522\n",
            "----------------------------------------\n",
            "Epoch 267\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0211, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2264556884765625\n",
            "SCOPE mean: 0.05082225427031517, SCOPE var: 0.00022813963005319238\n",
            "Total Loss: 0.24754448235034943\n",
            "----------------------------------------\n",
            "Epoch 268\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0209, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.22546471655368805\n",
            "SCOPE mean: 0.05077044665813446, SCOPE var: 0.0002276093582622707\n",
            "Total Loss: 0.24639075994491577\n",
            "----------------------------------------\n",
            "Epoch 269\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0208, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2244809865951538\n",
            "SCOPE mean: 0.050718531012535095, SCOPE var: 0.00022708225878886878\n",
            "Total Loss: 0.2452453225851059\n",
            "----------------------------------------\n",
            "Epoch 270\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0206, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.22350214421749115\n",
            "SCOPE mean: 0.050666444003582, SCOPE var: 0.00022655812790617347\n",
            "Total Loss: 0.24410206079483032\n",
            "----------------------------------------\n",
            "Epoch 271\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0204, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.22251811623573303\n",
            "SCOPE mean: 0.05061402544379234, SCOPE var: 0.00022603789693675935\n",
            "Total Loss: 0.24294015765190125\n",
            "----------------------------------------\n",
            "Epoch 272\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0202, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.221538245677948\n",
            "SCOPE mean: 0.05056132376194, SCOPE var: 0.0002255215513287112\n",
            "Total Loss: 0.2417834848165512\n",
            "----------------------------------------\n",
            "Epoch 273\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0201, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.22055672109127045\n",
            "SCOPE mean: 0.050507552921772, SCOPE var: 0.00022496395104099065\n",
            "Total Loss: 0.24063682556152344\n",
            "----------------------------------------\n",
            "Epoch 274\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0199, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.21957728266716003\n",
            "SCOPE mean: 0.050453025847673416, SCOPE var: 0.00022437606821767986\n",
            "Total Loss: 0.2394995242357254\n",
            "----------------------------------------\n",
            "Epoch 275\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0198, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2185990810394287\n",
            "SCOPE mean: 0.05039824917912483, SCOPE var: 0.00022379124129656702\n",
            "Total Loss: 0.238365039229393\n",
            "----------------------------------------\n",
            "Epoch 276\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0196, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.21762651205062866\n",
            "SCOPE mean: 0.05034271255135536, SCOPE var: 0.00022320874268189073\n",
            "Total Loss: 0.23723754286766052\n",
            "----------------------------------------\n",
            "Epoch 277\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0195, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.21666011214256287\n",
            "SCOPE mean: 0.05028663948178291, SCOPE var: 0.00022262867423705757\n",
            "Total Loss: 0.2361176311969757\n",
            "----------------------------------------\n",
            "Epoch 278\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0193, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2156994342803955\n",
            "SCOPE mean: 0.050230272114276886, SCOPE var: 0.00022205083223525435\n",
            "Total Loss: 0.23500490188598633\n",
            "----------------------------------------\n",
            "Epoch 279\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0192, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.21474526822566986\n",
            "SCOPE mean: 0.05017372965812683, SCOPE var: 0.00022147581330500543\n",
            "Total Loss: 0.23390009999275208\n",
            "----------------------------------------\n",
            "Epoch 280\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0190, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.21379688382148743\n",
            "SCOPE mean: 0.050117067992687225, SCOPE var: 0.00022090373386163265\n",
            "Total Loss: 0.23280251026153564\n",
            "----------------------------------------\n",
            "Epoch 281\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0189, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.21285377442836761\n",
            "SCOPE mean: 0.05006023496389389, SCOPE var: 0.00022033450659364462\n",
            "Total Loss: 0.23171159625053406\n",
            "----------------------------------------\n",
            "Epoch 282\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0187, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.21191620826721191\n",
            "SCOPE mean: 0.04999590292572975, SCOPE var: 0.00021971756359562278\n",
            "Total Loss: 0.23062759637832642\n",
            "----------------------------------------\n",
            "Epoch 283\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0186, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.21098418533802032\n",
            "SCOPE mean: 0.04992067813873291, SCOPE var: 0.00021903045126236975\n",
            "Total Loss: 0.22955046594142914\n",
            "----------------------------------------\n",
            "Epoch 284\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0184, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2100558876991272\n",
            "SCOPE mean: 0.049845121800899506, SCOPE var: 0.0002183467149734497\n",
            "Total Loss: 0.22847844660282135\n",
            "----------------------------------------\n",
            "Epoch 285\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0183, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.20913507044315338\n",
            "SCOPE mean: 0.04976914823055267, SCOPE var: 0.00021766623831354082\n",
            "Total Loss: 0.22741514444351196\n",
            "----------------------------------------\n",
            "Epoch 286\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0181, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.20822103321552277\n",
            "SCOPE mean: 0.049692828208208084, SCOPE var: 0.00021698929776903242\n",
            "Total Loss: 0.22635994851589203\n",
            "----------------------------------------\n",
            "Epoch 287\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0180, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.20731419324874878\n",
            "SCOPE mean: 0.049673862755298615, SCOPE var: 0.0002163208555430174\n",
            "Total Loss: 0.22531333565711975\n",
            "----------------------------------------\n",
            "Epoch 288\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0179, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2064136117696762\n",
            "SCOPE mean: 0.04969741031527519, SCOPE var: 0.00021565984934568405\n",
            "Total Loss: 0.22427430748939514\n",
            "----------------------------------------\n",
            "Epoch 289\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0177, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2055194079875946\n",
            "SCOPE mean: 0.049720440059900284, SCOPE var: 0.00021500267030205578\n",
            "Total Loss: 0.22324296832084656\n",
            "----------------------------------------\n",
            "Epoch 290\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0176, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.20463109016418457\n",
            "SCOPE mean: 0.04974295198917389, SCOPE var: 0.00021434936206787825\n",
            "Total Loss: 0.22221867740154266\n",
            "----------------------------------------\n",
            "Epoch 291\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0175, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.20374761521816254\n",
            "SCOPE mean: 0.04976506158709526, SCOPE var: 0.00021369950263760984\n",
            "Total Loss: 0.22120040655136108\n",
            "----------------------------------------\n",
            "Epoch 292\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0173, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.20287060737609863\n",
            "SCOPE mean: 0.049786798655986786, SCOPE var: 0.00021305331028997898\n",
            "Total Loss: 0.22018980979919434\n",
            "----------------------------------------\n",
            "Epoch 293\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0172, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.20200005173683167\n",
            "SCOPE mean: 0.04980813339352608, SCOPE var: 0.00021241068316157907\n",
            "Total Loss: 0.2191869169473648\n",
            "----------------------------------------\n",
            "Epoch 294\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0171, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.20113663375377655\n",
            "SCOPE mean: 0.04982908070087433, SCOPE var: 0.00021177210146561265\n",
            "Total Loss: 0.21819241344928741\n",
            "----------------------------------------\n",
            "Epoch 295\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0169, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.20027804374694824\n",
            "SCOPE mean: 0.04984967038035393, SCOPE var: 0.00021113755065016448\n",
            "Total Loss: 0.21720494329929352\n",
            "----------------------------------------\n",
            "Epoch 296\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0168, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.19942550361156464\n",
            "SCOPE mean: 0.04986991733312607, SCOPE var: 0.00021050717623438686\n",
            "Total Loss: 0.2162250578403473\n",
            "----------------------------------------\n",
            "Epoch 297\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0167, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.19857944548130035\n",
            "SCOPE mean: 0.049889810383319855, SCOPE var: 0.00020988086180295795\n",
            "Total Loss: 0.2152528315782547\n",
            "----------------------------------------\n",
            "Epoch 298\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0165, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.19773881137371063\n",
            "SCOPE mean: 0.04990937188267708, SCOPE var: 0.00020925881108269095\n",
            "Total Loss: 0.21428720653057098\n",
            "----------------------------------------\n",
            "Epoch 299\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0164, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.19690528512001038\n",
            "SCOPE mean: 0.04992866516113281, SCOPE var: 0.00020864131511189044\n",
            "Total Loss: 0.21332979202270508\n",
            "----------------------------------------\n",
            "Epoch 300\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0163, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1960778385400772\n",
            "SCOPE mean: 0.04994771257042885, SCOPE var: 0.0002080284320982173\n",
            "Total Loss: 0.21237950026988983\n",
            "----------------------------------------\n",
            "Epoch 301\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0162, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1952545940876007\n",
            "SCOPE mean: 0.0499664843082428, SCOPE var: 0.0002074196672765538\n",
            "Total Loss: 0.2114345133304596\n",
            "----------------------------------------\n",
            "Epoch 302\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0161, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.19443641602993011\n",
            "SCOPE mean: 0.04998510703444481, SCOPE var: 0.0002068154135486111\n",
            "Total Loss: 0.21049563586711884\n",
            "----------------------------------------\n",
            "Epoch 303\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0159, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.19362419843673706\n",
            "SCOPE mean: 0.050003532320261, SCOPE var: 0.0002062155690509826\n",
            "Total Loss: 0.20956377685070038\n",
            "----------------------------------------\n",
            "Epoch 304\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0158, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1928156316280365\n",
            "SCOPE mean: 0.050021685659885406, SCOPE var: 0.00020562006102409214\n",
            "Total Loss: 0.20863664150238037\n",
            "----------------------------------------\n",
            "Epoch 305\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0157, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.19201302528381348\n",
            "SCOPE mean: 0.05003958195447922, SCOPE var: 0.00020502896222751588\n",
            "Total Loss: 0.20771650969982147\n",
            "----------------------------------------\n",
            "Epoch 306\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0156, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.19121617078781128\n",
            "SCOPE mean: 0.05005723237991333, SCOPE var: 0.00020444254914764315\n",
            "Total Loss: 0.2068031132221222\n",
            "----------------------------------------\n",
            "Epoch 307\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0155, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.19042423367500305\n",
            "SCOPE mean: 0.05007469654083252, SCOPE var: 0.00020386086544021964\n",
            "Total Loss: 0.20589515566825867\n",
            "----------------------------------------\n",
            "Epoch 308\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0154, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.18961651623249054\n",
            "SCOPE mean: 0.05009175464510918, SCOPE var: 0.00020328248501755297\n",
            "Total Loss: 0.20497196912765503\n",
            "----------------------------------------\n",
            "Epoch 309\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0152, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.18881244957447052\n",
            "SCOPE mean: 0.050108402967453, SCOPE var: 0.00020270768436603248\n",
            "Total Loss: 0.2040536254644394\n",
            "----------------------------------------\n",
            "Epoch 310\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0151, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.18801192939281464\n",
            "SCOPE mean: 0.0501246303319931, SCOPE var: 0.0002021362161030993\n",
            "Total Loss: 0.20313984155654907\n",
            "----------------------------------------\n",
            "Epoch 311\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0150, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.18721529841423035\n",
            "SCOPE mean: 0.05014048144221306, SCOPE var: 0.00020156873506493866\n",
            "Total Loss: 0.2022312879562378\n",
            "----------------------------------------\n",
            "Epoch 312\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0149, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.18642009794712067\n",
            "SCOPE mean: 0.05015580728650093, SCOPE var: 0.00020100486290175468\n",
            "Total Loss: 0.20132529735565186\n",
            "----------------------------------------\n",
            "Epoch 313\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0148, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.18562979996204376\n",
            "SCOPE mean: 0.05017056316137314, SCOPE var: 0.00020044471602886915\n",
            "Total Loss: 0.20042599737644196\n",
            "----------------------------------------\n",
            "Epoch 314\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0147, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1848418116569519\n",
            "SCOPE mean: 0.05018472671508789, SCOPE var: 0.00019988960411865264\n",
            "Total Loss: 0.19953060150146484\n",
            "----------------------------------------\n",
            "Epoch 315\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0146, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.18405789136886597\n",
            "SCOPE mean: 0.05019828677177429, SCOPE var: 0.00019933938165195286\n",
            "Total Loss: 0.19864019751548767\n",
            "----------------------------------------\n",
            "Epoch 316\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0145, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.18327879905700684\n",
            "SCOPE mean: 0.050211306661367416, SCOPE var: 0.00019879417959600687\n",
            "Total Loss: 0.19775542616844177\n",
            "----------------------------------------\n",
            "Epoch 317\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0144, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1825045943260193\n",
            "SCOPE mean: 0.05022381618618965, SCOPE var: 0.00019825385243166238\n",
            "Total Loss: 0.19687630236148834\n",
            "----------------------------------------\n",
            "Epoch 318\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0143, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.18173517286777496\n",
            "SCOPE mean: 0.05023578181862831, SCOPE var: 0.00019771824008785188\n",
            "Total Loss: 0.19600290060043335\n",
            "----------------------------------------\n",
            "Epoch 319\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0142, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.18097054958343506\n",
            "SCOPE mean: 0.050247304141521454, SCOPE var: 0.0001971873571164906\n",
            "Total Loss: 0.1951352059841156\n",
            "----------------------------------------\n",
            "Epoch 320\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0141, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1802109032869339\n",
            "SCOPE mean: 0.05025830864906311, SCOPE var: 0.00019666099979076535\n",
            "Total Loss: 0.19427341222763062\n",
            "----------------------------------------\n",
            "Epoch 321\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0140, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.17945465445518494\n",
            "SCOPE mean: 0.050268933176994324, SCOPE var: 0.0001961393136298284\n",
            "Total Loss: 0.19341591000556946\n",
            "----------------------------------------\n",
            "Epoch 322\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0139, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.17870254814624786\n",
            "SCOPE mean: 0.05027881637215614, SCOPE var: 0.00019562173110898584\n",
            "Total Loss: 0.19256345927715302\n",
            "----------------------------------------\n",
            "Epoch 323\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0138, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.17795516550540924\n",
            "SCOPE mean: 0.050288036465644836, SCOPE var: 0.00019510829588398337\n",
            "Total Loss: 0.19171662628650665\n",
            "----------------------------------------\n",
            "Epoch 324\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0137, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.17721231281757355\n",
            "SCOPE mean: 0.05029681324958801, SCOPE var: 0.0001945991098182276\n",
            "Total Loss: 0.19087520241737366\n",
            "----------------------------------------\n",
            "Epoch 325\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0136, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1764744222164154\n",
            "SCOPE mean: 0.050305165350437164, SCOPE var: 0.0001940940273925662\n",
            "Total Loss: 0.19003963470458984\n",
            "----------------------------------------\n",
            "Epoch 326\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0135, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1757401078939438\n",
            "SCOPE mean: 0.05031310394406319, SCOPE var: 0.0001935930922627449\n",
            "Total Loss: 0.1892084926366806\n",
            "----------------------------------------\n",
            "Epoch 327\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0134, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.17500890791416168\n",
            "SCOPE mean: 0.05032062903046608, SCOPE var: 0.00019309608615003526\n",
            "Total Loss: 0.18838132917881012\n",
            "----------------------------------------\n",
            "Epoch 328\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0133, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.17428207397460938\n",
            "SCOPE mean: 0.05032782629132271, SCOPE var: 0.00019260318367742002\n",
            "Total Loss: 0.1875593513250351\n",
            "----------------------------------------\n",
            "Epoch 329\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0132, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.17355996370315552\n",
            "SCOPE mean: 0.05033469945192337, SCOPE var: 0.00019211422477383167\n",
            "Total Loss: 0.18674291670322418\n",
            "----------------------------------------\n",
            "Epoch 330\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0131, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.17284272611141205\n",
            "SCOPE mean: 0.05034126341342926, SCOPE var: 0.0001916292676469311\n",
            "Total Loss: 0.18593217432498932\n",
            "----------------------------------------\n",
            "Epoch 331\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0130, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1721300482749939\n",
            "SCOPE mean: 0.050347521901130676, SCOPE var: 0.00019114825408905745\n",
            "Total Loss: 0.18512681126594543\n",
            "----------------------------------------\n",
            "Epoch 332\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0129, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1714228242635727\n",
            "SCOPE mean: 0.05035347118973732, SCOPE var: 0.00019067121320404112\n",
            "Total Loss: 0.18432779610157013\n",
            "----------------------------------------\n",
            "Epoch 333\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0128, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.17072005569934845\n",
            "SCOPE mean: 0.0503590889275074, SCOPE var: 0.0001901981158880517\n",
            "Total Loss: 0.18353402614593506\n",
            "----------------------------------------\n",
            "Epoch 334\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0127, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1700223982334137\n",
            "SCOPE mean: 0.05036436766386032, SCOPE var: 0.00018972890393342823\n",
            "Total Loss: 0.18274618685245514\n",
            "----------------------------------------\n",
            "Epoch 335\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0126, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.16932949423789978\n",
            "SCOPE mean: 0.050369344651699066, SCOPE var: 0.0001892632426461205\n",
            "Total Loss: 0.18196389079093933\n",
            "----------------------------------------\n",
            "Epoch 336\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0125, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.16864152252674103\n",
            "SCOPE mean: 0.05037389695644379, SCOPE var: 0.00018880207790061831\n",
            "Total Loss: 0.18118733167648315\n",
            "----------------------------------------\n",
            "Epoch 337\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0125, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.16795842349529266\n",
            "SCOPE mean: 0.05037793144583702, SCOPE var: 0.00018834631191566586\n",
            "Total Loss: 0.18041642010211945\n",
            "----------------------------------------\n",
            "Epoch 338\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0124, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.16728007793426514\n",
            "SCOPE mean: 0.05038166046142578, SCOPE var: 0.0001878939801827073\n",
            "Total Loss: 0.17965103685855865\n",
            "----------------------------------------\n",
            "Epoch 339\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0123, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1666063666343689\n",
            "SCOPE mean: 0.05038507655262947, SCOPE var: 0.00018744514090940356\n",
            "Total Loss: 0.17889106273651123\n",
            "----------------------------------------\n",
            "Epoch 340\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0122, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.16593647003173828\n",
            "SCOPE mean: 0.050388213247060776, SCOPE var: 0.0001869997358880937\n",
            "Total Loss: 0.17813566327095032\n",
            "----------------------------------------\n",
            "Epoch 341\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0121, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.16527113318443298\n",
            "SCOPE mean: 0.050390999764204025, SCOPE var: 0.00018655770691111684\n",
            "Total Loss: 0.17738556861877441\n",
            "----------------------------------------\n",
            "Epoch 342\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0120, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.16461049020290375\n",
            "SCOPE mean: 0.050393469631671906, SCOPE var: 0.00018611890845932066\n",
            "Total Loss: 0.17664089798927307\n",
            "----------------------------------------\n",
            "Epoch 343\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0119, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.16395437717437744\n",
            "SCOPE mean: 0.05039558932185173, SCOPE var: 0.00018568352970760316\n",
            "Total Loss: 0.17590148746967316\n",
            "----------------------------------------\n",
            "Epoch 344\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0118, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.16330274939537048\n",
            "SCOPE mean: 0.050397392362356186, SCOPE var: 0.00018525107589084655\n",
            "Total Loss: 0.17514988780021667\n",
            "----------------------------------------\n",
            "Epoch 345\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0117, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.16265477240085602\n",
            "SCOPE mean: 0.05040114000439644, SCOPE var: 0.0001848230167524889\n",
            "Total Loss: 0.1743960976600647\n",
            "----------------------------------------\n",
            "Epoch 346\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0116, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1620098501443863\n",
            "SCOPE mean: 0.0504065565764904, SCOPE var: 0.00018439920677337795\n",
            "Total Loss: 0.17364558577537537\n",
            "----------------------------------------\n",
            "Epoch 347\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0115, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.16136810183525085\n",
            "SCOPE mean: 0.05041344463825226, SCOPE var: 0.0001839795004343614\n",
            "Total Loss: 0.17289859056472778\n",
            "----------------------------------------\n",
            "Epoch 348\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0114, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.16072970628738403\n",
            "SCOPE mean: 0.05042135715484619, SCOPE var: 0.00018356517830397934\n",
            "Total Loss: 0.17215535044670105\n",
            "----------------------------------------\n",
            "Epoch 349\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0113, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.160094752907753\n",
            "SCOPE mean: 0.05043027177453041, SCOPE var: 0.0001831546687753871\n",
            "Total Loss: 0.17141607403755188\n",
            "----------------------------------------\n",
            "Epoch 350\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0112, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1594633013010025\n",
            "SCOPE mean: 0.05044008046388626, SCOPE var: 0.00018274784088134766\n",
            "Total Loss: 0.17068088054656982\n",
            "----------------------------------------\n",
            "Epoch 351\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0111, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.15883564949035645\n",
            "SCOPE mean: 0.050450585782527924, SCOPE var: 0.00018234451999887824\n",
            "Total Loss: 0.16995014250278473\n",
            "----------------------------------------\n",
            "Epoch 352\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0110, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1582118272781372\n",
            "SCOPE mean: 0.05046166107058525, SCOPE var: 0.0001819445751607418\n",
            "Total Loss: 0.16922396421432495\n",
            "----------------------------------------\n",
            "Epoch 353\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0109, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1575920283794403\n",
            "SCOPE mean: 0.050473183393478394, SCOPE var: 0.00018154788995161653\n",
            "Total Loss: 0.16850270330905914\n",
            "----------------------------------------\n",
            "Epoch 354\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0108, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.15697607398033142\n",
            "SCOPE mean: 0.05048501491546631, SCOPE var: 0.00018115490092895925\n",
            "Total Loss: 0.16778625547885895\n",
            "----------------------------------------\n",
            "Epoch 355\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0107, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.15636414289474487\n",
            "SCOPE mean: 0.05049704387784004, SCOPE var: 0.00018076534615829587\n",
            "Total Loss: 0.16707465052604675\n",
            "----------------------------------------\n",
            "Epoch 356\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0106, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.15575625002384186\n",
            "SCOPE mean: 0.05050918087363243, SCOPE var: 0.00018037900736089796\n",
            "Total Loss: 0.16636797785758972\n",
            "----------------------------------------\n",
            "Epoch 357\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0105, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1551525592803955\n",
            "SCOPE mean: 0.050519634038209915, SCOPE var: 0.00018001077114604414\n",
            "Total Loss: 0.16566641628742218\n",
            "----------------------------------------\n",
            "Epoch 358\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0104, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.15455137193202972\n",
            "SCOPE mean: 0.050529200583696365, SCOPE var: 0.00017965266306418926\n",
            "Total Loss: 0.16496750712394714\n",
            "----------------------------------------\n",
            "Epoch 359\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0103, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1539534628391266\n",
            "SCOPE mean: 0.05053861439228058, SCOPE var: 0.00017929715977516025\n",
            "Total Loss: 0.16427282989025116\n",
            "----------------------------------------\n",
            "Epoch 360\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0102, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.15335895121097565\n",
            "SCOPE mean: 0.05054805427789688, SCOPE var: 0.00017894606571644545\n",
            "Total Loss: 0.16358251869678497\n",
            "----------------------------------------\n",
            "Epoch 361\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0101, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.15276825428009033\n",
            "SCOPE mean: 0.05056023225188255, SCOPE var: 0.00017862473032437265\n",
            "Total Loss: 0.162896990776062\n",
            "----------------------------------------\n",
            "Epoch 362\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0100, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1521814465522766\n",
            "SCOPE mean: 0.05057213455438614, SCOPE var: 0.0001783057232387364\n",
            "Total Loss: 0.16221635043621063\n",
            "----------------------------------------\n",
            "Epoch 363\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0099, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1515985131263733\n",
            "SCOPE mean: 0.05058366060256958, SCOPE var: 0.0001779888989403844\n",
            "Total Loss: 0.16154059767723083\n",
            "----------------------------------------\n",
            "Epoch 364\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0099, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1510196328163147\n",
            "SCOPE mean: 0.05059482157230377, SCOPE var: 0.00017767421377357095\n",
            "Total Loss: 0.16086989641189575\n",
            "----------------------------------------\n",
            "Epoch 365\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0098, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.15044257044792175\n",
            "SCOPE mean: 0.050605546683073044, SCOPE var: 0.00017736158042680472\n",
            "Total Loss: 0.1602025181055069\n",
            "----------------------------------------\n",
            "Epoch 366\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0097, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.14986826479434967\n",
            "SCOPE mean: 0.05061619356274605, SCOPE var: 0.00017705188656691462\n",
            "Total Loss: 0.15953899919986725\n",
            "----------------------------------------\n",
            "Epoch 367\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0096, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.14929784834384918\n",
            "SCOPE mean: 0.050626643002033234, SCOPE var: 0.00017674488481134176\n",
            "Total Loss: 0.1588802933692932\n",
            "----------------------------------------\n",
            "Epoch 368\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0095, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.14873260259628296\n",
            "SCOPE mean: 0.05064152553677559, SCOPE var: 0.0001764571206877008\n",
            "Total Loss: 0.1582251787185669\n",
            "----------------------------------------\n",
            "Epoch 369\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0094, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.148172065615654\n",
            "SCOPE mean: 0.050656504929065704, SCOPE var: 0.00017617295088712126\n",
            "Total Loss: 0.1575755774974823\n",
            "----------------------------------------\n",
            "Epoch 370\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0093, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1476144939661026\n",
            "SCOPE mean: 0.05067107081413269, SCOPE var: 0.00017589071649126709\n",
            "Total Loss: 0.15693023800849915\n",
            "----------------------------------------\n",
            "Epoch 371\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0092, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.14706078171730042\n",
            "SCOPE mean: 0.05068519711494446, SCOPE var: 0.00017561040294822305\n",
            "Total Loss: 0.15628975629806519\n",
            "----------------------------------------\n",
            "Epoch 372\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0091, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.14651086926460266\n",
            "SCOPE mean: 0.050698913633823395, SCOPE var: 0.00017533201025798917\n",
            "Total Loss: 0.15565405786037445\n",
            "----------------------------------------\n",
            "Epoch 373\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0091, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.14596448838710785\n",
            "SCOPE mean: 0.050712138414382935, SCOPE var: 0.0001750554220052436\n",
            "Total Loss: 0.15502288937568665\n",
            "----------------------------------------\n",
            "Epoch 374\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0090, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.14542073011398315\n",
            "SCOPE mean: 0.05072512850165367, SCOPE var: 0.00017478104564361274\n",
            "Total Loss: 0.15439525246620178\n",
            "----------------------------------------\n",
            "Epoch 375\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0089, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.14488041400909424\n",
            "SCOPE mean: 0.050737813115119934, SCOPE var: 0.00017450879386160523\n",
            "Total Loss: 0.1537719964981079\n",
            "----------------------------------------\n",
            "Epoch 376\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0088, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.14434459805488586\n",
            "SCOPE mean: 0.05075015127658844, SCOPE var: 0.0001742386957630515\n",
            "Total Loss: 0.15315420925617218\n",
            "----------------------------------------\n",
            "Epoch 377\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0087, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.14381204545497894\n",
            "SCOPE mean: 0.050762150436639786, SCOPE var: 0.00017397069314029068\n",
            "Total Loss: 0.15254057943820953\n",
            "----------------------------------------\n",
            "Epoch 378\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0086, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.14327983558177948\n",
            "SCOPE mean: 0.050774410367012024, SCOPE var: 0.00017370616842526942\n",
            "Total Loss: 0.15192753076553345\n",
            "----------------------------------------\n",
            "Epoch 379\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0086, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.14275090396404266\n",
            "SCOPE mean: 0.050786904990673065, SCOPE var: 0.00017344506341032684\n",
            "Total Loss: 0.15131855010986328\n",
            "----------------------------------------\n",
            "Epoch 380\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0085, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.14222551882266998\n",
            "SCOPE mean: 0.05079954117536545, SCOPE var: 0.00017318708705715835\n",
            "Total Loss: 0.15071390569210052\n",
            "----------------------------------------\n",
            "Epoch 381\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0084, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.14170359075069427\n",
            "SCOPE mean: 0.050812266767024994, SCOPE var: 0.000172932050190866\n",
            "Total Loss: 0.1501135379076004\n",
            "----------------------------------------\n",
            "Epoch 382\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0083, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1411849707365036\n",
            "SCOPE mean: 0.05082498490810394, SCOPE var: 0.00017267980729229748\n",
            "Total Loss: 0.14951729774475098\n",
            "----------------------------------------\n",
            "Epoch 383\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0083, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.14066950976848602\n",
            "SCOPE mean: 0.05083771422505379, SCOPE var: 0.00017243031470570713\n",
            "Total Loss: 0.1489250361919403\n",
            "----------------------------------------\n",
            "Epoch 384\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0082, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.14015662670135498\n",
            "SCOPE mean: 0.050850383937358856, SCOPE var: 0.000172183194081299\n",
            "Total Loss: 0.14834271371364594\n",
            "----------------------------------------\n",
            "Epoch 385\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0081, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1396482288837433\n",
            "SCOPE mean: 0.050861604511737823, SCOPE var: 0.00017193646635860205\n",
            "Total Loss: 0.14777091145515442\n",
            "----------------------------------------\n",
            "Epoch 386\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0081, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.13914231956005096\n",
            "SCOPE mean: 0.050871461629867554, SCOPE var: 0.00017169029160868376\n",
            "Total Loss: 0.14720237255096436\n",
            "----------------------------------------\n",
            "Epoch 387\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0080, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.13864001631736755\n",
            "SCOPE mean: 0.050879985094070435, SCOPE var: 0.00017144466983154416\n",
            "Total Loss: 0.14663805067539215\n",
            "----------------------------------------\n",
            "Epoch 388\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0079, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1381414830684662\n",
            "SCOPE mean: 0.050887275487184525, SCOPE var: 0.0001711997902020812\n",
            "Total Loss: 0.14607827365398407\n",
            "----------------------------------------\n",
            "Epoch 389\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0079, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.13764651119709015\n",
            "SCOPE mean: 0.050893425941467285, SCOPE var: 0.0001709557109279558\n",
            "Total Loss: 0.145522803068161\n",
            "----------------------------------------\n",
            "Epoch 390\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0078, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1371551752090454\n",
            "SCOPE mean: 0.05089850723743439, SCOPE var: 0.00017071238835342228\n",
            "Total Loss: 0.14497168362140656\n",
            "----------------------------------------\n",
            "Epoch 391\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0078, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.13666746020317078\n",
            "SCOPE mean: 0.05090261250734329, SCOPE var: 0.00017046998254954815\n",
            "Total Loss: 0.14442488551139832\n",
            "----------------------------------------\n",
            "Epoch 392\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0077, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.13618329167366028\n",
            "SCOPE mean: 0.05090580880641937, SCOPE var: 0.00017022858082782477\n",
            "Total Loss: 0.14388230443000793\n",
            "----------------------------------------\n",
            "Epoch 393\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0076, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.13570252060890198\n",
            "SCOPE mean: 0.050908155739307404, SCOPE var: 0.00016998818318825215\n",
            "Total Loss: 0.14334377646446228\n",
            "----------------------------------------\n",
            "Epoch 394\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0076, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.13522428274154663\n",
            "SCOPE mean: 0.050909727811813354, SCOPE var: 0.00016974893514998257\n",
            "Total Loss: 0.1428084820508957\n",
            "----------------------------------------\n",
            "Epoch 395\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0075, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.13474777340888977\n",
            "SCOPE mean: 0.050910964608192444, SCOPE var: 0.00016951175348367542\n",
            "Total Loss: 0.1422756463289261\n",
            "----------------------------------------\n",
            "Epoch 396\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0075, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.13427506387233734\n",
            "SCOPE mean: 0.05091184750199318, SCOPE var: 0.00016927655087783933\n",
            "Total Loss: 0.14174716174602509\n",
            "----------------------------------------\n",
            "Epoch 397\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0074, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.13380567729473114\n",
            "SCOPE mean: 0.05091254785656929, SCOPE var: 0.00016902423521969467\n",
            "Total Loss: 0.14122256636619568\n",
            "----------------------------------------\n",
            "Epoch 398\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0074, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.13333885371685028\n",
            "SCOPE mean: 0.05091310292482376, SCOPE var: 0.00016874828725121915\n",
            "Total Loss: 0.1407010853290558\n",
            "----------------------------------------\n",
            "Epoch 399\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0073, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1328752040863037\n",
            "SCOPE mean: 0.050913263112306595, SCOPE var: 0.0001684747403487563\n",
            "Total Loss: 0.14018332958221436\n",
            "----------------------------------------\n",
            "Epoch 400\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0073, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.13241207599639893\n",
            "SCOPE mean: 0.05091305077075958, SCOPE var: 0.00016820355085656047\n",
            "Total Loss: 0.13966409862041473\n",
            "----------------------------------------\n",
            "Epoch 401\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0072, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1319514960050583\n",
            "SCOPE mean: 0.050912536680698395, SCOPE var: 0.00016793454415164888\n",
            "Total Loss: 0.13914786279201508\n",
            "----------------------------------------\n",
            "Epoch 402\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0071, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.13149358332157135\n",
            "SCOPE mean: 0.050911735743284225, SCOPE var: 0.00016766776388976723\n",
            "Total Loss: 0.1386347860097885\n",
            "----------------------------------------\n",
            "Epoch 403\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0071, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.13103826344013214\n",
            "SCOPE mean: 0.05091067776083946, SCOPE var: 0.00016740318096708506\n",
            "Total Loss: 0.13812480866909027\n",
            "----------------------------------------\n",
            "Epoch 404\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0070, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1305856853723526\n",
            "SCOPE mean: 0.05090935155749321, SCOPE var: 0.0001671407517278567\n",
            "Total Loss: 0.1376180648803711\n",
            "----------------------------------------\n",
            "Epoch 405\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0070, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.13013584911823273\n",
            "SCOPE mean: 0.05090775713324547, SCOPE var: 0.00016688038886059076\n",
            "Total Loss: 0.13711461424827576\n",
            "----------------------------------------\n",
            "Epoch 406\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0069, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.12968865036964417\n",
            "SCOPE mean: 0.05090593546628952, SCOPE var: 0.00016662219422869384\n",
            "Total Loss: 0.13661439716815948\n",
            "----------------------------------------\n",
            "Epoch 407\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0069, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.12924394011497498\n",
            "SCOPE mean: 0.050903815776109695, SCOPE var: 0.00016636602231301367\n",
            "Total Loss: 0.13611716032028198\n",
            "----------------------------------------\n",
            "Epoch 408\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0068, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1288018822669983\n",
            "SCOPE mean: 0.05090147256851196, SCOPE var: 0.00016611198952887207\n",
            "Total Loss: 0.1356230527162552\n",
            "----------------------------------------\n",
            "Epoch 409\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0068, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.12836112082004547\n",
            "SCOPE mean: 0.050898876041173935, SCOPE var: 0.000165859964909032\n",
            "Total Loss: 0.13513049483299255\n",
            "----------------------------------------\n",
            "Epoch 410\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0067, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.12792302668094635\n",
            "SCOPE mean: 0.05089638754725456, SCOPE var: 0.0001656104577705264\n",
            "Total Loss: 0.13464102149009705\n",
            "----------------------------------------\n",
            "Epoch 411\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0067, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1274874210357666\n",
            "SCOPE mean: 0.050893984735012054, SCOPE var: 0.00016536327893845737\n",
            "Total Loss: 0.13415443897247314\n",
            "----------------------------------------\n",
            "Epoch 412\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0066, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.12705457210540771\n",
            "SCOPE mean: 0.05089164525270462, SCOPE var: 0.00016511838475707918\n",
            "Total Loss: 0.13367104530334473\n",
            "----------------------------------------\n",
            "Epoch 413\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0066, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.12662434577941895\n",
            "SCOPE mean: 0.05088934302330017, SCOPE var: 0.00016487597895320505\n",
            "Total Loss: 0.13319066166877747\n",
            "----------------------------------------\n",
            "Epoch 414\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0065, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1261952519416809\n",
            "SCOPE mean: 0.05088699236512184, SCOPE var: 0.00016463590145576745\n",
            "Total Loss: 0.13271184265613556\n",
            "----------------------------------------\n",
            "Epoch 415\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0065, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.12576840817928314\n",
            "SCOPE mean: 0.05088457092642784, SCOPE var: 0.00016439807950519025\n",
            "Total Loss: 0.13223564624786377\n",
            "----------------------------------------\n",
            "Epoch 416\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0064, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.12534400820732117\n",
            "SCOPE mean: 0.05088204890489578, SCOPE var: 0.00016416225116699934\n",
            "Total Loss: 0.1317623257637024\n",
            "----------------------------------------\n",
            "Epoch 417\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0064, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.12492160499095917\n",
            "SCOPE mean: 0.050879284739494324, SCOPE var: 0.00016390980454161763\n",
            "Total Loss: 0.13129140436649323\n",
            "----------------------------------------\n",
            "Epoch 418\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0063, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.12450168281793594\n",
            "SCOPE mean: 0.05087641254067421, SCOPE var: 0.00016365271585527807\n",
            "Total Loss: 0.13082337379455566\n",
            "----------------------------------------\n",
            "Epoch 419\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0063, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.12408392876386642\n",
            "SCOPE mean: 0.05087343603372574, SCOPE var: 0.000163397824508138\n",
            "Total Loss: 0.13035792112350464\n",
            "----------------------------------------\n",
            "Epoch 420\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0062, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1236652359366417\n",
            "SCOPE mean: 0.05087120085954666, SCOPE var: 0.0001631459454074502\n",
            "Total Loss: 0.12989185750484467\n",
            "----------------------------------------\n",
            "Epoch 421\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0062, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.12324882298707962\n",
            "SCOPE mean: 0.05086958780884743, SCOPE var: 0.00016289687482640147\n",
            "Total Loss: 0.12942840158939362\n",
            "----------------------------------------\n",
            "Epoch 422\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0061, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.12283498793840408\n",
            "SCOPE mean: 0.05086851119995117, SCOPE var: 0.00016265058366116136\n",
            "Total Loss: 0.12896792590618134\n",
            "----------------------------------------\n",
            "Epoch 423\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0061, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.12242352217435837\n",
            "SCOPE mean: 0.050867896527051926, SCOPE var: 0.0001624069846002385\n",
            "Total Loss: 0.12851014733314514\n",
            "----------------------------------------\n",
            "Epoch 424\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0060, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.12201424688100815\n",
            "SCOPE mean: 0.05086768418550491, SCOPE var: 0.00016216599033214152\n",
            "Total Loss: 0.1280549019575119\n",
            "----------------------------------------\n",
            "Epoch 425\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0060, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1216074526309967\n",
            "SCOPE mean: 0.050867799669504166, SCOPE var: 0.00016192751354537904\n",
            "Total Loss: 0.1276024878025055\n",
            "----------------------------------------\n",
            "Epoch 426\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0059, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.12120307236909866\n",
            "SCOPE mean: 0.05086817964911461, SCOPE var: 0.00016169145237654448\n",
            "Total Loss: 0.12715284526348114\n",
            "----------------------------------------\n",
            "Epoch 427\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0059, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.12080089747905731\n",
            "SCOPE mean: 0.05086876079440117, SCOPE var: 0.00016145787958521396\n",
            "Total Loss: 0.12670575082302094\n",
            "----------------------------------------\n",
            "Epoch 428\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0059, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.12040093541145325\n",
            "SCOPE mean: 0.05086950212717056, SCOPE var: 0.0001612266496522352\n",
            "Total Loss: 0.12626123428344727\n",
            "----------------------------------------\n",
            "Epoch 429\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0058, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.12000304460525513\n",
            "SCOPE mean: 0.05087033659219742, SCOPE var: 0.00016099767526611686\n",
            "Total Loss: 0.12581917643547058\n",
            "----------------------------------------\n",
            "Epoch 430\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0058, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11960732191801071\n",
            "SCOPE mean: 0.050871361047029495, SCOPE var: 0.00016077110194601119\n",
            "Total Loss: 0.12537965178489685\n",
            "----------------------------------------\n",
            "Epoch 431\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0057, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11921398341655731\n",
            "SCOPE mean: 0.050872523337602615, SCOPE var: 0.0001605468278285116\n",
            "Total Loss: 0.12494305521249771\n",
            "----------------------------------------\n",
            "Epoch 432\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0057, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11882312595844269\n",
            "SCOPE mean: 0.05087374150753021, SCOPE var: 0.00016032482380978763\n",
            "Total Loss: 0.12451036274433136\n",
            "----------------------------------------\n",
            "Epoch 433\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0056, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1184346005320549\n",
            "SCOPE mean: 0.0508749820291996, SCOPE var: 0.00016010497347451746\n",
            "Total Loss: 0.12408032268285751\n",
            "----------------------------------------\n",
            "Epoch 434\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0056, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11804856359958649\n",
            "SCOPE mean: 0.05087624490261078, SCOPE var: 0.00015988724771887064\n",
            "Total Loss: 0.1236530989408493\n",
            "----------------------------------------\n",
            "Epoch 435\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0056, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11766516417264938\n",
            "SCOPE mean: 0.05087748169898987, SCOPE var: 0.00015967154467944056\n",
            "Total Loss: 0.12322898209095001\n",
            "----------------------------------------\n",
            "Epoch 436\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0055, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11728512495756149\n",
            "SCOPE mean: 0.050878655165433884, SCOPE var: 0.00015945818449836224\n",
            "Total Loss: 0.12280880659818649\n",
            "----------------------------------------\n",
            "Epoch 437\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0055, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11690782755613327\n",
            "SCOPE mean: 0.05088016390800476, SCOPE var: 0.00015924395120237023\n",
            "Total Loss: 0.12239214777946472\n",
            "----------------------------------------\n",
            "Epoch 438\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0054, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11653244495391846\n",
            "SCOPE mean: 0.05088512599468231, SCOPE var: 0.00015900250582490116\n",
            "Total Loss: 0.12197786569595337\n",
            "----------------------------------------\n",
            "Epoch 439\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0054, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11615964025259018\n",
            "SCOPE mean: 0.050890013575553894, SCOPE var: 0.00015876363613642752\n",
            "Total Loss: 0.12156647443771362\n",
            "----------------------------------------\n",
            "Epoch 440\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0054, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11578905582427979\n",
            "SCOPE mean: 0.05089481547474861, SCOPE var: 0.00015852732758503407\n",
            "Total Loss: 0.12115761637687683\n",
            "----------------------------------------\n",
            "Epoch 441\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0053, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11542078852653503\n",
            "SCOPE mean: 0.05089956521987915, SCOPE var: 0.00015829360927455127\n",
            "Total Loss: 0.12075138837099075\n",
            "----------------------------------------\n",
            "Epoch 442\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0053, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11505475640296936\n",
            "SCOPE mean: 0.05090942606329918, SCOPE var: 0.00015804838039912283\n",
            "Total Loss: 0.12034769356250763\n",
            "----------------------------------------\n",
            "Epoch 443\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0053, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11469117552042007\n",
            "SCOPE mean: 0.0509195439517498, SCOPE var: 0.00015780492685735226\n",
            "Total Loss: 0.11994675546884537\n",
            "----------------------------------------\n",
            "Epoch 444\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0052, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11432996392250061\n",
            "SCOPE mean: 0.05092955380678177, SCOPE var: 0.00015756410721223801\n",
            "Total Loss: 0.119548499584198\n",
            "----------------------------------------\n",
            "Epoch 445\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0052, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11397109925746918\n",
            "SCOPE mean: 0.05093943327665329, SCOPE var: 0.00015732584870420396\n",
            "Total Loss: 0.11915288865566254\n",
            "----------------------------------------\n",
            "Epoch 446\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0051, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11361447721719742\n",
            "SCOPE mean: 0.05094917491078377, SCOPE var: 0.00015709006402175874\n",
            "Total Loss: 0.11875982582569122\n",
            "----------------------------------------\n",
            "Epoch 447\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0051, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11326014995574951\n",
            "SCOPE mean: 0.050958771258592606, SCOPE var: 0.00015685672406107187\n",
            "Total Loss: 0.11836936324834824\n",
            "----------------------------------------\n",
            "Epoch 448\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0051, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11290815472602844\n",
            "SCOPE mean: 0.05096820369362831, SCOPE var: 0.00015662571240682155\n",
            "Total Loss: 0.11798153072595596\n",
            "----------------------------------------\n",
            "Epoch 449\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0050, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11255841702222824\n",
            "SCOPE mean: 0.050977472215890884, SCOPE var: 0.0001563971018185839\n",
            "Total Loss: 0.11759626120328903\n",
            "----------------------------------------\n",
            "Epoch 450\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0050, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11221090704202652\n",
            "SCOPE mean: 0.05098654702305794, SCOPE var: 0.00015617077588103712\n",
            "Total Loss: 0.11721350997686386\n",
            "----------------------------------------\n",
            "Epoch 451\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0050, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11186564713716507\n",
            "SCOPE mean: 0.05099542438983917, SCOPE var: 0.00015594670549035072\n",
            "Total Loss: 0.11683331429958344\n",
            "----------------------------------------\n",
            "Epoch 452\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0049, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1115226075053215\n",
            "SCOPE mean: 0.05100413039326668, SCOPE var: 0.0001557249343022704\n",
            "Total Loss: 0.11645562946796417\n",
            "----------------------------------------\n",
            "Epoch 453\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0049, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11118174344301224\n",
            "SCOPE mean: 0.05101259425282478, SCOPE var: 0.00015550527314189821\n",
            "Total Loss: 0.11608041077852249\n",
            "----------------------------------------\n",
            "Epoch 454\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0049, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11083848774433136\n",
            "SCOPE mean: 0.05102112889289856, SCOPE var: 0.00015528615040238947\n",
            "Total Loss: 0.11570407450199127\n",
            "----------------------------------------\n",
            "Epoch 455\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0048, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11049336194992065\n",
            "SCOPE mean: 0.05103130638599396, SCOPE var: 0.00015506937052123249\n",
            "Total Loss: 0.11532669514417648\n",
            "----------------------------------------\n",
            "Epoch 456\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0048, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11014978587627411\n",
            "SCOPE mean: 0.05104287713766098, SCOPE var: 0.00015485522453673184\n",
            "Total Loss: 0.11495102196931839\n",
            "----------------------------------------\n",
            "Epoch 457\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0048, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10980778932571411\n",
            "SCOPE mean: 0.0510556735098362, SCOPE var: 0.00015464363968931139\n",
            "Total Loss: 0.11457707732915878\n",
            "----------------------------------------\n",
            "Epoch 458\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0047, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10946689546108246\n",
            "SCOPE mean: 0.05106969550251961, SCOPE var: 0.00015443461597897112\n",
            "Total Loss: 0.11420439183712006\n",
            "----------------------------------------\n",
            "Epoch 459\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0047, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10912737250328064\n",
            "SCOPE mean: 0.051084861159324646, SCOPE var: 0.00015422806609421968\n",
            "Total Loss: 0.1138332337141037\n",
            "----------------------------------------\n",
            "Epoch 460\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0047, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10878957062959671\n",
            "SCOPE mean: 0.05110101401805878, SCOPE var: 0.0001540240045869723\n",
            "Total Loss: 0.11346396803855896\n",
            "----------------------------------------\n",
            "Epoch 461\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0046, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10845324397087097\n",
            "SCOPE mean: 0.05111800506711006, SCOPE var: 0.00015382228593807667\n",
            "Total Loss: 0.11309707909822464\n",
            "----------------------------------------\n",
            "Epoch 462\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0046, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10811855643987656\n",
            "SCOPE mean: 0.05113571137189865, SCOPE var: 0.00015362301201093942\n",
            "Total Loss: 0.11273209005594254\n",
            "----------------------------------------\n",
            "Epoch 463\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0046, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10778453946113586\n",
            "SCOPE mean: 0.05115405470132828, SCOPE var: 0.0001534261100459844\n",
            "Total Loss: 0.11236793547868729\n",
            "----------------------------------------\n",
            "Epoch 464\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0046, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10745078325271606\n",
            "SCOPE mean: 0.05117291212081909, SCOPE var: 0.0001532314345240593\n",
            "Total Loss: 0.11200422793626785\n",
            "----------------------------------------\n",
            "Epoch 465\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0045, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10711845755577087\n",
            "SCOPE mean: 0.05119222402572632, SCOPE var: 0.00015303894178941846\n",
            "Total Loss: 0.11164214462041855\n",
            "----------------------------------------\n",
            "Epoch 466\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0045, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10678748786449432\n",
            "SCOPE mean: 0.051211901009082794, SCOPE var: 0.0001528485445305705\n",
            "Total Loss: 0.111281618475914\n",
            "----------------------------------------\n",
            "Epoch 467\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0045, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10645795613527298\n",
            "SCOPE mean: 0.051231879740953445, SCOPE var: 0.00015266000991687179\n",
            "Total Loss: 0.11092272400856018\n",
            "----------------------------------------\n",
            "Epoch 468\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0044, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1061292439699173\n",
            "SCOPE mean: 0.0512520931661129, SCOPE var: 0.00015247352712322026\n",
            "Total Loss: 0.11056484282016754\n",
            "----------------------------------------\n",
            "Epoch 469\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0044, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10580213367938995\n",
            "SCOPE mean: 0.0512724444270134, SCOPE var: 0.0001522889215266332\n",
            "Total Loss: 0.11020877212285995\n",
            "----------------------------------------\n",
            "Epoch 470\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0044, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10547666251659393\n",
            "SCOPE mean: 0.05129292607307434, SCOPE var: 0.00015210626588668674\n",
            "Total Loss: 0.10985454171895981\n",
            "----------------------------------------\n",
            "Epoch 471\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0043, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10515321791172028\n",
            "SCOPE mean: 0.05131347104907036, SCOPE var: 0.00015192544378805906\n",
            "Total Loss: 0.10950255393981934\n",
            "----------------------------------------\n",
            "Epoch 472\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0043, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10483164340257645\n",
            "SCOPE mean: 0.051333703100681305, SCOPE var: 0.00015174300642684102\n",
            "Total Loss: 0.10915274918079376\n",
            "----------------------------------------\n",
            "Epoch 473\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0043, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1045118123292923\n",
            "SCOPE mean: 0.05135196074843407, SCOPE var: 0.0001515308249508962\n",
            "Total Loss: 0.10880490392446518\n",
            "----------------------------------------\n",
            "Epoch 474\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0043, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10419366508722305\n",
            "SCOPE mean: 0.0513702817261219, SCOPE var: 0.00015132015687413514\n",
            "Total Loss: 0.10845896601676941\n",
            "----------------------------------------\n",
            "Epoch 475\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0042, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10387736558914185\n",
            "SCOPE mean: 0.05138853192329407, SCOPE var: 0.0001511118171038106\n",
            "Total Loss: 0.10811509191989899\n",
            "----------------------------------------\n",
            "Epoch 476\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0042, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10356242209672928\n",
            "SCOPE mean: 0.05140664055943489, SCOPE var: 0.00015090576198417693\n",
            "Total Loss: 0.10777278244495392\n",
            "----------------------------------------\n",
            "Epoch 477\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0042, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10324887186288834\n",
            "SCOPE mean: 0.051424767822027206, SCOPE var: 0.00015070202061906457\n",
            "Total Loss: 0.10743206739425659\n",
            "----------------------------------------\n",
            "Epoch 478\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0042, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1029369980096817\n",
            "SCOPE mean: 0.05144283547997475, SCOPE var: 0.00015050049114506692\n",
            "Total Loss: 0.10709323734045029\n",
            "----------------------------------------\n",
            "Epoch 479\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0041, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10262695699930191\n",
            "SCOPE mean: 0.051460832357406616, SCOPE var: 0.00015030120266601443\n",
            "Total Loss: 0.10675644874572754\n",
            "----------------------------------------\n",
            "Epoch 480\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0041, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10231863707304001\n",
            "SCOPE mean: 0.05147872865200043, SCOPE var: 0.00015010411152616143\n",
            "Total Loss: 0.1064215898513794\n",
            "----------------------------------------\n",
            "Epoch 481\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0041, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1020120307803154\n",
            "SCOPE mean: 0.051496513187885284, SCOPE var: 0.00014990914496593177\n",
            "Total Loss: 0.10608864575624466\n",
            "----------------------------------------\n",
            "Epoch 482\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0041, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10170711576938629\n",
            "SCOPE mean: 0.051514141261577606, SCOPE var: 0.0001497163320891559\n",
            "Total Loss: 0.10575760900974274\n",
            "----------------------------------------\n",
            "Epoch 483\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0040, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10140378773212433\n",
            "SCOPE mean: 0.051531627774238586, SCOPE var: 0.00014952565834391862\n",
            "Total Loss: 0.10542836040258408\n",
            "----------------------------------------\n",
            "Epoch 484\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0040, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10110212117433548\n",
            "SCOPE mean: 0.051548924297094345, SCOPE var: 0.000149337065522559\n",
            "Total Loss: 0.10510098189115524\n",
            "----------------------------------------\n",
            "Epoch 485\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0040, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10080202668905258\n",
            "SCOPE mean: 0.05156603828072548, SCOPE var: 0.00014915052452124655\n",
            "Total Loss: 0.10477537661790848\n",
            "----------------------------------------\n",
            "Epoch 486\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0039, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10050376504659653\n",
            "SCOPE mean: 0.0515829361975193, SCOPE var: 0.00014896593347657472\n",
            "Total Loss: 0.10445180535316467\n",
            "----------------------------------------\n",
            "Epoch 487\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0039, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10020728409290314\n",
            "SCOPE mean: 0.05159956216812134, SCOPE var: 0.00014878342335578054\n",
            "Total Loss: 0.10413020849227905\n",
            "----------------------------------------\n",
            "Epoch 488\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0039, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.09991254657506943\n",
            "SCOPE mean: 0.05161590129137039, SCOPE var: 0.00014860284863971174\n",
            "Total Loss: 0.10381056368350983\n",
            "----------------------------------------\n",
            "Epoch 489\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0039, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.09961952269077301\n",
            "SCOPE mean: 0.05163198336958885, SCOPE var: 0.00014842426753602922\n",
            "Total Loss: 0.10349282622337341\n",
            "----------------------------------------\n",
            "Epoch 490\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0038, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0993281900882721\n",
            "SCOPE mean: 0.05164775997400284, SCOPE var: 0.00014824756362941116\n",
            "Total Loss: 0.10317698121070862\n",
            "----------------------------------------\n",
            "Epoch 491\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0038, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.09903736412525177\n",
            "SCOPE mean: 0.05166324973106384, SCOPE var: 0.0001480728096794337\n",
            "Total Loss: 0.10286179184913635\n",
            "----------------------------------------\n",
            "Epoch 492\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0038, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.09874757379293442\n",
            "SCOPE mean: 0.05167883262038231, SCOPE var: 0.00014789984561502934\n",
            "Total Loss: 0.10254780203104019\n",
            "----------------------------------------\n",
            "Epoch 493\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0038, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.09845931082963943\n",
            "SCOPE mean: 0.05169447138905525, SCOPE var: 0.00014772862778045237\n",
            "Total Loss: 0.10223551094532013\n",
            "----------------------------------------\n",
            "Epoch 494\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0038, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.09817251563072205\n",
            "SCOPE mean: 0.0517101064324379, SCOPE var: 0.00014755917072761804\n",
            "Total Loss: 0.10192486643791199\n",
            "----------------------------------------\n",
            "Epoch 495\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0037, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.09788726270198822\n",
            "SCOPE mean: 0.05172574520111084, SCOPE var: 0.00014739147445652634\n",
            "Total Loss: 0.10161592811346054\n",
            "----------------------------------------\n",
            "Epoch 496\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0037, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.09760361909866333\n",
            "SCOPE mean: 0.0517413504421711, SCOPE var: 0.00014722552441526204\n",
            "Total Loss: 0.10130879282951355\n",
            "----------------------------------------\n",
            "Epoch 497\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0037, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0973215401172638\n",
            "SCOPE mean: 0.051757410168647766, SCOPE var: 0.00014706126239616424\n",
            "Total Loss: 0.10100341588258743\n",
            "----------------------------------------\n",
            "Epoch 498\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0037, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.09704092890024185\n",
            "SCOPE mean: 0.0517735593020916, SCOPE var: 0.0001468987320549786\n",
            "Total Loss: 0.10069969296455383\n",
            "----------------------------------------\n",
            "Epoch 499\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0036, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.09676312655210495\n",
            "SCOPE mean: 0.05178963765501976, SCOPE var: 0.000146737860632129\n",
            "Total Loss: 0.100398950278759\n",
            "----------------------------------------\n",
            "Epoch 500\n",
            "IS mean: 0.018765898421406746,IS variance: 6.291866156971082e-05\n",
            "SCOPE Var loss:  tensor(0.0036, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0964871495962143\n",
            "SCOPE mean: 0.051805250346660614, SCOPE var: 0.00014657870633527637\n",
            "Total Loss: 0.10010023415088654\n",
            "----------------------------------------\n",
            "800 trajectories:\n",
            "Epoch 1\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.0953, grad_fn=<VarBackward0>)\n",
            "MSE loss:  19.242347717285156\n",
            "SCOPE mean: -0.3048133850097656, SCOPE var: 0.6419631838798523\n",
            "Total Loss: 19.33769416809082\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(1.3364, grad_fn=<VarBackward0>)\n",
            "MSE loss:  17.99725914001465\n",
            "SCOPE mean: -0.2951449751853943, SCOPE var: 0.6086989045143127\n",
            "Total Loss: 19.333707809448242\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(1.2702, grad_fn=<VarBackward0>)\n",
            "MSE loss:  17.080053329467773\n",
            "SCOPE mean: -0.2799791395664215, SCOPE var: 0.5687143802642822\n",
            "Total Loss: 18.350252151489258\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(1.2061, grad_fn=<VarBackward0>)\n",
            "MSE loss:  16.19902801513672\n",
            "SCOPE mean: -0.26490074396133423, SCOPE var: 0.5302889347076416\n",
            "Total Loss: 17.405122756958008\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(1.1443, grad_fn=<VarBackward0>)\n",
            "MSE loss:  15.353083610534668\n",
            "SCOPE mean: -0.25001996755599976, SCOPE var: 0.49339428544044495\n",
            "Total Loss: 16.49742317199707\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(1.0849, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.543905258178711\n",
            "SCOPE mean: -0.22741776704788208, SCOPE var: 0.4575706422328949\n",
            "Total Loss: 15.628780364990234\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(1.0273, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.776400566101074\n",
            "SCOPE mean: -0.20119328796863556, SCOPE var: 0.42357221245765686\n",
            "Total Loss: 14.80372428894043\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.9714, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.043099403381348\n",
            "SCOPE mean: -0.17532509565353394, SCOPE var: 0.3914079964160919\n",
            "Total Loss: 14.014461517333984\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.9179, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.344206809997559\n",
            "SCOPE mean: -0.1475348025560379, SCOPE var: 0.35841983556747437\n",
            "Total Loss: 13.26208782196045\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.8664, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.678587913513184\n",
            "SCOPE mean: -0.11920692026615143, SCOPE var: 0.32645848393440247\n",
            "Total Loss: 12.545025825500488\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.8170, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.043910026550293\n",
            "SCOPE mean: -0.09132018685340881, SCOPE var: 0.2966049015522003\n",
            "Total Loss: 11.860892295837402\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.7710, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.437555313110352\n",
            "SCOPE mean: -0.06291443854570389, SCOPE var: 0.26716727018356323\n",
            "Total Loss: 11.20850658416748\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.7300, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.860523223876953\n",
            "SCOPE mean: -0.0309746116399765, SCOPE var: 0.23581217229366302\n",
            "Total Loss: 10.590563774108887\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.6838, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.312335014343262\n",
            "SCOPE mean: 0.001006586942821741, SCOPE var: 0.2066267430782318\n",
            "Total Loss: 9.996172904968262\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.6394, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.79149055480957\n",
            "SCOPE mean: 0.03242575377225876, SCOPE var: 0.1802304983139038\n",
            "Total Loss: 9.430927276611328\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.5974, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.298613548278809\n",
            "SCOPE mean: 0.06381634622812271, SCOPE var: 0.15621016919612885\n",
            "Total Loss: 8.895984649658203\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.5576, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.830657958984375\n",
            "SCOPE mean: 0.09469398111104965, SCOPE var: 0.13479723036289215\n",
            "Total Loss: 8.38823127746582\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.5200, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.386232376098633\n",
            "SCOPE mean: 0.12494722008705139, SCOPE var: 0.11591392010450363\n",
            "Total Loss: 7.906248569488525\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.4850, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.963882923126221\n",
            "SCOPE mean: 0.15456750988960266, SCOPE var: 0.09944723546504974\n",
            "Total Loss: 7.448893070220947\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.4520, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.563882350921631\n",
            "SCOPE mean: 0.18353816866874695, SCOPE var: 0.08530396968126297\n",
            "Total Loss: 7.015860080718994\n",
            "----------------------------------------\n",
            "Epoch 21\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.4208, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.186175346374512\n",
            "SCOPE mean: 0.21185041964054108, SCOPE var: 0.07336419820785522\n",
            "Total Loss: 6.606930255889893\n",
            "----------------------------------------\n",
            "Epoch 22\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.3943, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.830401420593262\n",
            "SCOPE mean: 0.23951169848442078, SCOPE var: 0.06350968778133392\n",
            "Total Loss: 6.224680423736572\n",
            "----------------------------------------\n",
            "Epoch 23\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.3716, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.49480676651001\n",
            "SCOPE mean: 0.26657846570014954, SCOPE var: 0.05554112046957016\n",
            "Total Loss: 5.866447925567627\n",
            "----------------------------------------\n",
            "Epoch 24\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.3507, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.178421974182129\n",
            "SCOPE mean: 0.2930506765842438, SCOPE var: 0.04940903186798096\n",
            "Total Loss: 5.529088973999023\n",
            "----------------------------------------\n",
            "Epoch 25\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.3308, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.880640506744385\n",
            "SCOPE mean: 0.3188663125038147, SCOPE var: 0.04510350525379181\n",
            "Total Loss: 5.211450099945068\n",
            "----------------------------------------\n",
            "Epoch 26\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.3120, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.5999579429626465\n",
            "SCOPE mean: 0.3438449501991272, SCOPE var: 0.042507559061050415\n",
            "Total Loss: 4.911927223205566\n",
            "----------------------------------------\n",
            "Epoch 27\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.2944, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.335799217224121\n",
            "SCOPE mean: 0.3680947422981262, SCOPE var: 0.0414874330163002\n",
            "Total Loss: 4.630204677581787\n",
            "----------------------------------------\n",
            "Epoch 28\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.2780, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.0879621505737305\n",
            "SCOPE mean: 0.39164119958877563, SCOPE var: 0.0419340655207634\n",
            "Total Loss: 4.365922451019287\n",
            "----------------------------------------\n",
            "Epoch 29\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.2626, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.8559036254882812\n",
            "SCOPE mean: 0.41456469893455505, SCOPE var: 0.04374252259731293\n",
            "Total Loss: 4.118483543395996\n",
            "----------------------------------------\n",
            "Epoch 30\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.2481, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.6379802227020264\n",
            "SCOPE mean: 0.43687617778778076, SCOPE var: 0.04681195318698883\n",
            "Total Loss: 3.8860385417938232\n",
            "----------------------------------------\n",
            "Epoch 31\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.2343, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.433290958404541\n",
            "SCOPE mean: 0.45858731865882874, SCOPE var: 0.05104611814022064\n",
            "Total Loss: 3.6676321029663086\n",
            "----------------------------------------\n",
            "Epoch 32\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.2214, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.2412216663360596\n",
            "SCOPE mean: 0.47971466183662415, SCOPE var: 0.05635403096675873\n",
            "Total Loss: 3.4626197814941406\n",
            "----------------------------------------\n",
            "Epoch 33\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.2093, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.061248302459717\n",
            "SCOPE mean: 0.5002704858779907, SCOPE var: 0.06264850497245789\n",
            "Total Loss: 3.2705163955688477\n",
            "----------------------------------------\n",
            "Epoch 34\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.1978, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.892754554748535\n",
            "SCOPE mean: 0.5202668905258179, SCOPE var: 0.06984668225049973\n",
            "Total Loss: 3.0905961990356445\n",
            "----------------------------------------\n",
            "Epoch 35\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.1871, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.73507022857666\n",
            "SCOPE mean: 0.5397160053253174, SCOPE var: 0.07786927372217178\n",
            "Total Loss: 2.922128200531006\n",
            "----------------------------------------\n",
            "Epoch 36\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.1769, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.587549924850464\n",
            "SCOPE mean: 0.5586345195770264, SCOPE var: 0.08664283901453018\n",
            "Total Loss: 2.764431953430176\n",
            "----------------------------------------\n",
            "Epoch 37\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.1674, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.4497642517089844\n",
            "SCOPE mean: 0.5770336985588074, SCOPE var: 0.09609582275152206\n",
            "Total Loss: 2.617173910140991\n",
            "----------------------------------------\n",
            "Epoch 38\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.1586, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.3211166858673096\n",
            "SCOPE mean: 0.5949268341064453, SCOPE var: 0.1061609610915184\n",
            "Total Loss: 2.47967529296875\n",
            "----------------------------------------\n",
            "Epoch 39\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.1502, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.2011592388153076\n",
            "SCOPE mean: 0.6123260855674744, SCOPE var: 0.11677446961402893\n",
            "Total Loss: 2.351378917694092\n",
            "----------------------------------------\n",
            "Epoch 40\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.1423, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.0895256996154785\n",
            "SCOPE mean: 0.6292409300804138, SCOPE var: 0.12787118554115295\n",
            "Total Loss: 2.2318663597106934\n",
            "----------------------------------------\n",
            "Epoch 41\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.1342, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.9852513074874878\n",
            "SCOPE mean: 0.6455541849136353, SCOPE var: 0.1392224133014679\n",
            "Total Loss: 2.1194279193878174\n",
            "----------------------------------------\n",
            "Epoch 42\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.1265, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.8882559537887573\n",
            "SCOPE mean: 0.6613989472389221, SCOPE var: 0.15092778205871582\n",
            "Total Loss: 2.0147173404693604\n",
            "----------------------------------------\n",
            "Epoch 43\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.1192, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7981464862823486\n",
            "SCOPE mean: 0.676791787147522, SCOPE var: 0.16293948888778687\n",
            "Total Loss: 1.9173226356506348\n",
            "----------------------------------------\n",
            "Epoch 44\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.1123, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7145159244537354\n",
            "SCOPE mean: 0.6917470693588257, SCOPE var: 0.17521168291568756\n",
            "Total Loss: 1.8268178701400757\n",
            "----------------------------------------\n",
            "Epoch 45\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.1058, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6370232105255127\n",
            "SCOPE mean: 0.7062828540802002, SCOPE var: 0.18770216405391693\n",
            "Total Loss: 1.7428441047668457\n",
            "----------------------------------------\n",
            "Epoch 46\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.0997, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5652340650558472\n",
            "SCOPE mean: 0.7204231023788452, SCOPE var: 0.20037169754505157\n",
            "Total Loss: 1.664947271347046\n",
            "----------------------------------------\n",
            "Epoch 47\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.0940, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.498792052268982\n",
            "SCOPE mean: 0.7341673374176025, SCOPE var: 0.21318289637565613\n",
            "Total Loss: 1.5927424430847168\n",
            "----------------------------------------\n",
            "Epoch 48\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.0885, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4373583793640137\n",
            "SCOPE mean: 0.7475333213806152, SCOPE var: 0.22610536217689514\n",
            "Total Loss: 1.525890827178955\n",
            "----------------------------------------\n",
            "Epoch 49\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.0834, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.3806540966033936\n",
            "SCOPE mean: 0.7605319619178772, SCOPE var: 0.2391059547662735\n",
            "Total Loss: 1.4640902280807495\n",
            "----------------------------------------\n",
            "Epoch 50\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.0786, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.3283650875091553\n",
            "SCOPE mean: 0.7731671929359436, SCOPE var: 0.25215503573417664\n",
            "Total Loss: 1.4070111513137817\n",
            "----------------------------------------\n",
            "Epoch 51\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.0741, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.2801944017410278\n",
            "SCOPE mean: 0.7854646444320679, SCOPE var: 0.26522526144981384\n",
            "Total Loss: 1.3543422222137451\n",
            "----------------------------------------\n",
            "Epoch 52\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.0699, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.2358428239822388\n",
            "SCOPE mean: 0.797432541847229, SCOPE var: 0.2782910466194153\n",
            "Total Loss: 1.3057706356048584\n",
            "----------------------------------------\n",
            "Epoch 53\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.0660, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1950068473815918\n",
            "SCOPE mean: 0.8090830445289612, SCOPE var: 0.29132992029190063\n",
            "Total Loss: 1.2609755992889404\n",
            "----------------------------------------\n",
            "Epoch 54\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.0623, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.157452940940857\n",
            "SCOPE mean: 0.8205275535583496, SCOPE var: 0.3044189512729645\n",
            "Total Loss: 1.2197034358978271\n",
            "----------------------------------------\n",
            "Epoch 55\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.0588, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1229394674301147\n",
            "SCOPE mean: 0.8317210674285889, SCOPE var: 0.31748923659324646\n",
            "Total Loss: 1.1817055940628052\n",
            "----------------------------------------\n",
            "Epoch 56\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.0555, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.091213345527649\n",
            "SCOPE mean: 0.8426238298416138, SCOPE var: 0.33047378063201904\n",
            "Total Loss: 1.146687626838684\n",
            "----------------------------------------\n",
            "Epoch 57\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.0524, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0620105266571045\n",
            "SCOPE mean: 0.8532510995864868, SCOPE var: 0.3433602452278137\n",
            "Total Loss: 1.1143718957901\n",
            "----------------------------------------\n",
            "Epoch 58\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.0494, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0351266860961914\n",
            "SCOPE mean: 0.8636149168014526, SCOPE var: 0.3561358153820038\n",
            "Total Loss: 1.0845742225646973\n",
            "----------------------------------------\n",
            "Epoch 59\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.0468, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.010393500328064\n",
            "SCOPE mean: 0.8737252950668335, SCOPE var: 0.3687874376773834\n",
            "Total Loss: 1.0571707487106323\n",
            "----------------------------------------\n",
            "Epoch 60\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.0443, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9876308441162109\n",
            "SCOPE mean: 0.8835931420326233, SCOPE var: 0.38130369782447815\n",
            "Total Loss: 1.0319194793701172\n",
            "----------------------------------------\n",
            "Epoch 61\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.0420, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9666613340377808\n",
            "SCOPE mean: 0.8932265639305115, SCOPE var: 0.393674373626709\n",
            "Total Loss: 1.0086190700531006\n",
            "----------------------------------------\n",
            "Epoch 62\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.0398, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9473291635513306\n",
            "SCOPE mean: 0.9026349782943726, SCOPE var: 0.405891090631485\n",
            "Total Loss: 0.9871060252189636\n",
            "----------------------------------------\n",
            "Epoch 63\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.0377, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9294736981391907\n",
            "SCOPE mean: 0.9118281006813049, SCOPE var: 0.41795140504837036\n",
            "Total Loss: 0.9672131538391113\n",
            "----------------------------------------\n",
            "Epoch 64\n",
            "IS mean: 1.026147723197937,IS variance: 0.7112858891487122\n",
            "SCOPE Var loss:  tensor(0.0358, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9129629731178284\n",
            "SCOPE mean: 0.9208387732505798, SCOPE var: 0.42991477251052856\n",
            "Total Loss: 0.9488028287887573\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing IS"
      ],
      "metadata": {
        "id": "jdFlKtPQqrTh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    # Parameters related to policy generation\n",
        "    \"pi_b_top_k\": 1,\n",
        "    \"pi_b_epsilon\": 0.01,\n",
        "    \"pi_e_top_k\": 1,\n",
        "    \"pi_e_epsilon\": 0.2,\n",
        "    \"q_table\": q_table,\n",
        "    \"gamma\": 0.99,\n",
        "    \"num_trajectories\": 400,\n",
        "    \"num_bootstraps\": 10000,\n",
        "    \"percent_to_estimate_phi\": 0.3,\n",
        "\n",
        "    # Parameters related to shaping\n",
        "    \"shaping_feature\": bottleneck_four_regions_k_p9_a_1,\n",
        "    \"shaping_coefficient\": 0.1,\n",
        "\n",
        "    # Parameters related to neural network architecture and training\n",
        "    \"hidden_dims\": [8,8],\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"dropout_prob\": 0.2,\n",
        "    \"l1_reg\": 0.00001,\n",
        "    \"l2_reg\": 0.00001,\n",
        "    \"scope_weight\": 1.0,\n",
        "    \"mse_weight\": 1.0,\n",
        "    \"num_epochs\": 500,\n",
        "\n",
        "    # Parameters related to environment\n",
        "    \"max_length\": 70,\n",
        "    \"death_drag\": 0.0,\n",
        "    # Other general parameters\n",
        "    \"dtype\": torch.float32,\n",
        "    \"experiment_type\": \"test\",\n",
        "    \"folder_path\": \"/content/drive/MyDrive/Lifegate_experiments\"\n",
        "    # \"folder_path\": \"/content\"\n",
        "}"
      ],
      "metadata": {
        "id": "1ynqesC0q6v9"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_experiment = SCOPE_experiment(**params)"
      ],
      "metadata": {
        "id": "T7e17Yd6qqaW"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test_load = existing_experiments(test_experiment)\n",
        "# test_load.plot_metrics()"
      ],
      "metadata": {
        "id": "gwReRyraq7qB"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pi_b = test_load.load_pi_b()"
      ],
      "metadata": {
        "id": "2ez0Z-OWq7qB"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pi_b_run, pi_e, model, experiment_class = test_experiment.prepare_experiment()"
      ],
      "metadata": {
        "id": "LwDwbb8V5CnI"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_rho(trajectories, P_pi_b, P_pi_e):\n",
        "    episode_rhos = []\n",
        "    episode_rews = []\n",
        "    episode_probs_b_and_e = []  # List to store (P_e, P_b) tuples\n",
        "\n",
        "    for i in range(len(trajectories)):\n",
        "        rho = []  # Initialize rho for the current episode\n",
        "        rew = []\n",
        "        probs_b_and_e = []  # Initialize (P_e, P_b) list for the current episode\n",
        "\n",
        "        for j in range(len(trajectories[i]['state'])):\n",
        "            state = trajectories[i]['state'][j]\n",
        "            action = trajectories[i]['action'][j]\n",
        "            reward = trajectories[i]['reward'][j]\n",
        "\n",
        "            P_e = P_pi_e[int(state[0])][int(state[1])][action]\n",
        "            P_b = P_pi_b[int(state[0])][int(state[1])][action]\n",
        "\n",
        "            rho.append(P_e / P_b)\n",
        "            rew.append(reward)\n",
        "            probs_b_and_e.append((state.tolist(), action, P_e, P_b, P_e/P_b))\n",
        "\n",
        "        episode_rews.append(rew)\n",
        "        episode_rhos.append(rho)\n",
        "        episode_probs_b_and_e.append(probs_b_and_e)\n",
        "\n",
        "    return episode_rhos, episode_rews, episode_probs_b_and_e\n",
        "\n",
        "def step_IS(episode_rhos, episode_rews, return_Qs=False):\n",
        "\n",
        "  V_step_IS = [np.sum(0.99**np.arange(len(rews)) * np.cumprod(np.array(rhos)) * np.array(rews))  for rhos, rews in zip(episode_rhos, episode_rews)]\n",
        "  if return_Qs:\n",
        "      return np.mean(V_step_IS), np.array(V_step_IS)\n",
        "  else:\n",
        "      return np.mean(V_step_IS)\n",
        "\n",
        "def calc_var_bootstrap(all_V_step_IS):\n",
        "  # Parameters\n",
        "  n_bootstrap_samples = 30000  # Number of bootstrap samples to generate\n",
        "  n_elements = len(all_V_step_IS)  # Number of elements in the original array\n",
        "\n",
        "  # Bootstrap sampling and calculation of means\n",
        "  bootstrap_means = np.empty(n_bootstrap_samples)\n",
        "\n",
        "  for i in range(n_bootstrap_samples):\n",
        "      bootstrap_sample = np.random.choice(all_V_step_IS, size=n_elements, replace=True)\n",
        "      bootstrap_means[i] = np.mean(bootstrap_sample)\n",
        "\n",
        "  # Calculate the variance of the bootstrap sample means\n",
        "  variance_of_means = np.var(bootstrap_means)\n",
        "\n",
        "  print(f\"Variance of stepIS: {variance_of_means}\")\n",
        "  return variance_of_means, bootstrap_means\n",
        "\n",
        "def PDIS(params):\n",
        "  test_experiment = SCOPE_experiment(**params)\n",
        "  pi_b_run, pi_e, model, experiment_class = test_experiment.prepare_experiment()\n",
        "  P_pi_b =  test_experiment.action_probs_top_n_epsilon(params[\"pi_b_top_k\"],params[\"pi_b_epsilon\"])\n",
        "  P_pi_e =  test_experiment.action_probs_top_n_epsilon(params[\"pi_e_top_k\"],params[\"pi_e_epsilon\"])\n",
        "  episode_rhos, episode_rews, episode_probs_b_and_e = get_rho(pi_b_run,P_pi_b, P_pi_e)\n",
        "  V_step_IS, all_V_step_IS = step_IS(episode_rhos, episode_rews, return_Qs=True)\n",
        "  print(f\"Value estimate of stepIS: {V_step_IS}\")\n",
        "  variance_of_means, bootstrap_means = calc_var_bootstrap(all_V_step_IS)\n",
        "  on_policy = experiment_class.calc_V_pi_e()\n",
        "  bias = V_step_IS - on_policy\n",
        "  mse = variance_of_means + bias**2\n",
        "  print(f\"On Policy Estimate: {on_policy}\")\n",
        "  print(f\"MSE: {mse}\")\n",
        "  # return V_step_IS, variance_of_means, on_policy, mse\n"
      ],
      "metadata": {
        "id": "FUBIrh2Bj89X"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params[\"num_trajectories\"] = 200000\n",
        "PDIS(params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqRXPdX69hjK",
        "outputId": "899d8c13-6adc-4d03-e38c-cdbb50b7431f"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Value estimate of stepIS: 0.8305026161037643\n",
            "Variance of stepIS: 0.01484951434268996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pi_b_load = test_load.load_pi_b()"
      ],
      "metadata": {
        "id": "jhzC9XSuzNca"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params[\"pi_b_epsilon\"] = 0.7\n",
        "params[\"pi_e_epsilon\"] = 0.2\n",
        "params[\"num_trajectories\"] = 200\n",
        "params[\"pi_b_top_k\"] = 1\n",
        "params[\"pi_e_top_k\"] = 1\n",
        "params[\"max_length\"] = 50\n",
        "\n",
        "test_experiment = SCOPE_experiment(**params)\n",
        "\n",
        "P_pi_b =  test_experiment.action_probs_top_n_epsilon(params[\"pi_b_top_k\"],params[\"pi_b_epsilon\"])\n",
        "P_pi_e =  test_experiment.action_probs_top_n_epsilon(params[\"pi_e_top_k\"],params[\"pi_e_epsilon\"])\n",
        "\n"
      ],
      "metadata": {
        "id": "Y9MkYbsQuX12"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_trajectories = [200, 400, 600, 800, 1000, 2000, 10000, 20000]\n",
        "\n",
        "for i in num_trajectories:\n",
        "  params[\"num_trajectories\"] = i\n",
        "  print(f\"stepIS for {i} trajectories:\")\n",
        "  test_experiment = SCOPE_experiment(**params)\n",
        "  pi_b_run, pi_e, model, experiment_class = test_experiment.prepare_experiment()\n",
        "  episode_rhos, episode_rews, episode_probs_b_and_e = get_rho(pi_b_run,P_pi_b, P_pi_e)\n",
        "  V_step_IS, all_V_step_IS = step_IS(episode_rhos, episode_rews, return_Qs=True)\n",
        "  print(f\"Value estimate of stepIS: {V_step_IS}\")\n",
        "  variance_of_means, bootstrap_means = calc_var_bootstrap(all_V_step_IS)\n",
        "  print(\"-\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejfHJHmlugU_",
        "outputId": "b1827cca-b7f3-4002-f33f-ad9dcc3f5a30"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stepIS for 200 trajectories:\n",
            "Value estimate of stepIS: 0.029821977525163846\n",
            "Variance of stepIS: 0.0004054829883995591\n",
            "------------------------------------------------------------\n",
            "stepIS for 400 trajectories:\n",
            "Value estimate of stepIS: 0.04527415996475298\n",
            "Variance of stepIS: 0.0005281308205243704\n",
            "------------------------------------------------------------\n",
            "stepIS for 600 trajectories:\n",
            "Value estimate of stepIS: 0.03327212328286666\n",
            "Variance of stepIS: 0.00023735137630116691\n",
            "------------------------------------------------------------\n",
            "stepIS for 800 trajectories:\n",
            "Value estimate of stepIS: 0.08724145638248061\n",
            "Variance of stepIS: 0.0015746900495902793\n",
            "------------------------------------------------------------\n",
            "stepIS for 1000 trajectories:\n",
            "Value estimate of stepIS: 0.24904094324123893\n",
            "Variance of stepIS: 0.03159243836446429\n",
            "------------------------------------------------------------\n",
            "stepIS for 2000 trajectories:\n",
            "Value estimate of stepIS: 0.23594812198374696\n",
            "Variance of stepIS: 0.012133435042476761\n",
            "------------------------------------------------------------\n",
            "stepIS for 10000 trajectories:\n",
            "Value estimate of stepIS: 0.5337471742005879\n",
            "Variance of stepIS: 0.051945964949647226\n",
            "------------------------------------------------------------\n",
            "stepIS for 20000 trajectories:\n",
            "Value estimate of stepIS: 0.5456738562100473\n",
            "Variance of stepIS: 0.05498380830103426\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_trajectories = [200, 400, 600, 800, 1000, 2000, 10000, 20000]\n",
        "params[\"pi_b_epsilon\"] = 0.7\n",
        "params[\"pi_e_epsilon\"] = 0.2\n",
        "params[\"max_length\"] = 70\n",
        "\n",
        "\n",
        "for i in num_trajectories:\n",
        "  params[\"num_trajectories\"] = i\n",
        "  print(f\"stepIS for {i} trajectories:\")\n",
        "  PDIS(params)\n",
        "  print(\"-\"*60)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3OXDg5mw7wM",
        "outputId": "312e7417-055f-4a9b-91c9-135226dbc11d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stepIS for 200 trajectories:\n",
            "Value estimate of stepIS: 0.04058253983072969\n",
            "Variance of stepIS: 0.0013015991629474674\n",
            "On Policy Estimate: 0.8210778338655641\n",
            "MSE: 0.6104745031734701\n",
            "------------------------------------------------------------\n",
            "stepIS for 400 trajectories:\n",
            "Value estimate of stepIS: 0.04056869655732113\n",
            "Variance of stepIS: 0.0006609250382466745\n",
            "On Policy Estimate: 0.8214166746973824\n",
            "MSE: 0.6103844900036683\n",
            "------------------------------------------------------------\n",
            "stepIS for 600 trajectories:\n",
            "Value estimate of stepIS: 1.9257653531359342\n",
            "Variance of stepIS: 3.5615824580710633\n",
            "On Policy Estimate: 0.8194442378007352\n",
            "MSE: 4.785528868307582\n",
            "------------------------------------------------------------\n",
            "stepIS for 800 trajectories:\n",
            "Value estimate of stepIS: 1.675742483891416\n",
            "Variance of stepIS: 2.0617370336993903\n",
            "On Policy Estimate: 0.818598120170397\n",
            "MSE: 2.7964334939581006\n",
            "------------------------------------------------------------\n",
            "stepIS for 1000 trajectories:\n",
            "Value estimate of stepIS: 1.350164161835282\n",
            "Variance of stepIS: 1.3186481212693715\n",
            "On Policy Estimate: 0.818985692663959\n",
            "MSE: 1.6007986873805615\n",
            "------------------------------------------------------------\n",
            "stepIS for 2000 trajectories:\n",
            "Value estimate of stepIS: 0.7085533278969905\n",
            "Variance of stepIS: 0.3298544348335098\n",
            "On Policy Estimate: 0.8195095647856238\n",
            "MSE: 0.3421657213379963\n",
            "------------------------------------------------------------\n",
            "stepIS for 10000 trajectories:\n",
            "Value estimate of stepIS: 0.3770674887422374\n",
            "Variance of stepIS: 0.017727573868890296\n",
            "On Policy Estimate: 0.8210598243323391\n",
            "MSE: 0.21485676793164382\n",
            "------------------------------------------------------------\n",
            "stepIS for 20000 trajectories:\n",
            "Value estimate of stepIS: 0.6605786714215226\n",
            "Variance of stepIS: 0.05113006009639058\n",
            "On Policy Estimate: 0.8204363405638934\n",
            "MSE: 0.07668453448002226\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_trajectories = [200, 400, 600, 800, 1000, 2000, 10000, 20000]\n",
        "params[\"pi_b_epsilon\"] = 0.4\n",
        "params[\"pi_e_epsilon\"] = 0.1\n",
        "\n",
        "\n",
        "for i in num_trajectories:\n",
        "  params[\"num_trajectories\"] = i\n",
        "  print(f\"stepIS for {i} trajectories:\")\n",
        "  PDIS(params)\n",
        "  print(\"-\"*60)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cG7_MrHwTPZr",
        "outputId": "9b962330-599c-4f2a-fe9e-9d79b91b50f3"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stepIS for 200 trajectories:\n",
            "Value estimate of stepIS: 0.7284906335294948\n",
            "Variance of stepIS: 0.07393974464103817\n",
            "On Policy Estimate: 0.8417444727027873\n",
            "MSE: 0.08676617672852815\n",
            "------------------------------------------------------------\n",
            "stepIS for 400 trajectories:\n",
            "Value estimate of stepIS: 0.754259635576002\n",
            "Variance of stepIS: 0.033584967453206896\n",
            "On Policy Estimate: 0.8415875713420845\n",
            "MSE: 0.041211135818371936\n",
            "------------------------------------------------------------\n",
            "stepIS for 600 trajectories:\n",
            "Value estimate of stepIS: 0.6785665894269916\n",
            "Variance of stepIS: 0.020293800503219637\n",
            "On Policy Estimate: 0.8420081631662425\n",
            "MSE: 0.04700694852958264\n",
            "------------------------------------------------------------\n",
            "stepIS for 800 trajectories:\n",
            "Value estimate of stepIS: 0.6784946549232012\n",
            "Variance of stepIS: 0.016145375344962683\n",
            "On Policy Estimate: 0.8416197230091972\n",
            "MSE: 0.042755163183023526\n",
            "------------------------------------------------------------\n",
            "stepIS for 1000 trajectories:\n",
            "Value estimate of stepIS: 0.7798957035411829\n",
            "Variance of stepIS: 0.02382030731642657\n",
            "On Policy Estimate: 0.8416055231580174\n",
            "MSE: 0.027628409153568827\n",
            "------------------------------------------------------------\n",
            "stepIS for 2000 trajectories:\n",
            "Value estimate of stepIS: 0.8769536367556888\n",
            "Variance of stepIS: 0.020015426289098612\n",
            "On Policy Estimate: 0.8418211490170474\n",
            "MSE: 0.0212497179838044\n",
            "------------------------------------------------------------\n",
            "stepIS for 10000 trajectories:\n",
            "Value estimate of stepIS: 0.8418988538920219\n",
            "Variance of stepIS: 0.003509501570434542\n",
            "On Policy Estimate: 0.8422862956484853\n",
            "MSE: 0.0035096516815491933\n",
            "------------------------------------------------------------\n",
            "stepIS for 20000 trajectories:\n",
            "Value estimate of stepIS: 0.859589383835973\n",
            "Variance of stepIS: 0.00184771022129013\n",
            "On Policy Estimate: 0.8417549168613438\n",
            "MSE: 0.00216577843355927\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_trajectories = [200, 400, 600, 800, 1000, 2000, 10000, 20000, 50000]\n",
        "params[\"pi_b_epsilon\"] = 0.5\n",
        "params[\"pi_e_epsilon\"] = 0.2\n",
        "\n",
        "\n",
        "for i in num_trajectories:\n",
        "  params[\"num_trajectories\"] = i\n",
        "  print(f\"stepIS for {i} trajectories:\")\n",
        "  PDIS(params)\n",
        "  print(\"-\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sa6PXeGCZIwg",
        "outputId": "f76aa4e0-1b9f-4f5c-a7e4-fa96f6a12d9f"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stepIS for 200 trajectories:\n",
            "Value estimate of stepIS: 1.3739434596319946\n",
            "Variance of stepIS: 0.35499455848865225\n",
            "On Policy Estimate: 0.8200626355198506\n",
            "MSE: 0.6617785258078\n",
            "------------------------------------------------------------\n",
            "stepIS for 400 trajectories:\n",
            "Value estimate of stepIS: 1.241113034486646\n",
            "Variance of stepIS: 0.1743812493136254\n",
            "On Policy Estimate: 0.8213999703006682\n",
            "MSE: 0.350540305562008\n",
            "------------------------------------------------------------\n",
            "stepIS for 600 trajectories:\n",
            "Value estimate of stepIS: 0.9008434635294275\n",
            "Variance of stepIS: 0.07975743285180345\n",
            "On Policy Estimate: 0.8214505599982884\n",
            "MSE: 0.0860606659829082\n",
            "------------------------------------------------------------\n",
            "stepIS for 800 trajectories:\n",
            "Value estimate of stepIS: 0.9433142197398461\n",
            "Variance of stepIS: 0.05028511794907695\n",
            "On Policy Estimate: 0.8210499544690547\n",
            "MSE: 0.0652336685112834\n",
            "------------------------------------------------------------\n",
            "stepIS for 1000 trajectories:\n",
            "Value estimate of stepIS: 0.8567005222065034\n",
            "Variance of stepIS: 0.03312907078216712\n",
            "On Policy Estimate: 0.8187027658185753\n",
            "MSE: 0.03457290027268345\n",
            "------------------------------------------------------------\n",
            "stepIS for 2000 trajectories:\n",
            "Value estimate of stepIS: 0.8590177397840439\n",
            "Variance of stepIS: 0.019730464923301386\n",
            "On Policy Estimate: 0.8205220655372653\n",
            "MSE: 0.021212381859015486\n",
            "------------------------------------------------------------\n",
            "stepIS for 10000 trajectories:\n",
            "Value estimate of stepIS: 0.8066584462850709\n",
            "Variance of stepIS: 0.0029393314644745117\n",
            "On Policy Estimate: 0.8186970425104675\n",
            "MSE: 0.003084259263552645\n",
            "------------------------------------------------------------\n",
            "stepIS for 20000 trajectories:\n",
            "Value estimate of stepIS: 0.817545359054923\n",
            "Variance of stepIS: 0.0014875151972241437\n",
            "On Policy Estimate: 0.8215838132046427\n",
            "MSE: 0.0015038243091435321\n",
            "------------------------------------------------------------\n",
            "stepIS for 50000 trajectories:\n",
            "Value estimate of stepIS: 0.8228384070025477\n",
            "Variance of stepIS: 0.0006373195432400581\n",
            "On Policy Estimate: 0.8190582870701512\n",
            "MSE: 0.00065160884994336\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params[\"num_trajectories\"] = 200\n",
        "test_experiment = SCOPE_experiment(**params)\n",
        "pi_b_run, pi_e, model, experiment_class = test_experiment.prepare_experiment()"
      ],
      "metadata": {
        "id": "nu8fbE1yUnxg"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experiment_class.calc_V_pi_e()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hSekH8SxPas",
        "outputId": "353f7202-3b73-49c8-d441-fbe067abf643"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8417444727027873"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pi_e  = test_experiment.experiment_actions(10000, test_experiment.initialize_env(),P_pi_e)"
      ],
      "metadata": {
        "id": "w1jf5yindefd"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_V_pi_e(pi_e):\n",
        "      all_timesteps = []\n",
        "      gamma = test_experiment.gamma\n",
        "      for j in range(len(pi_e)):\n",
        "          Timestep_values = []\n",
        "          for i in range(len(pi_e[j])):\n",
        "            # print(i)\n",
        "            timestep = gamma ** (i) * pi_e[j][i][2]\n",
        "            Timestep_values.append(timestep)\n",
        "\n",
        "          all_timesteps.append(Timestep_values)\n",
        "\n",
        "      V_est = sum([sum(sublist) for sublist in all_timesteps])/len(pi_e)\n",
        "      return V_est"
      ],
      "metadata": {
        "id": "Inr9VWwxdt-D"
      },
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calc_V_pi_e(pi_e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLSYllBYd1j5",
        "outputId": "13bae21c-31a8-4fd5-a121-e5d83445f42e"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8191611431930346"
            ]
          },
          "metadata": {},
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SC_straight = SCOPE_straight(model = None, gamma = test_experiment.gamma, num_bootstraps=30000, pi_b = pi_b_run, P_pi_b = P_pi_b, pi_e = pi_e, P_pi_e = P_pi_e, percent_to_estimate_phi = 0.3, shaping_function = smallest_distance_to_death, env = test_experiment.initialize_env(), dtype = None)"
      ],
      "metadata": {
        "id": "KI31_A7qsK-t"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SC_straight.IS_pipeline()"
      ],
      "metadata": {
        "id": "b3ghkvCMtPLD"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.var(all_V_step_IS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKw5LeUzIma7",
        "outputId": "94512f86-5f37-4eda-a95a-4e3a697cf963"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7917807934639121"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the min and max values\n",
        "min_value = np.min(bootstrap_means)\n",
        "max_value = np.max(bootstrap_means)\n",
        "\n",
        "# Normalize the array\n",
        "normalized_bootstrap_means = (bootstrap_means - min_value) / (max_value - min_value)\n",
        "\n",
        "variance = np.var(normalized_bootstrap_means)\n",
        "print(variance)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZKhQGOcAllb",
        "outputId": "0738ca5e-18ef-4569-cc69-f6a30d47ae59"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.019792605354133245\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_bootstrap_means = bootstrap_means * 1e2  # Example scaling factor\n",
        "variance = np.var(scaled_bootstrap_means)\n",
        "print(variance)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyeG_GZSC9wc",
        "outputId": "32c2a769-e856-4f64-f069-d6850946ca33"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "209.1000522177498\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mad = np.median(np.abs(bootstrap_means - np.median(bootstrap_means)))\n",
        "variance = mad * mad  # Variance approximation using MAD\n",
        "print(variance)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7cDXuN4DuaX",
        "outputId": "aae4c452-034a-41d7-8709-dfee64865a8d"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.009898897176736901\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "variance = np.var(bootstrap_means, dtype=np.float64)\n",
        "print(variance)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RLdQE5oECV2",
        "outputId": "2a866221-6d95-4f96-fe49-6b494193e8c6"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.020910005221774983\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# log_bootstrap_means = np.log(bootstrap_means + 1e-30)  # Add a small epsilon to handle zeros\n",
        "# variance = np.var(log_bootstrap_means)\n",
        "# print(variance)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FCTUZ0dDy0y",
        "outputId": "d6f313b6-7305-46fc-d011-29d47321b423"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2799471240982541\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bootstrap_means[0:200]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5VN8XFOEGS1",
        "outputId": "0e20099d-3004-47ec-8cfa-826cb5a63036"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.00083859, 0.00048591, 0.0003977 , 0.00045198, 0.00035291,\n",
              "       0.00058272, 0.0003522 , 0.00050414, 0.00072202, 0.00080958,\n",
              "       0.00050293, 0.00039444, 0.00036934, 0.00034041, 0.00042223,\n",
              "       0.00018258, 0.00045941, 0.00100866, 0.00023944, 0.00025301,\n",
              "       0.00067334, 0.00088244, 0.00043585, 0.00032923, 0.00046097,\n",
              "       0.00069782, 0.00018635, 0.00061946, 0.00023485, 0.00022877,\n",
              "       0.00079735, 0.00039855, 0.00046781, 0.00084626, 0.00035536,\n",
              "       0.0001066 , 0.00081174, 0.00048926, 0.0003119 , 0.00042377,\n",
              "       0.00042202, 0.00042292, 0.00036902, 0.00073654, 0.00048526,\n",
              "       0.00070892, 0.00046643, 0.00048265, 0.00030032, 0.00054691,\n",
              "       0.00084179, 0.0004032 , 0.00024322, 0.00065421, 0.00066153,\n",
              "       0.00087003, 0.00046687, 0.0006341 , 0.00043848, 0.00062417,\n",
              "       0.00050741, 0.00094303, 0.00079775, 0.00049285, 0.00042433,\n",
              "       0.00072435, 0.00040096, 0.0006425 , 0.0007355 , 0.0006746 ,\n",
              "       0.00034693, 0.00037134, 0.00069853, 0.00067243, 0.0007485 ,\n",
              "       0.00041602, 0.00059859, 0.0003665 , 0.00046144, 0.00043906,\n",
              "       0.00077715, 0.00031673, 0.00048384, 0.00077449, 0.00051174,\n",
              "       0.00056258, 0.00091236, 0.00060042, 0.00047133, 0.00089754,\n",
              "       0.00070693, 0.00078389, 0.00032781, 0.00068438, 0.0004965 ,\n",
              "       0.00054999, 0.00034681, 0.0002728 , 0.00044388, 0.00040284,\n",
              "       0.00035004, 0.00021634, 0.00038018, 0.0006256 , 0.00013369,\n",
              "       0.00033579, 0.00048075, 0.00048595, 0.00046872, 0.00065402,\n",
              "       0.00055752, 0.00046867, 0.00035063, 0.0005382 , 0.0003832 ,\n",
              "       0.00016867, 0.00039546, 0.00076398, 0.00054512, 0.00028678,\n",
              "       0.00031483, 0.00064282, 0.00093709, 0.00067242, 0.0005524 ,\n",
              "       0.00037299, 0.00039836, 0.00082176, 0.00054444, 0.00015809,\n",
              "       0.00031014, 0.00028543, 0.00047215, 0.00046578, 0.00095105,\n",
              "       0.00069543, 0.0004251 , 0.00054318, 0.00040886, 0.00059429,\n",
              "       0.00031441, 0.00076458, 0.00048524, 0.00049129, 0.00040838,\n",
              "       0.00032292, 0.00040808, 0.00047685, 0.00048552, 0.00068698,\n",
              "       0.00084895, 0.00025192, 0.00079149, 0.00031178, 0.00047269,\n",
              "       0.00048088, 0.00033894, 0.00032828, 0.00066667, 0.0005585 ,\n",
              "       0.00071842, 0.0003177 , 0.00060285, 0.0006388 , 0.00037794,\n",
              "       0.0005165 , 0.00074744, 0.00048129, 0.0005506 , 0.00096063,\n",
              "       0.00043101, 0.00063756, 0.00057549, 0.00098651, 0.00043737,\n",
              "       0.0006178 , 0.00050941, 0.00047827, 0.0006936 , 0.00075273,\n",
              "       0.00028262, 0.00046664, 0.00030551, 0.00019785, 0.00042926,\n",
              "       0.00050208, 0.00078758, 0.00036236, 0.00029232, 0.00046144,\n",
              "       0.00026931, 0.00043528, 0.00060617, 0.00053804, 0.0008908 ,\n",
              "       0.00049836, 0.00045417, 0.00073232, 0.00044254, 0.00049748])"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.var(bootstrap_means)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUBWXEKHA8l0",
        "outputId": "d6b2a219-7593-47ba-da15-9863a45cde60"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.729209224658027e-08"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.var(normalized_bootstrap_means)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "070NOLRPAnTE",
        "outputId": "aaa8bf32-ee70-45f4-b2e4-55151965e1e2"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.01785870756374992"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bootstrap_means"
      ],
      "metadata": {
        "id": "sYP6MOK5BWR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "episode_probs_b_and_e[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxxxuxwI22A5",
        "outputId": "ea0e52e1-7007-4134-e382-86fc14fe7bc4"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[([2.0, 9.0], 3, 0.96, 0.36, 2.6666666666666665),\n",
              " ([1.0, 9.0], 3, 0.96, 0.36, 2.6666666666666665),\n",
              " ([0.0, 9.0], 1, 0.96, 0.36, 2.6666666666666665),\n",
              " ([0.0, 8.0], 4, 0.01, 0.16, 0.0625),\n",
              " ([1.0, 8.0], 0, 0.01, 0.16, 0.0625),\n",
              " ([1.0, 8.0], 1, 0.96, 0.36, 2.6666666666666665),\n",
              " ([1.0, 7.0], 3, 0.96, 0.36, 2.6666666666666665),\n",
              " ([0.0, 7.0], 1, 0.96, 0.36, 2.6666666666666665),\n",
              " ([0.0, 6.0], 1, 0.96, 0.36, 2.6666666666666665),\n",
              " ([0.0, 5.0], 1, 0.96, 0.36, 2.6666666666666665),\n",
              " ([0.0, 4.0], 4, 0.96, 0.36, 2.6666666666666665),\n",
              " ([1.0, 4.0], 0, 0.01, 0.16, 0.0625),\n",
              " ([1.0, 4.0], 2, 0.01, 0.16, 0.0625),\n",
              " ([1.0, 4.0], 1, 0.96, 0.36, 2.6666666666666665),\n",
              " ([1.0, 3.0], 3, 0.01, 0.16, 0.0625),\n",
              " ([0.0, 3.0], 4, 0.01, 0.16, 0.0625),\n",
              " ([1.0, 3.0], 4, 0.96, 0.36, 2.6666666666666665),\n",
              " ([2.0, 3.0], 4, 0.01, 0.16, 0.0625),\n",
              " ([3.0, 3.0], 1, 0.96, 0.36, 2.6666666666666665),\n",
              " ([3.0, 2.0], 1, 0.96, 0.36, 2.6666666666666665),\n",
              " ([3.0, 1.0], 3, 0.01, 0.16, 0.0625),\n",
              " ([2.0, 1.0], 0, 0.01, 0.16, 0.0625),\n",
              " ([2.0, 1.0], 4, 0.01, 0.16, 0.0625),\n",
              " ([3.0, 1.0], 3, 0.01, 0.16, 0.0625),\n",
              " ([2.0, 1.0], 3, 0.01, 0.16, 0.0625),\n",
              " ([1.0, 1.0], 1, 0.01, 0.16, 0.0625),\n",
              " ([1.0, 1.0], 3, 0.01, 0.16, 0.0625),\n",
              " ([0.0, 1.0], 2, 0.96, 0.36, 2.6666666666666665),\n",
              " ([0.0, 2.0], 4, 0.01, 0.16, 0.0625),\n",
              " ([1.0, 2.0], 2, 0.96, 0.36, 2.6666666666666665),\n",
              " ([1.0, 3.0], 4, 0.96, 0.36, 2.6666666666666665),\n",
              " ([2.0, 3.0], 3, 0.01, 0.16, 0.0625),\n",
              " ([1.0, 3.0], 4, 0.96, 0.36, 2.6666666666666665),\n",
              " ([2.0, 3.0], 1, 0.96, 0.36, 2.6666666666666665),\n",
              " ([2.0, 2.0], 2, 0.01, 0.16, 0.0625),\n",
              " ([2.0, 3.0], 3, 0.01, 0.16, 0.0625),\n",
              " ([1.0, 3.0], 4, 0.96, 0.36, 2.6666666666666665),\n",
              " ([2.0, 3.0], 2, 0.01, 0.16, 0.0625),\n",
              " ([2.0, 4.0], 1, 0.96, 0.36, 2.6666666666666665),\n",
              " ([2.0, 3.0], 3, 0.01, 0.16, 0.0625),\n",
              " ([1.0, 3.0], 0, 0.01, 0.16, 0.0625),\n",
              " ([1.0, 3.0], 0, 0.01, 0.16, 0.0625),\n",
              " ([1.0, 3.0], 1, 0.01, 0.16, 0.0625),\n",
              " ([1.0, 2.0], 1, 0.01, 0.16, 0.0625),\n",
              " ([1.0, 1.0], 1, 0.01, 0.16, 0.0625),\n",
              " ([1.0, 1.0], 2, 0.96, 0.36, 2.6666666666666665),\n",
              " ([1.0, 2.0], 3, 0.01, 0.16, 0.0625),\n",
              " ([0.0, 2.0], 0, 0.01, 0.16, 0.0625),\n",
              " ([0.0, 2.0], 1, 0.01, 0.16, 0.0625),\n",
              " ([0.0, 1.0], 4, 0.01, 0.16, 0.0625),\n",
              " ([1.0, 1.0], 1, 0.01, 0.16, 0.0625),\n",
              " ([1.0, 1.0], 1, 0.01, 0.16, 0.0625),\n",
              " ([1.0, 1.0], 0, 0.01, 0.16, 0.0625),\n",
              " ([1.0, 1.0], 3, 0.01, 0.16, 0.0625),\n",
              " ([0.0, 1.0], 1, 0.01, 0.16, 0.0625),\n",
              " ([0.0, 1.0], 1, 0.01, 0.16, 0.0625),\n",
              " ([0.0, 1.0], 1, 0.01, 0.16, 0.0625),\n",
              " ([0.0, 1.0], 2, 0.96, 0.36, 2.6666666666666665),\n",
              " ([0.0, 2.0], 3, 0.01, 0.16, 0.0625),\n",
              " ([0.0, 2.0], 3, 0.01, 0.16, 0.0625),\n",
              " ([0.0, 2.0], 1, 0.01, 0.16, 0.0625),\n",
              " ([0.0, 1.0], 2, 0.96, 0.36, 2.6666666666666665),\n",
              " ([0.0, 2.0], 0, 0.01, 0.16, 0.0625),\n",
              " ([0.0, 2.0], 2, 0.96, 0.36, 2.6666666666666665),\n",
              " ([0.0, 3.0], 3, 0.01, 0.16, 0.0625),\n",
              " ([0.0, 3.0], 0, 0.01, 0.16, 0.0625),\n",
              " ([0.0, 3.0], 1, 0.01, 0.16, 0.0625),\n",
              " ([0.0, 2.0], 1, 0.01, 0.16, 0.0625),\n",
              " ([0.0, 1.0], 0, 0.01, 0.16, 0.0625),\n",
              " ([0.0, 1.0], 3, 0.01, 0.16, 0.0625)]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pi_b[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udU-dXkbze_G",
        "outputId": "471c81d9-c8ba-47ec-a550-2f2f830614db"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([([2., 9.], 0, 0., [2., 9.],  0, 0.00223088),\n",
              "       ([2., 9.], 3, 0., [1., 9.],  1, 0.00223088),\n",
              "       ([1., 9.], 1, 0., [1., 8.],  2, 0.00606415),\n",
              "       ([1., 8.], 3, 0., [0., 8.],  3, 0.01648407),\n",
              "       ([0., 8.], 0, 0., [0., 8.],  4, 0.04480836),\n",
              "       ([0., 8.], 2, 0., [0., 9.],  5, 0.04480836),\n",
              "       ([0., 9.], 1, 0., [0., 8.],  6, 0.01648407),\n",
              "       ([0., 8.], 2, 0., [0., 9.],  7, 0.04480836),\n",
              "       ([0., 9.], 0, 0., [0., 9.],  8, 0.01648407),\n",
              "       ([0., 9.], 1, 0., [0., 8.],  9, 0.01648407),\n",
              "       ([0., 8.], 0, 0., [0., 8.], 10, 0.04480836),\n",
              "       ([0., 8.], 1, 0., [0., 7.], 11, 0.04480836),\n",
              "       ([0., 7.], 4, 0., [1., 7.], 12, 0.12180176),\n",
              "       ([1., 7.], 0, 0., [1., 7.], 13, 0.04480836),\n",
              "       ([1., 7.], 2, 0., [1., 8.], 14, 0.04480836),\n",
              "       ([1., 8.], 1, 0., [1., 7.], 15, 0.01648407),\n",
              "       ([1., 7.], 3, 0., [0., 7.], 16, 0.04480836),\n",
              "       ([0., 7.], 4, 0., [1., 7.], 17, 0.12180176),\n",
              "       ([1., 7.], 0, 0., [1., 7.], 18, 0.04480836),\n",
              "       ([1., 7.], 3, 0., [0., 7.], 19, 0.04480836),\n",
              "       ([0., 7.], 4, 0., [1., 7.], 20, 0.12180176),\n",
              "       ([1., 7.], 2, 0., [1., 8.], 21, 0.04480836),\n",
              "       ([1., 8.], 0, 0., [1., 8.], 22, 0.01648407),\n",
              "       ([1., 8.], 3, 0., [0., 8.], 23, 0.01648407),\n",
              "       ([0., 8.], 1, 0., [0., 7.], 24, 0.04480836),\n",
              "       ([0., 7.], 1, 0., [0., 6.], 25, 0.12180176),\n",
              "       ([0., 6.], 2, 0., [0., 7.], 26, 0.3310915 ),\n",
              "       ([0., 7.], 0, 0., [0., 7.], 27, 0.12180176),\n",
              "       ([0., 7.], 2, 0., [0., 8.], 28, 0.12180176),\n",
              "       ([0., 8.], 4, 0., [1., 8.], 29, 0.04480836),\n",
              "       ([1., 8.], 1, 0., [1., 7.], 30, 0.01648407),\n",
              "       ([1., 7.], 0, 0., [1., 7.], 31, 0.04480836),\n",
              "       ([1., 7.], 3, 0., [0., 7.], 32, 0.04480836),\n",
              "       ([0., 7.], 1, 0., [0., 6.], 33, 0.12180176),\n",
              "       ([0., 6.], 1, 0., [0., 5.], 34, 0.3310915 ),\n",
              "       ([0., 5.], 1, 0., [0., 4.], 35, 0.9       ),\n",
              "       ([0., 4.], 0, 0., [0., 4.], 36, 0.10011107),\n",
              "       ([0., 4.], 1, 0., [0., 3.], 37, 0.10011107),\n",
              "       ([0., 3.], 3, 0., [0., 3.], 38, 0.10030191),\n",
              "       ([0., 3.], 2, 0., [0., 4.], 39, 0.10030191),\n",
              "       ([0., 4.], 4, 0., [1., 4.], 40, 0.10011107),\n",
              "       ([1., 4.], 4, 0., [2., 4.], 41, 0.10030191),\n",
              "       ([2., 4.], 1, 0., [2., 3.], 42, 0.10082069),\n",
              "       ([2., 3.], 1, 0., [2., 2.], 43, 0.10223088),\n",
              "       ([2., 2.], 3, 0., [1., 2.], 44, 0.10606416),\n",
              "       ([1., 2.], 1, 0., [1., 1.], 45, 0.10223088),\n",
              "       ([1., 1.], 3, 0., [0., 1.], 46, 0.10606416),\n",
              "       ([0., 1.], 4, 0., [1., 1.], 47, 0.10223088),\n",
              "       ([1., 1.], 2, 0., [1., 2.], 48, 0.10606416),\n",
              "       ([1., 2.], 1, 0., [1., 1.], 49, 0.10223088),\n",
              "       ([1., 1.], 3, 0., [0., 1.], 50, 0.10606416),\n",
              "       ([0., 1.], 0, 0., [0., 1.], 51, 0.10223088),\n",
              "       ([0., 1.], 3, 0., [0., 1.], 52, 0.10223088),\n",
              "       ([0., 1.], 4, 0., [1., 1.], 53, 0.10223088),\n",
              "       ([1., 1.], 2, 0., [1., 2.], 54, 0.10606416),\n",
              "       ([1., 2.], 2, 0., [1., 3.], 55, 0.10223088),\n",
              "       ([1., 3.], 3, 0., [0., 3.], 56, 0.10082069),\n",
              "       ([0., 3.], 0, 0., [0., 3.], 57, 0.10030191),\n",
              "       ([0., 3.], 4, 0., [1., 3.], 58, 0.10030191),\n",
              "       ([1., 3.], 1, 0., [1., 2.], 59, 0.10082069),\n",
              "       ([1., 2.], 0, 0., [1., 2.], 60, 0.10223088),\n",
              "       ([1., 2.], 2, 0., [1., 3.], 61, 0.10223088),\n",
              "       ([1., 3.], 4, 0., [2., 3.], 62, 0.10082069),\n",
              "       ([2., 3.], 1, 0., [2., 2.], 63, 0.10223088),\n",
              "       ([2., 2.], 4, 0., [3., 2.], 64, 0.10606416),\n",
              "       ([3., 2.], 4, 0., [4., 2.], 65, 0.11648408),\n",
              "       ([4., 2.], 3, 0., [3., 2.], 66, 0.14480837),\n",
              "       ([3., 2.], 4, 0., [4., 2.], 67, 0.11648408),\n",
              "       ([4., 2.], 3, 0., [3., 2.], 68, 0.14480837),\n",
              "       ([3., 2.], 1, 0., [3., 2.], 69, 0.11648408)],\n",
              "      dtype=[('state', '<f4', (2,)), ('action', '<i4'), ('reward', '<f4'), ('state_next', '<f4', (2,)), ('timestep', '<i4'), ('psi', '<f4')])"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.sum(0.99**np.arange(len(rews)) * np.cumprod(np.array(rhos)) * np.array(rews))"
      ],
      "metadata": {
        "id": "xZ5ATj7hz08s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rhos_0 = episode_rhos[0]"
      ],
      "metadata": {
        "id": "tkWxIrIxzHFr"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rhos_0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tq4mtjWc0LTj",
        "outputId": "0e195e40-4865-4c73-ae80-a41f0d7cfdc3"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.411764705882353,\n",
              " 1.411764705882353,\n",
              " 1.411764705882353,\n",
              " 1.411764705882353,\n",
              " 1.411764705882353,\n",
              " 1.411764705882353,\n",
              " 1.411764705882353,\n",
              " 1.411764705882353,\n",
              " 1.411764705882353,\n",
              " 1.411764705882353,\n",
              " 1.411764705882353,\n",
              " 1.411764705882353,\n",
              " 1.411764705882353,\n",
              " 1.411764705882353,\n",
              " 1.411764705882353,\n",
              " 0.125,\n",
              " 1.411764705882353,\n",
              " 1.411764705882353]"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.cumprod(np.array(rhos_0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8nhU9d00Brz",
        "outputId": "8c57c944-84d6-45aa-a77c-9fcb797eb91a"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  1.41176471,   1.99307958,   2.81375941,   3.97236623,\n",
              "         5.60804644,   7.91724204,  11.17728288,  15.77969348,\n",
              "        22.27721432,  31.45018492,  44.40026106,  62.6827215 ,\n",
              "        88.49325388, 124.93165254, 176.3740977 ,  22.04676221,\n",
              "        31.12484077,  43.94095168])"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "episode_rews[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxfC6e5Uz8VW",
        "outputId": "e9e69aa5-4bbe-4d5e-dcad-a930607d1528"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0]"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_e"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-uf4ZdcDIxz",
        "outputId": "2fb26fc7-7c12-419d-e2e6-8f85bf7933c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.01, 0.01, 0.01, 0.01, 0.96],\n",
              "        [0.01, 0.01, 0.96, 0.01, 0.01],\n",
              "        [0.01, 0.01, 0.96, 0.01, 0.01],\n",
              "        [0.01, 0.01, 0.96, 0.01, 0.01],\n",
              "        [0.01, 0.01, 0.01, 0.01, 0.96],\n",
              "        [0.01, 0.96, 0.01, 0.01, 0.01],\n",
              "        [0.01, 0.96, 0.01, 0.01, 0.01],\n",
              "        [0.01, 0.96, 0.01, 0.01, 0.01],\n",
              "        [0.01, 0.96, 0.01, 0.01, 0.01],\n",
              "        [0.01, 0.96, 0.01, 0.01, 0.01]],\n",
              "\n",
              "       [[0.01, 0.01, 0.01, 0.01, 0.96],\n",
              "        [0.01, 0.01, 0.96, 0.01, 0.01],\n",
              "        [0.01, 0.01, 0.96, 0.01, 0.01],\n",
              "        [0.01, 0.01, 0.01, 0.01, 0.96],\n",
              "        [0.01, 0.96, 0.01, 0.01, 0.01],\n",
              "        [0.01, 0.01, 0.01, 0.01, 0.96],\n",
              "        [0.01, 0.01, 0.01, 0.96, 0.01],\n",
              "        [0.01, 0.01, 0.01, 0.96, 0.01],\n",
              "        [0.01, 0.96, 0.01, 0.01, 0.01],\n",
              "        [0.01, 0.01, 0.01, 0.96, 0.01]],\n",
              "\n",
              "       [[0.01, 0.01, 0.01, 0.01, 0.96],\n",
              "        [0.01, 0.01, 0.96, 0.01, 0.01],\n",
              "        [0.01, 0.01, 0.01, 0.01, 0.96],\n",
              "        [0.01, 0.96, 0.01, 0.01, 0.01],\n",
              "        [0.01, 0.96, 0.01, 0.01, 0.01],\n",
              "        [0.01, 0.01, 0.01, 0.01, 0.96],\n",
              "        [0.01, 0.01, 0.01, 0.96, 0.01],\n",
              "        [0.01, 0.01, 0.01, 0.96, 0.01],\n",
              "        [0.01, 0.01, 0.01, 0.96, 0.01],\n",
              "        [0.01, 0.01, 0.01, 0.96, 0.01]],\n",
              "\n",
              "       [[0.01, 0.01, 0.01, 0.01, 0.96],\n",
              "        [0.01, 0.01, 0.01, 0.01, 0.96],\n",
              "        [0.01, 0.96, 0.01, 0.01, 0.01],\n",
              "        [0.01, 0.96, 0.01, 0.01, 0.01],\n",
              "        [0.01, 0.96, 0.01, 0.01, 0.01],\n",
              "        [0.01, 0.01, 0.01, 0.01, 0.96],\n",
              "        [0.01, 0.01, 0.01, 0.96, 0.01],\n",
              "        [0.01, 0.01, 0.01, 0.96, 0.01],\n",
              "        [0.01, 0.01, 0.01, 0.96, 0.01],\n",
              "        [0.01, 0.01, 0.01, 0.96, 0.01]],\n",
              "\n",
              "       [[0.01, 0.01, 0.01, 0.01, 0.96],\n",
              "        [0.01, 0.01, 0.01, 0.01, 0.96],\n",
              "        [0.01, 0.96, 0.01, 0.01, 0.01],\n",
              "        [0.01, 0.96, 0.01, 0.01, 0.01],\n",
              "        [0.01, 0.96, 0.01, 0.01, 0.01],\n",
              "        [0.01, 0.01, 0.01, 0.01, 0.96],\n",
              "        [0.01, 0.01, 0.01, 0.96, 0.01],\n",
              "        [0.01, 0.01, 0.01, 0.96, 0.01],\n",
              "        [0.01, 0.01, 0.01, 0.96, 0.01],\n",
              "        [0.01, 0.01, 0.01, 0.96, 0.01]],\n",
              "\n",
              "       [[0.01, 0.01, 0.01, 0.01, 0.96],\n",
              "        [0.01, 0.96, 0.01, 0.01, 0.01],\n",
              "        [0.01, 0.96, 0.01, 0.01, 0.01],\n",
              "        [0.01, 0.96, 0.01, 0.01, 0.01],\n",
              "        [0.01, 0.01, 0.01, 0.96, 0.01],\n",
              "        [0.01, 0.01, 0.01, 0.01, 0.96],\n",
              "        [0.01, 0.96, 0.01, 0.01, 0.01],\n",
              "        [0.01, 0.96, 0.01, 0.01, 0.01],\n",
              "        [0.01, 0.01, 0.01, 0.01, 0.96],\n",
              "        [0.01, 0.01, 0.01, 0.01, 0.96]],\n",
              "\n",
              "       [[0.01, 0.01, 0.01, 0.01, 0.96],\n",
              "        [0.01, 0.96, 0.01, 0.01, 0.01],\n",
              "        [0.01, 0.96, 0.01, 0.01, 0.01],\n",
              "        [0.01, 0.01, 0.01, 0.96, 0.01],\n",
              "        [0.01, 0.01, 0.01, 0.96, 0.01],\n",
              "        [0.01, 0.01, 0.01, 0.96, 0.01],\n",
              "        [0.96, 0.01, 0.01, 0.01, 0.01],\n",
              "        [0.01, 0.01, 0.96, 0.01, 0.01],\n",
              "        [0.01, 0.01, 0.01, 0.01, 0.96],\n",
              "        [0.96, 0.01, 0.01, 0.01, 0.01]],\n",
              "\n",
              "       [[0.01, 0.01, 0.01, 0.01, 0.96],\n",
              "        [0.01, 0.96, 0.01, 0.01, 0.01],\n",
              "        [0.01, 0.01, 0.01, 0.96, 0.01],\n",
              "        [0.01, 0.01, 0.01, 0.96, 0.01],\n",
              "        [0.01, 0.01, 0.01, 0.96, 0.01],\n",
              "        [0.01, 0.01, 0.01, 0.96, 0.01],\n",
              "        [0.01, 0.01, 0.01, 0.01, 0.96],\n",
              "        [0.96, 0.01, 0.01, 0.01, 0.01],\n",
              "        [0.01, 0.96, 0.01, 0.01, 0.01],\n",
              "        [0.96, 0.01, 0.01, 0.01, 0.01]],\n",
              "\n",
              "       [[0.01, 0.01, 0.01, 0.01, 0.96],\n",
              "        [0.01, 0.01, 0.01, 0.96, 0.01],\n",
              "        [0.01, 0.01, 0.01, 0.96, 0.01],\n",
              "        [0.01, 0.01, 0.01, 0.96, 0.01],\n",
              "        [0.01, 0.01, 0.01, 0.96, 0.01],\n",
              "        [0.01, 0.01, 0.01, 0.96, 0.01],\n",
              "        [0.01, 0.96, 0.01, 0.01, 0.01],\n",
              "        [0.01, 0.01, 0.01, 0.96, 0.01],\n",
              "        [0.01, 0.01, 0.96, 0.01, 0.01],\n",
              "        [0.96, 0.01, 0.01, 0.01, 0.01]],\n",
              "\n",
              "       [[0.01, 0.01, 0.01, 0.01, 0.96],\n",
              "        [0.01, 0.01, 0.01, 0.01, 0.96],\n",
              "        [0.01, 0.01, 0.01, 0.01, 0.96],\n",
              "        [0.01, 0.01, 0.01, 0.01, 0.96],\n",
              "        [0.01, 0.01, 0.01, 0.01, 0.96],\n",
              "        [0.01, 0.01, 0.01, 0.01, 0.96],\n",
              "        [0.01, 0.01, 0.01, 0.01, 0.96],\n",
              "        [0.01, 0.01, 0.01, 0.01, 0.96],\n",
              "        [0.01, 0.01, 0.01, 0.01, 0.96],\n",
              "        [0.01, 0.01, 0.01, 0.01, 0.96]]])"
            ]
          },
          "metadata": {},
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def kl_divergence(P, Q):\n",
        "    return np.sum(P * np.log(P / Q))\n",
        "\n",
        "def compute_kl_divergences(Q1, Q2):\n",
        "    kl_divs = []\n",
        "    for i in range(Q1.shape[0]):\n",
        "        for j in range(Q1.shape[1]):\n",
        "            P = Q1[i, j]\n",
        "            Q = Q2[i, j]\n",
        "            kl_divs.append(kl_divergence(P, Q))\n",
        "    return kl_divs"
      ],
      "metadata": {
        "id": "betY4i6cOWsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_e[0,1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crPFcjbQPe71",
        "outputId": "4047ada5-e843-479f-a140-f35b80182ccd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.01, 0.01, 0.96, 0.01, 0.01])"
            ]
          },
          "metadata": {},
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b = test_experiment.action_probs_top_n_epsilon(2,0.4)\n",
        "P_pi_e = test_experiment.action_probs_top_n_epsilon(1,0.05)"
      ],
      "metadata": {
        "id": "DYYMs7-pO5FQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute KL divergences\n",
        "kl_divs = compute_kl_divergences(P_pi_e, P_pi_b)\n",
        "\n",
        "# Aggregate KL divergences\n",
        "average_kl_divergence = np.mean(kl_divs)"
      ],
      "metadata": {
        "id": "Ui2BApcQOYpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kl_divs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9D85wY0IOkp9",
        "outputId": "d072b888-3772-494a-9f6e-e7524e27c6f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7909324426241334,\n",
              " 0.7909324426241333,\n",
              " 0.7909324426241333,\n",
              " 0.7909324426241333,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241333,\n",
              " 0.7909324426241333,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241333,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241333,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241333,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241333,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334,\n",
              " 0.7909324426241334]"
            ]
          },
          "metadata": {},
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "average_kl_divergence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOgGPcBBOgxv",
        "outputId": "980a1410-d8c7-4db9-de90-ed0255112c36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.24786920517286704"
            ]
          },
          "metadata": {},
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def PDIS(trajectories,p_e,p_b,negligible_states=[],period=float(\"inf\")):\n",
        "    E_G = 0\n",
        "    scores=[]\n",
        "    for i, trajectory in enumerate(trajectories):\n",
        "        G=0\n",
        "        for t in range(1,len(trajectory)+1):\n",
        "            importance_prod = 1\n",
        "            if p_e is None and p_b is None:\n",
        "                for (s,a,r,rho) in trajectory[0:t]:\n",
        "                    if s not in negligible_states:\n",
        "                        importance_prod = importance_prod * rho\n",
        "            else:\n",
        "                for (s,a,r) in trajectory[0:t]:\n",
        "                    if s not in negligible_states:\n",
        "                        importance_prod = importance_prod * p_e[s][a]/p_b[s][a]\n",
        "            # use the last r\n",
        "            G += importance_prod * r\n",
        "        E_G+=G\n",
        "        if i > 0 and i % period == 0:\n",
        "            scores.append(E_G/(i+1))\n",
        "    scores.append(E_G / len(trajectories))\n",
        "    print(\"PDIS \",scores[-1])\n",
        "    return scores"
      ],
      "metadata": {
        "id": "a4qXUwdI-BHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_load.save_heatmap()"
      ],
      "metadata": {
        "id": "v8minUJR4NGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_experiment = SCOPE_experiment(**params)\n",
        "test_experiment.run_experiment()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zRl0N5glDJu",
        "outputId": "345f5b79-c598-4032-eb75-fa2107a26a38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The file 600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_70.pt already exists in the folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_heatmap(data, save_path='heatmap.png'):\n",
        "    values = np.zeros((10, 10))\n",
        "    for (x, y), value in data.items():\n",
        "        values[y, x] = value\n",
        "\n",
        "    # Flip the values horizontally\n",
        "    values = np.flip(values, axis=1)\n",
        "\n",
        "    # Create the heatmap using Matplotlib\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(values, cmap='viridis', origin='lower')\n",
        "    plt.colorbar(label='Values')\n",
        "\n",
        "    # Add labels and title\n",
        "    plt.xlabel('X')\n",
        "    plt.ylabel('Y')\n",
        "    plt.title('Heatmap')\n",
        "    plt.xticks(np.arange(10), labels=np.arange(10))\n",
        "    plt.yticks(np.arange(10), labels=np.arange(9, -1, -1))\n",
        "\n",
        "    # Save the plot\n",
        "    plt.savefig(save_path)\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()\n",
        "\n",
        "# Dummy data for testing\n",
        "dummy_data = {(i, j): i * 10 + j for i in range(10) for j in range(10)}\n",
        "\n",
        "# Test the plotting function\n",
        "plot_heatmap(dummy_data, save_path='heatmap.png')"
      ],
      "metadata": {
        "id": "Y1b5Xlgz59kE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the varying trajectory lengths\n",
        "num_trajectories = [200, 400, 600, 800, 1000]\n",
        "# Define hidden_dims\n",
        "hidden_dimens = [[8],[8,8],[32]]\n",
        "# Define trajectory lengths\n",
        "trajectory_length = [30, 50, 70, 100]\n",
        "\n",
        "for num in num_trajectories:\n",
        "  # Modify the base parameters for each experiment\n",
        "  # params = base_params_test.copy()  # Make a copy to avoid modifying the base parameters\n",
        "  params[\"num_trajectories\"] = num  # Update the number of trajectories\n",
        "\n",
        "  for dims in hidden_dimens:\n",
        "    # params = base_params_test.copy()  # Make a copy to avoid modifying the base parameters\n",
        "    params[\"hidden_dims\"] = dims\n",
        "\n",
        "    for len in trajectory_length:\n",
        "      params[\"max_length\"] = len\n",
        "\n",
        "      # Create an instance of SCOPE_experiment with modified parameters\n",
        "      test_experiment = SCOPE_experiment(**params)\n",
        "      test_experiment.run_experiment()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uROLEOneSW4",
        "outputId": "96c67cd7-d4f3-4bef-d246-3d1007b1704d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Total Loss: 3.4867157889696476\n",
            "----------------------------------------\n",
            "Epoch 187\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0886, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.3721690147865973\n",
            "SCOPE mean: 0.43945066292784213, SCOPE var: 0.01642347647810597\n",
            "Total Loss: 3.4607559647653416\n",
            "----------------------------------------\n",
            "Epoch 188\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0881, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.3468963191805345\n",
            "SCOPE mean: 0.4399420037071746, SCOPE var: 0.016439998658329152\n",
            "Total Loss: 3.434981902076833\n",
            "----------------------------------------\n",
            "Epoch 189\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0876, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.32181137391798\n",
            "SCOPE mean: 0.4402677806285472, SCOPE var: 0.01645277806321618\n",
            "Total Loss: 3.4093903951776205\n",
            "----------------------------------------\n",
            "Epoch 190\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0871, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.296906088465894\n",
            "SCOPE mean: 0.44061743803469017, SCOPE var: 0.016465892920917533\n",
            "Total Loss: 3.383984746869441\n",
            "----------------------------------------\n",
            "Epoch 191\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0866, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.272173677391711\n",
            "SCOPE mean: 0.440975812676019, SCOPE var: 0.01647934722180799\n",
            "Total Loss: 3.358757054857406\n",
            "----------------------------------------\n",
            "Epoch 192\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0861, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.2476167678188785\n",
            "SCOPE mean: 0.44134389870658025, SCOPE var: 0.016493125989877146\n",
            "Total Loss: 3.3337098411917694\n",
            "----------------------------------------\n",
            "Epoch 193\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0856, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.223233913645634\n",
            "SCOPE mean: 0.4417499849812617, SCOPE var: 0.01650747844040169\n",
            "Total Loss: 3.308841694203983\n",
            "----------------------------------------\n",
            "Epoch 194\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0851, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.1990215249221325\n",
            "SCOPE mean: 0.44218959041585704, SCOPE var: 0.016522294811214262\n",
            "Total Loss: 3.28414879578158\n",
            "----------------------------------------\n",
            "Epoch 195\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0847, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.174979023333444\n",
            "SCOPE mean: 0.4426582048721608, SCOPE var: 0.01653747823749681\n",
            "Total Loss: 3.2596303650223843\n",
            "----------------------------------------\n",
            "Epoch 196\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0842, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.1511105381214666\n",
            "SCOPE mean: 0.4431516358619303, SCOPE var: 0.016552958137816473\n",
            "Total Loss: 3.2352903782173543\n",
            "----------------------------------------\n",
            "Epoch 197\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0837, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.1274106997450084\n",
            "SCOPE mean: 0.443635901822402, SCOPE var: 0.016568303221634172\n",
            "Total Loss: 3.2111229970746598\n",
            "----------------------------------------\n",
            "Epoch 198\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0833, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.103884367143805\n",
            "SCOPE mean: 0.44414135238792296, SCOPE var: 0.01658458059108537\n",
            "Total Loss: 3.1871358035785673\n",
            "----------------------------------------\n",
            "Epoch 199\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0828, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.080526877589732\n",
            "SCOPE mean: 0.44438277789212255, SCOPE var: 0.01659482140948637\n",
            "Total Loss: 3.16330692365645\n",
            "----------------------------------------\n",
            "Epoch 200\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0823, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.057343574885868\n",
            "SCOPE mean: 0.4446896331881855, SCOPE var: 0.01660667297717948\n",
            "Total Loss: 3.13966036373263\n",
            "----------------------------------------\n",
            "Epoch 201\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0819, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.0343238062054136\n",
            "SCOPE mean: 0.4450281091573384, SCOPE var: 0.016618817168678437\n",
            "Total Loss: 3.1161817071094444\n",
            "----------------------------------------\n",
            "Epoch 202\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0814, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.01146679970083\n",
            "SCOPE mean: 0.44539534943254677, SCOPE var: 0.016631197313870142\n",
            "Total Loss: 3.092870042909488\n",
            "----------------------------------------\n",
            "Epoch 203\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0810, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.988771929464231\n",
            "SCOPE mean: 0.4457880166182982, SCOPE var: 0.016643752042082453\n",
            "Total Loss: 3.069724599708141\n",
            "----------------------------------------\n",
            "Epoch 204\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0805, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.966246805317477\n",
            "SCOPE mean: 0.44621812088267526, SCOPE var: 0.01665697982617738\n",
            "Total Loss: 3.046754214725618\n",
            "----------------------------------------\n",
            "Epoch 205\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0801, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.9438883982765\n",
            "SCOPE mean: 0.44642013303416644, SCOPE var: 0.016665340693171507\n",
            "Total Loss: 3.0239428057526156\n",
            "----------------------------------------\n",
            "Epoch 206\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0796, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.921689612102445\n",
            "SCOPE mean: 0.4466479840714656, SCOPE var: 0.016674327831862467\n",
            "Total Loss: 3.0012966725213124\n",
            "----------------------------------------\n",
            "Epoch 207\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0792, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.899645439438576\n",
            "SCOPE mean: 0.44688574291260974, SCOPE var: 0.01668309903392279\n",
            "Total Loss: 2.978807699744322\n",
            "----------------------------------------\n",
            "Epoch 208\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0787, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.8777447772920497\n",
            "SCOPE mean: 0.4471324184212657, SCOPE var: 0.01669379100016445\n",
            "Total Loss: 2.9564668098832056\n",
            "----------------------------------------\n",
            "Epoch 209\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0783, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.85599007242657\n",
            "SCOPE mean: 0.4473923972753463, SCOPE var: 0.01670646853654523\n",
            "Total Loss: 2.9342778367533167\n",
            "----------------------------------------\n",
            "Epoch 210\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0779, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.834382646676471\n",
            "SCOPE mean: 0.44766774615642246, SCOPE var: 0.01672092190101885\n",
            "Total Loss: 2.912241888294122\n",
            "----------------------------------------\n",
            "Epoch 211\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0774, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.812923862090989\n",
            "SCOPE mean: 0.44796052979516715, SCOPE var: 0.016736968876174478\n",
            "Total Loss: 2.8903601589306995\n",
            "----------------------------------------\n",
            "Epoch 212\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0770, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.7916147305217147\n",
            "SCOPE mean: 0.4482725745668715, SCOPE var: 0.016754451728418523\n",
            "Total Loss: 2.868633544862382\n",
            "----------------------------------------\n",
            "Epoch 213\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0766, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.7704570844477012\n",
            "SCOPE mean: 0.4485790342644882, SCOPE var: 0.0167729511743353\n",
            "Total Loss: 2.8470635764635137\n",
            "----------------------------------------\n",
            "Epoch 214\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0762, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.7494507075337773\n",
            "SCOPE mean: 0.44888403829479057, SCOPE var: 0.01679235567382983\n",
            "Total Loss: 2.8256499313255232\n",
            "----------------------------------------\n",
            "Epoch 215\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0758, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.7285942742842866\n",
            "SCOPE mean: 0.4492189109501688, SCOPE var: 0.016812852751601746\n",
            "Total Loss: 2.8043912322717013\n",
            "----------------------------------------\n",
            "Epoch 216\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0754, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.70788810515415\n",
            "SCOPE mean: 0.4495896443847805, SCOPE var: 0.016834404662709457\n",
            "Total Loss: 2.7832871774360943\n",
            "----------------------------------------\n",
            "Epoch 217\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0750, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.6873308585761593\n",
            "SCOPE mean: 0.44998752008132525, SCOPE var: 0.016856733176969344\n",
            "Total Loss: 2.762336857704385\n",
            "----------------------------------------\n",
            "Epoch 218\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0746, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.666922153784169\n",
            "SCOPE mean: 0.45041110288908903, SCOPE var: 0.016879692827140594\n",
            "Total Loss: 2.7415397089151723\n",
            "----------------------------------------\n",
            "Epoch 219\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0742, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.646662046427817\n",
            "SCOPE mean: 0.4508585510693879, SCOPE var: 0.01690351676505909\n",
            "Total Loss: 2.7208959140535085\n",
            "----------------------------------------\n",
            "Epoch 220\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0739, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.626546779145145\n",
            "SCOPE mean: 0.45130184782716953, SCOPE var: 0.016927387910317258\n",
            "Total Loss: 2.7004009213144395\n",
            "----------------------------------------\n",
            "Epoch 221\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0735, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.6065765072092986\n",
            "SCOPE mean: 0.45174098604210783, SCOPE var: 0.016951178478296507\n",
            "Total Loss: 2.68005467187404\n",
            "----------------------------------------\n",
            "Epoch 222\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0731, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.586768110695277\n",
            "SCOPE mean: 0.45225572829084904, SCOPE var: 0.016977001415222803\n",
            "Total Loss: 2.6598784379249785\n",
            "----------------------------------------\n",
            "Epoch 223\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0727, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.567102956492806\n",
            "SCOPE mean: 0.45248897901278123, SCOPE var: 0.01699158130792186\n",
            "Total Loss: 2.6398232771957537\n",
            "----------------------------------------\n",
            "Epoch 224\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0723, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.547599123001748\n",
            "SCOPE mean: 0.45259342537866815, SCOPE var: 0.017000002880441043\n",
            "Total Loss: 2.619924845570763\n",
            "----------------------------------------\n",
            "Epoch 225\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0719, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.528238506897756\n",
            "SCOPE mean: 0.4527537381454782, SCOPE var: 0.017010018842718865\n",
            "Total Loss: 2.6001758543599633\n",
            "----------------------------------------\n",
            "Epoch 226\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0716, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.5090178188120307\n",
            "SCOPE mean: 0.45296319246329414, SCOPE var: 0.017021395716183146\n",
            "Total Loss: 2.580572297579938\n",
            "----------------------------------------\n",
            "Epoch 227\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0712, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.4899330735334275\n",
            "SCOPE mean: 0.4531950116484187, SCOPE var: 0.017033810610712116\n",
            "Total Loss: 2.5611098691365672\n",
            "----------------------------------------\n",
            "Epoch 228\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0708, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.4709866533123175\n",
            "SCOPE mean: 0.45346959044442664, SCOPE var: 0.017047289686239368\n",
            "Total Loss: 2.541790708364533\n",
            "----------------------------------------\n",
            "Epoch 229\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0704, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.4521775126591048\n",
            "SCOPE mean: 0.4537841251214062, SCOPE var: 0.017061740565475356\n",
            "Total Loss: 2.522613597952826\n",
            "----------------------------------------\n",
            "Epoch 230\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0701, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.433502967734274\n",
            "SCOPE mean: 0.4541098149786918, SCOPE var: 0.01707676763673236\n",
            "Total Loss: 2.5035754278605165\n",
            "----------------------------------------\n",
            "Epoch 231\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0697, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.4149613557585567\n",
            "SCOPE mean: 0.45445525383957863, SCOPE var: 0.017091987831534008\n",
            "Total Loss: 2.484674424644396\n",
            "----------------------------------------\n",
            "Epoch 232\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0694, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.3965492519649443\n",
            "SCOPE mean: 0.45481043918344677, SCOPE var: 0.017107037311488032\n",
            "Total Loss: 2.4659068698374442\n",
            "----------------------------------------\n",
            "Epoch 233\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0690, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.378270288264659\n",
            "SCOPE mean: 0.4551905114822983, SCOPE var: 0.0171224497162863\n",
            "Total Loss: 2.447276304684253\n",
            "----------------------------------------\n",
            "Epoch 234\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0687, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.360124196876534\n",
            "SCOPE mean: 0.4555895648010419, SCOPE var: 0.017138057464553675\n",
            "Total Loss: 2.428782134478859\n",
            "----------------------------------------\n",
            "Epoch 235\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0683, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.34211378399779\n",
            "SCOPE mean: 0.45600263478759134, SCOPE var: 0.017153735910200713\n",
            "Total Loss: 2.4104269011581922\n",
            "----------------------------------------\n",
            "Epoch 236\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0680, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.324232711487018\n",
            "SCOPE mean: 0.45639895139962483, SCOPE var: 0.01716901479679977\n",
            "Total Loss: 2.392203710655336\n",
            "----------------------------------------\n",
            "Epoch 237\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0676, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.306484757359069\n",
            "SCOPE mean: 0.45677653306617994, SCOPE var: 0.017183784843446993\n",
            "Total Loss: 2.37411613663754\n",
            "----------------------------------------\n",
            "Epoch 238\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0673, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.2888693857790643\n",
            "SCOPE mean: 0.4571570091040528, SCOPE var: 0.017198169190823197\n",
            "Total Loss: 2.3561635856947816\n",
            "----------------------------------------\n",
            "Epoch 239\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0670, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.2713933519721046\n",
            "SCOPE mean: 0.4575777818237033, SCOPE var: 0.01721353283936423\n",
            "Total Loss: 2.3383557604120195\n",
            "----------------------------------------\n",
            "Epoch 240\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0666, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.2540419366583935\n",
            "SCOPE mean: 0.4576885721777011, SCOPE var: 0.017217819420202573\n",
            "Total Loss: 2.3206564598314428\n",
            "----------------------------------------\n",
            "Epoch 241\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0663, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.2368268378354395\n",
            "SCOPE mean: 0.4578566382668568, SCOPE var: 0.01722370961589481\n",
            "Total Loss: 2.303099869045777\n",
            "----------------------------------------\n",
            "Epoch 242\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0659, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.2197383085595326\n",
            "SCOPE mean: 0.4580397061752845, SCOPE var: 0.017229739452095338\n",
            "Total Loss: 2.285673075009255\n",
            "----------------------------------------\n",
            "Epoch 243\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0656, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.2027754676554965\n",
            "SCOPE mean: 0.45823763495374287, SCOPE var: 0.01723594983943835\n",
            "Total Loss: 2.268375215227812\n",
            "----------------------------------------\n",
            "Epoch 244\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0653, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.1859344974202317\n",
            "SCOPE mean: 0.45845058518808474, SCOPE var: 0.017242359757413336\n",
            "Total Loss: 2.2512027276873936\n",
            "----------------------------------------\n",
            "Epoch 245\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0649, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.1692153991329857\n",
            "SCOPE mean: 0.45867362705564746, SCOPE var: 0.01724906629534763\n",
            "Total Loss: 2.2341555344787367\n",
            "----------------------------------------\n",
            "Epoch 246\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0646, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.152619732622342\n",
            "SCOPE mean: 0.4588818320114098, SCOPE var: 0.017255813525469742\n",
            "Total Loss: 2.2172347664902032\n",
            "----------------------------------------\n",
            "Epoch 247\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0643, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.1361465383310474\n",
            "SCOPE mean: 0.4590999603289186, SCOPE var: 0.017262850732614833\n",
            "Total Loss: 2.200439605416347\n",
            "----------------------------------------\n",
            "Epoch 248\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0640, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.119795408363704\n",
            "SCOPE mean: 0.4593266412018693, SCOPE var: 0.017270146619839253\n",
            "Total Loss: 2.1837695731449176\n",
            "----------------------------------------\n",
            "Epoch 249\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0637, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.1035648484997527\n",
            "SCOPE mean: 0.4595370789526389, SCOPE var: 0.0172774102052184\n",
            "Total Loss: 2.167222894313619\n",
            "----------------------------------------\n",
            "Epoch 250\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0633, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.087454857079024\n",
            "SCOPE mean: 0.45975537776755754, SCOPE var: 0.017284867717505124\n",
            "Total Loss: 2.150799687145648\n",
            "----------------------------------------\n",
            "Epoch 251\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0630, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.0714641284756454\n",
            "SCOPE mean: 0.45997963445202594, SCOPE var: 0.017292459903897005\n",
            "Total Loss: 2.134498537095977\n",
            "----------------------------------------\n",
            "Epoch 252\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0627, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.055591937415722\n",
            "SCOPE mean: 0.4602080481477883, SCOPE var: 0.017300129243649726\n",
            "Total Loss: 2.1183186118282196\n",
            "----------------------------------------\n",
            "Epoch 253\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0624, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.039837696904874\n",
            "SCOPE mean: 0.4604388003848255, SCOPE var: 0.01730781803181845\n",
            "Total Loss: 2.102259221816822\n",
            "----------------------------------------\n",
            "Epoch 254\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0621, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.0242007302207554\n",
            "SCOPE mean: 0.4606701240303689, SCOPE var: 0.017315469485161928\n",
            "Total Loss: 2.0863195904858824\n",
            "----------------------------------------\n",
            "Epoch 255\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0618, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.0086803494015406\n",
            "SCOPE mean: 0.46090035193529777, SCOPE var: 0.017323029229467737\n",
            "Total Loss: 2.0704989342032016\n",
            "----------------------------------------\n",
            "Epoch 256\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0615, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.9932761828799082\n",
            "SCOPE mean: 0.4611280061632847, SCOPE var: 0.017330449064716206\n",
            "Total Loss: 2.05479679642186\n",
            "----------------------------------------\n",
            "Epoch 257\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0612, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.9779874491747755\n",
            "SCOPE mean: 0.4613293419120972, SCOPE var: 0.01733744664071811\n",
            "Total Loss: 2.0392121288361893\n",
            "----------------------------------------\n",
            "Epoch 258\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0609, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.962813371687856\n",
            "SCOPE mean: 0.46152802748011273, SCOPE var: 0.01734424086284683\n",
            "Total Loss: 2.0237442795977776\n",
            "----------------------------------------\n",
            "Epoch 259\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0606, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.947752895670642\n",
            "SCOPE mean: 0.4617229753367181, SCOPE var: 0.01735079294748821\n",
            "Total Loss: 2.008392122009932\n",
            "----------------------------------------\n",
            "Epoch 260\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0603, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.9328052826200164\n",
            "SCOPE mean: 0.46191336133757743, SCOPE var: 0.017357074474098757\n",
            "Total Loss: 1.9931548618094008\n",
            "----------------------------------------\n",
            "Epoch 261\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0601, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.917969782801349\n",
            "SCOPE mean: 0.4620985793921771, SCOPE var: 0.017363065260722715\n",
            "Total Loss: 1.9780317052858352\n",
            "----------------------------------------\n",
            "Epoch 262\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0598, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.903245964899613\n",
            "SCOPE mean: 0.4622782946071898, SCOPE var: 0.017368755741052618\n",
            "Total Loss: 1.9630221935230652\n",
            "----------------------------------------\n",
            "Epoch 263\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0595, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.8886329065820753\n",
            "SCOPE mean: 0.4624304844111219, SCOPE var: 0.017373910537419684\n",
            "Total Loss: 1.9481251987449792\n",
            "----------------------------------------\n",
            "Epoch 264\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0592, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.874129881479843\n",
            "SCOPE mean: 0.462579408531105, SCOPE var: 0.017378785304035596\n",
            "Total Loss: 1.9333401805940496\n",
            "----------------------------------------\n",
            "Epoch 265\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0589, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.859735790145475\n",
            "SCOPE mean: 0.4627251320649647, SCOPE var: 0.017383383777274573\n",
            "Total Loss: 1.9186660286361112\n",
            "----------------------------------------\n",
            "Epoch 266\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0587, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.8454498564346318\n",
            "SCOPE mean: 0.46286791451685905, SCOPE var: 0.017387718355310732\n",
            "Total Loss: 1.9041019691305174\n",
            "----------------------------------------\n",
            "Epoch 267\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0584, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.8312713004071945\n",
            "SCOPE mean: 0.46300813101154126, SCOPE var: 0.017391806574562563\n",
            "Total Loss: 1.8896472315909392\n",
            "----------------------------------------\n",
            "Epoch 268\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0581, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.8171993395142705\n",
            "SCOPE mean: 0.4631462437888469, SCOPE var: 0.017395669866613676\n",
            "Total Loss: 1.8753010482136527\n",
            "----------------------------------------\n",
            "Epoch 269\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0578, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.8032331690929686\n",
            "SCOPE mean: 0.46328276664681944, SCOPE var: 0.017399332250377004\n",
            "Total Loss: 1.861062632418675\n",
            "----------------------------------------\n",
            "Epoch 270\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0576, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7893725401210046\n",
            "SCOPE mean: 0.4634189465961986, SCOPE var: 0.01740263603457514\n",
            "Total Loss: 1.8469314946733595\n",
            "----------------------------------------\n",
            "Epoch 271\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0573, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.775621428546807\n",
            "SCOPE mean: 0.46357845187424884, SCOPE var: 0.017404674900728948\n",
            "Total Loss: 1.8329104009380788\n",
            "----------------------------------------\n",
            "Epoch 272\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0570, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7619703396940531\n",
            "SCOPE mean: 0.46372980677311987, SCOPE var: 0.017406891406844278\n",
            "Total Loss: 1.8189919978737594\n",
            "----------------------------------------\n",
            "Epoch 273\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0568, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7484224214825568\n",
            "SCOPE mean: 0.4638938574522823, SCOPE var: 0.0174094346417445\n",
            "Total Loss: 1.8051794773511125\n",
            "----------------------------------------\n",
            "Epoch 274\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0565, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7349757440971947\n",
            "SCOPE mean: 0.464066997739108, SCOPE var: 0.017412159917405537\n",
            "Total Loss: 1.791470670104331\n",
            "----------------------------------------\n",
            "Epoch 275\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0562, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7216291084098563\n",
            "SCOPE mean: 0.464245694898427, SCOPE var: 0.017414930698578333\n",
            "Total Loss: 1.777864158977766\n",
            "----------------------------------------\n",
            "Epoch 276\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0560, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7083825116757934\n",
            "SCOPE mean: 0.4644263935225688, SCOPE var: 0.017417604166600924\n",
            "Total Loss: 1.7643597152005062\n",
            "----------------------------------------\n",
            "Epoch 277\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0557, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6952355895326512\n",
            "SCOPE mean: 0.4646056040078616, SCOPE var: 0.017420048110415448\n",
            "Total Loss: 1.7509567901665353\n",
            "----------------------------------------\n",
            "Epoch 278\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0555, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6821856345443698\n",
            "SCOPE mean: 0.4647611686395745, SCOPE var: 0.01742174856391204\n",
            "Total Loss: 1.737653280582542\n",
            "----------------------------------------\n",
            "Epoch 279\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0552, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6692347780090977\n",
            "SCOPE mean: 0.46489056638306936, SCOPE var: 0.017422837332257118\n",
            "Total Loss: 1.72445025487231\n",
            "----------------------------------------\n",
            "Epoch 280\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0550, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.656381632639225\n",
            "SCOPE mean: 0.4650148217123757, SCOPE var: 0.017423496159526153\n",
            "Total Loss: 1.7113464188583005\n",
            "----------------------------------------\n",
            "Epoch 281\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0547, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6436255416064771\n",
            "SCOPE mean: 0.4651327788894499, SCOPE var: 0.017423693220967318\n",
            "Total Loss: 1.6983410522287403\n",
            "----------------------------------------\n",
            "Epoch 282\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0545, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6309658272414533\n",
            "SCOPE mean: 0.46524368734291893, SCOPE var: 0.017423416501146424\n",
            "Total Loss: 1.685433441853092\n",
            "----------------------------------------\n",
            "Epoch 283\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0542, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6184017938863073\n",
            "SCOPE mean: 0.46534719987816087, SCOPE var: 0.01742267332930034\n",
            "Total Loss: 1.6726228836896189\n",
            "----------------------------------------\n",
            "Epoch 284\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0540, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6059327760341007\n",
            "SCOPE mean: 0.4654433544172787, SCOPE var: 0.01742148909985367\n",
            "Total Loss: 1.6599087289218386\n",
            "----------------------------------------\n",
            "Epoch 285\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0537, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5935582745185992\n",
            "SCOPE mean: 0.465532611315363, SCOPE var: 0.01741990635076672\n",
            "Total Loss: 1.647290517683399\n",
            "----------------------------------------\n",
            "Epoch 286\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0535, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5812773042193726\n",
            "SCOPE mean: 0.4656156587596654, SCOPE var: 0.01741797995178284\n",
            "Total Loss: 1.6347673221945955\n",
            "----------------------------------------\n",
            "Epoch 287\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0532, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5690891215348322\n",
            "SCOPE mean: 0.4656934381735581, SCOPE var: 0.017415775332155718\n",
            "Total Loss: 1.622338470596351\n",
            "----------------------------------------\n",
            "Epoch 288\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0530, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5569929773620492\n",
            "SCOPE mean: 0.46576708386688787, SCOPE var: 0.017413365257284926\n",
            "Total Loss: 1.610003295503037\n",
            "----------------------------------------\n",
            "Epoch 289\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0528, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5449891277439003\n",
            "SCOPE mean: 0.4658380321584376, SCOPE var: 0.017410834229032977\n",
            "Total Loss: 1.597762155981985\n",
            "----------------------------------------\n",
            "Epoch 290\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0525, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5330743517373187\n",
            "SCOPE mean: 0.4658877595288367, SCOPE var: 0.017408037848094825\n",
            "Total Loss: 1.5856117082765342\n",
            "----------------------------------------\n",
            "Epoch 291\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0523, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5212503189064102\n",
            "SCOPE mean: 0.4659396180497259, SCOPE var: 0.017405291880541286\n",
            "Total Loss: 1.5735539307713382\n",
            "----------------------------------------\n",
            "Epoch 292\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0521, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.509515701413706\n",
            "SCOPE mean: 0.46599462354123444, SCOPE var: 0.017402654473722103\n",
            "Total Loss: 1.5615875542946789\n",
            "----------------------------------------\n",
            "Epoch 293\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0518, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4978693688267408\n",
            "SCOPE mean: 0.46605389469241293, SCOPE var: 0.017400186071494243\n",
            "Total Loss: 1.5497115145600153\n",
            "----------------------------------------\n",
            "Epoch 294\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0516, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4863106058242452\n",
            "SCOPE mean: 0.46611839640558983, SCOPE var: 0.017397938826702906\n",
            "Total Loss: 1.5379251515786174\n",
            "----------------------------------------\n",
            "Epoch 295\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0514, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.474838712389806\n",
            "SCOPE mean: 0.4661889097900351, SCOPE var: 0.017395955223122535\n",
            "Total Loss: 1.526227808072371\n",
            "----------------------------------------\n",
            "Epoch 296\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0512, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4634530059658621\n",
            "SCOPE mean: 0.4662660118664789, SCOPE var: 0.017394267177071748\n",
            "Total Loss: 1.5146188304895916\n",
            "----------------------------------------\n",
            "Epoch 297\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0509, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4521528229185643\n",
            "SCOPE mean: 0.4663500649832518, SCOPE var: 0.017392895621869256\n",
            "Total Loss: 1.503097569973371\n",
            "----------------------------------------\n",
            "Epoch 298\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0507, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4409375191925407\n",
            "SCOPE mean: 0.4664412156801167, SCOPE var: 0.017391850557747415\n",
            "Total Loss: 1.491663383133963\n",
            "----------------------------------------\n",
            "Epoch 299\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0505, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4298073797181354\n",
            "SCOPE mean: 0.4665393849663993, SCOPE var: 0.01739111420601875\n",
            "Total Loss: 1.4803165133851954\n",
            "----------------------------------------\n",
            "Epoch 300\n",
            "IS mean: 0.42689932602545877,IS variance: 0.010250330599085356\n",
            "SCOPE Var loss:  tensor(0.0503, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4187591981227858\n",
            "SCOPE mean: 0.46662457724801615, SCOPE var: 0.017390353854610997\n",
            "Total Loss: 1.4690533184873578\n",
            "----------------------------------------\n",
            "Epoch 1\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.2281, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  46.17862338712032\n",
            "SCOPE mean: 3.321017109668501, SCOPE var: 0.33311961845313626\n",
            "Total Loss: 46.40673039882726\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.1690, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  42.90306568502954\n",
            "SCOPE mean: 3.213309965165227, SCOPE var: 0.3199422378817394\n",
            "Total Loss: 43.07202318266308\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.1648, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  39.882356798341746\n",
            "SCOPE mean: 3.1057016132033746, SCOPE var: 0.30705561774971757\n",
            "Total Loss: 40.04716877750087\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.1608, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  37.03320323370615\n",
            "SCOPE mean: 2.998051291204434, SCOPE var: 0.29439735941227524\n",
            "Total Loss: 37.19397415300988\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.1568, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  34.357091046649224\n",
            "SCOPE mean: 2.890416548491096, SCOPE var: 0.28196932213936243\n",
            "Total Loss: 34.51392465756371\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.1530, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  31.85328329616775\n",
            "SCOPE mean: 2.783062651714861, SCOPE var: 0.269813277559671\n",
            "Total Loss: 32.00629916853636\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.1493, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  29.521661473190797\n",
            "SCOPE mean: 2.6761602102953352, SCOPE var: 0.25795489522268333\n",
            "Total Loss: 29.67098796829761\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.1458, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  27.361090640653753\n",
            "SCOPE mean: 2.569853170738293, SCOPE var: 0.24640875445415605\n",
            "Total Loss: 27.50686039883175\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.1423, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  25.36957794393194\n",
            "SCOPE mean: 2.464303512508176, SCOPE var: 0.2351914202332375\n",
            "Total Loss: 25.51192742012581\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.1390, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  23.544888526646506\n",
            "SCOPE mean: 2.359833818217023, SCOPE var: 0.22434886142864252\n",
            "Total Loss: 23.68393247562737\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.1359, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.882662260653856\n",
            "SCOPE mean: 2.2565162422980283, SCOPE var: 0.2138729650618521\n",
            "Total Loss: 22.01854137376659\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.1329, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  20.37805138815548\n",
            "SCOPE mean: 2.1545284079300884, SCOPE var: 0.20377623526662395\n",
            "Total Loss: 20.510909379319077\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.1300, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  19.025604724886623\n",
            "SCOPE mean: 2.0540683514079916, SCOPE var: 0.1940706431246012\n",
            "Total Loss: 19.155583948743423\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.1272, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  17.81899486549083\n",
            "SCOPE mean: 1.9553384716563356, SCOPE var: 0.18476508028871222\n",
            "Total Loss: 17.94623547165151\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.1246, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  16.750965102643022\n",
            "SCOPE mean: 1.8585410583045268, SCOPE var: 0.17586547343636977\n",
            "Total Loss: 16.875603994107568\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.1222, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  15.813427495278694\n",
            "SCOPE mean: 1.763864216897011, SCOPE var: 0.16737392985573316\n",
            "Total Loss: 15.935597867253062\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.1198, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.997375844014805\n",
            "SCOPE mean: 1.6714349270181843, SCOPE var: 0.15928023169535718\n",
            "Total Loss: 15.1172086509608\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.1176, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.293552181402832\n",
            "SCOPE mean: 1.5816219861241125, SCOPE var: 0.15161016896362234\n",
            "Total Loss: 14.411165559727616\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.1155, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.691935086005202\n",
            "SCOPE mean: 1.4946189758786745, SCOPE var: 0.1443594168244153\n",
            "Total Loss: 13.80744085892637\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.1135, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.182570262105592\n",
            "SCOPE mean: 1.4105407547111273, SCOPE var: 0.1375051914422023\n",
            "Total Loss: 13.296077385331985\n",
            "----------------------------------------\n",
            "Epoch 21\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.1116, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.755040972645977\n",
            "SCOPE mean: 1.3295587953038863, SCOPE var: 0.1310413226950048\n",
            "Total Loss: 12.86665164570071\n",
            "----------------------------------------\n",
            "Epoch 22\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.1098, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.398908651369347\n",
            "SCOPE mean: 1.2518321590967683, SCOPE var: 0.12496151437114703\n",
            "Total Loss: 12.508723274051663\n",
            "----------------------------------------\n",
            "Epoch 23\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.1081, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.10390500590569\n",
            "SCOPE mean: 1.1775096784137102, SCOPE var: 0.1192609761731479\n",
            "Total Loss: 12.212033466088956\n",
            "----------------------------------------\n",
            "Epoch 24\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.1065, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.859663117304857\n",
            "SCOPE mean: 1.1066960392558896, SCOPE var: 0.11392811299178913\n",
            "Total Loss: 11.966191173419425\n",
            "----------------------------------------\n",
            "Epoch 25\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.1050, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.65686412775765\n",
            "SCOPE mean: 1.0394790729682772, SCOPE var: 0.1089549999634338\n",
            "Total Loss: 11.761872452737869\n",
            "----------------------------------------\n",
            "Epoch 26\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.1036, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.487391306407874\n",
            "SCOPE mean: 0.9758588395649085, SCOPE var: 0.1043132965010809\n",
            "Total Loss: 11.590948162755618\n",
            "----------------------------------------\n",
            "Epoch 27\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.1022, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.343228658570652\n",
            "SCOPE mean: 0.9158934853793717, SCOPE var: 0.10000157618439802\n",
            "Total Loss: 11.445403103402798\n",
            "----------------------------------------\n",
            "Epoch 28\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.1009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.21766285145744\n",
            "SCOPE mean: 0.8596471762772991, SCOPE var: 0.09600708689149368\n",
            "Total Loss: 11.318517176688916\n",
            "----------------------------------------\n",
            "Epoch 29\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0996, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.105093095271535\n",
            "SCOPE mean: 0.8071149266437585, SCOPE var: 0.0923161227779622\n",
            "Total Loss: 11.20468493637165\n",
            "----------------------------------------\n",
            "Epoch 30\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0984, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.000913056402897\n",
            "SCOPE mean: 0.7582705337055495, SCOPE var: 0.08891494470830567\n",
            "Total Loss: 11.099295949801087\n",
            "----------------------------------------\n",
            "Epoch 31\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0972, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.901442693851736\n",
            "SCOPE mean: 0.7130661936699009, SCOPE var: 0.08578990514305909\n",
            "Total Loss: 10.998666580560986\n",
            "----------------------------------------\n",
            "Epoch 32\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0961, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.803945372830682\n",
            "SCOPE mean: 0.6714339147506712, SCOPE var: 0.08292753932136632\n",
            "Total Loss: 10.900057034494678\n",
            "----------------------------------------\n",
            "Epoch 33\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0950, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.706375764318063\n",
            "SCOPE mean: 0.6337249521559009, SCOPE var: 0.0803150321636169\n",
            "Total Loss: 10.801419374684508\n",
            "----------------------------------------\n",
            "Epoch 34\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0940, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.607170065067177\n",
            "SCOPE mean: 0.6007642616471508, SCOPE var: 0.07794487227925717\n",
            "Total Loss: 10.701184342012269\n",
            "----------------------------------------\n",
            "Epoch 35\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0930, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.506557521259763\n",
            "SCOPE mean: 0.5711012283946846, SCOPE var: 0.07580317415336293\n",
            "Total Loss: 10.599578877916297\n",
            "----------------------------------------\n",
            "Epoch 36\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0921, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.404503927303109\n",
            "SCOPE mean: 0.5446265971445766, SCOPE var: 0.07387315610549937\n",
            "Total Loss: 10.496571440173811\n",
            "----------------------------------------\n",
            "Epoch 37\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0912, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.30150917630094\n",
            "SCOPE mean: 0.5211973368425333, SCOPE var: 0.07214342493988861\n",
            "Total Loss: 10.392660503637408\n",
            "----------------------------------------\n",
            "Epoch 38\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0903, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.197995409020223\n",
            "SCOPE mean: 0.5006905756193973, SCOPE var: 0.07060842243539868\n",
            "Total Loss: 10.288284911469692\n",
            "----------------------------------------\n",
            "Epoch 39\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0895, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.094951626276712\n",
            "SCOPE mean: 0.482939736172, SCOPE var: 0.06925586327271065\n",
            "Total Loss: 10.1844254666116\n",
            "----------------------------------------\n",
            "Epoch 40\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0887, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.99361405044443\n",
            "SCOPE mean: 0.46777064448039074, SCOPE var: 0.06807209832493366\n",
            "Total Loss: 10.082305961112525\n",
            "----------------------------------------\n",
            "Epoch 41\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0879, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.894760120463435\n",
            "SCOPE mean: 0.4550175874380526, SCOPE var: 0.06704747691136444\n",
            "Total Loss: 9.98270300618561\n",
            "----------------------------------------\n",
            "Epoch 42\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0872, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.79923599256893\n",
            "SCOPE mean: 0.44452298838676163, SCOPE var: 0.06617290521456592\n",
            "Total Loss: 9.886461566662794\n",
            "----------------------------------------\n",
            "Epoch 43\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0865, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.70784482135251\n",
            "SCOPE mean: 0.4361300417351559, SCOPE var: 0.06543935915164843\n",
            "Total Loss: 9.79438387935499\n",
            "----------------------------------------\n",
            "Epoch 44\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0859, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.620964707972513\n",
            "SCOPE mean: 0.4296800912960547, SCOPE var: 0.0648381425603668\n",
            "Total Loss: 9.706847107897758\n",
            "----------------------------------------\n",
            "Epoch 45\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0853, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.538954066296894\n",
            "SCOPE mean: 0.42501526963783115, SCOPE var: 0.06436094870225366\n",
            "Total Loss: 9.624208594646532\n",
            "----------------------------------------\n",
            "Epoch 46\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0847, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.461822334959255\n",
            "SCOPE mean: 0.4219824016011713, SCOPE var: 0.06399970575461986\n",
            "Total Loss: 9.546476753940308\n",
            "----------------------------------------\n",
            "Epoch 47\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0841, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.389456186709406\n",
            "SCOPE mean: 0.4204354255820577, SCOPE var: 0.06374672928546951\n",
            "Total Loss: 9.4735373206607\n",
            "----------------------------------------\n",
            "Epoch 48\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0835, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.32161787372797\n",
            "SCOPE mean: 0.4202257190008904, SCOPE var: 0.06359450126734073\n",
            "Total Loss: 9.405151423479715\n",
            "----------------------------------------\n",
            "Epoch 49\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0830, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.257864201575055\n",
            "SCOPE mean: 0.42120999096033995, SCOPE var: 0.06353583795471232\n",
            "Total Loss: 9.340874708313786\n",
            "----------------------------------------\n",
            "Epoch 50\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0825, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.197645400694713\n",
            "SCOPE mean: 0.42325026145339334, SCOPE var: 0.06356387199278755\n",
            "Total Loss: 9.280156221533948\n",
            "----------------------------------------\n",
            "Epoch 51\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0820, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.140290402108642\n",
            "SCOPE mean: 0.4262145889088109, SCOPE var: 0.06367206273308805\n",
            "Total Loss: 9.222323748067993\n",
            "----------------------------------------\n",
            "Epoch 52\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0816, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.085157498934\n",
            "SCOPE mean: 0.42998466319891615, SCOPE var: 0.06385431050900679\n",
            "Total Loss: 9.166734565798896\n",
            "----------------------------------------\n",
            "Epoch 53\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0811, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.031666975989529\n",
            "SCOPE mean: 0.4344403341831328, SCOPE var: 0.06410462300895586\n",
            "Total Loss: 9.112807661207215\n",
            "----------------------------------------\n",
            "Epoch 54\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0807, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.979211457775854\n",
            "SCOPE mean: 0.4394693923904961, SCOPE var: 0.06441731783404923\n",
            "Total Loss: 9.059934429600146\n",
            "----------------------------------------\n",
            "Epoch 55\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0803, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.92724582400509\n",
            "SCOPE mean: 0.44496751619343067, SCOPE var: 0.06478698709802497\n",
            "Total Loss: 9.00756852348316\n",
            "----------------------------------------\n",
            "Epoch 56\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0799, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.875283577285735\n",
            "SCOPE mean: 0.45083861537576514, SCOPE var: 0.06520877880689319\n",
            "Total Loss: 8.955222428046895\n",
            "----------------------------------------\n",
            "Epoch 57\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0796, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.822956344064465\n",
            "SCOPE mean: 0.4569990642845911, SCOPE var: 0.0656781066487258\n",
            "Total Loss: 8.902526833140758\n",
            "----------------------------------------\n",
            "Epoch 58\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0792, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.770012635009389\n",
            "SCOPE mean: 0.46336957850224497, SCOPE var: 0.06618971047647154\n",
            "Total Loss: 8.849228700318523\n",
            "----------------------------------------\n",
            "Epoch 59\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0789, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.716260681360014\n",
            "SCOPE mean: 0.46987899578095155, SCOPE var: 0.06673910958615896\n",
            "Total Loss: 8.79513509280447\n",
            "----------------------------------------\n",
            "Epoch 60\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0785, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.661602271792571\n",
            "SCOPE mean: 0.47646589776836556, SCOPE var: 0.0673220494992224\n",
            "Total Loss: 8.74014666799411\n",
            "----------------------------------------\n",
            "Epoch 61\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0782, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.606023798194123\n",
            "SCOPE mean: 0.48307830271055247, SCOPE var: 0.06793448744446447\n",
            "Total Loss: 8.684248722992288\n",
            "----------------------------------------\n",
            "Epoch 62\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0779, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.549583889174274\n",
            "SCOPE mean: 0.4896732117920528, SCOPE var: 0.06857257871389043\n",
            "Total Loss: 8.627498827416204\n",
            "----------------------------------------\n",
            "Epoch 63\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0776, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.492398825658292\n",
            "SCOPE mean: 0.496216028020038, SCOPE var: 0.06923266418796711\n",
            "Total Loss: 8.570012238072001\n",
            "----------------------------------------\n",
            "Epoch 64\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0773, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.434626896844438\n",
            "SCOPE mean: 0.5026798709733657, SCOPE var: 0.06991125929115341\n",
            "Total Loss: 8.511946254046576\n",
            "----------------------------------------\n",
            "Epoch 65\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0770, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.3764527517872\n",
            "SCOPE mean: 0.5090448130497353, SCOPE var: 0.07060504458344694\n",
            "Total Loss: 8.453484567703157\n",
            "----------------------------------------\n",
            "Epoch 66\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0767, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.318072649103426\n",
            "SCOPE mean: 0.515297063326079, SCOPE var: 0.07131085812396404\n",
            "Total Loss: 8.394822514253729\n",
            "----------------------------------------\n",
            "Epoch 67\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0765, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.259681322318402\n",
            "SCOPE mean: 0.52142812858382, SCOPE var: 0.07202568964977109\n",
            "Total Loss: 8.336153937539917\n",
            "----------------------------------------\n",
            "Epoch 68\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0762, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.201460977693458\n",
            "SCOPE mean: 0.5274339547694431, SCOPE var: 0.0727466766189407\n",
            "Total Loss: 8.277660188913961\n",
            "----------------------------------------\n",
            "Epoch 69\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0759, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.143572739626649\n",
            "SCOPE mean: 0.5333141032850248, SCOPE var: 0.07347110190581131\n",
            "Total Loss: 8.21950157429955\n",
            "----------------------------------------\n",
            "Epoch 70\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0757, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.086150668100903\n",
            "SCOPE mean: 0.5390709556856276, SCOPE var: 0.0741963930702913\n",
            "Total Loss: 8.161811373840957\n",
            "----------------------------------------\n",
            "Epoch 71\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0754, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.02929830273631\n",
            "SCOPE mean: 0.5447089638975658, SCOPE var: 0.07492012297648441\n",
            "Total Loss: 8.104692388587077\n",
            "----------------------------------------\n",
            "Epoch 72\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0751, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.973087545678525\n",
            "SCOPE mean: 0.5502339626449683, SCOPE var: 0.07564001148349965\n",
            "Total Loss: 8.048215826299968\n",
            "----------------------------------------\n",
            "Epoch 73\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0749, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.9175595851412135\n",
            "SCOPE mean: 0.5556525510057427, SCOPE var: 0.0763539279255846\n",
            "Total Loss: 7.992422228043338\n",
            "----------------------------------------\n",
            "Epoch 74\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0746, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.862727484832885\n",
            "SCOPE mean: 0.5609715491929779, SCOPE var: 0.07705989407547292\n",
            "Total Loss: 7.937324060610336\n",
            "----------------------------------------\n",
            "Epoch 75\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0743, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.808580021488092\n",
            "SCOPE mean: 0.5661975342106979, SCOPE var: 0.0777560872806796\n",
            "Total Loss: 7.882909556841991\n",
            "----------------------------------------\n",
            "Epoch 76\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0741, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.755086341157084\n",
            "SCOPE mean: 0.5713364558118277, SCOPE var: 0.07844084347020007\n",
            "Total Loss: 7.829147374333507\n",
            "----------------------------------------\n",
            "Epoch 77\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0738, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.702201021106048\n",
            "SCOPE mean: 0.5763933321994851, SCOPE var: 0.07911265974782361\n",
            "Total Loss: 7.775991659243243\n",
            "----------------------------------------\n",
            "Epoch 78\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0735, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.649869163287437\n",
            "SCOPE mean: 0.5813720231676501, SCOPE var: 0.07977019631682794\n",
            "Total Loss: 7.723387141052313\n",
            "----------------------------------------\n",
            "Epoch 79\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0732, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.598031201739444\n",
            "SCOPE mean: 0.5862750768810809, SCOPE var: 0.0804122775176953\n",
            "Total Loss: 7.671273940552256\n",
            "----------------------------------------\n",
            "Epoch 80\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0730, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.5466271740075115\n",
            "SCOPE mean: 0.5911036452523851, SCOPE var: 0.08103789180393157\n",
            "Total Loss: 7.619591841104493\n",
            "----------------------------------------\n",
            "Epoch 81\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0727, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.4956002798620425\n",
            "SCOPE mean: 0.5958574618876264, SCOPE var: 0.08164619052901605\n",
            "Total Loss: 7.568283846429464\n",
            "----------------------------------------\n",
            "Epoch 82\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0724, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.4448996237701595\n",
            "SCOPE mean: 0.600534875835956, SCOPE var: 0.08223648546772096\n",
            "Total Loss: 7.517298921398852\n",
            "----------------------------------------\n",
            "Epoch 83\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0721, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.394482106067012\n",
            "SCOPE mean: 0.6051329338817782, SCOPE var: 0.08280824504515374\n",
            "Total Loss: 7.466593880820918\n",
            "----------------------------------------\n",
            "Epoch 84\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0718, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.344313476385896\n",
            "SCOPE mean: 0.6096475038404293, SCOPE var: 0.08336108929466984\n",
            "Total Loss: 7.41613443984774\n",
            "----------------------------------------\n",
            "Epoch 85\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0715, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.2943685305564\n",
            "SCOPE mean: 0.6140734526649968, SCOPE var: 0.08389478905817792\n",
            "Total Loss: 7.365895408509218\n",
            "----------------------------------------\n",
            "Epoch 86\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0712, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.2446311881175856\n",
            "SCOPE mean: 0.6184047765950219, SCOPE var: 0.08440924747660743\n",
            "Total Loss: 7.315860762768042\n",
            "----------------------------------------\n",
            "Epoch 87\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0709, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.195093238528595\n",
            "SCOPE mean: 0.6226348545300763, SCOPE var: 0.08490449744888821\n",
            "Total Loss: 7.266022387616366\n",
            "----------------------------------------\n",
            "Epoch 88\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0706, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.145761970351345\n",
            "SCOPE mean: 0.626756870013171, SCOPE var: 0.08538069269375395\n",
            "Total Loss: 7.216387741908735\n",
            "----------------------------------------\n",
            "Epoch 89\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0703, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.096641357242764\n",
            "SCOPE mean: 0.6307588307743583, SCOPE var: 0.08583796918409234\n",
            "Total Loss: 7.166960833645651\n",
            "----------------------------------------\n",
            "Epoch 90\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0700, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.047731938992799\n",
            "SCOPE mean: 0.6346337346320704, SCOPE var: 0.08627670239472233\n",
            "Total Loss: 7.117742363429116\n",
            "----------------------------------------\n",
            "Epoch 91\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0697, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.999043537287265\n",
            "SCOPE mean: 0.6383749989500973, SCOPE var: 0.08669735759579282\n",
            "Total Loss: 7.068742369701438\n",
            "----------------------------------------\n",
            "Epoch 92\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0694, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.950582091029811\n",
            "SCOPE mean: 0.6419858171656005, SCOPE var: 0.08709539313554955\n",
            "Total Loss: 7.019966822062073\n",
            "----------------------------------------\n",
            "Epoch 93\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0691, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.902361841248884\n",
            "SCOPE mean: 0.6454575822109003, SCOPE var: 0.08747277448946333\n",
            "Total Loss: 6.971430232085967\n",
            "----------------------------------------\n",
            "Epoch 94\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0688, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.854400757882932\n",
            "SCOPE mean: 0.6487765164597361, SCOPE var: 0.08783351739894678\n",
            "Total Loss: 6.9231508789935665\n",
            "----------------------------------------\n",
            "Epoch 95\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0684, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.806699664251382\n",
            "SCOPE mean: 0.6519400969013204, SCOPE var: 0.0881783825916757\n",
            "Total Loss: 6.875129837512369\n",
            "----------------------------------------\n",
            "Epoch 96\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0681, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.75926464275543\n",
            "SCOPE mean: 0.6549453291820047, SCOPE var: 0.08850815968380311\n",
            "Total Loss: 6.8273734533770565\n",
            "----------------------------------------\n",
            "Epoch 97\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0678, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.712099766587549\n",
            "SCOPE mean: 0.6577903230136896, SCOPE var: 0.08882366196124922\n",
            "Total Loss: 6.779886060337797\n",
            "----------------------------------------\n",
            "Epoch 98\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0675, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.665247896720238\n",
            "SCOPE mean: 0.660481890437496, SCOPE var: 0.08912613321150976\n",
            "Total Loss: 6.732710871128608\n",
            "----------------------------------------\n",
            "Epoch 99\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0671, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.618683615351684\n",
            "SCOPE mean: 0.6630139309858718, SCOPE var: 0.08941320586581399\n",
            "Total Loss: 6.685822892015765\n",
            "----------------------------------------\n",
            "Epoch 100\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0668, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.572372816501633\n",
            "SCOPE mean: 0.6653818155325821, SCOPE var: 0.08968561042364162\n",
            "Total Loss: 6.639188133010942\n",
            "----------------------------------------\n",
            "Epoch 101\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0665, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.52630918579643\n",
            "SCOPE mean: 0.6675895363557759, SCOPE var: 0.08994442493772208\n",
            "Total Loss: 6.592800492104143\n",
            "----------------------------------------\n",
            "Epoch 102\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0662, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.480489379351719\n",
            "SCOPE mean: 0.6696417675631972, SCOPE var: 0.09019069383187081\n",
            "Total Loss: 6.5466568192506625\n",
            "----------------------------------------\n",
            "Epoch 103\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0658, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.434910584903961\n",
            "SCOPE mean: 0.6715443896681204, SCOPE var: 0.09042542661221954\n",
            "Total Loss: 6.500754483705979\n",
            "----------------------------------------\n",
            "Epoch 104\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0655, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.389570388518701\n",
            "SCOPE mean: 0.6733043863539968, SCOPE var: 0.09064959471298575\n",
            "Total Loss: 6.455091241463007\n",
            "----------------------------------------\n",
            "Epoch 105\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0652, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.34450932950664\n",
            "SCOPE mean: 0.6749376370480097, SCOPE var: 0.09086456731564026\n",
            "Total Loss: 6.409707885468665\n",
            "----------------------------------------\n",
            "Epoch 106\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0649, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.299721731593885\n",
            "SCOPE mean: 0.6764533259539113, SCOPE var: 0.09107414077095831\n",
            "Total Loss: 6.364598642555384\n",
            "----------------------------------------\n",
            "Epoch 107\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0646, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.255181601067371\n",
            "SCOPE mean: 0.6778557214826555, SCOPE var: 0.09127860469337674\n",
            "Total Loss: 6.319737626329226\n",
            "----------------------------------------\n",
            "Epoch 108\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0642, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.210924935154012\n",
            "SCOPE mean: 0.6791498561900297, SCOPE var: 0.09147917700888565\n",
            "Total Loss: 6.275159243918806\n",
            "----------------------------------------\n",
            "Epoch 109\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0639, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.166919218984831\n",
            "SCOPE mean: 0.6803217829997041, SCOPE var: 0.09167269863589196\n",
            "Total Loss: 6.230831892990723\n",
            "----------------------------------------\n",
            "Epoch 110\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0636, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.123183606833433\n",
            "SCOPE mean: 0.6813126751152793, SCOPE var: 0.09184153219141131\n",
            "Total Loss: 6.1867710588504705\n",
            "----------------------------------------\n",
            "Epoch 111\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0633, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.079692628765433\n",
            "SCOPE mean: 0.6822136454636286, SCOPE var: 0.09200617712480133\n",
            "Total Loss: 6.14295588403771\n",
            "----------------------------------------\n",
            "Epoch 112\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0629, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.0364514076567\n",
            "SCOPE mean: 0.6830242924290354, SCOPE var: 0.0921638580212474\n",
            "Total Loss: 6.099390897006885\n",
            "----------------------------------------\n",
            "Epoch 113\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0626, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.9934564393688685\n",
            "SCOPE mean: 0.6837732668711255, SCOPE var: 0.09231927122215858\n",
            "Total Loss: 6.056073652122634\n",
            "----------------------------------------\n",
            "Epoch 114\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0623, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.95070913736911\n",
            "SCOPE mean: 0.68447210162181, SCOPE var: 0.0924728166740246\n",
            "Total Loss: 6.01300566757302\n",
            "----------------------------------------\n",
            "Epoch 115\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0620, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.908210844282479\n",
            "SCOPE mean: 0.6851318951438112, SCOPE var: 0.0926248595478641\n",
            "Total Loss: 5.9701883788066255\n",
            "----------------------------------------\n",
            "Epoch 116\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0617, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.86596272216959\n",
            "SCOPE mean: 0.6857632030624193, SCOPE var: 0.0927757302110389\n",
            "Total Loss: 5.9276230296106505\n",
            "----------------------------------------\n",
            "Epoch 117\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0613, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.82396567110243\n",
            "SCOPE mean: 0.686375942354702, SCOPE var: 0.09292572453014245\n",
            "Total Loss: 5.8853105914884924\n",
            "----------------------------------------\n",
            "Epoch 118\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0610, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.782220756685276\n",
            "SCOPE mean: 0.6869792932469329, SCOPE var: 0.0930751042943405\n",
            "Total Loss: 5.843252194082581\n",
            "----------------------------------------\n",
            "Epoch 119\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0607, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.740732935396737\n",
            "SCOPE mean: 0.6875812325338113, SCOPE var: 0.09322408127066997\n",
            "Total Loss: 5.801452872317149\n",
            "----------------------------------------\n",
            "Epoch 120\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0604, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.6994971457303825\n",
            "SCOPE mean: 0.6881894686252639, SCOPE var: 0.09337284855902972\n",
            "Total Loss: 5.759907585670948\n",
            "----------------------------------------\n",
            "Epoch 121\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0601, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.658512949859648\n",
            "SCOPE mean: 0.6888106737611884, SCOPE var: 0.09352156744811328\n",
            "Total Loss: 5.718615931851272\n",
            "----------------------------------------\n",
            "Epoch 122\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0598, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.617779649185192\n",
            "SCOPE mean: 0.6894506229972032, SCOPE var: 0.09367037059969317\n",
            "Total Loss: 5.677577241477221\n",
            "----------------------------------------\n",
            "Epoch 123\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0595, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.5772963375913465\n",
            "SCOPE mean: 0.6901141854592595, SCOPE var: 0.09381936358824423\n",
            "Total Loss: 5.636790631949367\n",
            "----------------------------------------\n",
            "Epoch 124\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0592, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.537061959993064\n",
            "SCOPE mean: 0.6908053295285257, SCOPE var: 0.09396862653249374\n",
            "Total Loss: 5.596255066560539\n",
            "----------------------------------------\n",
            "Epoch 125\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0589, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.49707537089883\n",
            "SCOPE mean: 0.6915271410542434, SCOPE var: 0.09411821579433367\n",
            "Total Loss: 5.555969413571905\n",
            "----------------------------------------\n",
            "Epoch 126\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0586, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.4573353885853715\n",
            "SCOPE mean: 0.6922818535021822, SCOPE var: 0.09426816572270692\n",
            "Total Loss: 5.5159325008503535\n",
            "----------------------------------------\n",
            "Epoch 127\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0583, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.417840841548437\n",
            "SCOPE mean: 0.6930708887901045, SCOPE var: 0.09441849042227053\n",
            "Total Loss: 5.476143162732806\n",
            "----------------------------------------\n",
            "Epoch 128\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0580, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.378590605044835\n",
            "SCOPE mean: 0.6938949074403947, SCOPE var: 0.09456918552876095\n",
            "Total Loss: 5.436600276935184\n",
            "----------------------------------------\n",
            "Epoch 129\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0577, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.339583626670723\n",
            "SCOPE mean: 0.6947538665938225, SCOPE var: 0.09472022997504638\n",
            "Total Loss: 5.397302790454415\n",
            "----------------------------------------\n",
            "Epoch 130\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0574, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.300818940944658\n",
            "SCOPE mean: 0.6956470843767983, SCOPE var: 0.09487158773382183\n",
            "Total Loss: 5.358249734436124\n",
            "----------------------------------------\n",
            "Epoch 131\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0571, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.262295673718305\n",
            "SCOPE mean: 0.6965733090961919, SCOPE var: 0.09502320952471867\n",
            "Total Loss: 5.319440228835538\n",
            "----------------------------------------\n",
            "Epoch 132\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0569, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.224013037883654\n",
            "SCOPE mean: 0.6975307917489286, SCOPE var: 0.09517503447536392\n",
            "Total Loss: 5.280873478345306\n",
            "----------------------------------------\n",
            "Epoch 133\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0566, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.18597032226693\n",
            "SCOPE mean: 0.6985173602800823, SCOPE var: 0.09532699172834844\n",
            "Total Loss: 5.242548761485416\n",
            "----------------------------------------\n",
            "Epoch 134\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0563, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.148166875800258\n",
            "SCOPE mean: 0.6995304942058852, SCOPE var: 0.09547900198649101\n",
            "Total Loss: 5.204465414951092\n",
            "----------------------------------------\n",
            "Epoch 135\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0560, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.110602241559757\n",
            "SCOPE mean: 0.7005673994873222, SCOPE var: 0.0956309789726121\n",
            "Total Loss: 5.166622967811905\n",
            "----------------------------------------\n",
            "Epoch 136\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0557, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.0732763619348535\n",
            "SCOPE mean: 0.701625033368582, SCOPE var: 0.09578282832676835\n",
            "Total Loss: 5.129021347802718\n",
            "----------------------------------------\n",
            "Epoch 137\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0555, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.0361865093328655\n",
            "SCOPE mean: 0.7027001958319119, SCOPE var: 0.09593445497793268\n",
            "Total Loss: 5.091657809390017\n",
            "----------------------------------------\n",
            "Epoch 138\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0552, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.999332066767233\n",
            "SCOPE mean: 0.703789603565414, SCOPE var: 0.09608564598477902\n",
            "Total Loss: 5.054531701003496\n",
            "----------------------------------------\n",
            "Epoch 139\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0549, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.962713664283164\n",
            "SCOPE mean: 0.704890150875991, SCOPE var: 0.0962363141613952\n",
            "Total Loss: 5.01764363556091\n",
            "----------------------------------------\n",
            "Epoch 140\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0547, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.926330665385722\n",
            "SCOPE mean: 0.7059987129778179, SCOPE var: 0.09638637072132691\n",
            "Total Loss: 4.980992957594824\n",
            "----------------------------------------\n",
            "Epoch 141\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0544, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.890182393014555\n",
            "SCOPE mean: 0.7071122537828641, SCOPE var: 0.09653572547459706\n",
            "Total Loss: 4.944578969872897\n",
            "----------------------------------------\n",
            "Epoch 142\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0541, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.854268127519614\n",
            "SCOPE mean: 0.7082278680177136, SCOPE var: 0.09668428792259856\n",
            "Total Loss: 4.908400931548683\n",
            "----------------------------------------\n",
            "Epoch 143\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0539, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.818587107462219\n",
            "SCOPE mean: 0.7093428167909558, SCOPE var: 0.09683196825284983\n",
            "Total Loss: 4.872458059136733\n",
            "----------------------------------------\n",
            "Epoch 144\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0536, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.783138532637492\n",
            "SCOPE mean: 0.7104545565781735, SCOPE var: 0.0969786782357004\n",
            "Total Loss: 4.836749529707806\n",
            "----------------------------------------\n",
            "Epoch 145\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0534, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.747921568643849\n",
            "SCOPE mean: 0.7115607617175203, SCOPE var: 0.09712433202542572\n",
            "Total Loss: 4.801274485629411\n",
            "----------------------------------------\n",
            "Epoch 146\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0531, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.712934691440373\n",
            "SCOPE mean: 0.7126595052567088, SCOPE var: 0.0972690695171884\n",
            "Total Loss: 4.766031348808297\n",
            "----------------------------------------\n",
            "Epoch 147\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0528, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.678176010282103\n",
            "SCOPE mean: 0.7137486840432995, SCOPE var: 0.09741317269160474\n",
            "Total Loss: 4.731018143749479\n",
            "----------------------------------------\n",
            "Epoch 148\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0526, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.643647722373799\n",
            "SCOPE mean: 0.7148266316970016, SCOPE var: 0.09755597785442761\n",
            "Total Loss: 4.69623712623098\n",
            "----------------------------------------\n",
            "Epoch 149\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0523, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.609347481480937\n",
            "SCOPE mean: 0.7158920314334574, SCOPE var: 0.09769741712055642\n",
            "Total Loss: 4.661685928279961\n",
            "----------------------------------------\n",
            "Epoch 150\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0521, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.5752743753348595\n",
            "SCOPE mean: 0.7169438200263976, SCOPE var: 0.09783742731547443\n",
            "Total Loss: 4.627363616065449\n",
            "----------------------------------------\n",
            "Epoch 151\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0518, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.541427484412694\n",
            "SCOPE mean: 0.7179811656202452, SCOPE var: 0.09797595017233347\n",
            "Total Loss: 4.593269248681931\n",
            "----------------------------------------\n",
            "Epoch 152\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0516, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.507805883641374\n",
            "SCOPE mean: 0.7190034550874072, SCOPE var: 0.09811293259718801\n",
            "Total Loss: 4.559401880006552\n",
            "----------------------------------------\n",
            "Epoch 153\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0514, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.474408643059314\n",
            "SCOPE mean: 0.7200102785591836, SCOPE var: 0.09824832686656557\n",
            "Total Loss: 4.525760559501043\n",
            "----------------------------------------\n",
            "Epoch 154\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0511, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.441234827616055\n",
            "SCOPE mean: 0.7210014117455489, SCOPE var: 0.09838209076138585\n",
            "Total Loss: 4.492344332137793\n",
            "----------------------------------------\n",
            "Epoch 155\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0509, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.408283496334149\n",
            "SCOPE mean: 0.7219767966440357, SCOPE var: 0.09851418764139523\n",
            "Total Loss: 4.459152237673586\n",
            "----------------------------------------\n",
            "Epoch 156\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0506, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.37555377094931\n",
            "SCOPE mean: 0.7229365094240818, SCOPE var: 0.09864458833750975\n",
            "Total Loss: 4.426183375514805\n",
            "----------------------------------------\n",
            "Epoch 157\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0504, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.34305243893925\n",
            "SCOPE mean: 0.7238932480819296, SCOPE var: 0.09877395883187713\n",
            "Total Loss: 4.393444352602398\n",
            "----------------------------------------\n",
            "Epoch 158\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0502, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.3107676870572345\n",
            "SCOPE mean: 0.724846347506019, SCOPE var: 0.0989019745565535\n",
            "Total Loss: 4.360923787514092\n",
            "----------------------------------------\n",
            "Epoch 159\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0499, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.278699592873743\n",
            "SCOPE mean: 0.7257950245521825, SCOPE var: 0.09902858649629423\n",
            "Total Loss: 4.328621705569244\n",
            "----------------------------------------\n",
            "Epoch 160\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0497, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.246847685999117\n",
            "SCOPE mean: 0.7267382924577738, SCOPE var: 0.09915373918749742\n",
            "Total Loss: 4.296537593597705\n",
            "----------------------------------------\n",
            "Epoch 161\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0495, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.215211420330684\n",
            "SCOPE mean: 0.7276752639811752, SCOPE var: 0.09927738488713025\n",
            "Total Loss: 4.264670866271732\n",
            "----------------------------------------\n",
            "Epoch 162\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0492, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.183789936404912\n",
            "SCOPE mean: 0.7286050848052933, SCOPE var: 0.0993994837294563\n",
            "Total Loss: 4.233020626650871\n",
            "----------------------------------------\n",
            "Epoch 163\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0490, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.15258233720603\n",
            "SCOPE mean: 0.729527003047764, SCOPE var: 0.09952000315847463\n",
            "Total Loss: 4.201585943518656\n",
            "----------------------------------------\n",
            "Epoch 164\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0488, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.1215870652242685\n",
            "SCOPE mean: 0.7304403401153708, SCOPE var: 0.09963891758788203\n",
            "Total Loss: 4.170365225841673\n",
            "----------------------------------------\n",
            "Epoch 165\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0486, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.090800625384231\n",
            "SCOPE mean: 0.7313443533348261, SCOPE var: 0.09975620685409994\n",
            "Total Loss: 4.139354941165777\n",
            "----------------------------------------\n",
            "Epoch 166\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0483, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.060223892835027\n",
            "SCOPE mean: 0.7322386575456901, SCOPE var: 0.09987185877537358\n",
            "Total Loss: 4.108555945921035\n",
            "----------------------------------------\n",
            "Epoch 167\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0481, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.029855982838593\n",
            "SCOPE mean: 0.7331228842092768, SCOPE var: 0.09998586701592518\n",
            "Total Loss: 4.077967332476088\n",
            "----------------------------------------\n",
            "Epoch 168\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0479, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.999695974154983\n",
            "SCOPE mean: 0.7339967477143957, SCOPE var: 0.10009823068637308\n",
            "Total Loss: 4.04758815883496\n",
            "----------------------------------------\n",
            "Epoch 169\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0477, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.969742911974099\n",
            "SCOPE mean: 0.7348600196699892, SCOPE var: 0.10020895379503125\n",
            "Total Loss: 4.017417451383153\n",
            "----------------------------------------\n",
            "Epoch 170\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0475, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.939995810842138\n",
            "SCOPE mean: 0.7357125420249889, SCOPE var: 0.1003180449070829\n",
            "Total Loss: 3.987454207636958\n",
            "----------------------------------------\n",
            "Epoch 171\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0472, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.9104536576239632\n",
            "SCOPE mean: 0.7365542156060413, SCOPE var: 0.10042551667725845\n",
            "Total Loss: 3.957697399037435\n",
            "----------------------------------------\n",
            "Epoch 172\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0470, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.88111541450896\n",
            "SCOPE mean: 0.7373849942856914, SCOPE var: 0.10053138542020676\n",
            "Total Loss: 3.928145973796769\n",
            "----------------------------------------\n",
            "Epoch 173\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0468, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.851980218388603\n",
            "SCOPE mean: 0.7382048808044951, SCOPE var: 0.10063567070498375\n",
            "Total Loss: 3.8987990561314696\n",
            "----------------------------------------\n",
            "Epoch 174\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0466, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.8230468562023536\n",
            "SCOPE mean: 0.7390140002644717, SCOPE var: 0.10073839608725292\n",
            "Total Loss: 3.869655422611055\n",
            "----------------------------------------\n",
            "Epoch 175\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0464, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.7943141854880027\n",
            "SCOPE mean: 0.7398124245458487, SCOPE var: 0.10083958606609905\n",
            "Total Loss: 3.840713920081833\n",
            "----------------------------------------\n",
            "Epoch 176\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0462, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.7657810979567277\n",
            "SCOPE mean: 0.7406002593251757, SCOPE var: 0.100939267176089\n",
            "Total Loss: 3.8119734304610073\n",
            "----------------------------------------\n",
            "Epoch 177\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0460, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.737433503817083\n",
            "SCOPE mean: 0.7413887427368199, SCOPE var: 0.10103113727000919\n",
            "Total Loss: 3.7834177393464805\n",
            "----------------------------------------\n",
            "Epoch 178\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0458, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.7092630345206796\n",
            "SCOPE mean: 0.742171696811931, SCOPE var: 0.10111392226899844\n",
            "Total Loss: 3.7550383295796834\n",
            "----------------------------------------\n",
            "Epoch 179\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0456, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.6812748888558646\n",
            "SCOPE mean: 0.7429176609314547, SCOPE var: 0.10119521957225475\n",
            "Total Loss: 3.7268435818019783\n",
            "----------------------------------------\n",
            "Epoch 180\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0454, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.653477668529546\n",
            "SCOPE mean: 0.743654123944316, SCOPE var: 0.10127341197949674\n",
            "Total Loss: 3.6988406677201175\n",
            "----------------------------------------\n",
            "Epoch 181\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0452, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.625875365706811\n",
            "SCOPE mean: 0.744380801039166, SCOPE var: 0.10134757306848012\n",
            "Total Loss: 3.6710332695312937\n",
            "----------------------------------------\n",
            "Epoch 182\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0450, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.5984886482972813\n",
            "SCOPE mean: 0.7450949892122971, SCOPE var: 0.10141459645935302\n",
            "Total Loss: 3.6434411043988715\n",
            "----------------------------------------\n",
            "Epoch 183\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0448, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.5712063504217313\n",
            "SCOPE mean: 0.7461801268267565, SCOPE var: 0.1015802405089888\n",
            "Total Loss: 3.615971111118816\n",
            "----------------------------------------\n",
            "Epoch 184\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0446, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.5440973000083416\n",
            "SCOPE mean: 0.7473415529572465, SCOPE var: 0.101766305121324\n",
            "Total Loss: 3.588679234410547\n",
            "----------------------------------------\n",
            "Epoch 185\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0444, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.5171705929247485\n",
            "SCOPE mean: 0.7485357693528704, SCOPE var: 0.10195860955940778\n",
            "Total Loss: 3.5615715238562147\n",
            "----------------------------------------\n",
            "Epoch 186\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0442, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.490425730892582\n",
            "SCOPE mean: 0.7497814012308436, SCOPE var: 0.10214534384995679\n",
            "Total Loss: 3.534646131688963\n",
            "----------------------------------------\n",
            "Epoch 187\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0440, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.463861017936903\n",
            "SCOPE mean: 0.7510367311669043, SCOPE var: 0.10231432466909639\n",
            "Total Loss: 3.507903087745478\n",
            "----------------------------------------\n",
            "Epoch 188\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0439, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.437477404901928\n",
            "SCOPE mean: 0.7523203595117, SCOPE var: 0.1024883875793427\n",
            "Total Loss: 3.4813439086836966\n",
            "----------------------------------------\n",
            "Epoch 189\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0437, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.4112624576276493\n",
            "SCOPE mean: 0.7536485963537618, SCOPE var: 0.10266835225090876\n",
            "Total Loss: 3.4549557518550245\n",
            "----------------------------------------\n",
            "Epoch 190\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0435, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.385237281527787\n",
            "SCOPE mean: 0.7550123619970571, SCOPE var: 0.10284697430228541\n",
            "Total Loss: 3.428759772958708\n",
            "----------------------------------------\n",
            "Epoch 191\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0434, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.359410604218069\n",
            "SCOPE mean: 0.756402118197887, SCOPE var: 0.10302044389602129\n",
            "Total Loss: 3.402764523654064\n",
            "----------------------------------------\n",
            "Epoch 192\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0432, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.3338663365614827\n",
            "SCOPE mean: 0.7580575526450654, SCOPE var: 0.10318387018517854\n",
            "Total Loss: 3.377024663276816\n",
            "----------------------------------------\n",
            "Epoch 193\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0430, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.308545693984787\n",
            "SCOPE mean: 0.7597482884010598, SCOPE var: 0.10334009496776966\n",
            "Total Loss: 3.3515006830733958\n",
            "----------------------------------------\n",
            "Epoch 194\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0428, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.2834124663986026\n",
            "SCOPE mean: 0.7613798212099152, SCOPE var: 0.10349233294219394\n",
            "Total Loss: 3.326165785207241\n",
            "----------------------------------------\n",
            "Epoch 195\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0426, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.2584633378553267\n",
            "SCOPE mean: 0.762929418818047, SCOPE var: 0.10363855469612629\n",
            "Total Loss: 3.3010167543680615\n",
            "----------------------------------------\n",
            "Epoch 196\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0424, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.2336883506446146\n",
            "SCOPE mean: 0.764373992717922, SCOPE var: 0.10377638577007788\n",
            "Total Loss: 3.2760440638929786\n",
            "----------------------------------------\n",
            "Epoch 197\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0422, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.2091424559515\n",
            "SCOPE mean: 0.7656779765597547, SCOPE var: 0.10389029225349311\n",
            "Total Loss: 3.251300223207282\n",
            "----------------------------------------\n",
            "Epoch 198\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0420, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.1847525411105253\n",
            "SCOPE mean: 0.7666222197568935, SCOPE var: 0.10397717711269984\n",
            "Total Loss: 3.226718288086041\n",
            "----------------------------------------\n",
            "Epoch 199\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0418, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.1604914198998486\n",
            "SCOPE mean: 0.7672564421309503, SCOPE var: 0.10404220158011153\n",
            "Total Loss: 3.2022707559098222\n",
            "----------------------------------------\n",
            "Epoch 200\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0416, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.136365075235765\n",
            "SCOPE mean: 0.7676209571700382, SCOPE var: 0.10408901329260013\n",
            "Total Loss: 3.177963026397303\n",
            "----------------------------------------\n",
            "Epoch 201\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0414, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.1123819553922\n",
            "SCOPE mean: 0.7677541899134724, SCOPE var: 0.104120998441647\n",
            "Total Loss: 3.1538030910870027\n",
            "----------------------------------------\n",
            "Epoch 202\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0412, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.0885792783353554\n",
            "SCOPE mean: 0.7676866236717831, SCOPE var: 0.10414032327897349\n",
            "Total Loss: 3.1298275640654802\n",
            "----------------------------------------\n",
            "Epoch 203\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0411, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.064994686423907\n",
            "SCOPE mean: 0.7675691895122023, SCOPE var: 0.10414392062457829\n",
            "Total Loss: 3.1060689286247216\n",
            "----------------------------------------\n",
            "Epoch 204\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0409, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.041573402334259\n",
            "SCOPE mean: 0.7674467622851219, SCOPE var: 0.10413864207051912\n",
            "Total Loss: 3.0824737769825825\n",
            "----------------------------------------\n",
            "Epoch 205\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0407, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.018314983696843\n",
            "SCOPE mean: 0.7673332478783725, SCOPE var: 0.10412677077975468\n",
            "Total Loss: 3.0590417669752794\n",
            "----------------------------------------\n",
            "Epoch 206\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0406, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.9952232749993564\n",
            "SCOPE mean: 0.7672526907092091, SCOPE var: 0.10410955176444533\n",
            "Total Loss: 3.035775805597461\n",
            "----------------------------------------\n",
            "Epoch 207\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0404, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.9722957907875105\n",
            "SCOPE mean: 0.7672042377391213, SCOPE var: 0.10408920397223732\n",
            "Total Loss: 3.0126743072269084\n",
            "----------------------------------------\n",
            "Epoch 208\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0402, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.9495771964992827\n",
            "SCOPE mean: 0.7671623584383142, SCOPE var: 0.10406290121674477\n",
            "Total Loss: 2.9897810098585986\n",
            "----------------------------------------\n",
            "Epoch 209\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0400, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.9270233639053873\n",
            "SCOPE mean: 0.7670345403729208, SCOPE var: 0.10403693558966484\n",
            "Total Loss: 2.9670564896797273\n",
            "----------------------------------------\n",
            "Epoch 210\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0399, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.904629270629705\n",
            "SCOPE mean: 0.7668347617370311, SCOPE var: 0.10401280163386786\n",
            "Total Loss: 2.944495789874037\n",
            "----------------------------------------\n",
            "Epoch 211\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0397, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.8823944264036054\n",
            "SCOPE mean: 0.7665767709440454, SCOPE var: 0.10399166735588004\n",
            "Total Loss: 2.92209834185651\n",
            "----------------------------------------\n",
            "Epoch 212\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0395, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.860318671385025\n",
            "SCOPE mean: 0.7662759488307569, SCOPE var: 0.10397469425850699\n",
            "Total Loss: 2.899863867200107\n",
            "----------------------------------------\n",
            "Epoch 213\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0394, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.8384021313017302\n",
            "SCOPE mean: 0.7659490213748892, SCOPE var: 0.10396301605963883\n",
            "Total Loss: 2.8777923320987475\n",
            "----------------------------------------\n",
            "Epoch 214\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0392, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.8166450090972726\n",
            "SCOPE mean: 0.7656137215709714, SCOPE var: 0.10395772400021254\n",
            "Total Loss: 2.8558837393900935\n",
            "----------------------------------------\n",
            "Epoch 215\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0391, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.795078222942939\n",
            "SCOPE mean: 0.7652672101982829, SCOPE var: 0.10395668581984248\n",
            "Total Loss: 2.834167844385531\n",
            "----------------------------------------\n",
            "Epoch 216\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0389, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.7736779132655336\n",
            "SCOPE mean: 0.7651227662397092, SCOPE var: 0.10396047451875093\n",
            "Total Loss: 2.8126143617694708\n",
            "----------------------------------------\n",
            "Epoch 217\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0388, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.752423341956728\n",
            "SCOPE mean: 0.7653433248307545, SCOPE var: 0.10398138386452693\n",
            "Total Loss: 2.7911999649690147\n",
            "----------------------------------------\n",
            "Epoch 218\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0386, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.73130700550287\n",
            "SCOPE mean: 0.7657638904773548, SCOPE var: 0.10402279922837349\n",
            "Total Loss: 2.76993114121179\n",
            "----------------------------------------\n",
            "Epoch 219\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0385, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.710384869137381\n",
            "SCOPE mean: 0.7662935168183365, SCOPE var: 0.10407523818222371\n",
            "Total Loss: 2.7488544799468655\n",
            "----------------------------------------\n",
            "Epoch 220\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0383, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.6896159838520877\n",
            "SCOPE mean: 0.7668028462103929, SCOPE var: 0.10413243532146609\n",
            "Total Loss: 2.7279328385361756\n",
            "----------------------------------------\n",
            "Epoch 221\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0382, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.668989378456137\n",
            "SCOPE mean: 0.7672605916410634, SCOPE var: 0.10419505587742313\n",
            "Total Loss: 2.707158068798651\n",
            "----------------------------------------\n",
            "Epoch 222\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0380, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.648503999257536\n",
            "SCOPE mean: 0.767668636071772, SCOPE var: 0.1042620899268221\n",
            "Total Loss: 2.686528375370158\n",
            "----------------------------------------\n",
            "Epoch 223\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0379, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.628174794438515\n",
            "SCOPE mean: 0.7681960692138664, SCOPE var: 0.10434387905604842\n",
            "Total Loss: 2.6660523097774327\n",
            "----------------------------------------\n",
            "Epoch 224\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0377, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.607989176175275\n",
            "SCOPE mean: 0.7687939326077168, SCOPE var: 0.1044394846664843\n",
            "Total Loss: 2.6457224502807084\n",
            "----------------------------------------\n",
            "Epoch 225\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0376, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.587950304539471\n",
            "SCOPE mean: 0.7694548073706131, SCOPE var: 0.10454636878732262\n",
            "Total Loss: 2.625541614043597\n",
            "----------------------------------------\n",
            "Epoch 226\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0375, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.568059330066931\n",
            "SCOPE mean: 0.7702668597761265, SCOPE var: 0.1046650920410213\n",
            "Total Loss: 2.6055144197696074\n",
            "----------------------------------------\n",
            "Epoch 227\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0373, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.5483397932225604\n",
            "SCOPE mean: 0.7713043915621265, SCOPE var: 0.1047878816214291\n",
            "Total Loss: 2.5856522811895055\n",
            "----------------------------------------\n",
            "Epoch 228\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0372, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.5287631944797258\n",
            "SCOPE mean: 0.772217026931531, SCOPE var: 0.10490492421049363\n",
            "Total Loss: 2.565934120299527\n",
            "----------------------------------------\n",
            "Epoch 229\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0370, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.5093184925196756\n",
            "SCOPE mean: 0.7729603352473502, SCOPE var: 0.10501721658645713\n",
            "Total Loss: 2.5463532707391967\n",
            "----------------------------------------\n",
            "Epoch 230\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0369, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.4900346915899405\n",
            "SCOPE mean: 0.7737159424380503, SCOPE var: 0.10512173533907772\n",
            "Total Loss: 2.5269326429472647\n",
            "----------------------------------------\n",
            "Epoch 231\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0368, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.4708923123792625\n",
            "SCOPE mean: 0.7744865786957137, SCOPE var: 0.1052203106892594\n",
            "Total Loss: 2.5076534976107077\n",
            "----------------------------------------\n",
            "Epoch 232\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0366, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.4518911838531356\n",
            "SCOPE mean: 0.7752592003151504, SCOPE var: 0.10531260297196998\n",
            "Total Loss: 2.4885158291102263\n",
            "----------------------------------------\n",
            "Epoch 233\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0365, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.4330311053433067\n",
            "SCOPE mean: 0.7760199249619376, SCOPE var: 0.10539827139541649\n",
            "Total Loss: 2.469519628347416\n",
            "----------------------------------------\n",
            "Epoch 234\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0364, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.414330944483564\n",
            "SCOPE mean: 0.7767400488161922, SCOPE var: 0.10547477926771134\n",
            "Total Loss: 2.4506833332627873\n",
            "----------------------------------------\n",
            "Epoch 235\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0362, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.395736454035302\n",
            "SCOPE mean: 0.7772320802395328, SCOPE var: 0.10554676756239066\n",
            "Total Loss: 2.431959676924735\n",
            "----------------------------------------\n",
            "Epoch 236\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0361, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.377289665260165\n",
            "SCOPE mean: 0.777490616009013, SCOPE var: 0.10561010912620315\n",
            "Total Loss: 2.413388750525607\n",
            "----------------------------------------\n",
            "Epoch 237\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0360, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.3589857088595987\n",
            "SCOPE mean: 0.7777624910027533, SCOPE var: 0.1056683535884561\n",
            "Total Loss: 2.394960367279521\n",
            "----------------------------------------\n",
            "Epoch 238\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0358, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.3408185519581215\n",
            "SCOPE mean: 0.7780643773581692, SCOPE var: 0.10572326344405386\n",
            "Total Loss: 2.376668369044313\n",
            "----------------------------------------\n",
            "Epoch 239\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0357, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.3227896082264934\n",
            "SCOPE mean: 0.7785915704584855, SCOPE var: 0.10578803746132959\n",
            "Total Loss: 2.3585102334001844\n",
            "----------------------------------------\n",
            "Epoch 240\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0356, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.304891689194106\n",
            "SCOPE mean: 0.7792934075087478, SCOPE var: 0.1058631478602797\n",
            "Total Loss: 2.340482311112396\n",
            "----------------------------------------\n",
            "Epoch 241\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0355, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.2871311063513593\n",
            "SCOPE mean: 0.7799868772740906, SCOPE var: 0.10593300216698973\n",
            "Total Loss: 2.3225911801086365\n",
            "----------------------------------------\n",
            "Epoch 242\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0353, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.2695045461420684\n",
            "SCOPE mean: 0.7806480613574192, SCOPE var: 0.10599789526730458\n",
            "Total Loss: 2.3048349713381304\n",
            "----------------------------------------\n",
            "Epoch 243\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0352, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.2520238524705634\n",
            "SCOPE mean: 0.7812537641399424, SCOPE var: 0.10605597153602665\n",
            "Total Loss: 2.2872252996009057\n",
            "----------------------------------------\n",
            "Epoch 244\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0351, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.234649009217865\n",
            "SCOPE mean: 0.7816038105112421, SCOPE var: 0.1061099792461945\n",
            "Total Loss: 2.2697287364899794\n",
            "----------------------------------------\n",
            "Epoch 245\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0350, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.2174059310008967\n",
            "SCOPE mean: 0.7817125962841195, SCOPE var: 0.10615759780318382\n",
            "Total Loss: 2.2523696031142437\n",
            "----------------------------------------\n",
            "Epoch 246\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0348, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.200313317803368\n",
            "SCOPE mean: 0.7818894622063641, SCOPE var: 0.10619861883290951\n",
            "Total Loss: 2.2351538640840443\n",
            "----------------------------------------\n",
            "Epoch 247\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0347, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.183347469424729\n",
            "SCOPE mean: 0.7822602830596949, SCOPE var: 0.10625133198329294\n",
            "Total Loss: 2.218063673018558\n",
            "----------------------------------------\n",
            "Epoch 248\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0346, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.166493554892994\n",
            "SCOPE mean: 0.7827581422828122, SCOPE var: 0.10631843020433522\n",
            "Total Loss: 2.2010905405434475\n",
            "----------------------------------------\n",
            "Epoch 249\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0345, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.149756534653867\n",
            "SCOPE mean: 0.7833761363430837, SCOPE var: 0.10639759662256398\n",
            "Total Loss: 2.1842375217098633\n",
            "----------------------------------------\n",
            "Epoch 250\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0344, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.13316475927441\n",
            "SCOPE mean: 0.7840268814355017, SCOPE var: 0.10646753062493901\n",
            "Total Loss: 2.1675221227442227\n",
            "----------------------------------------\n",
            "Epoch 251\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0342, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.116698027305338\n",
            "SCOPE mean: 0.7846272000842326, SCOPE var: 0.10653251112813954\n",
            "Total Loss: 2.150933140328009\n",
            "----------------------------------------\n",
            "Epoch 252\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0341, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.100357138206052\n",
            "SCOPE mean: 0.7851654463878108, SCOPE var: 0.10659193003110229\n",
            "Total Loss: 2.134471451966955\n",
            "----------------------------------------\n",
            "Epoch 253\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0340, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.0841273453361038\n",
            "SCOPE mean: 0.7854309493337147, SCOPE var: 0.10664493520116411\n",
            "Total Loss: 2.1181277698368834\n",
            "----------------------------------------\n",
            "Epoch 254\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0339, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.0680214554671066\n",
            "SCOPE mean: 0.7856620391140701, SCOPE var: 0.10669351139607393\n",
            "Total Loss: 2.101908937976183\n",
            "----------------------------------------\n",
            "Epoch 255\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0338, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.0520366496914826\n",
            "SCOPE mean: 0.7858723424329932, SCOPE var: 0.10673894588247036\n",
            "Total Loss: 2.085812102230582\n",
            "----------------------------------------\n",
            "Epoch 256\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0337, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.036172213280459\n",
            "SCOPE mean: 0.7860729878024958, SCOPE var: 0.10678220080065531\n",
            "Total Loss: 2.0698364403810334\n",
            "----------------------------------------\n",
            "Epoch 257\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0335, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.0204362974640935\n",
            "SCOPE mean: 0.7863082400949425, SCOPE var: 0.10682181766579146\n",
            "Total Loss: 2.0539857257232623\n",
            "----------------------------------------\n",
            "Epoch 258\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0334, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.004810281785396\n",
            "SCOPE mean: 0.7866780357204494, SCOPE var: 0.10687567538686121\n",
            "Total Loss: 2.038248083042352\n",
            "----------------------------------------\n",
            "Epoch 259\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0333, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.989301837587356\n",
            "SCOPE mean: 0.7871935627620305, SCOPE var: 0.1069402780450279\n",
            "Total Loss: 2.022627506939738\n",
            "----------------------------------------\n",
            "Epoch 260\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0332, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.9739160832161344\n",
            "SCOPE mean: 0.7876955452458408, SCOPE var: 0.10700006004365041\n",
            "Total Loss: 2.007128124357522\n",
            "----------------------------------------\n",
            "Epoch 261\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0331, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.95864573525832\n",
            "SCOPE mean: 0.7881541324289992, SCOPE var: 0.10705637205968113\n",
            "Total Loss: 1.991745671309691\n",
            "----------------------------------------\n",
            "Epoch 262\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0330, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.9434894350475023\n",
            "SCOPE mean: 0.7885657399693136, SCOPE var: 0.10710914188458846\n",
            "Total Loss: 1.9764788464003848\n",
            "----------------------------------------\n",
            "Epoch 263\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0329, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.9284462168388108\n",
            "SCOPE mean: 0.7889297863552612, SCOPE var: 0.10715848441240797\n",
            "Total Loss: 1.9613267026585255\n",
            "----------------------------------------\n",
            "Epoch 264\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0328, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.9135152214796702\n",
            "SCOPE mean: 0.7892485356507652, SCOPE var: 0.10720468910321834\n",
            "Total Loss: 1.9462883620730937\n",
            "----------------------------------------\n",
            "Epoch 265\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0327, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.8986956895143736\n",
            "SCOPE mean: 0.7895268174489792, SCOPE var: 0.1072481991138191\n",
            "Total Loss: 1.9313630111127198\n",
            "----------------------------------------\n",
            "Epoch 266\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0326, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.8839869935842448\n",
            "SCOPE mean: 0.7897715554924147, SCOPE var: 0.10728957877410165\n",
            "Total Loss: 1.9165499384122486\n",
            "----------------------------------------\n",
            "Epoch 267\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0325, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.8693885489350592\n",
            "SCOPE mean: 0.7899911567746211, SCOPE var: 0.10732947359325552\n",
            "Total Loss: 1.901848452362425\n",
            "----------------------------------------\n",
            "Epoch 268\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0324, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.8548989448988773\n",
            "SCOPE mean: 0.7901941429915769, SCOPE var: 0.10736853908360348\n",
            "Total Loss: 1.8872570197124399\n",
            "----------------------------------------\n",
            "Epoch 269\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0323, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.8405185999901243\n",
            "SCOPE mean: 0.7903905501153242, SCOPE var: 0.10740747106552247\n",
            "Total Loss: 1.8727759307838485\n",
            "----------------------------------------\n",
            "Epoch 270\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0322, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.8262469646665924\n",
            "SCOPE mean: 0.7905900314759665, SCOPE var: 0.10744687132663269\n",
            "Total Loss: 1.8584044431630171\n",
            "----------------------------------------\n",
            "Epoch 271\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0321, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.8120859391823312\n",
            "SCOPE mean: 0.7909606590402497, SCOPE var: 0.10749844675544143\n",
            "Total Loss: 1.8441415878557563\n",
            "----------------------------------------\n",
            "Epoch 272\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0320, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7980315764875172\n",
            "SCOPE mean: 0.7913240994055591, SCOPE var: 0.10754979699580008\n",
            "Total Loss: 1.8299864718010688\n",
            "----------------------------------------\n",
            "Epoch 273\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0319, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7840829794324466\n",
            "SCOPE mean: 0.7916795249153585, SCOPE var: 0.10760092772955501\n",
            "Total Loss: 1.8159382443625973\n",
            "----------------------------------------\n",
            "Epoch 274\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0318, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7702394033091764\n",
            "SCOPE mean: 0.7920271904758746, SCOPE var: 0.10765183432730624\n",
            "Total Loss: 1.8019961326814085\n",
            "----------------------------------------\n",
            "Epoch 275\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0317, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7565001198593957\n",
            "SCOPE mean: 0.7923678229704585, SCOPE var: 0.10770253594700648\n",
            "Total Loss: 1.788159374404296\n",
            "----------------------------------------\n",
            "Epoch 276\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0316, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7428644147834886\n",
            "SCOPE mean: 0.7927025254979482, SCOPE var: 0.10775307035466308\n",
            "Total Loss: 1.7744272164070933\n",
            "----------------------------------------\n",
            "Epoch 277\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0315, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.729331584211762\n",
            "SCOPE mean: 0.7930326627645891, SCOPE var: 0.10780348755350089\n",
            "Total Loss: 1.7607989127849273\n",
            "----------------------------------------\n",
            "Epoch 278\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0314, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7159009309030424\n",
            "SCOPE mean: 0.7933597375871243, SCOPE var: 0.10785384283569593\n",
            "Total Loss: 1.7472737227350208\n",
            "----------------------------------------\n",
            "Epoch 279\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0313, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7025717608446178\n",
            "SCOPE mean: 0.7936852682205164, SCOPE var: 0.10790418985952638\n",
            "Total Loss: 1.7338509088673184\n",
            "----------------------------------------\n",
            "Epoch 280\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0312, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6893433807038496\n",
            "SCOPE mean: 0.7940106752695781, SCOPE var: 0.10795457429823321\n",
            "Total Loss: 1.720529736265604\n",
            "----------------------------------------\n",
            "Epoch 281\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0311, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6762150963060314\n",
            "SCOPE mean: 0.7943371854296822, SCOPE var: 0.10800502851399932\n",
            "Total Loss: 1.7073094723652766\n",
            "----------------------------------------\n",
            "Epoch 282\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0310, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6631862120632102\n",
            "SCOPE mean: 0.794665757402447, SCOPE var: 0.1080555675922512\n",
            "Total Loss: 1.6941893874893967\n",
            "----------------------------------------\n",
            "Epoch 283\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0309, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6502560311102297\n",
            "SCOPE mean: 0.7949970332302887, SCOPE var: 0.10810618693950116\n",
            "Total Loss: 1.6811687557451036\n",
            "----------------------------------------\n",
            "Epoch 284\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0308, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6374238558403293\n",
            "SCOPE mean: 0.7953313161654846, SCOPE var: 0.10815686151359837\n",
            "Total Loss: 1.668246855948709\n",
            "----------------------------------------\n",
            "Epoch 285\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0307, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6246889885643272\n",
            "SCOPE mean: 0.7956685741932035, SCOPE var: 0.10820754662881166\n",
            "Total Loss: 1.6554229723085128\n",
            "----------------------------------------\n",
            "Epoch 286\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0306, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6120507321125492\n",
            "SCOPE mean: 0.7960084665945513, SCOPE var: 0.10825818016812543\n",
            "Total Loss: 1.6426963947154212\n",
            "----------------------------------------\n",
            "Epoch 287\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0306, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5995083903151892\n",
            "SCOPE mean: 0.7963503895610979, SCOPE var: 0.1083086859476686\n",
            "Total Loss: 1.6300664186291447\n",
            "----------------------------------------\n",
            "Epoch 288\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0305, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5870612292003856\n",
            "SCOPE mean: 0.796693251290555, SCOPE var: 0.10835913429311295\n",
            "Total Loss: 1.617532310832461\n",
            "----------------------------------------\n",
            "Epoch 289\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0304, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5747080772004727\n",
            "SCOPE mean: 0.797032937347345, SCOPE var: 0.10841116364664255\n",
            "Total Loss: 1.605092957594523\n",
            "----------------------------------------\n",
            "Epoch 290\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0303, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5624487289908293\n",
            "SCOPE mean: 0.7973724066094355, SCOPE var: 0.10846281102058627\n",
            "Total Loss: 1.592748083616304\n",
            "----------------------------------------\n",
            "Epoch 291\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0302, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5502825052645317\n",
            "SCOPE mean: 0.7977110634715497, SCOPE var: 0.10851401985771206\n",
            "Total Loss: 1.5804970064676935\n",
            "----------------------------------------\n",
            "Epoch 292\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0301, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5382087294489168\n",
            "SCOPE mean: 0.7980482780068171, SCOPE var: 0.10856473471848911\n",
            "Total Loss: 1.5683390475653294\n",
            "----------------------------------------\n",
            "Epoch 293\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0300, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.526226728292358\n",
            "SCOPE mean: 0.7983834302221635, SCOPE var: 0.10861490412259991\n",
            "Total Loss: 1.5562735321131105\n",
            "----------------------------------------\n",
            "Epoch 294\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0300, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5143358324772815\n",
            "SCOPE mean: 0.7987159492810226, SCOPE var: 0.10866448301968706\n",
            "Total Loss: 1.5442997891358687\n",
            "----------------------------------------\n",
            "Epoch 295\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0299, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5025353772131624\n",
            "SCOPE mean: 0.7990453454599753, SCOPE var: 0.10871343474794988\n",
            "Total Loss: 1.5324171515933152\n",
            "----------------------------------------\n",
            "Epoch 296\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0298, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.49082470275231\n",
            "SCOPE mean: 0.7993712333401749, SCOPE var: 0.1087617323865103\n",
            "Total Loss: 1.5206249565399648\n",
            "----------------------------------------\n",
            "Epoch 297\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0297, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.479203154773965\n",
            "SCOPE mean: 0.799693345504321, SCOPE var: 0.10880935945744234\n",
            "Total Loss: 1.508922545288336\n",
            "----------------------------------------\n",
            "Epoch 298\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0296, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4676700845977055\n",
            "SCOPE mean: 0.8000115367571109, SCOPE var: 0.10885630998203336\n",
            "Total Loss: 1.4973092635372733\n",
            "----------------------------------------\n",
            "Epoch 299\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0296, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4562248492110563\n",
            "SCOPE mean: 0.8003257795597857, SCOPE var: 0.10890258794000936\n",
            "Total Loss: 1.4857844614412155\n",
            "----------------------------------------\n",
            "Epoch 300\n",
            "IS mean: 0.6495644945720374,IS variance: 0.05499459434326623\n",
            "SCOPE Var loss:  tensor(0.0295, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4448668111224787\n",
            "SCOPE mean: 0.8006361519255801, SCOPE var: 0.108948206217083\n",
            "Total Loss: 1.4743474936142256\n",
            "----------------------------------------\n",
            "Epoch 1\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.6661, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  45.81570033117865\n",
            "SCOPE mean: 3.760557922565476, SCOPE var: 0.6497822276239168\n",
            "Total Loss: 46.48178636842031\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(1.9886, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  42.849149073247766\n",
            "SCOPE mean: 3.6517073247707406, SCOPE var: 0.6268698772571679\n",
            "Total Loss: 44.83776085436481\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(1.8975, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  39.83141128593328\n",
            "SCOPE mean: 3.543791243360041, SCOPE var: 0.60487452041928\n",
            "Total Loss: 41.72894134051916\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(1.8084, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  36.98265435836324\n",
            "SCOPE mean: 3.436080345867737, SCOPE var: 0.5833144044700124\n",
            "Total Loss: 38.791020277784234\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(1.7217, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  34.30533122056946\n",
            "SCOPE mean: 3.3286765686393776, SCOPE var: 0.5621851606911062\n",
            "Total Loss: 36.02698400328107\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(1.6376, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  31.798694858284193\n",
            "SCOPE mean: 3.221611111921469, SCOPE var: 0.5414670870075338\n",
            "Total Loss: 33.43633686953625\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(1.5565, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  29.462732675482584\n",
            "SCOPE mean: 3.1149734041716473, SCOPE var: 0.5211622106246511\n",
            "Total Loss: 31.01924705032957\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(1.4784, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  27.296387209970586\n",
            "SCOPE mean: 3.008920814312996, SCOPE var: 0.5012989428515569\n",
            "Total Loss: 28.77473744739999\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(1.4032, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  25.297937762007162\n",
            "SCOPE mean: 2.903666243972356, SCOPE var: 0.4819249843371617\n",
            "Total Loss: 26.701123447738446\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(1.3311, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  23.464930986030335\n",
            "SCOPE mean: 2.7994287832721407, SCOPE var: 0.4630841203966258\n",
            "Total Loss: 24.795984156332324\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(1.2620, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.794202659121154\n",
            "SCOPE mean: 2.696418338865023, SCOPE var: 0.44481793064648384\n",
            "Total Loss: 23.0561909649951\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(1.1960, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  20.281832606689502\n",
            "SCOPE mean: 2.5948351143821116, SCOPE var: 0.4271702910396179\n",
            "Total Loss: 21.477859617909722\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(1.1332, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  18.921926326432374\n",
            "SCOPE mean: 2.4949020868454856, SCOPE var: 0.4101394418036912\n",
            "Total Loss: 20.055089873119364\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(1.0734, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  17.708669719937\n",
            "SCOPE mean: 2.3968044479492687, SCOPE var: 0.3937393375772644\n",
            "Total Loss: 18.782068552768067\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(1.0169, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  16.63448156175306\n",
            "SCOPE mean: 2.300809009438211, SCOPE var: 0.3780585109879147\n",
            "Total Loss: 17.65141280421508\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.9635, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  15.692129095899496\n",
            "SCOPE mean: 2.2070296213488416, SCOPE var: 0.36302271199324027\n",
            "Total Loss: 16.655673778174567\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.9132, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.87309328785037\n",
            "SCOPE mean: 2.1156507271124263, SCOPE var: 0.34861987626638724\n",
            "Total Loss: 15.786248549222506\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.8657, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.16812020589814\n",
            "SCOPE mean: 2.0268707281006018, SCOPE var: 0.3348553098431012\n",
            "Total Loss: 15.033844523267062\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.8212, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.567247000252449\n",
            "SCOPE mean: 1.940873265521167, SCOPE var: 0.32173636503465525\n",
            "Total Loss: 14.388464276724214\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.7797, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.059679764480972\n",
            "SCOPE mean: 1.857777324389171, SCOPE var: 0.30929613827324565\n",
            "Total Loss: 13.839332200789263\n",
            "----------------------------------------\n",
            "Epoch 21\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.7409, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.635394629578872\n",
            "SCOPE mean: 1.7778159701085605, SCOPE var: 0.29749002418354376\n",
            "Total Loss: 13.37627255746963\n",
            "----------------------------------------\n",
            "Epoch 22\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.7048, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.283915397417825\n",
            "SCOPE mean: 1.7011393990413446, SCOPE var: 0.28631087557191914\n",
            "Total Loss: 12.988737968051947\n",
            "----------------------------------------\n",
            "Epoch 23\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.6714, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.994944918362851\n",
            "SCOPE mean: 1.627878247394406, SCOPE var: 0.27574872691166646\n",
            "Total Loss: 12.666348863484936\n",
            "----------------------------------------\n",
            "Epoch 24\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.6405, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.758393640819824\n",
            "SCOPE mean: 1.5581310938868527, SCOPE var: 0.2658067931638178\n",
            "Total Loss: 12.398926575514754\n",
            "----------------------------------------\n",
            "Epoch 25\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.6121, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.56418527180751\n",
            "SCOPE mean: 1.4920694608197702, SCOPE var: 0.25648506260020576\n",
            "Total Loss: 12.176329392091262\n",
            "----------------------------------------\n",
            "Epoch 26\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.5861, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.404432403211077\n",
            "SCOPE mean: 1.4296253242239285, SCOPE var: 0.24771604806871714\n",
            "Total Loss: 11.990483243076303\n",
            "----------------------------------------\n",
            "Epoch 27\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.5622, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.27113553768687\n",
            "SCOPE mean: 1.3708911170124605, SCOPE var: 0.23950256745429158\n",
            "Total Loss: 11.833303247146135\n",
            "----------------------------------------\n",
            "Epoch 28\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.5404, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.15734414227719\n",
            "SCOPE mean: 1.3158816038315662, SCOPE var: 0.23182560565889396\n",
            "Total Loss: 11.697715695258127\n",
            "----------------------------------------\n",
            "Epoch 29\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.5205, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.056977693473412\n",
            "SCOPE mean: 1.2645880049316554, SCOPE var: 0.22466554050662754\n",
            "Total Loss: 11.577514450225829\n",
            "----------------------------------------\n",
            "Epoch 30\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.5025, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.964933010530295\n",
            "SCOPE mean: 1.2169786669346057, SCOPE var: 0.21800258346664453\n",
            "Total Loss: 11.46747047610733\n",
            "----------------------------------------\n",
            "Epoch 31\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.4862, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.877441161762317\n",
            "SCOPE mean: 1.1729993723690975, SCOPE var: 0.21181669854267995\n",
            "Total Loss: 11.363689457607528\n",
            "----------------------------------------\n",
            "Epoch 32\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.4717, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.791227030440556\n",
            "SCOPE mean: 1.1326237770634757, SCOPE var: 0.20613277786444348\n",
            "Total Loss: 11.262911522967961\n",
            "----------------------------------------\n",
            "Epoch 33\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.4587, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.70426777096762\n",
            "SCOPE mean: 1.0957499420836132, SCOPE var: 0.20091550705940805\n",
            "Total Loss: 11.16294227570923\n",
            "----------------------------------------\n",
            "Epoch 34\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.4470, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.615386557248915\n",
            "SCOPE mean: 1.0622468669862137, SCOPE var: 0.19612117005383442\n",
            "Total Loss: 11.062415020291253\n",
            "----------------------------------------\n",
            "Epoch 35\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.4366, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.523518748413192\n",
            "SCOPE mean: 1.032544619711154, SCOPE var: 0.19173093730896512\n",
            "Total Loss: 10.960154440232456\n",
            "----------------------------------------\n",
            "Epoch 36\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.4274, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.427935572393062\n",
            "SCOPE mean: 1.007307885409998, SCOPE var: 0.187734929506104\n",
            "Total Loss: 10.85529749730431\n",
            "----------------------------------------\n",
            "Epoch 37\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.4191, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.32993944318736\n",
            "SCOPE mean: 0.9851480536606063, SCOPE var: 0.18411104987012916\n",
            "Total Loss: 10.749048462105822\n",
            "----------------------------------------\n",
            "Epoch 38\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.4118, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.23028609716559\n",
            "SCOPE mean: 0.9658600015911812, SCOPE var: 0.18083749279171168\n",
            "Total Loss: 10.642084098438474\n",
            "----------------------------------------\n",
            "Epoch 39\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.4053, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.12993233966432\n",
            "SCOPE mean: 0.9492784150611769, SCOPE var: 0.17789739311895322\n",
            "Total Loss: 10.53526999897464\n",
            "----------------------------------------\n",
            "Epoch 40\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3997, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.029359019816651\n",
            "SCOPE mean: 0.9351779849448348, SCOPE var: 0.17529136526236558\n",
            "Total Loss: 10.429094048316019\n",
            "----------------------------------------\n",
            "Epoch 41\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3948, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.93016394909194\n",
            "SCOPE mean: 0.9234386933219193, SCOPE var: 0.1729892217956718\n",
            "Total Loss: 10.3249910650353\n",
            "----------------------------------------\n",
            "Epoch 42\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3905, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.83336794192912\n",
            "SCOPE mean: 0.9138937885588401, SCOPE var: 0.170973651024359\n",
            "Total Loss: 10.223897388623756\n",
            "----------------------------------------\n",
            "Epoch 43\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3868, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.739689533377666\n",
            "SCOPE mean: 0.9063756669636459, SCOPE var: 0.169229554060437\n",
            "Total Loss: 10.126462102973745\n",
            "----------------------------------------\n",
            "Epoch 44\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3835, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.650017713199528\n",
            "SCOPE mean: 0.9007117586010026, SCOPE var: 0.16774233297231192\n",
            "Total Loss: 10.033500579238876\n",
            "----------------------------------------\n",
            "Epoch 45\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3806, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.564898201135774\n",
            "SCOPE mean: 0.8967361323267938, SCOPE var: 0.1664978883988766\n",
            "Total Loss: 9.945504350826708\n",
            "----------------------------------------\n",
            "Epoch 46\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3781, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.48460083493939\n",
            "SCOPE mean: 0.8942838730198606, SCOPE var: 0.16548178041662584\n",
            "Total Loss: 9.862691736795696\n",
            "----------------------------------------\n",
            "Epoch 47\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3759, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.409287759040918\n",
            "SCOPE mean: 0.8931950172973415, SCOPE var: 0.164679646819157\n",
            "Total Loss: 9.785174119295473\n",
            "----------------------------------------\n",
            "Epoch 48\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3739, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.338656369585\n",
            "SCOPE mean: 0.8933123206965884, SCOPE var: 0.16407740904610782\n",
            "Total Loss: 9.712603209361983\n",
            "----------------------------------------\n",
            "Epoch 49\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3722, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.272606745281632\n",
            "SCOPE mean: 0.8944977513702624, SCOPE var: 0.1636617920997313\n",
            "Total Loss: 9.644837348038127\n",
            "----------------------------------------\n",
            "Epoch 50\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3707, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.210766029531149\n",
            "SCOPE mean: 0.8966093619915446, SCOPE var: 0.16341924483457837\n",
            "Total Loss: 9.581466509305463\n",
            "----------------------------------------\n",
            "Epoch 51\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3693, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.152604048098837\n",
            "SCOPE mean: 0.8995122932936912, SCOPE var: 0.1633365974140626\n",
            "Total Loss: 9.521927997667087\n",
            "----------------------------------------\n",
            "Epoch 52\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3681, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.097525678869669\n",
            "SCOPE mean: 0.9030802078925911, SCOPE var: 0.1634010473982084\n",
            "Total Loss: 9.465598300877943\n",
            "----------------------------------------\n",
            "Epoch 53\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3669, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.044804907678069\n",
            "SCOPE mean: 0.9071981192024299, SCOPE var: 0.1636002411688384\n",
            "Total Loss: 9.411727091364025\n",
            "----------------------------------------\n",
            "Epoch 54\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3659, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.993896832244424\n",
            "SCOPE mean: 0.9117602154847451, SCOPE var: 0.16392245083645002\n",
            "Total Loss: 9.359748907281487\n",
            "----------------------------------------\n",
            "Epoch 55\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3648, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.94419563297608\n",
            "SCOPE mean: 0.916665916763906, SCOPE var: 0.1643560677681044\n",
            "Total Loss: 9.309041144800625\n",
            "----------------------------------------\n",
            "Epoch 56\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3639, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.89514371943384\n",
            "SCOPE mean: 0.9218248403497091, SCOPE var: 0.1648899818614005\n",
            "Total Loss: 9.259032729319417\n",
            "----------------------------------------\n",
            "Epoch 57\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3630, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.846255083042104\n",
            "SCOPE mean: 0.9271371951371848, SCOPE var: 0.1655136565361668\n",
            "Total Loss: 9.209227391483845\n",
            "----------------------------------------\n",
            "Epoch 58\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3621, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.797148561164253\n",
            "SCOPE mean: 0.9324932353467348, SCOPE var: 0.16621779046475854\n",
            "Total Loss: 9.159236873914653\n",
            "----------------------------------------\n",
            "Epoch 59\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3612, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.747512495852343\n",
            "SCOPE mean: 0.9378892754390333, SCOPE var: 0.1669913546004248\n",
            "Total Loss: 9.10874236104108\n",
            "----------------------------------------\n",
            "Epoch 60\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3604, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.69712138641953\n",
            "SCOPE mean: 0.9432713830810304, SCOPE var: 0.16782521065579314\n",
            "Total Loss: 9.05751434421581\n",
            "----------------------------------------\n",
            "Epoch 61\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3596, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.645841423031662\n",
            "SCOPE mean: 0.9485953580333794, SCOPE var: 0.1687108120462286\n",
            "Total Loss: 9.005416492425613\n",
            "----------------------------------------\n",
            "Epoch 62\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3588, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.593623119942926\n",
            "SCOPE mean: 0.9538262365044837, SCOPE var: 0.16964020203843871\n",
            "Total Loss: 8.952397945617127\n",
            "----------------------------------------\n",
            "Epoch 63\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3580, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.540490516887031\n",
            "SCOPE mean: 0.9589376829472878, SCOPE var: 0.17060600572180895\n",
            "Total Loss: 8.898482207793442\n",
            "----------------------------------------\n",
            "Epoch 64\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3572, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.486528045728022\n",
            "SCOPE mean: 0.963911285811391, SCOPE var: 0.17160141624164138\n",
            "Total Loss: 8.843753741631708\n",
            "----------------------------------------\n",
            "Epoch 65\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3565, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.43186613657087\n",
            "SCOPE mean: 0.9687357767925466, SCOPE var: 0.1726201759878432\n",
            "Total Loss: 8.78834334112165\n",
            "----------------------------------------\n",
            "Epoch 66\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3557, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.376670487926868\n",
            "SCOPE mean: 0.9734061807673965, SCOPE var: 0.17365655372098307\n",
            "Total Loss: 8.732417207118253\n",
            "----------------------------------------\n",
            "Epoch 67\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3550, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.321118663342371\n",
            "SCOPE mean: 0.977923842073425, SCOPE var: 0.17470565517439404\n",
            "Total Loss: 8.676153535014121\n",
            "----------------------------------------\n",
            "Epoch 68\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3543, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.265392712514908\n",
            "SCOPE mean: 0.9822937070964425, SCOPE var: 0.1757626878328474\n",
            "Total Loss: 8.619734705655338\n",
            "----------------------------------------\n",
            "Epoch 69\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3537, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.20966924844797\n",
            "SCOPE mean: 0.9865244041657683, SCOPE var: 0.17682330365498633\n",
            "Total Loss: 8.563337433991533\n",
            "----------------------------------------\n",
            "Epoch 70\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3530, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.15410954911228\n",
            "SCOPE mean: 0.9906273945061994, SCOPE var: 0.1778835679698802\n",
            "Total Loss: 8.507122809002007\n",
            "----------------------------------------\n",
            "Epoch 71\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3524, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.098853040535246\n",
            "SCOPE mean: 0.9946161588283609, SCOPE var: 0.1789399284686741\n",
            "Total Loss: 8.45122973952599\n",
            "----------------------------------------\n",
            "Epoch 72\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3518, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.044013091195275\n",
            "SCOPE mean: 0.9985054359578959, SCOPE var: 0.1799891848629221\n",
            "Total Loss: 8.395770732092803\n",
            "----------------------------------------\n",
            "Epoch 73\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3512, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.989683275236927\n",
            "SCOPE mean: 1.0023111747062214, SCOPE var: 0.18102845780784563\n",
            "Total Loss: 8.340838233765599\n",
            "----------------------------------------\n",
            "Epoch 74\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3506, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.935916273851157\n",
            "SCOPE mean: 1.0060460977445667, SCOPE var: 0.1820550142366497\n",
            "Total Loss: 8.286483391535661\n",
            "----------------------------------------\n",
            "Epoch 75\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3500, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.882739586565339\n",
            "SCOPE mean: 1.0097248151454077, SCOPE var: 0.18306655785510362\n",
            "Total Loss: 8.232731822989106\n",
            "----------------------------------------\n",
            "Epoch 76\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3494, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.830162350070198\n",
            "SCOPE mean: 1.0133610871406726, SCOPE var: 0.1840610374601199\n",
            "Total Loss: 8.179590544763384\n",
            "----------------------------------------\n",
            "Epoch 77\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3489, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.778175424945023\n",
            "SCOPE mean: 1.016967549545839, SCOPE var: 0.18503677183005535\n",
            "Total Loss: 8.127048614212693\n",
            "----------------------------------------\n",
            "Epoch 78\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3483, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.726743993354822\n",
            "SCOPE mean: 1.020554720471359, SCOPE var: 0.18599212611880786\n",
            "Total Loss: 8.075068617279152\n",
            "----------------------------------------\n",
            "Epoch 79\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3478, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.6758281349356485\n",
            "SCOPE mean: 1.024131076179461, SCOPE var: 0.1869256557749268\n",
            "Total Loss: 8.023607896828638\n",
            "----------------------------------------\n",
            "Epoch 80\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3472, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.6253826449755\n",
            "SCOPE mean: 1.0277029515220846, SCOPE var: 0.18783609174983482\n",
            "Total Loss: 7.972618428828524\n",
            "----------------------------------------\n",
            "Epoch 81\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3467, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.575365554928496\n",
            "SCOPE mean: 1.0312749006965691, SCOPE var: 0.18872225500870699\n",
            "Total Loss: 7.922055916749409\n",
            "----------------------------------------\n",
            "Epoch 82\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3461, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.525720151837489\n",
            "SCOPE mean: 1.034848671139963, SCOPE var: 0.18958317814039144\n",
            "Total Loss: 7.871860633025064\n",
            "----------------------------------------\n",
            "Epoch 83\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3456, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.476401211468049\n",
            "SCOPE mean: 1.0384239598200333, SCOPE var: 0.19041806139318185\n",
            "Total Loss: 7.821984445131059\n",
            "----------------------------------------\n",
            "Epoch 84\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3450, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.427369316431683\n",
            "SCOPE mean: 1.0419983997372992, SCOPE var: 0.1912262384368853\n",
            "Total Loss: 7.772385091975049\n",
            "----------------------------------------\n",
            "Epoch 85\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3444, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.378588857424908\n",
            "SCOPE mean: 1.045571987186893, SCOPE var: 0.1920056610093964\n",
            "Total Loss: 7.723028837278159\n",
            "----------------------------------------\n",
            "Epoch 86\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3439, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.330014454991571\n",
            "SCOPE mean: 1.049177967549925, SCOPE var: 0.19274156811222168\n",
            "Total Loss: 7.673911180982535\n",
            "----------------------------------------\n",
            "Epoch 87\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3433, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.2816567675071004\n",
            "SCOPE mean: 1.0527645072642877, SCOPE var: 0.19344922063236278\n",
            "Total Loss: 7.624992634434063\n",
            "----------------------------------------\n",
            "Epoch 88\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3428, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.233548045128618\n",
            "SCOPE mean: 1.0563370917924022, SCOPE var: 0.19412963495421634\n",
            "Total Loss: 7.576310944041734\n",
            "----------------------------------------\n",
            "Epoch 89\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3422, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.18567367470916\n",
            "SCOPE mean: 1.059873051992471, SCOPE var: 0.19478023885551254\n",
            "Total Loss: 7.527837970709412\n",
            "----------------------------------------\n",
            "Epoch 90\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3415, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.138009244767723\n",
            "SCOPE mean: 1.0633490402086268, SCOPE var: 0.19540017447532057\n",
            "Total Loss: 7.479549943986791\n",
            "----------------------------------------\n",
            "Epoch 91\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3409, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.090555916468646\n",
            "SCOPE mean: 1.0667535030280684, SCOPE var: 0.19598916800259547\n",
            "Total Loss: 7.431444356727317\n",
            "----------------------------------------\n",
            "Epoch 92\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3402, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.043326841173083\n",
            "SCOPE mean: 1.0700765249613648, SCOPE var: 0.19654773900115718\n",
            "Total Loss: 7.383534860314439\n",
            "----------------------------------------\n",
            "Epoch 93\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3395, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.996332062267084\n",
            "SCOPE mean: 1.0733082537117313, SCOPE var: 0.1970765222838723\n",
            "Total Loss: 7.335830405381727\n",
            "----------------------------------------\n",
            "Epoch 94\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3388, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.949581469797091\n",
            "SCOPE mean: 1.0764390066545397, SCOPE var: 0.19757617770489824\n",
            "Total Loss: 7.288339942969282\n",
            "----------------------------------------\n",
            "Epoch 95\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3380, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.903085735943355\n",
            "SCOPE mean: 1.0794598419362238, SCOPE var: 0.19804745983567468\n",
            "Total Loss: 7.241073359170276\n",
            "----------------------------------------\n",
            "Epoch 96\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3372, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.857037636244871\n",
            "SCOPE mean: 1.0823995522497802, SCOPE var: 0.19849121984086557\n",
            "Total Loss: 7.194209349122655\n",
            "----------------------------------------\n",
            "Epoch 97\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3363, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.811329238380249\n",
            "SCOPE mean: 1.0851932844986738, SCOPE var: 0.1989034696227886\n",
            "Total Loss: 7.147650965297738\n",
            "----------------------------------------\n",
            "Epoch 98\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3354, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.765896564671525\n",
            "SCOPE mean: 1.0878220992047984, SCOPE var: 0.19928410092966953\n",
            "Total Loss: 7.101334645349541\n",
            "----------------------------------------\n",
            "Epoch 99\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3345, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.7208009147319165\n",
            "SCOPE mean: 1.0900706022815512, SCOPE var: 0.19956239564174316\n",
            "Total Loss: 7.055313368800725\n",
            "----------------------------------------\n",
            "Epoch 100\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3336, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.6759858415703714\n",
            "SCOPE mean: 1.0921235379857561, SCOPE var: 0.1998027732055764\n",
            "Total Loss: 7.009539389749072\n",
            "----------------------------------------\n",
            "Epoch 101\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3326, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.631438405315157\n",
            "SCOPE mean: 1.0940143045816788, SCOPE var: 0.20001800535448142\n",
            "Total Loss: 6.964002308046689\n",
            "----------------------------------------\n",
            "Epoch 102\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3315, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.587171920401294\n",
            "SCOPE mean: 1.0957434762879792, SCOPE var: 0.2002099083636158\n",
            "Total Loss: 6.918717231994802\n",
            "----------------------------------------\n",
            "Epoch 103\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3305, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.543223015345734\n",
            "SCOPE mean: 1.097291855997112, SCOPE var: 0.20037920898534636\n",
            "Total Loss: 6.873723429895417\n",
            "----------------------------------------\n",
            "Epoch 104\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3294, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.4995232811960815\n",
            "SCOPE mean: 1.0986670175858724, SCOPE var: 0.20052597068171504\n",
            "Total Loss: 6.828952411182713\n",
            "----------------------------------------\n",
            "Epoch 105\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3283, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.45606765114521\n",
            "SCOPE mean: 1.0998757381243298, SCOPE var: 0.200651787142873\n",
            "Total Loss: 6.784400884454634\n",
            "----------------------------------------\n",
            "Epoch 106\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3272, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.412849811224411\n",
            "SCOPE mean: 1.1009260365368048, SCOPE var: 0.20075825863203986\n",
            "Total Loss: 6.74006404813175\n",
            "----------------------------------------\n",
            "Epoch 107\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3261, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.369851310416586\n",
            "SCOPE mean: 1.1018256161939857, SCOPE var: 0.2008464432705449\n",
            "Total Loss: 6.6959203093951345\n",
            "----------------------------------------\n",
            "Epoch 108\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3249, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.327085896462274\n",
            "SCOPE mean: 1.1025849675999304, SCOPE var: 0.20091799841150085\n",
            "Total Loss: 6.651989322090765\n",
            "----------------------------------------\n",
            "Epoch 109\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3237, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.28455150094351\n",
            "SCOPE mean: 1.1032152002027216, SCOPE var: 0.20097455386705929\n",
            "Total Loss: 6.608271398913125\n",
            "----------------------------------------\n",
            "Epoch 110\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3225, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.242254652432902\n",
            "SCOPE mean: 1.1037279717242396, SCOPE var: 0.20101769998883062\n",
            "Total Loss: 6.564775501105544\n",
            "----------------------------------------\n",
            "Epoch 111\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3213, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.2002061185344495\n",
            "SCOPE mean: 1.1041342182775753, SCOPE var: 0.20104934885129774\n",
            "Total Loss: 6.521513136995522\n",
            "----------------------------------------\n",
            "Epoch 112\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3201, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.15839050464187\n",
            "SCOPE mean: 1.104431623082129, SCOPE var: 0.20106942440019349\n",
            "Total Loss: 6.47847226221518\n",
            "----------------------------------------\n",
            "Epoch 113\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3188, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.116798961163151\n",
            "SCOPE mean: 1.1046346845203645, SCOPE var: 0.20107920071246274\n",
            "Total Loss: 6.435647319691035\n",
            "----------------------------------------\n",
            "Epoch 114\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3176, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.075432532652746\n",
            "SCOPE mean: 1.1047574443871018, SCOPE var: 0.2010801897892743\n",
            "Total Loss: 6.393041503437936\n",
            "----------------------------------------\n",
            "Epoch 115\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3164, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.034292312866881\n",
            "SCOPE mean: 1.1048137437744452, SCOPE var: 0.2010738303309582\n",
            "Total Loss: 6.3506579867595\n",
            "----------------------------------------\n",
            "Epoch 116\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3151, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.993379277406009\n",
            "SCOPE mean: 1.1048170472068417, SCOPE var: 0.20106148129622067\n",
            "Total Loss: 6.308499736827586\n",
            "----------------------------------------\n",
            "Epoch 117\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3139, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.952715640649977\n",
            "SCOPE mean: 1.104786220462298, SCOPE var: 0.20104503051733932\n",
            "Total Loss: 6.266588178896578\n",
            "----------------------------------------\n",
            "Epoch 118\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3126, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.912290625297637\n",
            "SCOPE mean: 1.1047376286454953, SCOPE var: 0.201029807104775\n",
            "Total Loss: 6.224918640884495\n",
            "----------------------------------------\n",
            "Epoch 119\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3114, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.872085477130136\n",
            "SCOPE mean: 1.1046764714122663, SCOPE var: 0.20101587206006685\n",
            "Total Loss: 6.183475990120594\n",
            "----------------------------------------\n",
            "Epoch 120\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3102, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.832100346524135\n",
            "SCOPE mean: 1.104612476314347, SCOPE var: 0.20100379554416706\n",
            "Total Loss: 6.142261444060454\n",
            "----------------------------------------\n",
            "Epoch 121\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3089, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.792335068923592\n",
            "SCOPE mean: 1.1045544066112776, SCOPE var: 0.20099409124711326\n",
            "Total Loss: 6.101275799447951\n",
            "----------------------------------------\n",
            "Epoch 122\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3077, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.752789226210186\n",
            "SCOPE mean: 1.1045100191735449, SCOPE var: 0.20098721372772302\n",
            "Total Loss: 6.060519488751376\n",
            "----------------------------------------\n",
            "Epoch 123\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3065, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.71346221688014\n",
            "SCOPE mean: 1.1044860414904512, SCOPE var: 0.20098355688964578\n",
            "Total Loss: 6.019992647533093\n",
            "----------------------------------------\n",
            "Epoch 124\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3053, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.674353328319747\n",
            "SCOPE mean: 1.1044881668035837, SCOPE var: 0.2009834535054589\n",
            "Total Loss: 5.979695185884566\n",
            "----------------------------------------\n",
            "Epoch 125\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3042, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.635461482982602\n",
            "SCOPE mean: 1.104521066118232, SCOPE var: 0.20098717569371777\n",
            "Total Loss: 5.9396265355546385\n",
            "----------------------------------------\n",
            "Epoch 126\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3030, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.596794478753752\n",
            "SCOPE mean: 1.1045879607237354, SCOPE var: 0.2009952808723491\n",
            "Total Loss: 5.899793693665998\n",
            "----------------------------------------\n",
            "Epoch 127\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3018, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.558349124964301\n",
            "SCOPE mean: 1.1047046147843758, SCOPE var: 0.20100866816030397\n",
            "Total Loss: 5.860194897065371\n",
            "----------------------------------------\n",
            "Epoch 128\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.3007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.520120775764449\n",
            "SCOPE mean: 1.1048714814136125, SCOPE var: 0.20102723561334207\n",
            "Total Loss: 5.820826132980497\n",
            "----------------------------------------\n",
            "Epoch 129\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2996, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.48213709412108\n",
            "SCOPE mean: 1.105095946077189, SCOPE var: 0.20105173615732455\n",
            "Total Loss: 5.78171158564886\n",
            "----------------------------------------\n",
            "Epoch 130\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2985, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.4443702654631325\n",
            "SCOPE mean: 1.105362786355192, SCOPE var: 0.2010770033328841\n",
            "Total Loss: 5.74282353589286\n",
            "----------------------------------------\n",
            "Epoch 131\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2973, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.406818956947415\n",
            "SCOPE mean: 1.1056703792815623, SCOPE var: 0.20110329186723802\n",
            "Total Loss: 5.704160963033512\n",
            "----------------------------------------\n",
            "Epoch 132\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2962, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.369482947435884\n",
            "SCOPE mean: 1.106016897425333, SCOPE var: 0.2011308130408731\n",
            "Total Loss: 5.6657237487726375\n",
            "----------------------------------------\n",
            "Epoch 133\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2951, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.332362126933581\n",
            "SCOPE mean: 1.1064001240020502, SCOPE var: 0.20115971586877635\n",
            "Total Loss: 5.627511801287148\n",
            "----------------------------------------\n",
            "Epoch 134\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2941, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.295456470754046\n",
            "SCOPE mean: 1.1068175275290018, SCOPE var: 0.2011900947749441\n",
            "Total Loss: 5.589525040265596\n",
            "----------------------------------------\n",
            "Epoch 135\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2930, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.258766013897264\n",
            "SCOPE mean: 1.107266334494179, SCOPE var: 0.20122199688500894\n",
            "Total Loss: 5.551763381817616\n",
            "----------------------------------------\n",
            "Epoch 136\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2919, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.222290826825699\n",
            "SCOPE mean: 1.107743598985172, SCOPE var: 0.2012554289039059\n",
            "Total Loss: 5.514226724342142\n",
            "----------------------------------------\n",
            "Epoch 137\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2909, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.186030993576365\n",
            "SCOPE mean: 1.1082462683589176, SCOPE var: 0.20129036355175053\n",
            "Total Loss: 5.476914936207268\n",
            "----------------------------------------\n",
            "Epoch 138\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2899, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.149989387088219\n",
            "SCOPE mean: 1.1087816169094613, SCOPE var: 0.20133760530824305\n",
            "Total Loss: 5.439857163291199\n",
            "----------------------------------------\n",
            "Epoch 139\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2889, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.114166491580892\n",
            "SCOPE mean: 1.109350466703935, SCOPE var: 0.2013945467672384\n",
            "Total Loss: 5.403038922156886\n",
            "----------------------------------------\n",
            "Epoch 140\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2879, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.0785606345365855\n",
            "SCOPE mean: 1.1099433776791676, SCOPE var: 0.20145496322706893\n",
            "Total Loss: 5.366444065973691\n",
            "----------------------------------------\n",
            "Epoch 141\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2869, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.043185644276315\n",
            "SCOPE mean: 1.1105667614432184, SCOPE var: 0.2015231057088282\n",
            "Total Loss: 5.3300876279294895\n",
            "----------------------------------------\n",
            "Epoch 142\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2859, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.008021091677669\n",
            "SCOPE mean: 1.1112107387485213, SCOPE var: 0.2015976731388562\n",
            "Total Loss: 5.293951124143137\n",
            "----------------------------------------\n",
            "Epoch 143\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2850, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.973067372807003\n",
            "SCOPE mean: 1.1118713552342423, SCOPE var: 0.2016780053740115\n",
            "Total Loss: 5.258034482538605\n",
            "----------------------------------------\n",
            "Epoch 144\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2840, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.93832477861984\n",
            "SCOPE mean: 1.1125448908757223, SCOPE var: 0.2017634902435863\n",
            "Total Loss: 5.222337537343469\n",
            "----------------------------------------\n",
            "Epoch 145\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2831, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.903793490043727\n",
            "SCOPE mean: 1.113227897124277, SCOPE var: 0.2018535612473559\n",
            "Total Loss: 5.186860028601678\n",
            "----------------------------------------\n",
            "Epoch 146\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2821, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.869485857667595\n",
            "SCOPE mean: 1.1139206918112126, SCOPE var: 0.20194811691946066\n",
            "Total Loss: 5.151612924792416\n",
            "----------------------------------------\n",
            "Epoch 147\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2815, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.83542226294176\n",
            "SCOPE mean: 1.114672798495732, SCOPE var: 0.20209391685605343\n",
            "Total Loss: 5.116913115205087\n",
            "----------------------------------------\n",
            "Epoch 148\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2809, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.801573403727137\n",
            "SCOPE mean: 1.1154348248413888, SCOPE var: 0.20224306130566436\n",
            "Total Loss: 5.082437249007928\n",
            "----------------------------------------\n",
            "Epoch 149\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2802, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.767938509616161\n",
            "SCOPE mean: 1.1162037898308397, SCOPE var: 0.2023951662101242\n",
            "Total Loss: 5.048183808865034\n",
            "----------------------------------------\n",
            "Epoch 150\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2796, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.734516802681009\n",
            "SCOPE mean: 1.1169771583234707, SCOPE var: 0.20254988114314432\n",
            "Total Loss: 5.01415133202047\n",
            "----------------------------------------\n",
            "Epoch 151\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2790, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.701307504510653\n",
            "SCOPE mean: 1.1177528238974705, SCOPE var: 0.20270688668806444\n",
            "Total Loss: 4.980338413038914\n",
            "----------------------------------------\n",
            "Epoch 152\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2784, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.668313711113211\n",
            "SCOPE mean: 1.1185301726204162, SCOPE var: 0.20286600397785315\n",
            "Total Loss: 4.9467471311011035\n",
            "----------------------------------------\n",
            "Epoch 153\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2778, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.63553459545787\n",
            "SCOPE mean: 1.119313762841834, SCOPE var: 0.20303098266171407\n",
            "Total Loss: 4.9133788557541775\n",
            "----------------------------------------\n",
            "Epoch 154\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2773, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.602961059730832\n",
            "SCOPE mean: 1.1200994814770788, SCOPE var: 0.203200915196788\n",
            "Total Loss: 4.880224653660001\n",
            "----------------------------------------\n",
            "Epoch 155\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2767, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.5705928611001445\n",
            "SCOPE mean: 1.120885993940135, SCOPE var: 0.20337521127816488\n",
            "Total Loss: 4.847283500593121\n",
            "----------------------------------------\n",
            "Epoch 156\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2761, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.538432128413362\n",
            "SCOPE mean: 1.1216729162593546, SCOPE var: 0.20355340574773528\n",
            "Total Loss: 4.81455653509592\n",
            "----------------------------------------\n",
            "Epoch 157\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2755, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.506499052229295\n",
            "SCOPE mean: 1.1224303950063403, SCOPE var: 0.2037267800863689\n",
            "Total Loss: 4.782044842593457\n",
            "----------------------------------------\n",
            "Epoch 158\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2750, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.474777893892464\n",
            "SCOPE mean: 1.1231715531577355, SCOPE var: 0.2038977783872829\n",
            "Total Loss: 4.74974195192559\n",
            "----------------------------------------\n",
            "Epoch 159\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2744, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.4432624499353555\n",
            "SCOPE mean: 1.1239072150005487, SCOPE var: 0.20406823424162235\n",
            "Total Loss: 4.7176476341795395\n",
            "----------------------------------------\n",
            "Epoch 160\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2738, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.41195252479766\n",
            "SCOPE mean: 1.1246437986147242, SCOPE var: 0.20424206142300608\n",
            "Total Loss: 4.685764062349121\n",
            "----------------------------------------\n",
            "Epoch 161\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2732, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.380847538563322\n",
            "SCOPE mean: 1.1253812759542992, SCOPE var: 0.20441882968034522\n",
            "Total Loss: 4.654090170705394\n",
            "----------------------------------------\n",
            "Epoch 162\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2727, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.349945636034378\n",
            "SCOPE mean: 1.1261136029585834, SCOPE var: 0.20459421817711454\n",
            "Total Loss: 4.622621225563935\n",
            "----------------------------------------\n",
            "Epoch 163\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2721, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.319245893818181\n",
            "SCOPE mean: 1.1268414662769182, SCOPE var: 0.204768268416526\n",
            "Total Loss: 4.591356226104522\n",
            "----------------------------------------\n",
            "Epoch 164\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2715, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.288754179883229\n",
            "SCOPE mean: 1.127567583358865, SCOPE var: 0.20494121904279283\n",
            "Total Loss: 4.5603001883699\n",
            "----------------------------------------\n",
            "Epoch 165\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2710, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.258457457130122\n",
            "SCOPE mean: 1.1282955269114028, SCOPE var: 0.20511664961221374\n",
            "Total Loss: 4.529443656059779\n",
            "----------------------------------------\n",
            "Epoch 166\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2704, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.228356387450716\n",
            "SCOPE mean: 1.1290255480710978, SCOPE var: 0.20529399044189858\n",
            "Total Loss: 4.498786635612044\n",
            "----------------------------------------\n",
            "Epoch 167\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2699, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.198451412726851\n",
            "SCOPE mean: 1.1297577397790253, SCOPE var: 0.20547292368413536\n",
            "Total Loss: 4.468329214109752\n",
            "----------------------------------------\n",
            "Epoch 168\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2693, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.1687512765976\n",
            "SCOPE mean: 1.1304948472259446, SCOPE var: 0.2056534380659206\n",
            "Total Loss: 4.438078736569779\n",
            "----------------------------------------\n",
            "Epoch 169\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2688, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.139247849792232\n",
            "SCOPE mean: 1.131229184566926, SCOPE var: 0.20583126537152424\n",
            "Total Loss: 4.408025122627374\n",
            "----------------------------------------\n",
            "Epoch 170\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2682, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.10994016787377\n",
            "SCOPE mean: 1.1319611659995934, SCOPE var: 0.2060065415962493\n",
            "Total Loss: 4.378167449914635\n",
            "----------------------------------------\n",
            "Epoch 171\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2677, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.080827503208517\n",
            "SCOPE mean: 1.1326912492895753, SCOPE var: 0.2061793937058268\n",
            "Total Loss: 4.348504997996953\n",
            "----------------------------------------\n",
            "Epoch 172\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2671, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.051910378470626\n",
            "SCOPE mean: 1.1334202201601908, SCOPE var: 0.2063499723703911\n",
            "Total Loss: 4.319038144499074\n",
            "----------------------------------------\n",
            "Epoch 173\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2666, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.023190114662836\n",
            "SCOPE mean: 1.134154836091643, SCOPE var: 0.2065221659183276\n",
            "Total Loss: 4.289770402397629\n",
            "----------------------------------------\n",
            "Epoch 174\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2660, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.9946567411309077\n",
            "SCOPE mean: 1.1348934186630169, SCOPE var: 0.20669543636590373\n",
            "Total Loss: 4.260692611561701\n",
            "----------------------------------------\n",
            "Epoch 175\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2655, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.966311170657606\n",
            "SCOPE mean: 1.1356347813890344, SCOPE var: 0.20686951973975073\n",
            "Total Loss: 4.231805134058344\n",
            "----------------------------------------\n",
            "Epoch 176\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2650, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.938158761887912\n",
            "SCOPE mean: 1.1363749647266332, SCOPE var: 0.2070407023573289\n",
            "Total Loss: 4.203109885763621\n",
            "----------------------------------------\n",
            "Epoch 177\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2644, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.910198863223295\n",
            "SCOPE mean: 1.137113768885799, SCOPE var: 0.20720911924600835\n",
            "Total Loss: 4.174606288585067\n",
            "----------------------------------------\n",
            "Epoch 178\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2639, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.882423948875848\n",
            "SCOPE mean: 1.1378542357217534, SCOPE var: 0.2073783287640925\n",
            "Total Loss: 4.14628997446004\n",
            "----------------------------------------\n",
            "Epoch 179\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2633, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.854835015489298\n",
            "SCOPE mean: 1.1385959173304991, SCOPE var: 0.20754809257202203\n",
            "Total Loss: 4.118161595281234\n",
            "----------------------------------------\n",
            "Epoch 180\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2628, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.8274359548995585\n",
            "SCOPE mean: 1.1393343582211137, SCOPE var: 0.20771472411873282\n",
            "Total Loss: 4.090221873419109\n",
            "----------------------------------------\n",
            "Epoch 181\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2622, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.8002256043202323\n",
            "SCOPE mean: 1.140069210817642, SCOPE var: 0.20787837414425642\n",
            "Total Loss: 4.062469737214341\n",
            "----------------------------------------\n",
            "Epoch 182\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2617, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.773197815822482\n",
            "SCOPE mean: 1.1408038023933122, SCOPE var: 0.20804260756445622\n",
            "Total Loss: 4.034901982746154\n",
            "----------------------------------------\n",
            "Epoch 183\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2612, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.74635315659041\n",
            "SCOPE mean: 1.141537700429091, SCOPE var: 0.20820722395249266\n",
            "Total Loss: 4.007518791421698\n",
            "----------------------------------------\n",
            "Epoch 184\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2606, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.7196941301378774\n",
            "SCOPE mean: 1.1422659223070866, SCOPE var: 0.20836854990787393\n",
            "Total Loss: 3.9803198235545802\n",
            "----------------------------------------\n",
            "Epoch 185\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2601, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.693214201562163\n",
            "SCOPE mean: 1.142990664083007, SCOPE var: 0.20852759460517956\n",
            "Total Loss: 3.9532995477922714\n",
            "----------------------------------------\n",
            "Epoch 186\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2595, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.666898251450782\n",
            "SCOPE mean: 1.1437230339541562, SCOPE var: 0.2086896261893768\n",
            "Total Loss: 3.926447019813606\n",
            "----------------------------------------\n",
            "Epoch 187\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2590, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.640762438864025\n",
            "SCOPE mean: 1.144454241178483, SCOPE var: 0.2088518104519573\n",
            "Total Loss: 3.899775428143393\n",
            "----------------------------------------\n",
            "Epoch 188\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2585, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.614805606392665\n",
            "SCOPE mean: 1.1451780788445565, SCOPE var: 0.20901042003435288\n",
            "Total Loss: 3.8732812917757586\n",
            "----------------------------------------\n",
            "Epoch 189\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2579, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.5890264199517636\n",
            "SCOPE mean: 1.145894039645412, SCOPE var: 0.20916561828193156\n",
            "Total Loss: 3.8469634317241264\n",
            "----------------------------------------\n",
            "Epoch 190\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2574, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.563429250015055\n",
            "SCOPE mean: 1.1466034754775596, SCOPE var: 0.20931773479754748\n",
            "Total Loss: 3.8208257053864516\n",
            "----------------------------------------\n",
            "Epoch 191\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2569, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.5380061707195227\n",
            "SCOPE mean: 1.1473090361591534, SCOPE var: 0.20947016087763565\n",
            "Total Loss: 3.794863234882111\n",
            "----------------------------------------\n",
            "Epoch 192\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2563, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.512755528710862\n",
            "SCOPE mean: 1.1480097412482093, SCOPE var: 0.2096226398141542\n",
            "Total Loss: 3.7690742850605132\n",
            "----------------------------------------\n",
            "Epoch 193\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2558, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.487653254011981\n",
            "SCOPE mean: 1.148771015639352, SCOPE var: 0.20975178259859825\n",
            "Total Loss: 3.7434193595848884\n",
            "----------------------------------------\n",
            "Epoch 194\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2552, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.4627258168321298\n",
            "SCOPE mean: 1.1495327961429498, SCOPE var: 0.20987387921413322\n",
            "Total Loss: 3.717934877637011\n",
            "----------------------------------------\n",
            "Epoch 195\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2546, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.4379677710025187\n",
            "SCOPE mean: 1.1502932217516633, SCOPE var: 0.20998920838333457\n",
            "Total Loss: 3.692616292990217\n",
            "----------------------------------------\n",
            "Epoch 196\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2541, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.413381976925231\n",
            "SCOPE mean: 1.1510529800197509, SCOPE var: 0.21009804805687146\n",
            "Total Loss: 3.667466176239875\n",
            "----------------------------------------\n",
            "Epoch 197\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2535, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.389039737896964\n",
            "SCOPE mean: 1.1517735488098708, SCOPE var: 0.21019028010792223\n",
            "Total Loss: 3.6425576769073356\n",
            "----------------------------------------\n",
            "Epoch 198\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2530, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.3648745834011637\n",
            "SCOPE mean: 1.1524751434864433, SCOPE var: 0.21028590922281176\n",
            "Total Loss: 3.6178292684234825\n",
            "----------------------------------------\n",
            "Epoch 199\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2524, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.3408452789143954\n",
            "SCOPE mean: 1.1532756552454642, SCOPE var: 0.21042354403293553\n",
            "Total Loss: 3.593295196795889\n",
            "----------------------------------------\n",
            "Epoch 200\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2518, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.317022225771064\n",
            "SCOPE mean: 1.1537945625497266, SCOPE var: 0.21051677573913996\n",
            "Total Loss: 3.56886529997423\n",
            "----------------------------------------\n",
            "Epoch 201\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2513, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.2933280345747384\n",
            "SCOPE mean: 1.1544200114921965, SCOPE var: 0.21065201535795536\n",
            "Total Loss: 3.5446242723365797\n",
            "----------------------------------------\n",
            "Epoch 202\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2508, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.2697971925434492\n",
            "SCOPE mean: 1.1550392715743156, SCOPE var: 0.21078962171447066\n",
            "Total Loss: 3.5205477384718042\n",
            "----------------------------------------\n",
            "Epoch 203\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2502, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.2464304160469735\n",
            "SCOPE mean: 1.155647690665287, SCOPE var: 0.21092614032292153\n",
            "Total Loss: 3.4966342434168025\n",
            "----------------------------------------\n",
            "Epoch 204\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2497, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.2232252088785036\n",
            "SCOPE mean: 1.1562450658231496, SCOPE var: 0.21106170486988432\n",
            "Total Loss: 3.4728817075352714\n",
            "----------------------------------------\n",
            "Epoch 205\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2491, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.2001822780294593\n",
            "SCOPE mean: 1.1568322812589626, SCOPE var: 0.21119653480493308\n",
            "Total Loss: 3.449290869923398\n",
            "----------------------------------------\n",
            "Epoch 206\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2486, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.1772986491000195\n",
            "SCOPE mean: 1.1574138923612831, SCOPE var: 0.2113339978539371\n",
            "Total Loss: 3.4258611441310283\n",
            "----------------------------------------\n",
            "Epoch 207\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2480, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.1545728223565486\n",
            "SCOPE mean: 1.1579895577650883, SCOPE var: 0.211473852524908\n",
            "Total Loss: 3.4025910680572866\n",
            "----------------------------------------\n",
            "Epoch 208\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2475, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.132006830685509\n",
            "SCOPE mean: 1.1585553186094655, SCOPE var: 0.21161272495107483\n",
            "Total Loss: 3.379480391796595\n",
            "----------------------------------------\n",
            "Epoch 209\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2469, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.1096056182464853\n",
            "SCOPE mean: 1.1591069827460796, SCOPE var: 0.2117493607800165\n",
            "Total Loss: 3.3565341309129013\n",
            "----------------------------------------\n",
            "Epoch 210\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2464, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.0873924207284715\n",
            "SCOPE mean: 1.15965135584759, SCOPE var: 0.21187248381745996\n",
            "Total Loss: 3.3337718977626443\n",
            "----------------------------------------\n",
            "Epoch 211\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2458, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.065328969890801\n",
            "SCOPE mean: 1.1602055210672695, SCOPE var: 0.21198664854607233\n",
            "Total Loss: 3.311155258159072\n",
            "----------------------------------------\n",
            "Epoch 212\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2453, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.043414127749103\n",
            "SCOPE mean: 1.1607731271900565, SCOPE var: 0.21209572440716895\n",
            "Total Loss: 3.288685563341138\n",
            "----------------------------------------\n",
            "Epoch 213\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2447, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.0216484444043235\n",
            "SCOPE mean: 1.1613485052717454, SCOPE var: 0.2121967980073323\n",
            "Total Loss: 3.266361655408826\n",
            "----------------------------------------\n",
            "Epoch 214\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2442, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.0000610077306327\n",
            "SCOPE mean: 1.1619150589835394, SCOPE var: 0.21228516848802523\n",
            "Total Loss: 3.2442115829136786\n",
            "----------------------------------------\n",
            "Epoch 215\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2436, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.9786290454805227\n",
            "SCOPE mean: 1.162469741442934, SCOPE var: 0.2123779238960878\n",
            "Total Loss: 3.222220766505107\n",
            "----------------------------------------\n",
            "Epoch 216\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2430, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.9573436551909866\n",
            "SCOPE mean: 1.1630194125863595, SCOPE var: 0.21247676527530898\n",
            "Total Loss: 3.200380395007142\n",
            "----------------------------------------\n",
            "Epoch 217\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2425, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.9362053581774483\n",
            "SCOPE mean: 1.1635599755292005, SCOPE var: 0.21257826901752225\n",
            "Total Loss: 3.1786889088416985\n",
            "----------------------------------------\n",
            "Epoch 218\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2419, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.915211991677271\n",
            "SCOPE mean: 1.1640915885420897, SCOPE var: 0.2126824104595132\n",
            "Total Loss: 3.157144400000489\n",
            "----------------------------------------\n",
            "Epoch 219\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2414, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.8943636730805213\n",
            "SCOPE mean: 1.1646151284172728, SCOPE var: 0.21278920618833733\n",
            "Total Loss: 3.135746969945258\n",
            "----------------------------------------\n",
            "Epoch 220\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2408, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.8736581804508563\n",
            "SCOPE mean: 1.1651352599931735, SCOPE var: 0.2129016848033612\n",
            "Total Loss: 3.114496410080915\n",
            "----------------------------------------\n",
            "Epoch 221\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2403, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.853102926449275\n",
            "SCOPE mean: 1.1656478209536016, SCOPE var: 0.21301804015003736\n",
            "Total Loss: 3.0933994840348813\n",
            "----------------------------------------\n",
            "Epoch 222\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2398, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.832683364874369\n",
            "SCOPE mean: 1.1662645707465873, SCOPE var: 0.2131559967908228\n",
            "Total Loss: 3.0724863156864233\n",
            "----------------------------------------\n",
            "Epoch 223\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2392, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.8124822593918677\n",
            "SCOPE mean: 1.166617692010085, SCOPE var: 0.21323625555815884\n",
            "Total Loss: 3.0516946073193316\n",
            "----------------------------------------\n",
            "Epoch 224\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2387, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.7923894026447553\n",
            "SCOPE mean: 1.167091326237989, SCOPE var: 0.21334401027589966\n",
            "Total Loss: 3.0310611329874964\n",
            "----------------------------------------\n",
            "Epoch 225\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2381, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.77243222754193\n",
            "SCOPE mean: 1.167584664490485, SCOPE var: 0.21344659347067402\n",
            "Total Loss: 3.0105624382477947\n",
            "----------------------------------------\n",
            "Epoch 226\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2376, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.7526115120053807\n",
            "SCOPE mean: 1.168096445120431, SCOPE var: 0.21354435929807986\n",
            "Total Loss: 2.990199426065592\n",
            "----------------------------------------\n",
            "Epoch 227\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2370, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.7329270288603653\n",
            "SCOPE mean: 1.1686205129700897, SCOPE var: 0.21363455367285134\n",
            "Total Loss: 2.969970392879759\n",
            "----------------------------------------\n",
            "Epoch 228\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2365, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.713366994097749\n",
            "SCOPE mean: 1.1691976111351083, SCOPE var: 0.21373248494160127\n",
            "Total Loss: 2.949885369187505\n",
            "----------------------------------------\n",
            "Epoch 229\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2360, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.693989099174953\n",
            "SCOPE mean: 1.169632798486971, SCOPE var: 0.21381625807072527\n",
            "Total Loss: 2.92994914264866\n",
            "----------------------------------------\n",
            "Epoch 230\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2354, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.6747420848069243\n",
            "SCOPE mean: 1.1701032494172598, SCOPE var: 0.21391752832796812\n",
            "Total Loss: 2.9101673228516685\n",
            "----------------------------------------\n",
            "Epoch 231\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2349, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.6556374050625866\n",
            "SCOPE mean: 1.1705823699853555, SCOPE var: 0.2140115674661515\n",
            "Total Loss: 2.8905268932620976\n",
            "----------------------------------------\n",
            "Epoch 232\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2344, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.636658723890971\n",
            "SCOPE mean: 1.171059665783553, SCOPE var: 0.21411278030677197\n",
            "Total Loss: 2.871017780137674\n",
            "----------------------------------------\n",
            "Epoch 233\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2338, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.617813252033123\n",
            "SCOPE mean: 1.1715332228993185, SCOPE var: 0.21421984093443164\n",
            "Total Loss: 2.8516463075858276\n",
            "----------------------------------------\n",
            "Epoch 234\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2333, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.599109126453743\n",
            "SCOPE mean: 1.1720160837831972, SCOPE var: 0.21431717963326724\n",
            "Total Loss: 2.8324129887159755\n",
            "----------------------------------------\n",
            "Epoch 235\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2328, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.58054928616076\n",
            "SCOPE mean: 1.1725019321386656, SCOPE var: 0.21440404271507235\n",
            "Total Loss: 2.8133210225699976\n",
            "----------------------------------------\n",
            "Epoch 236\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2322, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.562116070008989\n",
            "SCOPE mean: 1.1729800463575972, SCOPE var: 0.21449590184465675\n",
            "Total Loss: 2.7943594258061184\n",
            "----------------------------------------\n",
            "Epoch 237\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2317, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.543806693067731\n",
            "SCOPE mean: 1.1734523048482253, SCOPE var: 0.2145929505194127\n",
            "Total Loss: 2.7755254886689595\n",
            "----------------------------------------\n",
            "Epoch 238\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2312, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.525637931139004\n",
            "SCOPE mean: 1.17390977361975, SCOPE var: 0.2146917115652299\n",
            "Total Loss: 2.75683452688081\n",
            "----------------------------------------\n",
            "Epoch 239\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2307, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.50760083657086\n",
            "SCOPE mean: 1.1743816683470771, SCOPE var: 0.21478429767093837\n",
            "Total Loss: 2.7382745212489445\n",
            "----------------------------------------\n",
            "Epoch 240\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2302, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.4896854877054597\n",
            "SCOPE mean: 1.174870336988931, SCOPE var: 0.21487257080909555\n",
            "Total Loss: 2.719836520984692\n",
            "----------------------------------------\n",
            "Epoch 241\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2296, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.471913126186869\n",
            "SCOPE mean: 1.1753612042218027, SCOPE var: 0.21495080031532557\n",
            "Total Loss: 2.701538493609956\n",
            "----------------------------------------\n",
            "Epoch 242\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2291, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.454268002157826\n",
            "SCOPE mean: 1.1758380015164116, SCOPE var: 0.21503407814207975\n",
            "Total Loss: 2.683371573205483\n",
            "----------------------------------------\n",
            "Epoch 243\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2286, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.436708492912662\n",
            "SCOPE mean: 1.1764270865715476, SCOPE var: 0.21516758164972496\n",
            "Total Loss: 2.665355020716759\n",
            "----------------------------------------\n",
            "Epoch 244\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2281, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.4193486809534748\n",
            "SCOPE mean: 1.1767101937967956, SCOPE var: 0.2152466218328613\n",
            "Total Loss: 2.647434627596739\n",
            "----------------------------------------\n",
            "Epoch 245\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2276, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.402094689973803\n",
            "SCOPE mean: 1.1771140554733917, SCOPE var: 0.21535434523321523\n",
            "Total Loss: 2.6296752004610795\n",
            "----------------------------------------\n",
            "Epoch 246\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2271, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.384961833117279\n",
            "SCOPE mean: 1.1775341816948677, SCOPE var: 0.2154545639580617\n",
            "Total Loss: 2.612034897022745\n",
            "----------------------------------------\n",
            "Epoch 247\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2266, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.3679452208625107\n",
            "SCOPE mean: 1.177972041052618, SCOPE var: 0.21555060891357616\n",
            "Total Loss: 2.5945111891631103\n",
            "----------------------------------------\n",
            "Epoch 248\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2261, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.3510466838077186\n",
            "SCOPE mean: 1.178426623375167, SCOPE var: 0.2156428527192517\n",
            "Total Loss: 2.5771058184088798\n",
            "----------------------------------------\n",
            "Epoch 249\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2256, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.3342677288113776\n",
            "SCOPE mean: 1.178892558745114, SCOPE var: 0.21572880959104104\n",
            "Total Loss: 2.559818754253733\n",
            "----------------------------------------\n",
            "Epoch 250\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2250, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.317607029368006\n",
            "SCOPE mean: 1.1793682336556857, SCOPE var: 0.215808997539908\n",
            "Total Loss: 2.542649073586793\n",
            "----------------------------------------\n",
            "Epoch 251\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2245, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.3010645315758387\n",
            "SCOPE mean: 1.179852521997364, SCOPE var: 0.2158839356172619\n",
            "Total Loss: 2.525596951830786\n",
            "----------------------------------------\n",
            "Epoch 252\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2240, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.2846563586084954\n",
            "SCOPE mean: 1.1803333706688182, SCOPE var: 0.2159505291841702\n",
            "Total Loss: 2.5086772363524075\n",
            "----------------------------------------\n",
            "Epoch 253\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2235, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.268390922371218\n",
            "SCOPE mean: 1.18078606875865, SCOPE var: 0.21601924142434686\n",
            "Total Loss: 2.491902356663382\n",
            "----------------------------------------\n",
            "Epoch 254\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2231, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.2521792708827997\n",
            "SCOPE mean: 1.1814110754005738, SCOPE var: 0.21616142226612545\n",
            "Total Loss: 2.4752775212105895\n",
            "----------------------------------------\n",
            "Epoch 255\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2225, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.236138319839735\n",
            "SCOPE mean: 1.1816434319430054, SCOPE var: 0.21621944104423846\n",
            "Total Loss: 2.4586648320421114\n",
            "----------------------------------------\n",
            "Epoch 256\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2220, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.220205659722677\n",
            "SCOPE mean: 1.1820226599200527, SCOPE var: 0.21633571771098958\n",
            "Total Loss: 2.4422494548502995\n",
            "----------------------------------------\n",
            "Epoch 257\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2216, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.204396638588146\n",
            "SCOPE mean: 1.1824100364516088, SCOPE var: 0.21644199421625437\n",
            "Total Loss: 2.4259547044154175\n",
            "----------------------------------------\n",
            "Epoch 258\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2211, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.1886985044598064\n",
            "SCOPE mean: 1.182811073675833, SCOPE var: 0.216541279803437\n",
            "Total Loss: 2.4097693845162453\n",
            "----------------------------------------\n",
            "Epoch 259\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2206, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.173110814546726\n",
            "SCOPE mean: 1.1832245625194568, SCOPE var: 0.21663420754285412\n",
            "Total Loss: 2.3936933823114197\n",
            "----------------------------------------\n",
            "Epoch 260\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2201, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.1576332371986418\n",
            "SCOPE mean: 1.183649345386427, SCOPE var: 0.2167213597741553\n",
            "Total Loss: 2.3777266532708174\n",
            "----------------------------------------\n",
            "Epoch 261\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2196, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.1422631274316704\n",
            "SCOPE mean: 1.184084339460824, SCOPE var: 0.21680327299230556\n",
            "Total Loss: 2.361866805251096\n",
            "----------------------------------------\n",
            "Epoch 262\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2191, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.127000916873452\n",
            "SCOPE mean: 1.1845286984316787, SCOPE var: 0.21688018588133676\n",
            "Total Loss: 2.346114236015474\n",
            "----------------------------------------\n",
            "Epoch 263\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2186, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.1118504526981585\n",
            "SCOPE mean: 1.1849822608643215, SCOPE var: 0.21695267172480004\n",
            "Total Loss: 2.3304727021655633\n",
            "----------------------------------------\n",
            "Epoch 264\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2181, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.0968094041704632\n",
            "SCOPE mean: 1.1854470754013318, SCOPE var: 0.2170237590177006\n",
            "Total Loss: 2.3149416905010045\n",
            "----------------------------------------\n",
            "Epoch 265\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2176, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.0819177076543878\n",
            "SCOPE mean: 1.1858902302921048, SCOPE var: 0.21708354734075816\n",
            "Total Loss: 2.2995569058738403\n",
            "----------------------------------------\n",
            "Epoch 266\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2172, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.067121019324387\n",
            "SCOPE mean: 1.1863263972195432, SCOPE var: 0.21715469315595223\n",
            "Total Loss: 2.2842739392771523\n",
            "----------------------------------------\n",
            "Epoch 267\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2167, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.0524198132813734\n",
            "SCOPE mean: 1.1867600004406846, SCOPE var: 0.21723720361125462\n",
            "Total Loss: 2.2690926867385657\n",
            "----------------------------------------\n",
            "Epoch 268\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2162, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.0377874004918928\n",
            "SCOPE mean: 1.1872861374928758, SCOPE var: 0.2173624945935211\n",
            "Total Loss: 2.25403452737601\n",
            "----------------------------------------\n",
            "Epoch 269\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2157, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.023276263031043\n",
            "SCOPE mean: 1.1875717699261235, SCOPE var: 0.21745326529548445\n",
            "Total Loss: 2.23901474573168\n",
            "----------------------------------------\n",
            "Epoch 270\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2153, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.0089013836009926\n",
            "SCOPE mean: 1.1879085197150518, SCOPE var: 0.21756710725574382\n",
            "Total Loss: 2.2241765707264296\n",
            "----------------------------------------\n",
            "Epoch 271\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2148, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.9946347888007794\n",
            "SCOPE mean: 1.1882557298326732, SCOPE var: 0.21767212463925245\n",
            "Total Loss: 2.2094442525743196\n",
            "----------------------------------------\n",
            "Epoch 272\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2143, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.980469554514992\n",
            "SCOPE mean: 1.1886169217225027, SCOPE var: 0.2177705171223545\n",
            "Total Loss: 2.194811918619519\n",
            "----------------------------------------\n",
            "Epoch 273\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2139, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.9664061755860704\n",
            "SCOPE mean: 1.1889950656177375, SCOPE var: 0.21786554409991174\n",
            "Total Loss: 2.1802815911732147\n",
            "----------------------------------------\n",
            "Epoch 274\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2134, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.9524403234842658\n",
            "SCOPE mean: 1.189387174788388, SCOPE var: 0.21795735383136833\n",
            "Total Loss: 2.1658494912391837\n",
            "----------------------------------------\n",
            "Epoch 275\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2129, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.9385760037214845\n",
            "SCOPE mean: 1.1897895175355042, SCOPE var: 0.21804380002378085\n",
            "Total Loss: 2.151517919798388\n",
            "----------------------------------------\n",
            "Epoch 276\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2125, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.9248106299191974\n",
            "SCOPE mean: 1.1902039257856225, SCOPE var: 0.2181278946287826\n",
            "Total Loss: 2.137286068179768\n",
            "----------------------------------------\n",
            "Epoch 277\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2120, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.9111446485009325\n",
            "SCOPE mean: 1.1906254699900827, SCOPE var: 0.21820730386727694\n",
            "Total Loss: 2.123153043506318\n",
            "----------------------------------------\n",
            "Epoch 278\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2115, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.8975774898988842\n",
            "SCOPE mean: 1.1910530651461393, SCOPE var: 0.21828247658415625\n",
            "Total Loss: 2.1091184823399214\n",
            "----------------------------------------\n",
            "Epoch 279\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2111, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.8841110812633208\n",
            "SCOPE mean: 1.1914865981342417, SCOPE var: 0.21835391644491617\n",
            "Total Loss: 2.0951842171343693\n",
            "----------------------------------------\n",
            "Epoch 280\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2106, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.8707411793365323\n",
            "SCOPE mean: 1.1919274797734265, SCOPE var: 0.21842440297463336\n",
            "Total Loss: 2.081347840483918\n",
            "----------------------------------------\n",
            "Epoch 281\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2101, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.8574675382188988\n",
            "SCOPE mean: 1.192374475598149, SCOPE var: 0.21849402332849507\n",
            "Total Loss: 2.067609057850799\n",
            "----------------------------------------\n",
            "Epoch 282\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2097, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.8442959059188282\n",
            "SCOPE mean: 1.1928225766918819, SCOPE var: 0.21855997710454594\n",
            "Total Loss: 2.0539716172998834\n",
            "----------------------------------------\n",
            "Epoch 283\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2092, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.831248028493613\n",
            "SCOPE mean: 1.193230992165913, SCOPE var: 0.21862573506186278\n",
            "Total Loss: 2.040458181145637\n",
            "----------------------------------------\n",
            "Epoch 284\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2088, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.818246024073262\n",
            "SCOPE mean: 1.1937760739078296, SCOPE var: 0.21875235277383842\n",
            "Total Loss: 2.0270681157474324\n",
            "----------------------------------------\n",
            "Epoch 285\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2083, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.8053862998029635\n",
            "SCOPE mean: 1.193981535459756, SCOPE var: 0.21881192366930316\n",
            "Total Loss: 2.0136950323041365\n",
            "----------------------------------------\n",
            "Epoch 286\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2079, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7926137007984508\n",
            "SCOPE mean: 1.1943143460117798, SCOPE var: 0.21890822621533676\n",
            "Total Loss: 2.0004747487759005\n",
            "----------------------------------------\n",
            "Epoch 287\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2074, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7799348555950254\n",
            "SCOPE mean: 1.1946532745295924, SCOPE var: 0.21899779284370652\n",
            "Total Loss: 1.9873478532821025\n",
            "----------------------------------------\n",
            "Epoch 288\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2070, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.767348574654072\n",
            "SCOPE mean: 1.1950028324571533, SCOPE var: 0.21908308535741494\n",
            "Total Loss: 1.974313212411141\n",
            "----------------------------------------\n",
            "Epoch 289\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2065, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7548540171625506\n",
            "SCOPE mean: 1.1953615810302733, SCOPE var: 0.2191640928222963\n",
            "Total Loss: 1.9613694051518198\n",
            "----------------------------------------\n",
            "Epoch 290\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2061, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7424524374317842\n",
            "SCOPE mean: 1.195729203611683, SCOPE var: 0.2192413194566901\n",
            "Total Loss: 1.9485177331417667\n",
            "----------------------------------------\n",
            "Epoch 291\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2056, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7301401241518455\n",
            "SCOPE mean: 1.1961071952215314, SCOPE var: 0.21931750666172992\n",
            "Total Loss: 1.9357562415586536\n",
            "----------------------------------------\n",
            "Epoch 292\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2052, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7179164354041276\n",
            "SCOPE mean: 1.1964941510824691, SCOPE var: 0.21939275266265088\n",
            "Total Loss: 1.9230843485447533\n",
            "----------------------------------------\n",
            "Epoch 293\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2047, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7057844500874346\n",
            "SCOPE mean: 1.1968864539937352, SCOPE var: 0.21946483823696863\n",
            "Total Loss: 1.9105035918501019\n",
            "----------------------------------------\n",
            "Epoch 294\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2043, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6937419807492995\n",
            "SCOPE mean: 1.1972826092721274, SCOPE var: 0.21953404482011377\n",
            "Total Loss: 1.8980121245166965\n",
            "----------------------------------------\n",
            "Epoch 295\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2038, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.681798245698063\n",
            "SCOPE mean: 1.1976744065179605, SCOPE var: 0.2195981977903916\n",
            "Total Loss: 1.8856178348003814\n",
            "----------------------------------------\n",
            "Epoch 296\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2034, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6699377623033822\n",
            "SCOPE mean: 1.1980499989428561, SCOPE var: 0.21966992744632416\n",
            "Total Loss: 1.8733109066740852\n",
            "----------------------------------------\n",
            "Epoch 297\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2029, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6581509430462429\n",
            "SCOPE mean: 1.1984203459946396, SCOPE var: 0.21975016556439894\n",
            "Total Loss: 1.8610822534116258\n",
            "----------------------------------------\n",
            "Epoch 298\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2025, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.646445324099372\n",
            "SCOPE mean: 1.1987833657682014, SCOPE var: 0.219838511975887\n",
            "Total Loss: 1.8489392125439923\n",
            "----------------------------------------\n",
            "Epoch 299\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2021, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6348389468791613\n",
            "SCOPE mean: 1.1991422847550663, SCOPE var: 0.21991939531136265\n",
            "Total Loss: 1.8368927961686792\n",
            "----------------------------------------\n",
            "Epoch 300\n",
            "IS mean: 1.3770242730685123,IS variance: 0.19509742356123738\n",
            "SCOPE Var loss:  tensor(0.2016, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6233176218280967\n",
            "SCOPE mean: 1.1995065119692876, SCOPE var: 0.21999663604699446\n",
            "Total Loss: 1.824930910277112\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the varying trajectory lengths\n",
        "num_trajectories = [200, 400, 600, 800, 1000]\n",
        "# Define hidden_dims\n",
        "hidden_dimens = [[8],[8,8],[32]]\n",
        "# Define trajectory lengths\n",
        "trajectory_length = [30, 50, 70, 100]\n",
        "\n",
        "for num in num_trajectories:\n",
        "  # Modify the base parameters for each experiment\n",
        "  # params = base_params_test.copy()  # Make a copy to avoid modifying the base parameters\n",
        "  params[\"num_trajectories\"] = num  # Update the number of trajectories\n",
        "\n",
        "  for dims in hidden_dimens:\n",
        "    # params = base_params_test.copy()  # Make a copy to avoid modifying the base parameters\n",
        "    params[\"hidden_dims\"] = dims\n",
        "\n",
        "    for len in trajectory_length:\n",
        "      params[\"max_length\"] = len\n",
        "\n",
        "      # Create an instance of SCOPE_experiment with modified parameters\n",
        "      test_experiment = SCOPE_experiment(**params)\n",
        "      # test_experiment.run_experiment()\n",
        "      test_load = existing_experiments(test_experiment)\n",
        "      # test_load.plot_metrics_save(save = True)\n",
        "      print(test_load.experiment_instance.generate_file_name())\n",
        "      # test_load.get_heatmap()\n",
        "      test_load.save_heatmap()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLNKh9RPSNR2",
        "outputId": "e04311d3-7683-4906-9190-5cdd460372e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30\n",
            "200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50\n",
            "200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_70\n",
            "200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_100\n",
            "200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_30\n",
            "200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_50\n",
            "200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_70\n",
            "200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_100\n",
            "200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_30\n",
            "200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_50\n",
            "200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_70\n",
            "200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_100\n",
            "400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30\n",
            "400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50\n",
            "400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_70\n",
            "400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_100\n",
            "400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_30\n",
            "400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_50\n",
            "400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_70\n",
            "400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/Shaping/existing_experiments.py:272: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
            "  plt.figure(figsize=(8, 6))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_30\n",
            "400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_50\n",
            "400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_70\n",
            "400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_100\n",
            "600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30\n",
            "600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50\n",
            "600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_70\n",
            "600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_100\n",
            "600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_30\n",
            "600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_50\n",
            "600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_70\n",
            "600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_100\n",
            "600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_30\n",
            "600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_50\n",
            "600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_70\n",
            "600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_100\n",
            "800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30\n",
            "800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50\n",
            "800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_70\n",
            "800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_100\n",
            "800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_30\n",
            "800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_50\n",
            "800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_70\n",
            "800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_100\n",
            "800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_30\n",
            "800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_50\n",
            "800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_70\n",
            "800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_100\n",
            "1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30\n",
            "1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50\n",
            "1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_70\n",
            "1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_100\n",
            "1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_30\n",
            "1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_50\n",
            "1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_70\n",
            "1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_100\n",
            "1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_30\n",
            "1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_50\n",
            "1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_70\n",
            "1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_trajectories = [200, 400, 600, 800, 1000]\n",
        "dims = [[8], [8,8], [32]]\n",
        "trajectory_length = [30, 50, 70, 100]\n",
        "\n",
        "for i in dims:\n",
        "  params[\"hidden_dims\"] = i\n",
        "  for len in trajectory_length:\n",
        "    params[\"max_length\"] = len\n",
        "    viz_over_num_trajectories_multi(params, num_trajectories, save=True, folder_path=None, filename=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVW1BcqncC9n",
        "outputId": "b2dd8efb-acea-4f37-b8b1-7d46455b77e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/Shaping/SCOPE_straight.py:115: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  padded_timestep_tensors = torch.tensor(padded_timesteps, dtype = self.dtype)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test_experiment.continue_training(200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JC3d-dNqMssI",
        "outputId": "7ed99a02-a3d7-4fce-abba-20f44fa9818b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.0951, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6409151562014548\n",
            "SCOPE mean: -0.04567254602060098, SCOPE var: 0.03338151550439484\n",
            "Total Loss: 1.7360354050523952\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.4372, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5705323031103025\n",
            "SCOPE mean: -0.045928751469007593, SCOPE var: 0.03335577320105847\n",
            "Total Loss: 2.007761324068151\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.4359, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5344446202269266\n",
            "SCOPE mean: -0.042520794559055955, SCOPE var: 0.03330584676820575\n",
            "Total Loss: 1.970296805517244\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.4349, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4984808975552497\n",
            "SCOPE mean: -0.03675088748597543, SCOPE var: 0.03324191970106417\n",
            "Total Loss: 1.933398236447734\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.4341, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4631379729771798\n",
            "SCOPE mean: -0.029436798900589242, SCOPE var: 0.033173182639385734\n",
            "Total Loss: 1.8972807098859135\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.4331, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4289876040510359\n",
            "SCOPE mean: -0.02393122611017231, SCOPE var: 0.03312276340337965\n",
            "Total Loss: 1.8621173057928588\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.4318, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.395779263772282\n",
            "SCOPE mean: -0.020194122429844384, SCOPE var: 0.033087160245342286\n",
            "Total Loss: 1.8275477392544723\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.4303, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.363391509308555\n",
            "SCOPE mean: -0.017374492739647057, SCOPE var: 0.033054507347764286\n",
            "Total Loss: 1.793651589726148\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.4286, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.3317513501326501\n",
            "SCOPE mean: -0.015005954730980622, SCOPE var: 0.03302516319802413\n",
            "Total Loss: 1.7603862339210232\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.4271, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.3008408359970405\n",
            "SCOPE mean: -0.012544582535579522, SCOPE var: 0.03299371118515353\n",
            "Total Loss: 1.7279723988170481\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.4258, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.2704329794279297\n",
            "SCOPE mean: -0.009363653973925159, SCOPE var: 0.032959214923896515\n",
            "Total Loss: 1.6962579233677573\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.4246, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.2406081469506478\n",
            "SCOPE mean: -0.006068954711446692, SCOPE var: 0.032925379112067645\n",
            "Total Loss: 1.665193911784527\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.4234, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.2113100725180952\n",
            "SCOPE mean: -0.0024904373941455594, SCOPE var: 0.032891854369899914\n",
            "Total Loss: 1.6347239094479538\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.4223, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1825217008475108\n",
            "SCOPE mean: 0.0014392030371004417, SCOPE var: 0.032858365900868484\n",
            "Total Loss: 1.6048681441394497\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.4213, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1542834531945145\n",
            "SCOPE mean: 0.005553661781140893, SCOPE var: 0.032826340747518584\n",
            "Total Loss: 1.5756096809753868\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.4203, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1266460431225993\n",
            "SCOPE mean: 0.009615790582581473, SCOPE var: 0.032796559193641474\n",
            "Total Loss: 1.5469797824896592\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.4193, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0996200628280022\n",
            "SCOPE mean: 0.013675106815286258, SCOPE var: 0.032768640428336195\n",
            "Total Loss: 1.518969154397691\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.4183, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0732309194730543\n",
            "SCOPE mean: 0.01756461811967338, SCOPE var: 0.032742854927104915\n",
            "Total Loss: 1.4915628463765285\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.4172, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0474816215045246\n",
            "SCOPE mean: 0.02115468061003135, SCOPE var: 0.03271944632600936\n",
            "Total Loss: 1.4647285491178306\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.4161, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0223604897875076\n",
            "SCOPE mean: 0.024444360475008912, SCOPE var: 0.032697928961950125\n",
            "Total Loss: 1.4384835867620773\n",
            "----------------------------------------\n",
            "Epoch 21\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.4149, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9978837167563773\n",
            "SCOPE mean: 0.027293530202373507, SCOPE var: 0.0326787063918818\n",
            "Total Loss: 1.412816397338036\n",
            "----------------------------------------\n",
            "Epoch 22\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.4137, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9740181186501575\n",
            "SCOPE mean: 0.029879147530749346, SCOPE var: 0.03266125962686789\n",
            "Total Loss: 1.3877145198408785\n",
            "----------------------------------------\n",
            "Epoch 23\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.4125, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9507142166174761\n",
            "SCOPE mean: 0.03241502035176826, SCOPE var: 0.03264503767122788\n",
            "Total Loss: 1.3631790057804243\n",
            "----------------------------------------\n",
            "Epoch 24\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.4113, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9279144804296926\n",
            "SCOPE mean: 0.03509496820501036, SCOPE var: 0.032629590907077816\n",
            "Total Loss: 1.3392142168508792\n",
            "----------------------------------------\n",
            "Epoch 25\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.4102, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9055477869006571\n",
            "SCOPE mean: 0.038183942475004236, SCOPE var: 0.0326145693443877\n",
            "Total Loss: 1.3157950813933208\n",
            "----------------------------------------\n",
            "Epoch 26\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.4093, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8836180494357042\n",
            "SCOPE mean: 0.04162683950097767, SCOPE var: 0.03260040495277361\n",
            "Total Loss: 1.2929014729807564\n",
            "----------------------------------------\n",
            "Epoch 27\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.4084, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8621923095116828\n",
            "SCOPE mean: 0.045106363630712756, SCOPE var: 0.032587733500468175\n",
            "Total Loss: 1.2705538684994846\n",
            "----------------------------------------\n",
            "Epoch 28\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.4074, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8412974600926748\n",
            "SCOPE mean: 0.048482428837465015, SCOPE var: 0.03257656316635691\n",
            "Total Loss: 1.2487307618616093\n",
            "----------------------------------------\n",
            "Epoch 29\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.4065, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8209527674538106\n",
            "SCOPE mean: 0.05161771991128883, SCOPE var: 0.03256674971458765\n",
            "Total Loss: 1.2274292546443495\n",
            "----------------------------------------\n",
            "Epoch 30\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.4055, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8011391881125319\n",
            "SCOPE mean: 0.0545896667327037, SCOPE var: 0.03255785919751352\n",
            "Total Loss: 1.2066326577787763\n",
            "----------------------------------------\n",
            "Epoch 31\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.4045, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7818529847328344\n",
            "SCOPE mean: 0.057365078699068046, SCOPE var: 0.032549801854053276\n",
            "Total Loss: 1.1863215010076393\n",
            "----------------------------------------\n",
            "Epoch 32\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.4034, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7631007307762052\n",
            "SCOPE mean: 0.05983159289950243, SCOPE var: 0.032542588404876144\n",
            "Total Loss: 1.1665003530226385\n",
            "----------------------------------------\n",
            "Epoch 33\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.4023, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7448515298284097\n",
            "SCOPE mean: 0.062110485850322014, SCOPE var: 0.03253609472085932\n",
            "Total Loss: 1.1471705351307366\n",
            "----------------------------------------\n",
            "Epoch 34\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.4013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.72704747110687\n",
            "SCOPE mean: 0.06447424901074514, SCOPE var: 0.03253036523420397\n",
            "Total Loss: 1.128308592792479\n",
            "----------------------------------------\n",
            "Epoch 35\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.4003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7097099374989051\n",
            "SCOPE mean: 0.06701341741126399, SCOPE var: 0.032526837260734756\n",
            "Total Loss: 1.1099855462515746\n",
            "----------------------------------------\n",
            "Epoch 36\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3993, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6928510972633822\n",
            "SCOPE mean: 0.06964032582360727, SCOPE var: 0.03252561684485652\n",
            "Total Loss: 1.0921053116734638\n",
            "----------------------------------------\n",
            "Epoch 37\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3982, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6764219659409003\n",
            "SCOPE mean: 0.07235532184827559, SCOPE var: 0.03252616511375269\n",
            "Total Loss: 1.0745823975471593\n",
            "----------------------------------------\n",
            "Epoch 38\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3971, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6604094046643824\n",
            "SCOPE mean: 0.0750716491081945, SCOPE var: 0.03253078038997501\n",
            "Total Loss: 1.057555074217525\n",
            "----------------------------------------\n",
            "Epoch 39\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3963, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6448169854125249\n",
            "SCOPE mean: 0.07779459864418677, SCOPE var: 0.032536020815350085\n",
            "Total Loss: 1.0411522755864937\n",
            "----------------------------------------\n",
            "Epoch 40\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3956, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6296515304351546\n",
            "SCOPE mean: 0.08043229214472566, SCOPE var: 0.03254074132199917\n",
            "Total Loss: 1.0252392643693031\n",
            "----------------------------------------\n",
            "Epoch 41\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3948, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6149289599476284\n",
            "SCOPE mean: 0.0828108244736474, SCOPE var: 0.03254544173885571\n",
            "Total Loss: 1.0097280517558376\n",
            "----------------------------------------\n",
            "Epoch 42\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3940, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.600633401895463\n",
            "SCOPE mean: 0.08495531104247818, SCOPE var: 0.032549921478511885\n",
            "Total Loss: 0.9946153420671324\n",
            "----------------------------------------\n",
            "Epoch 43\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3932, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5867219671854066\n",
            "SCOPE mean: 0.08704462025290059, SCOPE var: 0.03255439522087319\n",
            "Total Loss: 0.9798757816706851\n",
            "----------------------------------------\n",
            "Epoch 44\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3923, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5731444192387379\n",
            "SCOPE mean: 0.08925480832265974, SCOPE var: 0.0325591449633536\n",
            "Total Loss: 0.9654830338585678\n",
            "----------------------------------------\n",
            "Epoch 45\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3915, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5598622006416855\n",
            "SCOPE mean: 0.09164554764986733, SCOPE var: 0.03256438708203411\n",
            "Total Loss: 0.9514034365108062\n",
            "----------------------------------------\n",
            "Epoch 46\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3907, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5469012386104396\n",
            "SCOPE mean: 0.09408512212783962, SCOPE var: 0.03257018738177143\n",
            "Total Loss: 0.9376507278115906\n",
            "----------------------------------------\n",
            "Epoch 47\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3900, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5342500774857636\n",
            "SCOPE mean: 0.09662254974696544, SCOPE var: 0.032576192119216\n",
            "Total Loss: 0.9242855879882343\n",
            "----------------------------------------\n",
            "Epoch 48\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3894, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5219503827537226\n",
            "SCOPE mean: 0.09908317968836133, SCOPE var: 0.03258169817608688\n",
            "Total Loss: 0.9113167292895659\n",
            "----------------------------------------\n",
            "Epoch 49\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3887, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5099905817285586\n",
            "SCOPE mean: 0.1014646313641778, SCOPE var: 0.0325872615868146\n",
            "Total Loss: 0.8986905668026316\n",
            "----------------------------------------\n",
            "Epoch 50\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3880, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4983680281664769\n",
            "SCOPE mean: 0.10366264898759321, SCOPE var: 0.03259309522515501\n",
            "Total Loss: 0.8863725233373778\n",
            "----------------------------------------\n",
            "Epoch 51\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3873, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4870509273525762\n",
            "SCOPE mean: 0.10581173104184459, SCOPE var: 0.03259935007738362\n",
            "Total Loss: 0.8743498955589972\n",
            "----------------------------------------\n",
            "Epoch 52\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3866, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.47603670141264576\n",
            "SCOPE mean: 0.10786384990595192, SCOPE var: 0.03260598986778351\n",
            "Total Loss: 0.86262361518446\n",
            "----------------------------------------\n",
            "Epoch 53\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3859, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4652867972674271\n",
            "SCOPE mean: 0.1099784197149525, SCOPE var: 0.03261331196939236\n",
            "Total Loss: 0.8511816121830342\n",
            "----------------------------------------\n",
            "Epoch 54\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3852, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4548030430293996\n",
            "SCOPE mean: 0.11209034747803359, SCOPE var: 0.032621263302926536\n",
            "Total Loss: 0.8400166327784955\n",
            "----------------------------------------\n",
            "Epoch 55\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3846, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4445613972986101\n",
            "SCOPE mean: 0.11429575111992345, SCOPE var: 0.03262995461286125\n",
            "Total Loss: 0.8291279674192695\n",
            "----------------------------------------\n",
            "Epoch 56\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3839, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4345774391333632\n",
            "SCOPE mean: 0.11647964514649928, SCOPE var: 0.03263906918793303\n",
            "Total Loss: 0.8185004564750541\n",
            "----------------------------------------\n",
            "Epoch 57\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3833, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.42485586618748533\n",
            "SCOPE mean: 0.11859770423017774, SCOPE var: 0.0326483562432921\n",
            "Total Loss: 0.8081363507261192\n",
            "----------------------------------------\n",
            "Epoch 58\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3826, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4153827189075117\n",
            "SCOPE mean: 0.12070403223517878, SCOPE var: 0.03265778961770004\n",
            "Total Loss: 0.7980240002739516\n",
            "----------------------------------------\n",
            "Epoch 59\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3820, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4061593686345349\n",
            "SCOPE mean: 0.12276442214669242, SCOPE var: 0.032667172113648404\n",
            "Total Loss: 0.7881572254057965\n",
            "----------------------------------------\n",
            "Epoch 60\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3813, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.39719505241944664\n",
            "SCOPE mean: 0.12469344194264549, SCOPE var: 0.03267618901931403\n",
            "Total Loss: 0.7785355400017215\n",
            "----------------------------------------\n",
            "Epoch 61\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3807, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3884793963879499\n",
            "SCOPE mean: 0.12651442048105674, SCOPE var: 0.032684923740127575\n",
            "Total Loss: 0.7691478088930384\n",
            "----------------------------------------\n",
            "Epoch 62\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3800, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3799834730178727\n",
            "SCOPE mean: 0.1283475067949017, SCOPE var: 0.032693764800728324\n",
            "Total Loss: 0.759988195985692\n",
            "----------------------------------------\n",
            "Epoch 63\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3794, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.37169210147623466\n",
            "SCOPE mean: 0.1302297255560117, SCOPE var: 0.03270286436719168\n",
            "Total Loss: 0.751059749695103\n",
            "----------------------------------------\n",
            "Epoch 64\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3787, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3636104949876203\n",
            "SCOPE mean: 0.13210599915133736, SCOPE var: 0.03271202462201374\n",
            "Total Loss: 0.7423513388182899\n",
            "----------------------------------------\n",
            "Epoch 65\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3781, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3557287161538187\n",
            "SCOPE mean: 0.13401229527399577, SCOPE var: 0.03272107949443667\n",
            "Total Loss: 0.7338692330332496\n",
            "----------------------------------------\n",
            "Epoch 66\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3775, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3480437876527158\n",
            "SCOPE mean: 0.1359163636229162, SCOPE var: 0.03273014819617107\n",
            "Total Loss: 0.7255912683952526\n",
            "----------------------------------------\n",
            "Epoch 67\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3770, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3405515283644537\n",
            "SCOPE mean: 0.13782670189271612, SCOPE var: 0.03273917297783474\n",
            "Total Loss: 0.7175147591329595\n",
            "----------------------------------------\n",
            "Epoch 68\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3764, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3332603034177462\n",
            "SCOPE mean: 0.1396953596080177, SCOPE var: 0.03274787150338128\n",
            "Total Loss: 0.709634885526176\n",
            "----------------------------------------\n",
            "Epoch 69\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3758, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3261789313746457\n",
            "SCOPE mean: 0.14144797489922442, SCOPE var: 0.032755872708334036\n",
            "Total Loss: 0.7019458051307086\n",
            "----------------------------------------\n",
            "Epoch 70\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3751, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.31929653981916023\n",
            "SCOPE mean: 0.14310074296077982, SCOPE var: 0.03276324044767224\n",
            "Total Loss: 0.6944371691770386\n",
            "----------------------------------------\n",
            "Epoch 71\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3745, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.31259884677461525\n",
            "SCOPE mean: 0.14469910962848084, SCOPE var: 0.032770227539009676\n",
            "Total Loss: 0.6871147216084872\n",
            "----------------------------------------\n",
            "Epoch 72\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3739, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.30606196668473296\n",
            "SCOPE mean: 0.14633996883271347, SCOPE var: 0.03277733080743111\n",
            "Total Loss: 0.6799636689117288\n",
            "----------------------------------------\n",
            "Epoch 73\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3733, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2996747512062246\n",
            "SCOPE mean: 0.14804842279880737, SCOPE var: 0.03278471267746101\n",
            "Total Loss: 0.6729793944008684\n",
            "----------------------------------------\n",
            "Epoch 74\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3727, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.29343817565374847\n",
            "SCOPE mean: 0.14979820145385087, SCOPE var: 0.03279225655698852\n",
            "Total Loss: 0.6661670965781724\n",
            "----------------------------------------\n",
            "Epoch 75\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3722, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.28736621573267007\n",
            "SCOPE mean: 0.15151310605196522, SCOPE var: 0.032799419702563185\n",
            "Total Loss: 0.659525483985076\n",
            "----------------------------------------\n",
            "Epoch 76\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3716, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2814774538211361\n",
            "SCOPE mean: 0.15311931687110178, SCOPE var: 0.03280812253210678\n",
            "Total Loss: 0.6530910741237654\n",
            "----------------------------------------\n",
            "Epoch 77\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3711, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.27574329601715863\n",
            "SCOPE mean: 0.1546497102019387, SCOPE var: 0.032817098344711984\n",
            "Total Loss: 0.6468068199101882\n",
            "----------------------------------------\n",
            "Epoch 78\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3705, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2701543234795988\n",
            "SCOPE mean: 0.15612865849454394, SCOPE var: 0.03282609278364077\n",
            "Total Loss: 0.640660211978697\n",
            "----------------------------------------\n",
            "Epoch 79\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3699, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2647036414545249\n",
            "SCOPE mean: 0.15759616326865167, SCOPE var: 0.0328355183536607\n",
            "Total Loss: 0.6346348182441616\n",
            "----------------------------------------\n",
            "Epoch 80\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3693, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.25940109067952805\n",
            "SCOPE mean: 0.15910067670385356, SCOPE var: 0.03284509509417009\n",
            "Total Loss: 0.6287319461275227\n",
            "----------------------------------------\n",
            "Epoch 81\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3687, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2542519582533089\n",
            "SCOPE mean: 0.1606379139443038, SCOPE var: 0.032855160089692435\n",
            "Total Loss: 0.622960562599834\n",
            "----------------------------------------\n",
            "Epoch 82\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3681, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.24924574303074115\n",
            "SCOPE mean: 0.162184813369706, SCOPE var: 0.03286601971119905\n",
            "Total Loss: 0.6173580346497636\n",
            "----------------------------------------\n",
            "Epoch 83\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3675, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.24437727497584252\n",
            "SCOPE mean: 0.16366892527919755, SCOPE var: 0.03287645562816801\n",
            "Total Loss: 0.6118871001443008\n",
            "----------------------------------------\n",
            "Epoch 84\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3669, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.23964858995625335\n",
            "SCOPE mean: 0.16506769173831037, SCOPE var: 0.03288628445341666\n",
            "Total Loss: 0.6065412518105309\n",
            "----------------------------------------\n",
            "Epoch 85\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3664, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.23504026884979912\n",
            "SCOPE mean: 0.1663764216580713, SCOPE var: 0.0328958662409827\n",
            "Total Loss: 0.6014373173208187\n",
            "----------------------------------------\n",
            "Epoch 86\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3659, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.23054278603469058\n",
            "SCOPE mean: 0.1676641781530398, SCOPE var: 0.032904981996715224\n",
            "Total Loss: 0.5964454642444775\n",
            "----------------------------------------\n",
            "Epoch 87\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3654, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.22614813653104457\n",
            "SCOPE mean: 0.16896507933985686, SCOPE var: 0.032913907927488065\n",
            "Total Loss: 0.5915531721505185\n",
            "----------------------------------------\n",
            "Epoch 88\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3649, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.22185207117511585\n",
            "SCOPE mean: 0.17029027161279592, SCOPE var: 0.03292279346704883\n",
            "Total Loss: 0.5867656207852652\n",
            "----------------------------------------\n",
            "Epoch 89\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3644, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.21765104286169482\n",
            "SCOPE mean: 0.17165830929576584, SCOPE var: 0.03293167522462836\n",
            "Total Loss: 0.5820776519160518\n",
            "----------------------------------------\n",
            "Epoch 90\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3639, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.21354820399237281\n",
            "SCOPE mean: 0.1730440548740086, SCOPE var: 0.03294042392534998\n",
            "Total Loss: 0.5774809187403646\n",
            "----------------------------------------\n",
            "Epoch 91\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3634, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.20955381326403522\n",
            "SCOPE mean: 0.17439806689065, SCOPE var: 0.03294867544534516\n",
            "Total Loss: 0.5729751792879824\n",
            "----------------------------------------\n",
            "Epoch 92\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3629, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.20567989935049713\n",
            "SCOPE mean: 0.17566246214377287, SCOPE var: 0.03295604614300454\n",
            "Total Loss: 0.568567703960771\n",
            "----------------------------------------\n",
            "Epoch 93\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3623, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.20192356152494534\n",
            "SCOPE mean: 0.17684019074506604, SCOPE var: 0.03296256245071699\n",
            "Total Loss: 0.5642491637297634\n",
            "----------------------------------------\n",
            "Epoch 94\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3617, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.19827479502749887\n",
            "SCOPE mean: 0.1779693461587116, SCOPE var: 0.032968553782071953\n",
            "Total Loss: 0.5600166491680889\n",
            "----------------------------------------\n",
            "Epoch 95\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3612, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.19472120284517233\n",
            "SCOPE mean: 0.17910021687178726, SCOPE var: 0.032974407513287105\n",
            "Total Loss: 0.5558729561944709\n",
            "----------------------------------------\n",
            "Epoch 96\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3606, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.19125479530456035\n",
            "SCOPE mean: 0.1802597568935553, SCOPE var: 0.03298042938688636\n",
            "Total Loss: 0.5518148582151928\n",
            "----------------------------------------\n",
            "Epoch 97\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3600, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.18786984930025627\n",
            "SCOPE mean: 0.18147161360950537, SCOPE var: 0.03298679697601838\n",
            "Total Loss: 0.5478400632728255\n",
            "----------------------------------------\n",
            "Epoch 98\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3594, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.18457475327316422\n",
            "SCOPE mean: 0.1826854897555106, SCOPE var: 0.03299313577690412\n",
            "Total Loss: 0.5439448913574166\n",
            "----------------------------------------\n",
            "Epoch 99\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3588, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.18136829960273435\n",
            "SCOPE mean: 0.18386978341325083, SCOPE var: 0.03299926101841963\n",
            "Total Loss: 0.5401866885496946\n",
            "----------------------------------------\n",
            "Epoch 100\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3582, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1782786652569702\n",
            "SCOPE mean: 0.1849594832411761, SCOPE var: 0.03300466532927996\n",
            "Total Loss: 0.5365119806675795\n",
            "----------------------------------------\n",
            "Epoch 101\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3576, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.17530383567314825\n",
            "SCOPE mean: 0.18595862497144994, SCOPE var: 0.0330092888235035\n",
            "Total Loss: 0.5329023169013604\n",
            "----------------------------------------\n",
            "Epoch 102\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3569, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.17243241011947052\n",
            "SCOPE mean: 0.18690419566828764, SCOPE var: 0.03301341542827547\n",
            "Total Loss: 0.5293566030222001\n",
            "----------------------------------------\n",
            "Epoch 103\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3562, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.16965152298539804\n",
            "SCOPE mean: 0.1878399248534005, SCOPE var: 0.0330174225180169\n",
            "Total Loss: 0.5258734689477693\n",
            "----------------------------------------\n",
            "Epoch 104\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3555, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.16694814186243553\n",
            "SCOPE mean: 0.18881082898473403, SCOPE var: 0.03302165849333467\n",
            "Total Loss: 0.5224498836312815\n",
            "----------------------------------------\n",
            "Epoch 105\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3548, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.16432152053425508\n",
            "SCOPE mean: 0.18980953366434383, SCOPE var: 0.03302606690393705\n",
            "Total Loss: 0.5190859703051223\n",
            "----------------------------------------\n",
            "Epoch 106\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3540, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.16177931251912908\n",
            "SCOPE mean: 0.19079479469236993, SCOPE var: 0.033030277441737255\n",
            "Total Loss: 0.5157788679532815\n",
            "----------------------------------------\n",
            "Epoch 107\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3532, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1593259559720585\n",
            "SCOPE mean: 0.19173744360057474, SCOPE var: 0.03303398159362189\n",
            "Total Loss: 0.5125263766099915\n",
            "----------------------------------------\n",
            "Epoch 108\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3524, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.15696413064277703\n",
            "SCOPE mean: 0.19261672272238356, SCOPE var: 0.033036955733520314\n",
            "Total Loss: 0.5093264455268466\n",
            "----------------------------------------\n",
            "Epoch 109\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3515, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1546916165921136\n",
            "SCOPE mean: 0.19343382556929742, SCOPE var: 0.033039184737414865\n",
            "Total Loss: 0.5061773515272814\n",
            "----------------------------------------\n",
            "Epoch 110\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3506, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.15250188597368922\n",
            "SCOPE mean: 0.19420955368295745, SCOPE var: 0.033040842177540664\n",
            "Total Loss: 0.5030785918876679\n",
            "----------------------------------------\n",
            "Epoch 111\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3497, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.15038459394393336\n",
            "SCOPE mean: 0.1949613480752622, SCOPE var: 0.033042194912081255\n",
            "Total Loss: 0.5000742440241642\n",
            "----------------------------------------\n",
            "Epoch 112\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3488, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1483273681631849\n",
            "SCOPE mean: 0.19572795872404636, SCOPE var: 0.03304336889060156\n",
            "Total Loss: 0.4971122021665487\n",
            "----------------------------------------\n",
            "Epoch 113\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3479, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.14632988308112324\n",
            "SCOPE mean: 0.19650850194413916, SCOPE var: 0.033044357310046485\n",
            "Total Loss: 0.49419054518927685\n",
            "----------------------------------------\n",
            "Epoch 114\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3469, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.14439347710345007\n",
            "SCOPE mean: 0.19729358167972283, SCOPE var: 0.03304502920174871\n",
            "Total Loss: 0.4913067028552698\n",
            "----------------------------------------\n",
            "Epoch 115\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3459, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.14252296815207752\n",
            "SCOPE mean: 0.19805725735465932, SCOPE var: 0.033045122937839976\n",
            "Total Loss: 0.4884579045873655\n",
            "----------------------------------------\n",
            "Epoch 116\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3449, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.14072580519588118\n",
            "SCOPE mean: 0.19876298440296242, SCOPE var: 0.03304432046035021\n",
            "Total Loss: 0.48564425520107257\n",
            "----------------------------------------\n",
            "Epoch 117\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3439, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1390023624717999\n",
            "SCOPE mean: 0.19940680440748215, SCOPE var: 0.03304255484915441\n",
            "Total Loss: 0.4828651363592723\n",
            "----------------------------------------\n",
            "Epoch 118\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3428, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1373496670987123\n",
            "SCOPE mean: 0.19999990261453118, SCOPE var: 0.03303996765159917\n",
            "Total Loss: 0.48011955191400935\n",
            "----------------------------------------\n",
            "Epoch 119\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3416, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1357603804773455\n",
            "SCOPE mean: 0.20057196029399482, SCOPE var: 0.03303686486179393\n",
            "Total Loss: 0.4774059584453814\n",
            "----------------------------------------\n",
            "Epoch 120\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3405, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.13422629635453198\n",
            "SCOPE mean: 0.20114929455689318, SCOPE var: 0.03303354352557817\n",
            "Total Loss: 0.47473787835836906\n",
            "----------------------------------------\n",
            "Epoch 121\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3394, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1327526220829676\n",
            "SCOPE mean: 0.20173088259429894, SCOPE var: 0.03303010000077489\n",
            "Total Loss: 0.472117559955628\n",
            "----------------------------------------\n",
            "Epoch 122\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3382, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1313404262745798\n",
            "SCOPE mean: 0.2023125819794928, SCOPE var: 0.03302642987810991\n",
            "Total Loss: 0.4695229584979611\n",
            "----------------------------------------\n",
            "Epoch 123\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3370, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.12999257079798066\n",
            "SCOPE mean: 0.20287528813175504, SCOPE var: 0.033022308945219965\n",
            "Total Loss: 0.4669516751359025\n",
            "----------------------------------------\n",
            "Epoch 124\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3357, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.12871334967814246\n",
            "SCOPE mean: 0.20339313188638253, SCOPE var: 0.03301746874912825\n",
            "Total Loss: 0.46440399110795794\n",
            "----------------------------------------\n",
            "Epoch 125\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3344, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.12750503211172945\n",
            "SCOPE mean: 0.20385047609290066, SCOPE var: 0.033011751236957536\n",
            "Total Loss: 0.46187905128609186\n",
            "----------------------------------------\n",
            "Epoch 126\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3330, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.12636482030157878\n",
            "SCOPE mean: 0.20425496315580532, SCOPE var: 0.03300522976484159\n",
            "Total Loss: 0.45937663073475066\n",
            "----------------------------------------\n",
            "Epoch 127\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3316, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.12528588614289088\n",
            "SCOPE mean: 0.20463116210779103, SCOPE var: 0.03299815139399007\n",
            "Total Loss: 0.45689656960176117\n",
            "----------------------------------------\n",
            "Epoch 128\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3302, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.12425246853328885\n",
            "SCOPE mean: 0.20501242364098762, SCOPE var: 0.032990787795904426\n",
            "Total Loss: 0.45445757725436453\n",
            "----------------------------------------\n",
            "Epoch 129\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3288, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.12326436644008874\n",
            "SCOPE mean: 0.20540574312230334, SCOPE var: 0.03298317721481143\n",
            "Total Loss: 0.4520359814042463\n",
            "----------------------------------------\n",
            "Epoch 130\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3273, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.12232458160823775\n",
            "SCOPE mean: 0.2057960506737541, SCOPE var: 0.032975171546719986\n",
            "Total Loss: 0.44963239340638306\n",
            "----------------------------------------\n",
            "Epoch 131\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3258, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.12143896213328569\n",
            "SCOPE mean: 0.20615604501430443, SCOPE var: 0.03296650947655921\n",
            "Total Loss: 0.4472457643245065\n",
            "----------------------------------------\n",
            "Epoch 132\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3243, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.12061006406593883\n",
            "SCOPE mean: 0.2064671697644092, SCOPE var: 0.03295703610860725\n",
            "Total Loss: 0.44488987990306617\n",
            "----------------------------------------\n",
            "Epoch 133\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3227, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11984399428361041\n",
            "SCOPE mean: 0.20672523870542128, SCOPE var: 0.0329467728917317\n",
            "Total Loss: 0.4425529497398741\n",
            "----------------------------------------\n",
            "Epoch 134\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3211, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11913585152138927\n",
            "SCOPE mean: 0.20694773919615536, SCOPE var: 0.03293589676568053\n",
            "Total Loss: 0.4402313889698187\n",
            "----------------------------------------\n",
            "Epoch 135\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3194, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11848012616206909\n",
            "SCOPE mean: 0.20715487651982256, SCOPE var: 0.03292462595593284\n",
            "Total Loss: 0.4379253479917945\n",
            "----------------------------------------\n",
            "Epoch 136\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3178, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11787222766891427\n",
            "SCOPE mean: 0.2073655283723177, SCOPE var: 0.03291315013310952\n",
            "Total Loss: 0.4356358667473936\n",
            "----------------------------------------\n",
            "Epoch 137\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3161, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11730948737072892\n",
            "SCOPE mean: 0.20757762983676784, SCOPE var: 0.032901472951917816\n",
            "Total Loss: 0.4333759292730884\n",
            "----------------------------------------\n",
            "Epoch 138\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3143, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11678892957759131\n",
            "SCOPE mean: 0.20778261322741937, SCOPE var: 0.03288941179032579\n",
            "Total Loss: 0.4311336166598405\n",
            "----------------------------------------\n",
            "Epoch 139\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3126, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1163148842510208\n",
            "SCOPE mean: 0.20795968032241557, SCOPE var: 0.03287675750560884\n",
            "Total Loss: 0.428905558007625\n",
            "----------------------------------------\n",
            "Epoch 140\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3108, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11588893300245924\n",
            "SCOPE mean: 0.2080977450697744, SCOPE var: 0.032863403966273234\n",
            "Total Loss: 0.42669233835168485\n",
            "----------------------------------------\n",
            "Epoch 141\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3090, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1155132313921432\n",
            "SCOPE mean: 0.20819781477421065, SCOPE var: 0.03284937644905743\n",
            "Total Loss: 0.42449701261108225\n",
            "----------------------------------------\n",
            "Epoch 142\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3072, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11518135733600372\n",
            "SCOPE mean: 0.20827162329382803, SCOPE var: 0.03283480945653126\n",
            "Total Loss: 0.42233267531947494\n",
            "----------------------------------------\n",
            "Epoch 143\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3053, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11489421606294188\n",
            "SCOPE mean: 0.20832605724975628, SCOPE var: 0.032819866771860336\n",
            "Total Loss: 0.4201882196676708\n",
            "----------------------------------------\n",
            "Epoch 144\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3034, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11464466664843706\n",
            "SCOPE mean: 0.20838673094842325, SCOPE var: 0.03280477894211914\n",
            "Total Loss: 0.41805947935273735\n",
            "----------------------------------------\n",
            "Epoch 145\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.3015, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11443263569073762\n",
            "SCOPE mean: 0.20844904607505454, SCOPE var: 0.032789527564473286\n",
            "Total Loss: 0.415947309635941\n",
            "----------------------------------------\n",
            "Epoch 146\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.2995, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11425746824569233\n",
            "SCOPE mean: 0.2085103899041141, SCOPE var: 0.03277354661598245\n",
            "Total Loss: 0.41375661191543034\n",
            "----------------------------------------\n",
            "Epoch 147\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.2975, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11411793587312327\n",
            "SCOPE mean: 0.20855268480734848, SCOPE var: 0.03275713960547217\n",
            "Total Loss: 0.41157458267249025\n",
            "----------------------------------------\n",
            "Epoch 148\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.2954, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1140095881635244\n",
            "SCOPE mean: 0.20857085060363514, SCOPE var: 0.03274022955650067\n",
            "Total Loss: 0.4094128922256062\n",
            "----------------------------------------\n",
            "Epoch 149\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.2933, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1139406132376844\n",
            "SCOPE mean: 0.2085661163970642, SCOPE var: 0.03272282090341397\n",
            "Total Loss: 0.40727027471299104\n",
            "----------------------------------------\n",
            "Epoch 150\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.2912, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11389587715384766\n",
            "SCOPE mean: 0.20855097500690853, SCOPE var: 0.03270496796543898\n",
            "Total Loss: 0.40514216678644055\n",
            "----------------------------------------\n",
            "Epoch 151\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.2892, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11387169648173993\n",
            "SCOPE mean: 0.20853257148988286, SCOPE var: 0.032686795915447715\n",
            "Total Loss: 0.4030408023800733\n",
            "----------------------------------------\n",
            "Epoch 152\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.2871, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11387267488347572\n",
            "SCOPE mean: 0.20850812647882727, SCOPE var: 0.032668360577367175\n",
            "Total Loss: 0.4009553101556026\n",
            "----------------------------------------\n",
            "Epoch 153\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.2850, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1138962520426407\n",
            "SCOPE mean: 0.2084822978386029, SCOPE var: 0.032649713372361694\n",
            "Total Loss: 0.39888793747402657\n",
            "----------------------------------------\n",
            "Epoch 154\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.2829, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11394012193492786\n",
            "SCOPE mean: 0.20845738215943702, SCOPE var: 0.032630880024749245\n",
            "Total Loss: 0.3968391885171703\n",
            "----------------------------------------\n",
            "Epoch 155\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.2808, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11400355800419\n",
            "SCOPE mean: 0.20842894791865643, SCOPE var: 0.032611824735920406\n",
            "Total Loss: 0.3948102358527158\n",
            "----------------------------------------\n",
            "Epoch 156\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.2787, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11408563267979491\n",
            "SCOPE mean: 0.20839075766626197, SCOPE var: 0.03259252373743504\n",
            "Total Loss: 0.3928129848035856\n",
            "----------------------------------------\n",
            "Epoch 157\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.2767, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.114179917846063\n",
            "SCOPE mean: 0.2083493133928707, SCOPE var: 0.032572930818716\n",
            "Total Loss: 0.39083847666862503\n",
            "----------------------------------------\n",
            "Epoch 158\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.2746, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11428618611819985\n",
            "SCOPE mean: 0.2083005921832896, SCOPE var: 0.03255302862919492\n",
            "Total Loss: 0.3888844802982167\n",
            "----------------------------------------\n",
            "Epoch 159\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.2725, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11440201252959613\n",
            "SCOPE mean: 0.20824816341272395, SCOPE var: 0.03253286454389114\n",
            "Total Loss: 0.38695144036607254\n",
            "----------------------------------------\n",
            "Epoch 160\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.2705, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11452468126179384\n",
            "SCOPE mean: 0.20819862493125788, SCOPE var: 0.03251251658904436\n",
            "Total Loss: 0.3850401248179767\n",
            "----------------------------------------\n",
            "Epoch 161\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.2685, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11465140897776584\n",
            "SCOPE mean: 0.2081560517664874, SCOPE var: 0.032492060797612125\n",
            "Total Loss: 0.3831654562264862\n",
            "----------------------------------------\n",
            "Epoch 162\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.2665, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11478492821188434\n",
            "SCOPE mean: 0.208117923157909, SCOPE var: 0.03247152258829952\n",
            "Total Loss: 0.3813148797911182\n",
            "----------------------------------------\n",
            "Epoch 163\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.2646, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11492354706951055\n",
            "SCOPE mean: 0.20808261179053866, SCOPE var: 0.0324508794253821\n",
            "Total Loss: 0.3794872564531431\n",
            "----------------------------------------\n",
            "Epoch 164\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.2629, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11506675068165685\n",
            "SCOPE mean: 0.20807888058877688, SCOPE var: 0.03242973146050663\n",
            "Total Loss: 0.37798401295081074\n",
            "----------------------------------------\n",
            "Epoch 165\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.2613, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11479035533273632\n",
            "SCOPE mean: 0.208248831129698, SCOPE var: 0.032404378476617375\n",
            "Total Loss: 0.3760942370015524\n",
            "----------------------------------------\n",
            "Epoch 166\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.2601, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11417144349193427\n",
            "SCOPE mean: 0.20859309683379965, SCOPE var: 0.032376645485241294\n",
            "Total Loss: 0.3742378756992619\n",
            "----------------------------------------\n",
            "Epoch 167\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.2589, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11362182363328326\n",
            "SCOPE mean: 0.20891587755648702, SCOPE var: 0.03234938969034139\n",
            "Total Loss: 0.37256214787017816\n",
            "----------------------------------------\n",
            "Epoch 168\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.2578, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11313389815293963\n",
            "SCOPE mean: 0.20920368991040522, SCOPE var: 0.03232269430268182\n",
            "Total Loss: 0.37090778714915934\n",
            "----------------------------------------\n",
            "Epoch 169\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.2566, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1127038833480398\n",
            "SCOPE mean: 0.20946384864462717, SCOPE var: 0.032296515364696333\n",
            "Total Loss: 0.36926642729156134\n",
            "----------------------------------------\n",
            "Epoch 170\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.2553, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11232738209661124\n",
            "SCOPE mean: 0.20970477968351628, SCOPE var: 0.032270857509832565\n",
            "Total Loss: 0.36763871207659554\n",
            "----------------------------------------\n",
            "Epoch 171\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.2540, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11200046821393662\n",
            "SCOPE mean: 0.20993143108459772, SCOPE var: 0.03224571880151112\n",
            "Total Loss: 0.3660310499752081\n",
            "----------------------------------------\n",
            "Epoch 172\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.2527, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11172448692139246\n",
            "SCOPE mean: 0.21013918880225024, SCOPE var: 0.032221052548249196\n",
            "Total Loss: 0.3644422585348197\n",
            "----------------------------------------\n",
            "Epoch 173\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.2514, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11149586859940787\n",
            "SCOPE mean: 0.21032898621170515, SCOPE var: 0.03219678433282654\n",
            "Total Loss: 0.36287001500154387\n",
            "----------------------------------------\n",
            "Epoch 174\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.2500, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11131248105134586\n",
            "SCOPE mean: 0.2104960409508797, SCOPE var: 0.03217281889236116\n",
            "Total Loss: 0.36131399630966776\n",
            "----------------------------------------\n",
            "Epoch 175\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.2486, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11117141138415304\n",
            "SCOPE mean: 0.21063904825736413, SCOPE var: 0.03214909582230499\n",
            "Total Loss: 0.3597748248493793\n",
            "----------------------------------------\n",
            "Epoch 176\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.2472, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11106880834512202\n",
            "SCOPE mean: 0.21076054205483397, SCOPE var: 0.03212562374501805\n",
            "Total Loss: 0.35826111941428107\n",
            "----------------------------------------\n",
            "Epoch 177\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.2458, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11099605721619867\n",
            "SCOPE mean: 0.21087380670359818, SCOPE var: 0.032102395426492625\n",
            "Total Loss: 0.35676464992310597\n",
            "----------------------------------------\n",
            "Epoch 178\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.2443, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11095065980143692\n",
            "SCOPE mean: 0.21097918022992077, SCOPE var: 0.03207939615182553\n",
            "Total Loss: 0.3552854819566612\n",
            "----------------------------------------\n",
            "Epoch 179\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.2429, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11092963707041105\n",
            "SCOPE mean: 0.211077059830398, SCOPE var: 0.03205661220717261\n",
            "Total Loss: 0.35382306342636266\n",
            "----------------------------------------\n",
            "Epoch 180\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.2415, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11093038068251536\n",
            "SCOPE mean: 0.21116717746769942, SCOPE var: 0.03203403211386808\n",
            "Total Loss: 0.35238210837637335\n",
            "----------------------------------------\n",
            "Epoch 181\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.2400, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11095422309136703\n",
            "SCOPE mean: 0.2112445714317321, SCOPE var: 0.032011651578925375\n",
            "Total Loss: 0.35096560287737566\n",
            "----------------------------------------\n",
            "Epoch 182\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.2386, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11099706307672316\n",
            "SCOPE mean: 0.21131449576401565, SCOPE var: 0.03198947895316292\n",
            "Total Loss: 0.34956756434723135\n",
            "----------------------------------------\n",
            "Epoch 183\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.2371, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11105550406985278\n",
            "SCOPE mean: 0.2113798147005965, SCOPE var: 0.03196752254764304\n",
            "Total Loss: 0.34818825692228483\n",
            "----------------------------------------\n",
            "Epoch 184\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.2357, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11112619097155477\n",
            "SCOPE mean: 0.211443597366458, SCOPE var: 0.03194579414286801\n",
            "Total Loss: 0.3468279211875511\n",
            "----------------------------------------\n",
            "Epoch 185\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.2343, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1112060813901531\n",
            "SCOPE mean: 0.21150755217990228, SCOPE var: 0.03192430379171527\n",
            "Total Loss: 0.3454896499567728\n",
            "----------------------------------------\n",
            "Epoch 186\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.2329, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11128869199440436\n",
            "SCOPE mean: 0.2115772373814105, SCOPE var: 0.03190301532175159\n",
            "Total Loss: 0.3441741585292342\n",
            "----------------------------------------\n",
            "Epoch 187\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.2315, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1113721371562108\n",
            "SCOPE mean: 0.2116592562540975, SCOPE var: 0.031881679685116085\n",
            "Total Loss: 0.34291165237596355\n",
            "----------------------------------------\n",
            "Epoch 188\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.2302, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11145690355160484\n",
            "SCOPE mean: 0.21174080952704627, SCOPE var: 0.031860453349628975\n",
            "Total Loss: 0.34167765689895513\n",
            "----------------------------------------\n",
            "Epoch 189\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.2289, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11154424605380835\n",
            "SCOPE mean: 0.21181778811761914, SCOPE var: 0.03183941158970737\n",
            "Total Loss: 0.34046594198337976\n",
            "----------------------------------------\n",
            "Epoch 190\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.2276, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11163030373692255\n",
            "SCOPE mean: 0.21189882065724297, SCOPE var: 0.03181861140412406\n",
            "Total Loss: 0.3392730438761072\n",
            "----------------------------------------\n",
            "Epoch 191\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.2264, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11171153362353727\n",
            "SCOPE mean: 0.21199139701759637, SCOPE var: 0.031798105241487115\n",
            "Total Loss: 0.33809937561071335\n",
            "----------------------------------------\n",
            "Epoch 192\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.2252, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11178511710317872\n",
            "SCOPE mean: 0.21209874737513965, SCOPE var: 0.031777913243006724\n",
            "Total Loss: 0.3369480038709652\n",
            "----------------------------------------\n",
            "Epoch 193\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.2240, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11184714171148541\n",
            "SCOPE mean: 0.21221912399200846, SCOPE var: 0.03175793687811796\n",
            "Total Loss: 0.3358136527216911\n",
            "----------------------------------------\n",
            "Epoch 194\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.2228, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11189819306215644\n",
            "SCOPE mean: 0.21234320577978674, SCOPE var: 0.03173807641529429\n",
            "Total Loss: 0.33469450124691635\n",
            "----------------------------------------\n",
            "Epoch 195\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.2217, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11193822435789608\n",
            "SCOPE mean: 0.2124655510906208, SCOPE var: 0.03171829076437203\n",
            "Total Loss: 0.3335944866564384\n",
            "----------------------------------------\n",
            "Epoch 196\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.2205, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11196901076966417\n",
            "SCOPE mean: 0.21258554064952742, SCOPE var: 0.0316986147489925\n",
            "Total Loss: 0.33251279379797344\n",
            "----------------------------------------\n",
            "Epoch 197\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.2195, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11198868556393435\n",
            "SCOPE mean: 0.21270974732515127, SCOPE var: 0.03167911374998354\n",
            "Total Loss: 0.3314460588081653\n",
            "----------------------------------------\n",
            "Epoch 198\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.2184, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11199428441155668\n",
            "SCOPE mean: 0.2128497160593287, SCOPE var: 0.031659891177346064\n",
            "Total Loss: 0.33039363747102424\n",
            "----------------------------------------\n",
            "Epoch 199\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.2174, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11198404148881905\n",
            "SCOPE mean: 0.21301156552110415, SCOPE var: 0.031640996699554044\n",
            "Total Loss: 0.3293552117534281\n",
            "----------------------------------------\n",
            "Epoch 200\n",
            "IS mean: 0.3970366370089854,IS variance: 0.05239271808991322\n",
            "SCOPE Var loss:  tensor(0.2164, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11195821193150353\n",
            "SCOPE mean: 0.21319161019970315, SCOPE var: 0.03162240167632291\n",
            "Total Loss: 0.32833484301014243\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_load = existing_experiments(test_experiment)"
      ],
      "metadata": {
        "id": "_Qcj0DgXn9Xs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_load.get_heatmap()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "pTeL8QHLoFXG",
        "outputId": "f168da50-fbdb-44be-bf66-b254e063be00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"df95996e-563a-4a02-8aa0-1f8e1c4868d9\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"df95996e-563a-4a02-8aa0-1f8e1c4868d9\")) {                    Plotly.newPlot(                        \"df95996e-563a-4a02-8aa0-1f8e1c4868d9\",                        [{\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"z\":[[0.17591929894273806,0.18086819482641642,0.1821788013301984,0.15885675893447576,0.13000789687595898,0.10212242305816263,0.0822025012997939,0.06457294027462515,0.04694337924945652,0.02931381822428783],[0.17763687732523437,0.13720922356276322,0.1284364478444852,0.11966367212620718,0.10850201066395228,0.0796531486054355,0.05080428654691874,0.021955424488401903,-0.006893437570114874,-0.03574229962863165],[0.18869080529227028,0.11256361027103073,0.07469409435877199,0.06592131864049403,0.05714854292221602,0.048375767203938075,0.02929840033491199,0.00044953827639518384,-0.028399323782121594,-0.057248185840638344],[0.18547129325648945,0.12296683360425531,0.05507757396574267,0.012178965154780869,0.003406189436502921,-0.005366586281775082,-0.01413936200005314,-0.022912137718331144,-0.0499052099941282,-0.07875407205264498],[0.16178088493451132,0.1334430898066858,0.05921558235517149,-0.002408462339545364,-0.049194394956185106,-0.05910893976748835,-0.0678817154857663,-0.07665449120404441,-0.08542726692232236,-0.10025995826465181],[0.13809047661253324,0.11417523068227776,0.0682967898832763,0.0017295460498834847,-0.059894498644833455,-0.10607116621013893,-0.12162406897147945,-0.13039684468975757,-0.13916962040803552,-0.14794239612631346],[0.10954331837572441,0.09490737155786973,0.056646279637163593,0.0058675544393123336,-0.055756490255404606,-0.11738053495012138,-0.16294793746409283,-0.18413919817547084,-0.19291197389374867,-0.20168474961202662],[0.07887144223498957,0.07563951243346173,0.037378420512755556,-0.000882671407950536,-0.05161848186597576,-0.11324252656069259,-0.17486657125540947,-0.21982470871804674,-0.24665432737946177,-0.25542710309773986],[0.03520802453373856,0.041898921939902106,0.018110561388347685,-0.02015053053235849,-0.05308859882276176,-0.10910451817126374,-0.17072856286598068,-0.2323526075606975,-0.2767014799720008,-0.30916945658345296],[-0.008455393167512426,0.0013129883070684412,-0.01497671122327382,-0.04522250012563797,-0.07767948157747281,-0.10496650978183489,-0.16659055447655183,-0.22821459917126882,-0.2898386438659857,-0.33357825122595464]],\"type\":\"heatmap\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"Values\"},\"ticks\":\"outside\",\"tickvals\":[-0.33357825122595464,0.18869080529227028],\"ticktext\":[-0.33357825122595464,0.18869080529227028]}},\"xaxis\":{\"tickvals\":[0,1,2,3,4,5,6,7,8,9],\"ticktext\":[0,1,2,3,4,5,6,7,8,9],\"title\":{\"text\":\"X\"}},\"yaxis\":{\"tickvals\":[9,8,7,6,5,4,3,2,1,0],\"ticktext\":[9,8,7,6,5,4,3,2,1,0],\"title\":{\"text\":\"Y\"},\"autorange\":\"reversed\"},\"title\":{\"text\":\"Heatmap\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('df95996e-563a-4a02-8aa0-1f8e1c4868d9');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_load.plot_metrics()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "wce8dM3mcQGy",
        "outputId": "e16f2e01-ef1a-4fb1-edfa-f6b1db543b66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"44b51df4-8f1a-4b37-a3b0-9441906a3492\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"44b51df4-8f1a-4b37-a3b0-9441906a3492\")) {                    Plotly.newPlot(                        \"44b51df4-8f1a-4b37-a3b0-9441906a3492\",                        [{\"mode\":\"lines\",\"name\":\"IS Estimate\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300],\"y\":[0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462,0.5352202109319462],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"Train Estimate\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300],\"y\":[2.906856737768048,3.4562781115994645,3.4149831714422545,3.3742819215288735,3.333300746134237,3.29299919648528,3.2545816647957455,3.2183407973868525,3.1825289694875822,3.147241970088257,3.1103554699293627,3.072844054245762,3.03442356075059,2.996388133284181,2.958407571097189,2.9219114570306344,2.886650928699989,2.8519140352254975,2.818068210845772,2.784633917870655,2.751925113564261,2.7197893290680777,2.688046196031982,2.656873821043123,2.6263461035894506,2.5960881165736645,2.566424258957585,2.537412244350667,2.508532411729686,2.480215574131549,2.4527609278970246,2.4259785525919733,2.3991810716758093,2.372508897033491,2.3458368954538398,2.3194223706613273,2.2936816026946762,2.2685938038194755,2.2440406579262104,2.2198934832603134,2.1962713704395807,2.1731564186421166,2.1505806421226823,2.1288045222134695,2.107232914804199,2.086160570409898,2.065508550415634,2.045277605278892,2.025594850061814,2.0063670286013617,1.9875882021552287,1.9692470542111682,1.9510720152774215,1.9330300185305918,1.9152367594191813,1.897854060858314,1.8808114101764528,1.8641571211551846,1.8478669661912879,1.831982225807693,1.816631034505695,1.8016601624645752,1.7868946066741744,1.7725208839832347,1.7585509938721413,1.744947722078379,1.7316624218575984,1.7184472281099188,1.7055728599437403,1.6930331283035862,1.6808232973793347,1.6689380377500747,1.6573709086079744,1.6466020050942665,1.6362558130127531,1.6261643480372292,1.6163269871844639,1.6068016532149616,1.5975566341494192,1.5885288560697381,1.5797306274454823,1.5711547238352506,1.5628000864674352,1.5547458671817034,1.5468999280344458,1.5392565328133907,1.531809802942221,1.5245407449751731,1.5174738415665008,1.5106220539378588,1.5039396324759382,1.4974075267246616,1.491014762682922,1.4847739061554561,1.4786792280457637,1.4727032569146359,1.4668533856271637,1.4611315465102808,1.455532798016561,1.4500526091534742,1.4446869688642527,1.4394295748869728,1.4342761352676134,1.4292222666417067,1.4242636811796565,1.4193995904245176,1.414625786551814,1.409933897802896,1.4053215204781113,1.4007849463753765,1.3963205992643475,1.391925049703632,1.3875949940382972,1.3833271394626805,1.3791183311043838,1.3749675431102477,1.3708460174240342,1.3667206732318828,1.3626409038262441,1.3586052973120841,1.3546118000552367,1.3506584516713103,1.346743420806587,1.3428649030332016,1.3390826658954411,1.3353556050988669,1.3316735161088993,1.328020906868624,1.324396424202982,1.3207928730966734,1.3172104877593735,1.3136519362004386,1.3101165453194705,1.3066039396956615,1.3031123909649773,1.2996413811193142,1.2961816821552428,1.2927414686547927,1.2893201528680684,1.2859171761984005,1.2825601854883313,1.2792356013776487,1.275929035004022,1.272639666184838,1.2693662965911956,1.2661074515488129,1.2628635173151508,1.259635466531822,1.2564228467460463,1.2532248890217033,1.2500416992003909,1.2468730625622557,1.2437187735818416,1.2405780070046424,1.2374507046592162,1.2343249591648353,1.2312088501705656,1.2281058350417728,1.2250160836486366,1.221939332750691,1.2188755574647352,1.2158247373458786,1.2128235540704655,1.2098609971943945,1.2069111564782922,1.203973396450961,1.2010476922313806,1.198134013323118,1.1952321078877635,1.1923419616513455,1.1894635633809132,1.186575686228246,1.1836543065330323,1.1807431791613372,1.1778423758542664,1.1749462528338208,1.1720356239605076,1.1691353108658968,1.1662610179654578,1.1634083369027837,1.16056483143199,1.1577306282511786,1.1549057822967859,1.1522103798882228,1.1495383591237835,1.1468753450842288,1.1442214776028166,1.1415769454853448,1.1389426252393242,1.1363270932137313,1.1337199692410902,1.1311221796855302,1.1285336014657332,1.1259540860424562,1.123412144839547,1.1208847913395976,1.1183747864808822,1.1158863856577885,1.1134113247749575,1.1109451503528505,1.1085201890765832,1.106125923620952,1.1037417415714306,1.1013674246634713,1.0990026634482355,1.096647575205087,1.0943021748673951,1.0919699838077401,1.0896479082973156,1.0873360482877952,1.0850336929099798,1.0827405998474375,1.0804570046027628,1.078182919155213,1.075918463655954,1.0736633050220417,1.0714174021817355,1.0691810044227985,1.0669543302815687,1.0647354297083775,1.0625227694899329,1.0603079412921055,1.0580224552754427,1.055749134548167,1.0534886522508122,1.051276501810972,1.0491074650982992,1.0470074296047667,1.0450129081696258,1.0430166632166198,1.0410225898312293,1.039031939901969,1.0370468043172418,1.0350656475729436,1.0331357018701333,1.0312314673506184,1.029329890400191,1.0274182500953697,1.025510851779001,1.023607983131941,1.0217101913676456,1.0198179681741608,1.017935040118271,1.0160577147831866,1.0141856672706546,1.0123193281515306,1.0104709874995368,1.0086587199424664,1.00684481301429,1.0050977573658093,1.0033747438120242,1.0016463489804583,0.9999115958991123,0.9981750069789245,0.9964364727551303,0.9946962089023961,0.9929555189755552,0.991215556966493,0.9894780630965534,0.987745082111155,0.9860172203920397,0.9846105587502476,0.9831962095461884,0.9817814153280873,0.9803670740619186,0.978956626450916,0.9775479229022052,0.9761411861244178,0.9747370648336003,0.9733360474668685,0.9719386201921141,0.9705452013513423,0.9689180566245679,0.9672568560356242,0.9656008165475672,0.9639468999840983,0.9622918220531687,0.9606412836589592,0.9589958356771906,0.9573559740843842,0.9557347941964819,0.9541197306177454,0.9525107843922568,0.9509076348752533,0.9493094291047713,0.9477166592514644,0.9461297641876445,0.9445488286114141,0.9429753625860136,0.9414093916780101,0.9398509745005998,0.9383014247577838,0.9367608866157247,0.9352293734094519,0.9337069725913718,0.9321937631296005,0.9306915706117547,0.9291988742515072,0.9277145684224998,0.9262386988540162],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"Test Estimate\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300],\"y\":[1.792645622477775,1.779743811063828,1.76668435883926,1.7537084240318774,1.7409414546171151,1.7284923189342407,1.7132090059522387,1.6966803344674635,1.6803631953754106,1.664248329248718,1.6486943549861386,1.633325563091111,1.6181846308243082,1.6033159734908187,1.5887910192883004,1.5745621984272362,1.5605530367028122,1.5467457984136304,1.5331451410861947,1.5197252371433034,1.5062825868767975,1.4930032363581607,1.4798922441624545,1.4669933611358366,1.4542413324459746,1.4416098907226127,1.429157247065012,1.4168696159361234,1.4047279183275605,1.3925997863116402,1.3805141499304607,1.3685755312574652,1.3567417321260618,1.3450722633297194,1.333582342257746,1.3222766682844547,1.3109633203038542,1.29901835151435,1.2872836013860656,1.2757454960721908,1.2644056661560406,1.2532574209598923,1.2422977900639003,1.2315240468849595,1.2209211785573968,1.2104395745059222,1.2001348979316315,1.1900046066407315,1.1800430809040539,1.170252955950449,1.160629327018188,1.1511697942358914,1.141872931343754,1.132728303599409,1.1237342184386052,1.1148897714925923,1.1061872610604495,1.097629883773703,1.0892549611485411,1.0809701604105753,1.0728680948117642,1.0648985315399166,1.0570595760381192,1.0493527890641328,1.0417790875052706,1.034337099773156,1.0270262704578255,1.0198344657449396,1.0127623612698458,1.0058105301282518,0.998960282067486,0.9922314680424732,0.9856245366746782,0.979139633009076,0.9727646749815745,0.9665009051708606,0.9603493612348708,0.9543108056873454,0.9483834725194918,0.942566144250187,0.9368509383861314,0.9312099374675232,0.9256775952820204,0.9202553507909812,0.9149427276491552,0.909739067553445,0.9046435324042089,0.8996551320124913,0.8947727394468746,0.8899916765625394,0.8853109965910835,0.8807456856433328,0.8763002747415699,0.8719522879818593,0.8677001099352989,0.8635420898843289,0.859472813441039,0.8554907405977654,0.851594232952964,0.8477816287431832,0.8440514285320305,0.8404016413945327,0.836830467047019,0.8333360969603142,0.829916710754051,0.8265704173969427,0.8232947787246107,0.8200878415845404,0.8169478565601462,0.8138730823659868,0.8108617910217079,0.8079130324808562,0.8050401890685612,0.8022252322093837,0.7994664101134674,0.7967621659067724,0.794111898734782,0.7915104675608028,0.7889564917085197,0.7864488449579745,0.7839863553744937,0.781567871078622,0.7791923050342366,0.7768585462319672,0.7745654938237112,0.7723130128459718,0.7701001635646093,0.7679258360661381,0.7657888982698821,0.7636883836255929,0.7616233060909616,0.7595927773943405,0.7575958829689529,0.7556317260161466,0.7536994762202858,0.7517984083301001,0.7499275589493417,0.7480861988110205,0.7462736223297772,0.7444892235091338,0.7427318448481722,0.7410008379257772,0.7392962778558977,0.7376168481860917,0.735962059216673,0.7343314362585064,0.7327243531389073,0.7311403829127073,0.7295793572529027,0.7280407335356068,0.7265241072288645,0.7250290873625167,0.7235552723133054,0.7221022884528088,0.7206697820196654,0.7192576102076972,0.7178654845871785,0.7164930502760066,0.7151399652849277,0.713805899014742,0.7124905317706309,0.7111935539988269,0.7099144646525503,0.7086540829087324,0.7074119675111309,0.7061880391829287,0.7049818839123297,0.703793063429603,0.7026212070910598,0.701465961331541,0.7003269884616345,0.6992039653748047,0.69809440979206,0.6969982443116028,0.6959153403782764,0.6948456295343545,0.6937746631443903,0.6926982305299054,0.691634922505378,0.6905847754431496,0.6895475638012686,0.6885231486932155,0.6875113790274101,0.6865047090898856,0.6855095870966422,0.6845267540970169,0.6835560049139587,0.6825971843456198,0.6816501339496649,0.6807147980506554,0.679790974574534,0.6788785041695518,0.6779772282446315,0.6770870751058755,0.6762078766662131,0.675340079948794,0.6744834628411485,0.6736386880526313,0.6728055594378647,0.6719837746714027,0.6711730554165596,0.6703746206465633,0.6695880744244761,0.6688129818622339,0.6680489875304759,0.6672957751762092,0.6665530475626492,0.6658205379177909,0.6650979474225966,0.6643850275046532,0.6636816703411512,0.6629876396878801,0.6623027069340769,0.6616266900188038,0.6609593385952456,0.660300456036335,0.6596498538786334,0.6590073637601097,0.6583728107830155,0.6577460380545476,0.657126882448005,0.6565153966090477,0.6559116821301875,0.655313276959451,0.6547202340766052,0.6541325054500152,0.6535507449454262,0.652974843424925,0.6524086615822526,0.6518519428341389,0.6513043162230029,0.6507654417687496,0.6502350023860469,0.6497127108011816,0.6491983015574239,0.6486919158605083,0.6481934035994893,0.6477028376774331,0.6472199883683802,0.6467446407918476,0.6462765642901952,0.6458152735604985,0.6453605352139211,0.6449139271136252,0.6444751297929312,0.6440438336890543,0.6436197144614069,0.6432058496635066,0.6428016659766533,0.6424066373047149,0.6420229566264123,0.6416502468630796,0.6412877908426061,0.6409349403998998,0.6405910957606961,0.6402558338230121,0.6399286428418869,0.6396090518041733,0.6392964073330458,0.6389904354628421,0.6386910791908045,0.638399016542929,0.6381061884661466,0.6378122653970688,0.6375175567526128,0.6372223929741163,0.6369272179027737,0.6366322761457318,0.6363378163704959,0.6360440154496606,0.6357511596508538,0.6354595248527325,0.6351689407872274,0.6348885317957506,0.6346181893519525,0.6343571229581515,0.634104574907476,0.6338410776305277,0.6335802467958659,0.6333253943044744,0.6330760499534854,0.6328319220768042,0.6325926043863974,0.6323577307828133,0.6321269492376071,0.6318999351883702,0.6316763890041214,0.6314560337081543,0.6312386093299498,0.6310468779775853,0.63087242076825,0.6307001886847852,0.6305300473521016,0.6303618685666087,0.6301955299043336,0.6300311583724882,0.6298686154911715,0.6297078563999435,0.6295487771099586,0.6293912247883724],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"On-policy Estimate\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300],\"y\":[0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053,0.8519115297369053],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"IS Variance\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300],\"y\":[0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363,0.022440204571842363],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"lines\",\"name\":\"Train Variance\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300],\"y\":[2.3360467785657937,3.372517197462628,3.2412933245211732,3.1150444806642295,2.995366511933634,2.879164849703174,2.7702942286324004,2.6687632598325464,2.5700582810939183,2.4746631872818887,2.3815789886144887,2.2887781218808985,2.19723190406035,2.1090072627412604,2.0237011632063133,1.9433847169094294,1.8663249691306425,1.7921415871029225,1.7205238686107347,1.6509886145962502,1.584315501000752,1.5203524743088777,1.4590397510763569,1.400322270017226,1.3440453422966308,1.2895865055960891,1.2375272322160809,1.1878148417204053,1.1400145159956514,1.094376869152315,1.051098372849607,1.0100397992268852,0.970458880165094,0.9327578458180109,0.8966400725334279,0.8619919019001009,0.8292622464996372,0.7984257897232385,0.7693926646731135,0.7420224932066927,0.7162423148293735,0.6919899233424847,0.669150563259908,0.6477785251175115,0.6277309139113906,0.6089434415628822,0.5913484443353042,0.5748674120371087,0.5594540402097168,0.5450741393700134,0.5316711110514448,0.5191857689182213,0.5075274028968575,0.4966255609306477,0.4863374550687147,0.47678828915411425,0.46794138821987064,0.45971049813570136,0.45201189177701945,0.4448639858496663,0.43822143558854443,0.43205393773667355,0.42629307901004265,0.4209073010683676,0.415893464328305,0.41122230224332845,0.4068639237057176,0.4027800330917371,0.39895922439681697,0.39537751760419954,0.39201276228251863,0.3888439417605966,0.38585147144893855,0.3832751960950149,0.38090969756459175,0.3786472227986451,0.3764755311688826,0.37440811702544863,0.3724236380857935,0.37042960321062707,0.3684894903910469,0.3665969821628351,0.36475041726445473,0.3630245912658984,0.36133339809952525,0.35967308673950427,0.3580404706333313,0.3564366647363703,0.3548639544039524,0.3533118989430716,0.3517790098264871,0.35024283811640844,0.3486956654985229,0.3471644562983436,0.34564877712552977,0.3441014923704516,0.3425556203185087,0.34102628015439124,0.33951362804703084,0.33801817273507073,0.33654026207497767,0.33507969172128177,0.33363675727647846,0.33221165263069524,0.3308045458965397,0.32941650519167753,0.3280478962641915,0.3266977502382481,0.32536606223893544,0.3240527710745134,0.32275776923433624,0.32148091403779,0.3202220047172257,0.3189807742575816,0.3177568617669495,0.31655016039681055,0.31534747930992696,0.3141334337118029,0.3129346496703475,0.3117509498667937,0.31058195181596804,0.3094272468930812,0.30828641443531674,0.30715901049898126,0.306056708361525,0.3049671302289981,0.3038896399456603,0.3028238208542879,0.30176915131003396,0.300725091246438,0.2996910770677997,0.298666598011437,0.29765119178499305,0.2966445216041482,0.2956461281215185,0.2946553688237916,0.293666821118046,0.29268533517377104,0.29171052343387716,0.29074203639016616,0.28978793763528665,0.288840258104703,0.2878986166715387,0.2869625328491192,0.2860314780563178,0.28510493124326364,0.28418285942299326,0.28326516316189765,0.28235169385676334,0.2814422411168627,0.28053657083162375,0.27963446736844977,0.2787357229376015,0.2778401075214551,0.276947454813348,0.2760575480787057,0.27517011129197605,0.2742850120901042,0.27340216253951155,0.27252147243587793,0.2716428659242646,0.27076627503775325,0.2698996923585158,0.2690404729858982,0.2681828534288915,0.26732641509321364,0.26647114250883025,0.2656170227146775,0.2647640612024389,0.2639122618479729,0.26306163106740066,0.2621941020786159,0.26128924920322444,0.2603847337309861,0.2594807411865731,0.25857616405894995,0.2576662025156797,0.2567569106563736,0.2558482734720847,0.2549403979864677,0.254033290208251,0.2531270741995502,0.25222187767555243,0.2513614238496606,0.2505069904931289,0.24965336807107089,0.24880066765872155,0.24794900000235476,0.24709861080007034,0.2462523758589402,0.24540777823019747,0.24456466717729755,0.24372311069776495,0.24288310465535123,0.24205980643087838,0.24124041269936128,0.24042267975682283,0.23960678886898326,0.23879207174663417,0.23797862420883087,0.23718342011555804,0.23640116342944975,0.23562076581083052,0.23484222738510668,0.23406554069119284,0.23329071699494613,0.23251776600954013,0.23174666233175012,0.23097743592394188,0.23021014955583385,0.2294447331025355,0.22868119302317333,0.2279195637740536,0.22715987222975398,0.2264021179180702,0.22564632443527102,0.22489251983297434,0.22414074253426058,0.22339100541457083,0.2226433893195075,0.22189600262778011,0.22114423083540174,0.22035343313143246,0.2195665725180415,0.21878398262766638,0.21802368550614398,0.2172828987759652,0.21657764173579647,0.21592833985295004,0.21527914147151045,0.21463020417909856,0.2139816969110324,0.21333380817767167,0.21268662449897294,0.21204676808393744,0.21141120355672285,0.21077630953856547,0.2101418030756076,0.20950802277250707,0.20887498029227056,0.20824283523668044,0.20761175874055313,0.20698203163556636,0.20635214567237653,0.20572232086922052,0.20509279833273786,0.20447076890963817,0.20386846414413914,0.2032637018188211,0.20269625128123003,0.20213891655160507,0.20157489753462107,0.20100454484027946,0.20042879650016726,0.19984858109736167,0.1992647317114753,0.19867796126183543,0.1980889265747379,0.19749826543239393,0.19690675268064586,0.19631484303791097,0.19588513139087174,0.19545523316389807,0.1950249179590683,0.19459443045578034,0.1941640809563905,0.19373360363632647,0.1933032201784818,0.1928730970154585,0.19244341690642458,0.19201433891537056,0.1915860007518269,0.19104106589087086,0.19046726653096466,0.18989066440705807,0.18931184630745249,0.1887311863395041,0.18814966463279617,0.18756782559957086,0.1869861594432387,0.18640478673659347,0.1858241724661117,0.1852447137707422,0.18466551842267098,0.18408704256557953,0.1835096661465044,0.18293372822309456,0.18235952167564698,0.18178728621967502,0.18121737435024746,0.18065002669695834,0.18008595907207917,0.17952521986116413,0.17896788286705936,0.1784140083971955,0.17786365725358744,0.17731682733647963,0.17677347053631887,0.17623345764051748,0.17569682884709004],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"lines\",\"name\":\"Test Variance\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300],\"y\":[0.04497041203251437,0.044784791205783055,0.04460068010753587,0.04442440198127437,0.04425374554208556,0.04409328016711651,0.04400051188473257,0.04391118408276282,0.04382631454614875,0.04374708186162396,0.043670126732825006,0.043596539824597214,0.04352866089950975,0.04346929827753097,0.043404848914285254,0.043332951629117177,0.04325886914450317,0.043189583021841796,0.04312402372232279,0.04306077892067807,0.04298170732982315,0.04290438029770317,0.042828741940618684,0.04274502094846611,0.04265632588272968,0.04256818841769959,0.04248448810204548,0.04240297698606973,0.04232348925729607,0.042243918924787884,0.04216447008955284,0.04208598214284651,0.04200913895037156,0.04193331126766944,0.04185861882022991,0.041785390872478095,0.041687809376707415,0.04148197270931215,0.0412818703068633,0.041086412694729596,0.0408959205443236,0.040709815176438846,0.040527864188956174,0.040349890542333566,0.0401756173428707,0.04000508946168782,0.03983800430808153,0.03967420980872656,0.039513541546768706,0.03935599779460668,0.0392013628091729,0.039049393543381355,0.0388999264725753,0.038752710505667615,0.03860746283653476,0.038464077220230986,0.038322326147694416,0.038182096338637284,0.03804303181905336,0.03790837073765021,0.03779102909173117,0.037674575076582055,0.03755842742364367,0.03744267951478726,0.03732734125162027,0.03721239454002199,0.03709783085473038,0.036983420908475236,0.03686921122900353,0.03675526341009836,0.036641531142712236,0.03652816832614662,0.03641523199783121,0.03630277643980229,0.03619100429666593,0.03607996710495683,0.03596971524237836,0.03586030105099778,0.03575171383155777,0.03564401320743245,0.03553737460282985,0.03543225236430823,0.03532820676683692,0.035225243787312226,0.0351234104731025,0.03502275019946699,0.034923301541796174,0.03482509992930722,0.03472817779309055,0.03463251898557,0.034538151801850325,0.0344448568112352,0.034352549091975965,0.03426158911749932,0.03417199765314457,0.03408379196111091,0.0339969449955274,0.03391147181138155,0.033827391029551665,0.03374471083005647,0.03366345344552091,0.033583616831002694,0.033505200943300284,0.03342820317969371,0.03335261897472027,0.03327843219814631,0.03320566868129897,0.03313431692576852,0.0330643640827341,0.03299579616470193,0.03292859814927414,0.03286281545387727,0.032799642172790695,0.03273776723406807,0.03267716240915885,0.03261781003260829,0.03255976441838329,0.032503050516058056,0.032447624288816555,0.03239346231755916,0.03234053661299944,0.03228881976340682,0.0322382836173178,0.032188902002811354,0.032140648865388845,0.03209358263667117,0.032047683297725164,0.03200291628480394,0.0319592483285455,0.031916647166146984,0.03187508546113151,0.03183453967036064,0.031794981093147,0.03175638374941342,0.031718719159357665,0.03168196769606393,0.03164611020809067,0.03161112185860243,0.031576978309521206,0.031543661171218984,0.031511184860942704,0.031479506339503915,0.031448638164088015,0.03141851730134013,0.0313891237702794,0.03136043834670949,0.031332424796002914,0.03130506697775272,0.03127836668234072,0.031252302474497076,0.031226858146828986,0.031202018039807305,0.031177767800530443,0.031154092266478136,0.031130977285642816,0.031108424738272064,0.0310864219018741,0.031064953292525024,0.031044004088460257,0.03102356003649301,0.031003607441318626,0.030984133130295112,0.030965124020421453,0.030946572851640042,0.030928465504035444,0.030910805525710315,0.03089357962710902,0.030876771840593596,0.030860370319141628,0.03084436369473932,0.030828741047523107,0.03081349187760758,0.03079844504443737,0.03078360872112048,0.030768989397284563,0.03075459244702164,0.030740433328970796,0.030726518435750087,0.030712834866886543,0.03069939642426302,0.030686201682114486,0.030673250525378743,0.030660541476853355,0.030647638894857585,0.030634991834390127,0.03062264419485528,0.030610592146014404,0.030598825756030783,0.0305873362398763,0.030576123025138867,0.0305651762553558,0.03055448768364603,0.03054404986547013,0.0305338622833275,0.030523916975241427,0.030514210321709624,0.03050473480792301,0.030495465495141837,0.03048640496888673,0.03047754738011437,0.030468887105811276,0.03046049689493145,0.03045236399618039,0.030444483186088216,0.030436846667714876,0.030429443167065317,0.030422262175684764,0.030415295212177212,0.030408530606717533,0.030401959864406657,0.030395581359193125,0.03038938700483378,0.030383369203016087,0.03037752403488062,0.030371841097767124,0.030366314064426733,0.03036093696028544,0.030355705084050427,0.03035061300167073,0.03034565400046373,0.030340823379806207,0.030336123412942322,0.030331559722421145,0.030326936448732456,0.03032226760259061,0.03031755858175482,0.030312938980667406,0.03030840569460583,0.03030429897594795,0.030300574105515347,0.030297202634882576,0.030294158451252714,0.030291417483743734,0.03028895770334793,0.030286758853410034,0.0302848358743595,0.0302831732367086,0.030281763039221084,0.030280585124258283,0.0302796279590465,0.03027887308191281,0.03027831492577216,0.03027792422385538,0.030277755128094375,0.030277791219276085,0.030278016192106204,0.030278415447879067,0.03027921935672643,0.030280390650082437,0.030281895240962538,0.030283973038512758,0.03028653463459548,0.030289531312792807,0.03029291762162207,0.030296651039788524,0.030300685752548243,0.030304988225128338,0.030309527862683126,0.03031425511494328,0.03031911708113028,0.03032410126661286,0.03032919962765678,0.030334194664081236,0.030339086924431866,0.030343877650677885,0.030348571045524495,0.03035318867225275,0.030357732360494584,0.030362203831368322,0.03036660476302402,0.030370937463012594,0.03037520422280572,0.03037940499399927,0.030383860654075272,0.03038854355440996,0.03039342576966122,0.030398478758736507,0.030404431188855857,0.03041068472293247,0.03041706082898322,0.030423537008127055,0.030430102789968935,0.03043673826036285,0.030443426370665147,0.03045015046667486,0.030456895386928664,0.0304636473398969,0.030470393791472483,0.030477123327512744,0.03048666438819186,0.03049801628470227,0.03050938446009809,0.030520761531029388,0.03053214070435836,0.030543515727050764,0.030554880333884215,0.030566229242048153,0.030577563953670134,0.030588871158329367,0.030600146301570423],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"lines\",\"name\":\"Train MSE Loss\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300],\"y\":[48.83242029921817,46.46492759670809,44.769895479077704,43.13141018851994,41.558328275415484,40.036957103139294,38.56952457550281,37.15316480980074,35.78435971293497,34.45987737617629,33.172510339977734,31.93181213632253,30.738825102595936,29.591915070477135,28.486000606727206,27.417938230989723,26.388712492475086,25.399150907857475,24.4435719006317,23.523514368918203,22.636761139181242,21.781112165487894,20.96116221883348,20.1759069046793,19.419702537119733,18.691357830217143,17.993912666194618,17.32267738451117,16.674605152240677,16.05377391457174,15.459133159460377,14.890080385151869,14.34603850494294,13.826050328339122,13.329753323909328,12.855679815160258,12.402951813524233,11.971142263683861,11.559312319651537,11.16634222681892,10.791756730681568,10.434956252151657,10.09533447222773,9.770901678265394,9.461144375924677,9.166432539754412,8.886177982245842,8.619775212604521,8.366800041094177,8.126312620222027,7.897616545107382,7.68053040267716,7.473732118218899,7.2766259069249095,7.0895104804827405,6.91126462835178,6.741537343753772,6.580473208096906,6.4276465785645085,6.2825967093784785,6.144206567220973,6.012869097259909,5.888164015452948,5.769826390819478,5.657397279292937,5.550575221510399,5.449022239517898,5.351179106754808,5.258024143785061,5.169293455654618,5.084722093103023,5.0040669119995,4.927081301918648,4.853049580113531,4.781779218348475,4.713519387980237,4.648085761371285,4.58518973981773,4.524590183082361,4.4662982052970905,4.410177505632913,4.356088941744072,4.303901624979371,4.253478839750215,4.204730188065732,4.157547888807873,4.111832320690469,4.067489133501143,4.0243506353212375,3.9823322858169767,3.94144731413245,3.901656192064153,3.8629191211279275,3.82513666671291,3.78825692837926,3.7521512712126808,3.7168145979715854,3.6822303192811274,3.6483624147327367,3.61518258711134,3.582655774509187,3.5507436568679154,3.5194293951510454,3.488689638073062,3.458496112024568,3.4288238457447253,3.3996569347829704,3.370981282310929,3.342782258273171,3.3150448415620586,3.287755429649467,3.260900855050429,3.234460036117145,3.2084283786308174,3.182793723114941,3.157551707842928,3.132669856445296,3.1081071946505543,3.0838967190158897,3.0600332563818724,3.0365079275459173,3.0133144733789012,2.990446986777647,2.967898037866864,2.9456812369352217,2.9237765761182066,2.9021782366685316,2.8808748214167244,2.8598614503960706,2.8391286239046956,2.818673589243716,2.7984918176163034,2.778575856662291,2.758918328909261,2.739518343655636,2.7203696262504815,2.7014643760964234,2.6827995713560844,2.6643714829815752,2.646175826795979,2.6281982008488125,2.610437732164823,2.592891448423879,2.575554803370741,2.5584273318511817,2.5414999326229544,2.5247697368113324,2.5082397554202345,2.4919044458016555,2.4757551033993628,2.4597923649152538,2.444012922581885,2.428412333672793,2.4129880447186287,2.3977403679688853,2.382666146173664,2.3677591378814986,2.3530170861241735,2.3384370713380047,2.324016240285525,2.3097518052176986,2.295638440313006,2.2816783772720983,2.2678691740581756,2.2542018841378546,2.240673179126384,2.2272846886853204,2.214033915239206,2.200918954741426,2.1879375097984126,2.175087343294061,2.1623674239244863,2.149773049382391,2.137300243748125,2.12494741104306,2.112713108180713,2.10059463978505,2.0885909781455734,2.076703112063706,2.0649251575491845,2.05325575107544,2.041695124819706,2.0302423360033583,2.018889127096775,2.00764273380495,1.996500630006254,1.9854626754368825,1.9745273808544375,1.963692947764905,1.9529586820620364,1.9423226592034166,1.9317834243537195,1.9213396327276007,1.9109907994815314,1.9007154919971767,1.890527701043858,1.8804320754818855,1.8704293680006294,1.8605164269226793,1.8506901301829897,1.840962079857245,1.8313307064012985,1.821783315315635,1.8123175562545433,1.8029333804973884,1.793630077675013,1.7844065948940397,1.7752597708147433,1.766188913981919,1.7571959294032145,1.7482790130726025,1.7394360390128831,1.7306658251414802,1.7219678843280626,1.7133407843383452,1.7047836132222671,1.6962956400617515,1.6878758364800954,1.6795226439833846,1.6712352390988747,1.663012369658337,1.654847879034034,1.6467437162729945,1.6386948321855523,1.630700052459925,1.6227593133980736,1.6148762921634594,1.6070554387875982,1.5993064659435257,1.591621094774214,1.5839991193134426,1.5764394582975556,1.5689411784734328,1.5615030992156074,1.5541239077579752,1.5468022703199273,1.5395348064494863,1.5323176099732785,1.5251564314139017,1.5180500206140268,1.5109973265551004,1.5039960204315959,1.4970111328127185,1.490066757329795,1.4831712222813211,1.4763236172916638,1.4695232126198796,1.4627729096780924,1.4560734633412469,1.4494225202042692,1.4428276565616525,1.4362880274757313,1.429803720367013,1.423373093720799,1.4169943356250236,1.410666630529403,1.404388662179373,1.3981592741738962,1.3919674510659235,1.385817677254966,1.3797123609823434,1.3736456217005693,1.3676315849821659,1.3616686635410278,1.3557548873543983,1.3498907243817624,1.3440737755390786,1.3383015780363947,1.3325727409239019,1.3268867938957818,1.321242663163831,1.3156393606871037,1.3100463759537073,1.304475093095276,1.2989287160932474,1.2934076100463665,1.2879125086556211,1.2824439902884566,1.277002663957886,1.2715890692970622,1.2662019892409835,1.260844192302697,1.2555151511521743,1.2502149036134151,1.2449448351248267,1.2397050151753815,1.2344954785615387,1.2293160711685125,1.2241645627635962,1.2190424247240126,1.2139476198044665,1.2088788176902043,1.2038387257189413,1.1988273875101496,1.1938454425046752,1.1888923855072675,1.1839678592572869,1.1790701167991393,1.174200643608784,1.1693595075979528],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"mode\":\"lines\",\"name\":\"IS MSE\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300],\"y\":[0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664,0.12273359597826664],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"mode\":\"lines\",\"name\":\"Train MSE\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300],\"y\":[6.5588465865759495,10.155242490185099,9.810629565035327,9.477396874052996,9.152658955186599,8.838073846454197,8.543118006536066,8.268750738622812,8.001835931563917,7.743205017685419,7.482148019606521,7.221319400302182,6.960590669579828,6.70778716590292,6.461026735472859,6.228284415905473,6.006489390823292,5.792151609063569,5.5862959632797695,5.386404444189674,5.1943671197292245,5.009319947543141,4.83043026384689,4.658211143054617,4.492663399179895,4.3317384716656155,4.177081130875825,4.028727500683907,3.8844072626501904,3.745750930144268,3.6138171684392235,3.4877267916667023,3.36450191557692,3.244974199247318,3.128453070865904,3.0155799701308053,2.9079631897762934,2.8054144554230014,2.7074161742262284,2.6133971183724127,2.523545696123496,2.437677979800629,2.35569202672477,2.2782342393532664,2.2035626937186588,2.132314135965085,2.0641661729355905,1.9989900022915912,1.9369865766186194,1.8778416382283942,1.8214326153266005,1.7676244431703974,1.7156811758705206,1.6654427477421918,1.6169979991475796,1.5707840675627733,1.5265763521883857,1.4843516354814434,1.4439391231800591,1.4054025551463445,1.3689051584698833,1.3340764031047518,1.300486433169126,1.2684288841942113,1.2378885822557328,1.208735943075086,1.180825555892873,1.1536641496465432,1.12769689108732,1.1028630611795682,1.0791074808186154,1.05637625655679,1.034616282460307,1.0148081477187234,0.9961056522720952,0.9781146494446396,0.9608065227536429,0.9442672155501637,0.9284102598201421,0.9130346886643581,0.8982101293803741,0.883907754419625,0.8701129573548705,0.8570006971573667,0.8443422718677059,0.832116239993718,0.8203021325409012,0.8088667259284184,0.7978371453319081,0.7872114536361665,0.7769196565879499,0.766907920243626,0.7571486078605734,0.747679243784479,0.7384865247689139,0.7294838609027614,0.7207091064442641,0.7121753089917431,0.7038722635665711,0.695790923620689,0.6879229833075973,0.6802571450982384,0.6727852910514157,0.6654993395762601,0.6583915311576857,0.6514592042146646,0.6446952310869465,0.638086713500224,0.6316286800911172,0.6253147985669023,0.6191390042180716,0.6130955157846443,0.6071787786431663,0.601383324517799,0.5957038731750774,0.5901377535228247,0.5846404818210299,0.5791618879378353,0.5737791432280352,0.568489523966323,0.5632895135940915,0.5581757390321247,0.553145014854914,0.5481942252499937,0.5433924242675237,0.53868530423158,0.5340612035132617,0.529503959847041,0.5250111268086536,0.5205748053972987,0.5161941974045944,0.511870800972546,0.5076030280900119,0.5033897092782498,0.49922834529447246,0.4951173886427055,0.4910427894478588,0.48701637022011934,0.483036827023377,0.4791029375506265,0.47524620233579684,0.47144612030832617,0.46768946144448803,0.46397469764806953,0.46029996042568766,0.45666319288887947,0.45306439551750366,0.4495039717974428,0.4459810994452331,0.44249465345731204,0.4390442026686475,0.4356290797802001,0.4322486392669669,0.42890173807316745,0.42558791021312425,0.4222975790855361,0.41903656858013083,0.4158071674339161,0.4126091706891835,0.40944204743908696,0.40630546357049613,0.40319909771000495,0.40015718166706415,0.39716829423899835,0.3942075884154155,0.3912739730873991,0.38836720247019896,0.3854870308552828,0.38263308058427836,0.37980514082142525,0.37700300648460605,0.3741941997186764,0.37134251915962935,0.36851498739417854,0.36571165763735203,0.36292759638525085,0.3601456382181615,0.35738783797014795,0.3546638742216376,0.35197065886100415,0.349300150855528,0.34665239521563296,0.3440273947598731,0.3415408232518641,0.3390887200640148,0.33665702043532086,0.3342457732800933,0.33185505308307106,0.3294854605853891,0.3271445886067806,0.3248237748059813,0.3225232542220311,0.32024288126531375,0.31798242732183224,0.31577239043199123,0.3135870281565516,0.31142534695142937,0.3092895134274343,0.30717421455157745,0.3050770408182363,0.3030314241636649,0.30102612148728297,0.2990392214034524,0.2970704708987206,0.2951195690499433,0.29318644894635004,0.2912709908563152,0.28937472370262923,0.2874960216149606,0.2856348534907521,0.28379067606502906,0.2819632526312663,0.2801525978557139,0.2783586138990454,0.27658122436188326,0.27482017427738065,0.2730753478707404,0.2713467671645446,0.2696344114806627,0.2679374017185747,0.26625309693808735,0.26457329518448613,0.26283514675778497,0.2611163416532336,0.259417318948653,0.2577700775962374,0.2561691356990202,0.25464005188104705,0.25321648220556675,0.25180031351380994,0.2503931972290976,0.24899574481137404,0.24760887807160825,0.24623205537927034,0.24488896864931126,0.24356684358250882,0.24225358423901322,0.2409444119665918,0.23964474738598235,0.2383546524007042,0.2370744207282711,0.235804330809237,0.2345458376349178,0.23329611573762454,0.2320552165815427,0.2308234601249649,0.22961187055561788,0.22843814578147748,0.22726802408593144,0.22616227161640443,0.22508002176957037,0.22399541362852057,0.2229085644242971,0.22182180127509393,0.22073604025178284,0.21965219631586744,0.2185713681621878,0.2174945385771196,0.2164228165329851,0.2153575066312539,0.21429917930400155,0.2134941636919556,0.21269090031652405,0.21189110514253498,0.21109525732361578,0.21030453755546283,0.20951810692391226,0.20873622770464123,0.20795920908724796,0.20718733041237872,0.20642084135851343,0.20565994879254898,0.20473159322518417,0.20377181082992257,0.202815918342575,0.2018637704938781,0.20091499527132783,0.19997182402074656,0.19903487417828347,0.1981046902869873,0.19718405697963665,0.19627068879340984,0.19536492380795445,0.19446574725523383,0.1935733933668525,0.19268828898780585,0.19181080392610902,0.19094119081841204,0.19007990787284534,0.1892272416422765,0.18838337264230523,0.18754917303379756,0.18672463322391336,0.18590974594130227,0.1851045028689538,0.18430889425210661,0.18352312217672256,0.1827468041584376,0.1819795583144872,0.18122135691605365],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"mode\":\"lines\",\"name\":\"Test MSE\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300],\"y\":[0.9299510452775015,0.9056575334781047,0.8814100089714616,0.8576620405413315,0.8346279528745971,0.8124871601569399,0.7858338544196353,0.7575455175286587,0.7301584768453624,0.7036381577027189,0.6785329973449752,0.6542044313474848,0.6307031263496149,0.6080779363706589,0.5863962310358097,0.5655569405876996,0.5454316545394147,0.5259842439493612,0.5072032569543174,0.48903592672055635,0.4711831877522032,0.4539029565962569,0.4371885196310418,0.4210706802655294,0.405457517114276,0.39031234536692927,0.3756971062756859,0.3615806161479528,0.34792944875171034,0.3345877097226142,0.321585200165045,0.3090276726100837,0.2968626721946482,0.285140820425472,0.27386539045471675,0.2630287544333334,0.25241635579942934,0.2413864827892399,0.23083071107894482,0.2207216437142295,0.21104733312449175,0.2017883395780126,0.19292929644105247,0.18445555371781533,0.17634373826549316,0.168547448347582,0.1610975184649614,0.15398113845902306,0.14718385641812773,0.14069726143827982,0.13450804116738005,0.12860490241432648,0.12297754089438342,0.1176107709882121,0.11249503692955601,0.10762163285714352,0.10297847368781765,0.09855960584919038,0.09437493625330323,0.09037622702374694,0.08661283274141149,0.083038038013618,0.07964414832484865,0.07642573039950874,0.0733770307445438,0.07049148314307299,0.06776300327248547,0.06518153334603363,0.06274220123384192,0.06044016573155404,0.05826486670469269,0.056217853412225,0.05429440022217211,0.05248976670203642,0.05079648701219503,0.04921069206730079,0.047728478542359516,0.046345912766172156,0.04505854957580442,0.04386227233998416,0.04275207774451008,0.04172048983291955,0.04076963919284314,0.03989612166358377,0.039096342383355714,0.03836677432939032,0.03770396564710069,0.03710455148755656,0.03656526109089252,0.03608261656783185,0.03565367618799367,0.035276265358071365,0.034947359974878515,0.03466322110853201,0.03442127691782568,0.03421906189045375,0.0340541180067818,0.03392428256176805,0.033827491706800765,0.03376176691227442,0.033725234636471785,0.03371609436065658,0.03373263939515656,0.033773249882531366,0.0338363910368088,0.033920604172772914,0.03402458711979864,0.034147064053387494,0.034286822524745325,0.03444271964309207,0.03461367919786012,0.034798683214667836,0.03499656474883866,0.03520649539606147,0.03542765298147556,0.03565926236347666,0.0359005617623649,0.03615133882805946,0.03641096110197204,0.03667882541602482,0.03695436592516346,0.037237050076839896,0.037526369258675016,0.037821852335803874,0.03812305813687396,0.03842950652790741,0.038740782932702666,0.03905651302616389,0.0393763559793502,0.03969997067592497,0.040027048790271455,0.040357291704448454,0.040690422318404175,0.04102618435392125,0.041364326615309005,0.041704604773877635,0.0420468405056893,0.04239082120047193,0.04273634579087817,0.043083213046512095,0.04343138845334575,0.043780687897526954,0.04413083312031081,0.04448179153214202,0.04483340348420162,0.04518551672909852,0.045538007861405286,0.04589073688298471,0.04624352710699649,0.0465962766260407,0.04694886387003892,0.04730117222269735,0.04765309662032389,0.04800453138923093,0.04835537362951847,0.048705487104733686,0.0490547641221567,0.049403117872026864,0.04975046493110172,0.05009672527365955,0.05044182211523052,0.05078568182611754,0.05112829051299202,0.05146926892336682,0.051808588987475895,0.05214614122494522,0.05248190044924424,0.052815851901821045,0.05314797075484228,0.053478232747552465,0.05380661420115737,0.05413309209101269,0.054458151432564286,0.05478173472238171,0.055103800491697774,0.0554242894534593,0.05574770190466969,0.05607539308012776,0.05640142569253584,0.056725718075220866,0.05704825911646309,0.057369013585456714,0.05768795103015809,0.05800705521141294,0.058324598348843536,0.058640307310871054,0.058954174884424185,0.059266173311310316,0.05957627913529563,0.05988444396519272,0.06019066176475872,0.06049491562063846,0.06079719110107534,0.0610974522203645,0.06139569067762761,0.061691687201985146,0.06198545373028817,0.06227667157732807,0.06256535356564755,0.06285154442302587,0.06313528320545755,0.06341614625700656,0.06369420635324377,0.06396956141990154,0.0642422810943259,0.06451241999908051,0.06478002908962878,0.06504515244839891,0.06530784514382251,0.0655681489038695,0.06582606132733848,0.06608162323608995,0.06633487488769048,0.06658584426142419,0.06683458039956808,0.06708111762911212,0.06732548896411666,0.06756772233525353,0.0678078487359835,0.06804589216071547,0.06828188219926751,0.0685157722542618,0.06874749998427776,0.0689778094438803,0.06920667468677852,0.06943410102962908,0.0696599399237589,0.0698842108553971,0.07010569337788068,0.07032441241722087,0.07054045674869501,0.07075390715614574,0.07096483916804527,0.0711733200823495,0.07137941173235654,0.07158304733843138,0.07178424815364876,0.07198295295186144,0.0721792122320809,0.07237308027844017,0.07256461209618248,0.07275398173570327,0.07294123756228924,0.07312576261987977,0.07330765124099246,0.073486995252348,0.07366389575864143,0.0738372802516263,0.07400732577191357,0.07417419519398621,0.07433718616087154,0.07449634171034245,0.07465189069860673,0.07480403886989752,0.07495297685568193,0.07509881936534267,0.07524173256147451,0.07538186999906131,0.07551944538975143,0.0756545094679948,0.0757870617976951,0.0759167929180647,0.07604691861998682,0.07617758191529106,0.07630865330266744,0.07643999648947601,0.07657144300704788,0.07670288938726738,0.07683422972595116,0.07696538848757782,0.07709624305875135,0.0772266746411837,0.07735675485860831,0.07748284228944174,0.07760493933006093,0.0777233456785167,0.07783834833080559,0.0779591532707358,0.07807923383361268,0.07819695943226823,0.07831250422016663,0.07842597728247279,0.07853752927726451,0.078647297005839,0.07875541229192734,0.07886199712271769,0.07896716455348604,0.07907101952075515,0.07917366112844727,0.07926785878495757,0.07935630397835935,0.0794438418701755,0.07953052227392254,0.0796163930690316,0.07970150030880771,0.07978577953069585,0.07986928500878647,0.07995203639810936,0.08003406491416207,0.0801154324159585],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.45],\"title\":{\"text\":\"Epoch\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.625,1.0],\"title\":{\"text\":\"Estimate\"}},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.55,1.0],\"title\":{\"text\":\"Epoch\"}},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.625,1.0],\"title\":{\"text\":\"Variance\"}},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.0,0.45],\"title\":{\"text\":\"Epoch\"}},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,0.375],\"title\":{\"text\":\"MSE Loss\"}},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.55,1.0],\"title\":{\"text\":\"Epoch\"}},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.0,0.375],\"title\":{\"text\":\"MSE\"}},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Estimate over Epochs\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Variance over Epochs\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Shaping Train MSE Loss over Epochs\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Total MSE over Epochs\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Metrics over Epochs\"},\"showlegend\":true},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('44b51df4-8f1a-4b37-a3b0-9441906a3492');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env = test_experiment.initialize_env()"
      ],
      "metadata": {
        "id": "a31Sm5GXpYzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env.main_deaths"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcwofDocCUP5",
        "outputId": "3366887b-7cd2-4459-e2c3-ad9bec0e9e0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[9, 0],\n",
              " [9, 1],\n",
              " [9, 2],\n",
              " [9, 3],\n",
              " [9, 4],\n",
              " [9, 5],\n",
              " [9, 6],\n",
              " [9, 7],\n",
              " [9, 8],\n",
              " [9, 9],\n",
              " [8, 0]]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.dead_ends"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTLCPERtCWIJ",
        "outputId": "cd4c91ad-9993-4ab5-8a7d-9a0e80acb061"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[5, 5],\n",
              " [5, 6],\n",
              " [5, 7],\n",
              " [5, 8],\n",
              " [5, 9],\n",
              " [6, 5],\n",
              " [6, 6],\n",
              " [6, 7],\n",
              " [6, 8],\n",
              " [6, 9],\n",
              " [7, 5],\n",
              " [7, 6],\n",
              " [7, 7],\n",
              " [7, 8],\n",
              " [7, 9],\n",
              " [8, 5],\n",
              " [8, 6],\n",
              " [8, 7],\n",
              " [8, 8],\n",
              " [8, 9]]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.dead_ends + env.main_deaths"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2zxYGXrCfM2",
        "outputId": "6b0e8ceb-b5ce-4fa7-b55e-36a2e85705fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[5, 5],\n",
              " [5, 6],\n",
              " [5, 7],\n",
              " [5, 8],\n",
              " [5, 9],\n",
              " [6, 5],\n",
              " [6, 6],\n",
              " [6, 7],\n",
              " [6, 8],\n",
              " [6, 9],\n",
              " [7, 5],\n",
              " [7, 6],\n",
              " [7, 7],\n",
              " [7, 8],\n",
              " [7, 9],\n",
              " [8, 5],\n",
              " [8, 6],\n",
              " [8, 7],\n",
              " [8, 8],\n",
              " [8, 9],\n",
              " [9, 0],\n",
              " [9, 1],\n",
              " [9, 2],\n",
              " [9, 3],\n",
              " [9, 4],\n",
              " [9, 5],\n",
              " [9, 6],\n",
              " [9, 7],\n",
              " [9, 8],\n",
              " [9, 9],\n",
              " [8, 0]]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def smallest_distance_to_dead_end_or_death(current_state,env):\n",
        "\n",
        "    all_death = env.main_deaths + env.dead_ends\n",
        "    return min(manhattan_distance(current_state, dead_end) for dead_end in all_death)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def bottleneck_four_regions_k_p9_a_1(current_state, env,k = 0.9,a = 1):\n",
        "\n",
        "    # Bottom left region\n",
        "    if current_state[0] <4 and current_state[1]>4:\n",
        "        dist_to_bottleneck = manhattan_distance(current_state, [0,5])\n",
        "        return k*math.exp(-a*dist_to_bottleneck)\n",
        "\n",
        "    # Top left region\n",
        "    elif current_state[0] <5 and current_state[1] <5:\n",
        "        dist_to_recovery = smallest_distance_to_recovery(current_state,env)\n",
        "        return k*math.exp(-a*dist_to_recovery) + 0.1\n",
        "\n",
        "    # Top right region\n",
        "    elif current_state[0]>4 and current_state[1]<5:\n",
        "        dist_to_recovery = smallest_distance_to_recovery(current_state,env)\n",
        "        dist_to_ded_death = smallest_distance_to_dead_end_or_death(current_state, env)\n",
        "        # diff_distance = dist_to_recovery - dist_to_deadend\n",
        "        return k*math.exp(-a*dist_to_recovery) - k*math.exp(-a*dist_to_ded_death)\n",
        "\n",
        "    # Bottom right region\n",
        "    elif current_state[0]>3 and current_state[1]>4:\n",
        "        dist_to_ded_death = smallest_distance_to_dead_end_or_death(current_state, env)\n",
        "        return -k*math.exp(-a*dist_to_ded_death) - 0.1"
      ],
      "metadata": {
        "id": "wcMrEd25DcMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_bottleneck_function():\n",
        "    grid_size = 10\n",
        "    values = np.zeros((grid_size, grid_size))\n",
        "\n",
        "    # Example environment\n",
        "    # env = {\n",
        "    #     'recovery': [[2, 2], [4, 4]],  # Define recovery points\n",
        "    #     'deadend': [[7, 2], [9, 1]]   # Define deadend points\n",
        "    # }\n",
        "\n",
        "    for i in range(grid_size):\n",
        "        for j in range(grid_size):\n",
        "            current_state = [j, i]\n",
        "            values[i, j] = bottleneck_four_regions_k_p9_a_1(current_state, env)\n",
        "\n",
        "    # Reverse the y-axis values for the flip\n",
        "    values = values[::-1]\n",
        "\n",
        "    fig = go.Figure(data=go.Heatmap(\n",
        "        z=values,\n",
        "        x=list(range(grid_size)),\n",
        "        y=list(range(grid_size)),\n",
        "        colorscale='Viridis'\n",
        "    ))\n",
        "\n",
        "    fig.update_layout(\n",
        "        title='Bottleneck Function Values on 10x10 Grid',\n",
        "        xaxis_title='X',\n",
        "        yaxis_title='Y',\n",
        "        yaxis=dict(scaleanchor=\"x\", scaleratio=1)  # Ensure the aspect ratio is equal\n",
        "    )\n",
        "\n",
        "    fig.show()\n",
        "\n",
        "plot_bottleneck_function()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "CZveFUFTpUJB",
        "outputId": "77de417d-7805-4fd8-bd53-cbaffa99660e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"f6ab374f-90ac-4afa-8018-46409bad5f5e\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"f6ab374f-90ac-4afa-8018-46409bad5f5e\")) {                    Plotly.newPlot(                        \"f6ab374f-90ac-4afa-8018-46409bad5f5e\",                        [{\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"x\":[0,1,2,3,4,5,6,7,8,9],\"y\":[0,1,2,3,4,5,6,7,8,9],\"z\":[[0.01648407499986076,0.006064152299176921,0.0022308769589997226,0.0008206937689990647,-0.43109149705429817,-1.0,-1.0,-1.0,-1.0,-1.0],[0.04480836153107755,0.01648407499986076,0.006064152299176921,0.0022308769589997226,-0.43109149705429817,-1.0,-1.0,-1.0,-1.0,-1.0],[0.12180175491295143,0.04480836153107755,0.01648407499986076,0.006064152299176921,-0.43109149705429817,-1.0,-1.0,-1.0,-1.0,-1.0],[0.33109149705429813,0.12180175491295143,0.04480836153107755,0.01648407499986076,-0.43109149705429817,-1.0,-1.0,-1.0,-1.0,-1.0],[0.9,0.33109149705429813,0.12180175491295143,0.04480836153107755,-0.43109149705429817,-1.0,-1.0,-1.0,-1.0,-1.0],[0.10011106882367801,0.10030191636511226,0.10082069376899908,0.10223087695899973,0.10606415229917693,-0.31460742205443737,-0.31460742205443737,-0.31460742205443737,-0.32502734475512124,-0.8977691230410003],[0.10030191636511226,0.10082069376899908,0.10223087695899973,0.10606415229917693,0.11648407499986077,-0.07699339338187389,-0.07699339338187389,-0.07699339338187389,-0.31460742205443737,-0.8939358477008231],[0.10082069376899908,0.10223087695899973,0.10606415229917693,0.11648407499986077,0.14480836153107757,0.07699339338187389,0.07699339338187389,0.0,-0.2862831355232206,-0.8835159250001393],[0.10223087695899973,0.10606415229917693,0.11648407499986077,0.14480836153107757,0.22180175491295145,0.31460742205443737,0.2862831355232206,0.2092897421413467,-0.2092897421413467,-0.8551916384689224],[0.10606415229917693,0.11648407499986077,0.14480836153107757,0.22180175491295145,0.43109149705429817,0.8551916384689224,0.7781982450870486,0.5689085029457019,-0.5689085029457019,-0.7781982450870486]],\"type\":\"heatmap\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"yaxis\":{\"title\":{\"text\":\"Y\"},\"scaleanchor\":\"x\",\"scaleratio\":1},\"title\":{\"text\":\"Bottleneck Function Values on 10x10 Grid\"},\"xaxis\":{\"title\":{\"text\":\"X\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('f6ab374f-90ac-4afa-8018-46409bad5f5e');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grid_size = 10\n",
        "values = np.zeros((grid_size, grid_size))\n",
        "\n",
        "# # Example environment\n",
        "# env = {\n",
        "#     'recovery': [[2, 2], [4, 4]],  # Define recovery points\n",
        "#     'deadend': [[7, 2], [9, 1]]   # Define deadend points\n",
        "# }\n",
        "\n",
        "for i in range(grid_size):\n",
        "    for j in range(grid_size):\n",
        "        current_state = [i, j]\n",
        "        values[i, j] = bottleneck_four_regions_k_p9_a_1(current_state, env)\n",
        "\n",
        "fig = go.Figure(data=go.Heatmap(\n",
        "    z=values,\n",
        "    x=list(range(grid_size)),\n",
        "    y=list(range(grid_size)),\n",
        "    colorscale='Viridis'\n",
        "))\n",
        "\n",
        "fig.update_layout(\n",
        "    title='Bottleneck Function Values on 10x10 Grid',\n",
        "    xaxis_title='X',\n",
        "    yaxis_title='Y',\n",
        "    yaxis=dict(scaleanchor=\"x\", scaleratio=1)  # Ensure the aspect ratio is equal\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "7w_wnPqNplqT",
        "outputId": "f0fc1d2d-d232-44fe-ed53-be38b66715da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'bottleneck_four_regions_k_p9_a_1' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-df61483994ae>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mcurrent_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbottleneck_four_regions_k_p9_a_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m fig = go.Figure(data=go.Heatmap(\n",
            "\u001b[0;31mNameError\u001b[0m: name 'bottleneck_four_regions_k_p9_a_1' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# No dropout or regularization"
      ],
      "metadata": {
        "id": "S44qA-ec0X2P"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "st1ezEeq0e3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combination of distance to dead end and recovery"
      ],
      "metadata": {
        "id": "KSP3b6LWSgc0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7GKZp_nYkyOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Misc."
      ],
      "metadata": {
        "id": "a1eS6jbCSRTx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the varying trajectory lengths\n",
        "trajectory_lengths = [200, 400, 600, 800, 1000]\n",
        "\n",
        "# Iterate over each trajectory length and create corresponding experiments\n",
        "for length in trajectory_lengths:\n",
        "    # Modify the base parameters for each experiment\n",
        "    params = base_params_test.copy()  # Make a copy to avoid modifying the base parameters\n",
        "    params[\"num_trajectories\"] = length  # Update the number of trajectories\n",
        "\n",
        "    # Create an instance of SCOPE_experiment with modified parameters\n",
        "    test_experiment = SCOPE_experiment(**params)\n",
        "    test_experiment.run_experiment()  # Assuming you have a run_experiment method"
      ],
      "metadata": {
        "id": "I3zaV_eZjC9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "WBxRlu_QV17g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    # Parameters related to policy generation\n",
        "    \"pi_b_top_k\": 1,\n",
        "    \"pi_b_epsilon\": 0.4,\n",
        "    \"pi_e_top_k\": 1,\n",
        "    \"pi_e_epsilon\": 0.05,\n",
        "    \"q_table\": q_table,\n",
        "    \"gamma\": 0.99,\n",
        "    \"num_trajectories\": 200,\n",
        "    \"num_bootstraps\": 10000,\n",
        "    \"percent_to_estimate_phi\": 0.3,\n",
        "\n",
        "    # Parameters related to shaping\n",
        "    \"shaping_feature\": smallest_distance_to_deadend,\n",
        "    \"shaping_coefficient\": 0.1,\n",
        "\n",
        "    # Parameters related to neural network architecture and training\n",
        "    \"hidden_dims\": [8, 8],\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"dropout_prob\": 0.2,\n",
        "    \"l1_reg\": 0.00001,\n",
        "    \"l2_reg\": 0.00001,\n",
        "    \"scope_weight\": 1,\n",
        "    \"mse_weight\": 1,\n",
        "    \"num_epochs\": 300,\n",
        "\n",
        "    # Parameters related to environment\n",
        "    \"max_length\": 50,\n",
        "    \"death_drag\": 0.0,\n",
        "    # Other general parameters\n",
        "    \"dtype\": torch.float64,\n",
        "    \"experiment_type\": \"test\",\n",
        "    \"folder_path\": \"/content/drive/MyDrive/Lifegate_experiments\"\n",
        "    # \"folder_path\": \"/content\"\n",
        "}"
      ],
      "metadata": {
        "id": "5ftUhy9SWClZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_experiment = SCOPE_experiment(**params)\n",
        "test_load = existing_experiments(test_experiment)\n",
        "# IS_all_means, IS_all_variances, Train_means, Train_variances, Test_means, Test_variances = test_load.load_multi_estimates()"
      ],
      "metadata": {
        "id": "BsG7PzsNWGbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_trajectories = [200, 400, 600, 800, 1000]\n",
        "dims = [[8], [8,8], [32]]\n",
        "trajectory_length = [30, 50, 70, 100]\n",
        "\n",
        "for i in dims:\n",
        "  params[\"hidden_dims\"] = i\n",
        "  for len in trajectory_length:\n",
        "    params[\"max_length\"] = len\n",
        "    viz_over_num_trajectories_multi(params, num_trajectories, save=True, folder_path=None, filename=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_ytSIBC7FwI",
        "outputId": "86f310aa-21d9-49b0-a713-f875aef7df8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/Shaping/multi_experiment_visualisations.py:203: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
            "  fig, axs = plt.subplots(3, 1, figsize=(10, 18))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_trajectories = [200, 400, 600, 800, 1000]\n",
        "viz_over_num_trajectories_multi(params, num_trajectories, save=True, folder_path=None, filename=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJL_Zxkn5AfZ",
        "outputId": "cbdc1376-94cc-425f-82fd-3b1a2697078e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/Shaping/SCOPE_straight.py:115: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  padded_timestep_tensors = torch.tensor(padded_timesteps, dtype = self.dtype)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_load.get_heatmap()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "CHWKSXmcIAmP",
        "outputId": "3a4fbef8-c7ea-40c2-890c-6f5f861b0284"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"866c5898-3652-49bb-9dbc-caba5095ea1f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"866c5898-3652-49bb-9dbc-caba5095ea1f\")) {                    Plotly.newPlot(                        \"866c5898-3652-49bb-9dbc-caba5095ea1f\",                        [{\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"z\":[[0.4435052876164469,0.42251285088190094,0.45153827555022275,0.5252388090472102,0.5624928565401094,0.5997469040330086,0.6370009515259079,0.6742549990188071,0.7115090465117064,0.7487630940046056],[0.44368191813669744,0.42619337660654993,0.4101422363631683,0.4108541809316323,0.4127540061282623,0.522784388038271,0.5600545141019364,0.5973085615948356,0.6345626090877348,0.671816656580634],[0.4486566102672189,0.4311680687370714,0.41367952720692386,0.4101422363631683,0.4101422363631683,0.4114664234547256,0.41336624865135563,0.4818760549254745,0.5576161716637632,0.5948702191566626],[0.45313604025425813,0.43569448622245266,0.41825293219064724,0.4101422363631683,0.4101422363631683,0.4101422363631683,0.41020862257870666,0.41210188833578765,0.41399515409286863,0.4409115053020096],[0.45679885593452313,0.43935730190271766,0.42191574787091224,0.4101422363631683,0.4101422363631683,0.4101422363631683,0.4101422363631683,0.4101422363631683,0.4109908837502334,0.4128841495073144],[0.4604616716147881,0.4430201175829826,0.42557856355117724,0.4101422363631683,0.4101422363631683,0.4101422363631683,0.4101422363631683,0.4101422363631683,0.4101422363631683,0.4101422363631683],[0.4641244872950531,0.4466829332632477,0.4292413792314423,0.41179982519963676,0.4101422363631683,0.4101422363631683,0.4101422363631683,0.4101422363631683,0.4101422363631683,0.4101422363631683],[0.4677873029753181,0.45034574894351265,0.43290419491170723,0.4154626408799018,0.4101422363631683,0.4101422363631683,0.4101422363631683,0.4101422363631683,0.4101422363631683,0.4101422363631683],[0.4714501186555831,0.4540085646237777,0.43656701059197217,0.41912545656016675,0.4101422363631683,0.4101422363631683,0.4101422363631683,0.4101422363631683,0.4101422363631683,0.4101422363631683],[0.4751129343358481,0.4576713803040427,0.4402298262722372,0.42278827224043175,0.4101422363631683,0.4101422363631683,0.4101422363631683,0.4101422363631683,0.4101422363631683,0.4101422363631683]],\"type\":\"heatmap\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"Values\"},\"ticks\":\"outside\",\"tickvals\":[0.4101422363631683,0.7487630940046056],\"ticktext\":[0.4101422363631683,0.7487630940046056]}},\"xaxis\":{\"tickvals\":[0,1,2,3,4,5,6,7,8,9],\"ticktext\":[0,1,2,3,4,5,6,7,8,9],\"title\":{\"text\":\"X\"}},\"yaxis\":{\"tickvals\":[9,8,7,6,5,4,3,2,1,0],\"ticktext\":[9,8,7,6,5,4,3,2,1,0],\"title\":{\"text\":\"Y\"},\"autorange\":\"reversed\"},\"title\":{\"text\":\"Heatmap\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('866c5898-3652-49bb-9dbc-caba5095ea1f');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env = test_experiment.initialize_env()"
      ],
      "metadata": {
        "id": "3UupAQsoML-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env.main_deaths"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ufAGLkwMZ-a",
        "outputId": "0c14cd18-d7e5-427d-e804-8c66cb0f768d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[9, 0],\n",
              " [9, 1],\n",
              " [9, 2],\n",
              " [9, 3],\n",
              " [9, 4],\n",
              " [9, 5],\n",
              " [9, 6],\n",
              " [9, 7],\n",
              " [9, 8],\n",
              " [9, 9],\n",
              " [8, 0]]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kq_sDaQ965pv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_load.load_on_policy_estimate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrBmiXm2yMx6",
        "outputId": "d5e4c371-7f3d-4359-d68e-7e38bcacaa46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8514780808647641"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[estimate - test_load.load_on_policy_estimate() for estimate in IS_all_means]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbdoBTz5xzPE",
        "outputId": "e223f82b-40d9-473a-b793-7b24f3899d19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.6832966869467842,\n",
              " 1.7093622028177835,\n",
              " 1.71117787960983,\n",
              " 1.7293877726207971,\n",
              " 1.7048175696304875]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_experiment.get_multi_experiment()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExOYtF9yYXxS",
        "outputId": "0caf41ac-8d03-44d0-a6fa-d347fa5e65eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/Shaping/SCOPE_straight.py:115: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  padded_timestep_tensors = torch.tensor(padded_timesteps, dtype = self.dtype)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([2.5290068415280103,\n",
              "  2.5482847820745445,\n",
              "  2.553100612083396,\n",
              "  2.5279662530334126,\n",
              "  2.561294712012935],\n",
              " [2.2950895376523412,\n",
              "  2.3045730505152293,\n",
              "  2.25439504747676,\n",
              "  2.354724263194598,\n",
              "  2.301225143136116],\n",
              " [4.066361256809858,\n",
              "  4.05700443802146,\n",
              "  4.139420225588691,\n",
              "  4.090003913832987,\n",
              "  4.010852962560537],\n",
              " [16.255051428225073,\n",
              "  16.039218957691634,\n",
              "  16.407065601508204,\n",
              "  16.61423409290501,\n",
              "  15.986347081758947],\n",
              " [2.307795945640806,\n",
              "  2.293187794614861,\n",
              "  2.3104521327752665,\n",
              "  2.2658604438947374,\n",
              "  2.3152241242410154],\n",
              " [3.105943786183369,\n",
              "  3.0943760957291935,\n",
              "  3.082721648820779,\n",
              "  3.0886605708466432,\n",
              "  3.120175526084799])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "szpRT5N0ujpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Continue Training"
      ],
      "metadata": {
        "id": "wV9zV-WgHqL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_params_load = {\n",
        "    # Parameters related to policy generation\n",
        "    \"pi_b_top_k\": 1,\n",
        "    \"pi_b_epsilon\": 0.4,\n",
        "    \"pi_e_top_k\": 1,\n",
        "    \"pi_e_epsilon\": 0.05,\n",
        "    \"q_table\": q_table,\n",
        "    \"gamma\": 0.99,\n",
        "    \"num_trajectories\": 200,\n",
        "    \"num_bootstraps\": 10000,\n",
        "    \"percent_to_estimate_phi\": 0.3,\n",
        "\n",
        "    # Parameters related to shaping\n",
        "    \"shaping_feature\": smallest_distance_to_deadend,\n",
        "    \"shaping_coefficient\": 0.1,\n",
        "\n",
        "    # Parameters related to neural network architecture and training\n",
        "    \"hidden_dims\": [8],\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"dropout_prob\": 0.2,\n",
        "    \"l1_reg\": 0.00001,\n",
        "    \"l2_reg\": 0.00001,\n",
        "    \"scope_weight\": 1,\n",
        "    \"mse_weight\": 1,\n",
        "    \"num_epochs\": 300,\n",
        "\n",
        "    # Parameters related to environment\n",
        "    \"max_length\": 30,\n",
        "    \"death_drag\": 0.0,\n",
        "    # Other general parameters\n",
        "    \"dtype\": torch.float64,\n",
        "    \"experiment_type\": \"test\",\n",
        "    \"folder_path\": \"/content/drive/MyDrive/Lifegate_experiments\"\n",
        "    # \"folder_path\": \"/content\"\n",
        "}"
      ],
      "metadata": {
        "id": "Jt5uzyLlHsII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_experiment = SCOPE_experiment(**base_params_load)"
      ],
      "metadata": {
        "id": "RlpSfzDhH2J7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_experiment.continue_training(100)"
      ],
      "metadata": {
        "id": "MeweS6DRH92l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving Plots"
      ],
      "metadata": {
        "id": "mvqvPLEYsG9x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_params_load = {\n",
        "    # Parameters related to policy generation\n",
        "    \"pi_b_top_k\": 1,\n",
        "    \"pi_b_epsilon\": 0.4,\n",
        "    \"pi_e_top_k\": 1,\n",
        "    \"pi_e_epsilon\": 0.05,\n",
        "    \"q_table\": q_table,\n",
        "    \"gamma\": 0.99,\n",
        "    \"num_trajectories\": 200,\n",
        "    \"num_bootstraps\": 10000,\n",
        "    \"percent_to_estimate_phi\": 0.3,\n",
        "\n",
        "    # Parameters related to shaping\n",
        "    \"shaping_feature\": smallest_distance_to_deadend,\n",
        "    \"shaping_coefficient\": 0.1,\n",
        "\n",
        "    # Parameters related to neural network architecture and training\n",
        "    \"hidden_dims\": [32],\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"dropout_prob\": 0.2,\n",
        "    \"l1_reg\": 0.00001,\n",
        "    \"l2_reg\": 0.00001,\n",
        "    \"scope_weight\": 1,\n",
        "    \"mse_weight\": 1,\n",
        "    \"num_epochs\": 300,\n",
        "\n",
        "    # Parameters related to environment\n",
        "    \"max_length\": 100,\n",
        "    \"death_drag\": 0.0,\n",
        "    # Other general parameters\n",
        "    \"dtype\": torch.float64,\n",
        "    \"experiment_type\": \"test\",\n",
        "    \"folder_path\": \"/content/drive/MyDrive/Lifegate_experiments\"\n",
        "    # \"folder_path\": \"/content\"\n",
        "}"
      ],
      "metadata": {
        "id": "FL48kB1dsIo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_trajectories = [200, 400, 600, 800, 1000]\n",
        "\n",
        "def save__experiments_over_trajectories(base_params_load, num_trajectories):\n",
        "  for i in num_trajectories:\n",
        "    print(\"-\"*100)\n",
        "    print(f\"{i} trajectories: \")\n",
        "    print(\"-\"*100)\n",
        "    params = base_params_load.copy()\n",
        "    params[\"num_trajectories\"] = i\n",
        "    test_experiment = SCOPE_experiment(**params)\n",
        "    test_load = existing_experiments(test_experiment)\n",
        "    test_load.plot_metrics_save(save = True)\n",
        "    # test_load.plot_metrics()\n",
        "    print(test_load.experiment_instance.generate_file_name())\n",
        "\n",
        "  viz_over_num_trajectories_save(base_params_load, num_trajectories)"
      ],
      "metadata": {
        "id": "w72v9XTLsWKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_trajectories = [200, 400, 600, 800, 1000]\n",
        "dims = [[8], [8,8], [32]]\n",
        "\n",
        "\n",
        "for i in dims:\n",
        "  params_dim = base_params_load.copy()\n",
        "  params_dim[\"hidden_dims\"] = dims\n",
        "  save__experiments_over_trajectories(params_dim, num_trajectories)\n"
      ],
      "metadata": {
        "id": "KidowxUYLQcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_trajectories = [200, 400, 600, 800, 1000]\n",
        "viz_over_num_trajectories_save(base_params_load, num_trajectories)"
      ],
      "metadata": {
        "id": "aZly5HOasdn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Latex figure code generation"
      ],
      "metadata": {
        "id": "_f_VMH6o5gsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "b = \"123\"\n",
        "figure_names = [\"a\", \"b\"]\n",
        "# LaTeX template for including figures\n",
        "latex_template = r\"\"\"\n",
        "\\begin{figure}[h]\n",
        "    \\centering\n",
        "    \\includegraphics[width=\\textwidth]{%s.png}\n",
        "    \\caption{Caption for %s}\n",
        "    \\label{fig:%s}\n",
        "\\end{figure}\n",
        "\"\"\"\n",
        "\n",
        "# Loop through figure names and generate LaTeX code\n",
        "for name in figure_names:\n",
        "    latex_code = latex_template % (name, b, name)\n",
        "    print(latex_code)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dh-96-jg5kS4",
        "outputId": "2d6ede21-0f14-44fb-86f4-7e078b815681"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\\begin{figure}[h]\n",
            "    \\centering\n",
            "    \\includegraphics[width=\\textwidth]{a.png}\n",
            "    \\caption{Caption for 123}\n",
            "    \\label{fig:a}\n",
            "\\end{figure}\n",
            "\n",
            "\n",
            "\\begin{figure}[h]\n",
            "    \\centering\n",
            "    \\includegraphics[width=\\textwidth]{b.png}\n",
            "    \\caption{Caption for 123}\n",
            "    \\label{fig:b}\n",
            "\\end{figure}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the varying trajectory lengths\n",
        "num_trajectories = [200, 400, 600, 800, 1000]\n",
        "# Define hidden_dims\n",
        "hidden_dimens = [[8],[8,8],[32]]\n",
        "# Define trajectory lengths\n",
        "trajectory_length = [30, 50, 70, 100]\n",
        "\n",
        "for num in num_trajectories:\n",
        "  # Modify the base parameters for each experiment\n",
        "  # params = base_params_test.copy()  # Make a copy to avoid modifying the base parameters\n",
        "  params[\"num_trajectories\"] = num  # Update the number of trajectories\n",
        "\n",
        "  for dims in hidden_dimens:\n",
        "    # params = base_params_test.copy()  # Make a copy to avoid modifying the base parameters\n",
        "    params[\"hidden_dims\"] = dims\n",
        "\n",
        "    for len in trajectory_length:\n",
        "      params[\"max_length\"] = len\n",
        "\n",
        "      # Create an instance of SCOPE_experiment with modified parameters\n",
        "      test_experiment = SCOPE_experiment(**params)\n",
        "      # test_experiment.run_experiment()\n",
        "      test_load = existing_experiments(test_experiment)\n",
        "      # test_load.plot_metrics_save(save = True)\n",
        "      # print(test_load.experiment_instance.generate_file_name())\n",
        "      filename = test_load.experiment_instance.generate_file_name()\n",
        "\n",
        "      num_trajectories = str(test_experiment.num_trajectories)\n",
        "      hidden_dims = str(test_experiment.hidden_dims[0])\n",
        "      max_length = str(test_experiment.max_length)\n",
        "\n",
        "      latex_template = r\"\"\"\n",
        "      \\subsection*{Experiment with Trajectories: %s Hidden Dimensions: %s Max. Trajectory Length: %s}\n",
        "\n",
        "      \\begin{figure}[h]\n",
        "          \\centering\n",
        "          \\includegraphics[width=\\textwidth]{plt_plots/%s.png}\n",
        "          \\caption{Metrics for Trajectories: %s Hidden Dimensions: %s Max. Trajectory Length: %s}\n",
        "          \\label{fig:%s}\n",
        "      \\end{figure}\n",
        "\n",
        "      \\begin{figure}[h]\n",
        "          \\centering\n",
        "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_%s.png}\n",
        "          \\caption{Shaping prediction heatmap for with Trajectories: %s Hidden Dimensions: %s Max. Trajectory Length: %s}\n",
        "          \\label{fig:%s}\n",
        "      \\end{figure}\n",
        "      \"\"\"\n",
        "      latex_code = latex_template % (num_trajectories, hidden_dims, max_length,filename, num_trajectories, hidden_dims, max_length,filename, filename, num_trajectories, hidden_dims, max_length,filename )\n",
        "      print(latex_code)\n",
        "\n",
        "      # test_load.get_heatmap()\n",
        "      # test_load.save_heatmap()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ssuV0qw6jYN",
        "outputId": "3b67c610-bf6e-47a3-d314-672d7e7ad1bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      \\subsection*{Experiment with Trajectories: 200 Hidden Dimensions: 8 Max. Trajectory Length: 30}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Metrics for Trajectories: 200 Hidden Dimensions: 8 Max. Trajectory Length: 30}\n",
            "          \\label{fig:200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 200 Hidden Dimensions: 8 Max. Trajectory Length: 30}\n",
            "          \\label{fig:200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 200 Hidden Dimensions: 8 Max. Trajectory Length: 50}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Metrics for Trajectories: 200 Hidden Dimensions: 8 Max. Trajectory Length: 50}\n",
            "          \\label{fig:200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 200 Hidden Dimensions: 8 Max. Trajectory Length: 50}\n",
            "          \\label{fig:200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 200 Hidden Dimensions: 8 Max. Trajectory Length: 70}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Metrics for Trajectories: 200 Hidden Dimensions: 8 Max. Trajectory Length: 70}\n",
            "          \\label{fig:200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 200 Hidden Dimensions: 8 Max. Trajectory Length: 70}\n",
            "          \\label{fig:200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 200 Hidden Dimensions: 8 Max. Trajectory Length: 100}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Metrics for Trajectories: 200 Hidden Dimensions: 8 Max. Trajectory Length: 100}\n",
            "          \\label{fig:200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 200 Hidden Dimensions: 8 Max. Trajectory Length: 100}\n",
            "          \\label{fig:200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 200 Hidden Dimensions: 8 Max. Trajectory Length: 30}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Metrics for Trajectories: 200 Hidden Dimensions: 8 Max. Trajectory Length: 30}\n",
            "          \\label{fig:200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 200 Hidden Dimensions: 8 Max. Trajectory Length: 30}\n",
            "          \\label{fig:200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 200 Hidden Dimensions: 8 Max. Trajectory Length: 50}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Metrics for Trajectories: 200 Hidden Dimensions: 8 Max. Trajectory Length: 50}\n",
            "          \\label{fig:200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 200 Hidden Dimensions: 8 Max. Trajectory Length: 50}\n",
            "          \\label{fig:200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 200 Hidden Dimensions: 8 Max. Trajectory Length: 70}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Metrics for Trajectories: 200 Hidden Dimensions: 8 Max. Trajectory Length: 70}\n",
            "          \\label{fig:200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 200 Hidden Dimensions: 8 Max. Trajectory Length: 70}\n",
            "          \\label{fig:200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 200 Hidden Dimensions: 8 Max. Trajectory Length: 100}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Metrics for Trajectories: 200 Hidden Dimensions: 8 Max. Trajectory Length: 100}\n",
            "          \\label{fig:200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 200 Hidden Dimensions: 8 Max. Trajectory Length: 100}\n",
            "          \\label{fig:200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 200 Hidden Dimensions: 32 Max. Trajectory Length: 30}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Metrics for Trajectories: 200 Hidden Dimensions: 32 Max. Trajectory Length: 30}\n",
            "          \\label{fig:200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 200 Hidden Dimensions: 32 Max. Trajectory Length: 30}\n",
            "          \\label{fig:200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 200 Hidden Dimensions: 32 Max. Trajectory Length: 50}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Metrics for Trajectories: 200 Hidden Dimensions: 32 Max. Trajectory Length: 50}\n",
            "          \\label{fig:200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 200 Hidden Dimensions: 32 Max. Trajectory Length: 50}\n",
            "          \\label{fig:200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 200 Hidden Dimensions: 32 Max. Trajectory Length: 70}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Metrics for Trajectories: 200 Hidden Dimensions: 32 Max. Trajectory Length: 70}\n",
            "          \\label{fig:200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 200 Hidden Dimensions: 32 Max. Trajectory Length: 70}\n",
            "          \\label{fig:200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 200 Hidden Dimensions: 32 Max. Trajectory Length: 100}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Metrics for Trajectories: 200 Hidden Dimensions: 32 Max. Trajectory Length: 100}\n",
            "          \\label{fig:200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 200 Hidden Dimensions: 32 Max. Trajectory Length: 100}\n",
            "          \\label{fig:200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 400 Hidden Dimensions: 8 Max. Trajectory Length: 30}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Metrics for Trajectories: 400 Hidden Dimensions: 8 Max. Trajectory Length: 30}\n",
            "          \\label{fig:400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 400 Hidden Dimensions: 8 Max. Trajectory Length: 30}\n",
            "          \\label{fig:400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 400 Hidden Dimensions: 8 Max. Trajectory Length: 50}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Metrics for Trajectories: 400 Hidden Dimensions: 8 Max. Trajectory Length: 50}\n",
            "          \\label{fig:400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 400 Hidden Dimensions: 8 Max. Trajectory Length: 50}\n",
            "          \\label{fig:400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 400 Hidden Dimensions: 8 Max. Trajectory Length: 70}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Metrics for Trajectories: 400 Hidden Dimensions: 8 Max. Trajectory Length: 70}\n",
            "          \\label{fig:400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 400 Hidden Dimensions: 8 Max. Trajectory Length: 70}\n",
            "          \\label{fig:400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 400 Hidden Dimensions: 8 Max. Trajectory Length: 100}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Metrics for Trajectories: 400 Hidden Dimensions: 8 Max. Trajectory Length: 100}\n",
            "          \\label{fig:400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 400 Hidden Dimensions: 8 Max. Trajectory Length: 100}\n",
            "          \\label{fig:400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 400 Hidden Dimensions: 8 Max. Trajectory Length: 30}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Metrics for Trajectories: 400 Hidden Dimensions: 8 Max. Trajectory Length: 30}\n",
            "          \\label{fig:400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 400 Hidden Dimensions: 8 Max. Trajectory Length: 30}\n",
            "          \\label{fig:400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 400 Hidden Dimensions: 8 Max. Trajectory Length: 50}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Metrics for Trajectories: 400 Hidden Dimensions: 8 Max. Trajectory Length: 50}\n",
            "          \\label{fig:400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 400 Hidden Dimensions: 8 Max. Trajectory Length: 50}\n",
            "          \\label{fig:400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 400 Hidden Dimensions: 8 Max. Trajectory Length: 70}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Metrics for Trajectories: 400 Hidden Dimensions: 8 Max. Trajectory Length: 70}\n",
            "          \\label{fig:400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 400 Hidden Dimensions: 8 Max. Trajectory Length: 70}\n",
            "          \\label{fig:400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 400 Hidden Dimensions: 8 Max. Trajectory Length: 100}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Metrics for Trajectories: 400 Hidden Dimensions: 8 Max. Trajectory Length: 100}\n",
            "          \\label{fig:400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 400 Hidden Dimensions: 8 Max. Trajectory Length: 100}\n",
            "          \\label{fig:400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 400 Hidden Dimensions: 32 Max. Trajectory Length: 30}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Metrics for Trajectories: 400 Hidden Dimensions: 32 Max. Trajectory Length: 30}\n",
            "          \\label{fig:400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 400 Hidden Dimensions: 32 Max. Trajectory Length: 30}\n",
            "          \\label{fig:400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 400 Hidden Dimensions: 32 Max. Trajectory Length: 50}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Metrics for Trajectories: 400 Hidden Dimensions: 32 Max. Trajectory Length: 50}\n",
            "          \\label{fig:400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 400 Hidden Dimensions: 32 Max. Trajectory Length: 50}\n",
            "          \\label{fig:400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 400 Hidden Dimensions: 32 Max. Trajectory Length: 70}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Metrics for Trajectories: 400 Hidden Dimensions: 32 Max. Trajectory Length: 70}\n",
            "          \\label{fig:400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 400 Hidden Dimensions: 32 Max. Trajectory Length: 70}\n",
            "          \\label{fig:400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 400 Hidden Dimensions: 32 Max. Trajectory Length: 100}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Metrics for Trajectories: 400 Hidden Dimensions: 32 Max. Trajectory Length: 100}\n",
            "          \\label{fig:400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 400 Hidden Dimensions: 32 Max. Trajectory Length: 100}\n",
            "          \\label{fig:400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 600 Hidden Dimensions: 8 Max. Trajectory Length: 30}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Metrics for Trajectories: 600 Hidden Dimensions: 8 Max. Trajectory Length: 30}\n",
            "          \\label{fig:600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 600 Hidden Dimensions: 8 Max. Trajectory Length: 30}\n",
            "          \\label{fig:600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 600 Hidden Dimensions: 8 Max. Trajectory Length: 50}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Metrics for Trajectories: 600 Hidden Dimensions: 8 Max. Trajectory Length: 50}\n",
            "          \\label{fig:600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 600 Hidden Dimensions: 8 Max. Trajectory Length: 50}\n",
            "          \\label{fig:600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 600 Hidden Dimensions: 8 Max. Trajectory Length: 70}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Metrics for Trajectories: 600 Hidden Dimensions: 8 Max. Trajectory Length: 70}\n",
            "          \\label{fig:600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 600 Hidden Dimensions: 8 Max. Trajectory Length: 70}\n",
            "          \\label{fig:600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 600 Hidden Dimensions: 8 Max. Trajectory Length: 100}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Metrics for Trajectories: 600 Hidden Dimensions: 8 Max. Trajectory Length: 100}\n",
            "          \\label{fig:600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 600 Hidden Dimensions: 8 Max. Trajectory Length: 100}\n",
            "          \\label{fig:600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 600 Hidden Dimensions: 8 Max. Trajectory Length: 30}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Metrics for Trajectories: 600 Hidden Dimensions: 8 Max. Trajectory Length: 30}\n",
            "          \\label{fig:600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 600 Hidden Dimensions: 8 Max. Trajectory Length: 30}\n",
            "          \\label{fig:600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 600 Hidden Dimensions: 8 Max. Trajectory Length: 50}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Metrics for Trajectories: 600 Hidden Dimensions: 8 Max. Trajectory Length: 50}\n",
            "          \\label{fig:600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 600 Hidden Dimensions: 8 Max. Trajectory Length: 50}\n",
            "          \\label{fig:600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 600 Hidden Dimensions: 8 Max. Trajectory Length: 70}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Metrics for Trajectories: 600 Hidden Dimensions: 8 Max. Trajectory Length: 70}\n",
            "          \\label{fig:600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 600 Hidden Dimensions: 8 Max. Trajectory Length: 70}\n",
            "          \\label{fig:600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 600 Hidden Dimensions: 8 Max. Trajectory Length: 100}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Metrics for Trajectories: 600 Hidden Dimensions: 8 Max. Trajectory Length: 100}\n",
            "          \\label{fig:600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 600 Hidden Dimensions: 8 Max. Trajectory Length: 100}\n",
            "          \\label{fig:600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 600 Hidden Dimensions: 32 Max. Trajectory Length: 30}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Metrics for Trajectories: 600 Hidden Dimensions: 32 Max. Trajectory Length: 30}\n",
            "          \\label{fig:600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 600 Hidden Dimensions: 32 Max. Trajectory Length: 30}\n",
            "          \\label{fig:600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 600 Hidden Dimensions: 32 Max. Trajectory Length: 50}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Metrics for Trajectories: 600 Hidden Dimensions: 32 Max. Trajectory Length: 50}\n",
            "          \\label{fig:600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 600 Hidden Dimensions: 32 Max. Trajectory Length: 50}\n",
            "          \\label{fig:600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 600 Hidden Dimensions: 32 Max. Trajectory Length: 70}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Metrics for Trajectories: 600 Hidden Dimensions: 32 Max. Trajectory Length: 70}\n",
            "          \\label{fig:600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 600 Hidden Dimensions: 32 Max. Trajectory Length: 70}\n",
            "          \\label{fig:600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 600 Hidden Dimensions: 32 Max. Trajectory Length: 100}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Metrics for Trajectories: 600 Hidden Dimensions: 32 Max. Trajectory Length: 100}\n",
            "          \\label{fig:600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 600 Hidden Dimensions: 32 Max. Trajectory Length: 100}\n",
            "          \\label{fig:600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 800 Hidden Dimensions: 8 Max. Trajectory Length: 30}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Metrics for Trajectories: 800 Hidden Dimensions: 8 Max. Trajectory Length: 30}\n",
            "          \\label{fig:800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 800 Hidden Dimensions: 8 Max. Trajectory Length: 30}\n",
            "          \\label{fig:800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 800 Hidden Dimensions: 8 Max. Trajectory Length: 50}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Metrics for Trajectories: 800 Hidden Dimensions: 8 Max. Trajectory Length: 50}\n",
            "          \\label{fig:800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 800 Hidden Dimensions: 8 Max. Trajectory Length: 50}\n",
            "          \\label{fig:800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 800 Hidden Dimensions: 8 Max. Trajectory Length: 70}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Metrics for Trajectories: 800 Hidden Dimensions: 8 Max. Trajectory Length: 70}\n",
            "          \\label{fig:800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 800 Hidden Dimensions: 8 Max. Trajectory Length: 70}\n",
            "          \\label{fig:800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 800 Hidden Dimensions: 8 Max. Trajectory Length: 100}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Metrics for Trajectories: 800 Hidden Dimensions: 8 Max. Trajectory Length: 100}\n",
            "          \\label{fig:800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 800 Hidden Dimensions: 8 Max. Trajectory Length: 100}\n",
            "          \\label{fig:800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 800 Hidden Dimensions: 8 Max. Trajectory Length: 30}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Metrics for Trajectories: 800 Hidden Dimensions: 8 Max. Trajectory Length: 30}\n",
            "          \\label{fig:800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 800 Hidden Dimensions: 8 Max. Trajectory Length: 30}\n",
            "          \\label{fig:800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 800 Hidden Dimensions: 8 Max. Trajectory Length: 50}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Metrics for Trajectories: 800 Hidden Dimensions: 8 Max. Trajectory Length: 50}\n",
            "          \\label{fig:800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 800 Hidden Dimensions: 8 Max. Trajectory Length: 50}\n",
            "          \\label{fig:800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 800 Hidden Dimensions: 8 Max. Trajectory Length: 70}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Metrics for Trajectories: 800 Hidden Dimensions: 8 Max. Trajectory Length: 70}\n",
            "          \\label{fig:800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 800 Hidden Dimensions: 8 Max. Trajectory Length: 70}\n",
            "          \\label{fig:800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 800 Hidden Dimensions: 8 Max. Trajectory Length: 100}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Metrics for Trajectories: 800 Hidden Dimensions: 8 Max. Trajectory Length: 100}\n",
            "          \\label{fig:800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 800 Hidden Dimensions: 8 Max. Trajectory Length: 100}\n",
            "          \\label{fig:800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 800 Hidden Dimensions: 32 Max. Trajectory Length: 30}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Metrics for Trajectories: 800 Hidden Dimensions: 32 Max. Trajectory Length: 30}\n",
            "          \\label{fig:800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 800 Hidden Dimensions: 32 Max. Trajectory Length: 30}\n",
            "          \\label{fig:800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 800 Hidden Dimensions: 32 Max. Trajectory Length: 50}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Metrics for Trajectories: 800 Hidden Dimensions: 32 Max. Trajectory Length: 50}\n",
            "          \\label{fig:800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 800 Hidden Dimensions: 32 Max. Trajectory Length: 50}\n",
            "          \\label{fig:800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 800 Hidden Dimensions: 32 Max. Trajectory Length: 70}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Metrics for Trajectories: 800 Hidden Dimensions: 32 Max. Trajectory Length: 70}\n",
            "          \\label{fig:800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 800 Hidden Dimensions: 32 Max. Trajectory Length: 70}\n",
            "          \\label{fig:800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 800 Hidden Dimensions: 32 Max. Trajectory Length: 100}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Metrics for Trajectories: 800 Hidden Dimensions: 32 Max. Trajectory Length: 100}\n",
            "          \\label{fig:800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 800 Hidden Dimensions: 32 Max. Trajectory Length: 100}\n",
            "          \\label{fig:800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 1000 Hidden Dimensions: 8 Max. Trajectory Length: 30}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Metrics for Trajectories: 1000 Hidden Dimensions: 8 Max. Trajectory Length: 30}\n",
            "          \\label{fig:1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 1000 Hidden Dimensions: 8 Max. Trajectory Length: 30}\n",
            "          \\label{fig:1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 1000 Hidden Dimensions: 8 Max. Trajectory Length: 50}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Metrics for Trajectories: 1000 Hidden Dimensions: 8 Max. Trajectory Length: 50}\n",
            "          \\label{fig:1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 1000 Hidden Dimensions: 8 Max. Trajectory Length: 50}\n",
            "          \\label{fig:1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 1000 Hidden Dimensions: 8 Max. Trajectory Length: 70}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Metrics for Trajectories: 1000 Hidden Dimensions: 8 Max. Trajectory Length: 70}\n",
            "          \\label{fig:1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 1000 Hidden Dimensions: 8 Max. Trajectory Length: 70}\n",
            "          \\label{fig:1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 1000 Hidden Dimensions: 8 Max. Trajectory Length: 100}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Metrics for Trajectories: 1000 Hidden Dimensions: 8 Max. Trajectory Length: 100}\n",
            "          \\label{fig:1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 1000 Hidden Dimensions: 8 Max. Trajectory Length: 100}\n",
            "          \\label{fig:1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 1000 Hidden Dimensions: 8 Max. Trajectory Length: 30}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Metrics for Trajectories: 1000 Hidden Dimensions: 8 Max. Trajectory Length: 30}\n",
            "          \\label{fig:1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 1000 Hidden Dimensions: 8 Max. Trajectory Length: 30}\n",
            "          \\label{fig:1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 1000 Hidden Dimensions: 8 Max. Trajectory Length: 50}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Metrics for Trajectories: 1000 Hidden Dimensions: 8 Max. Trajectory Length: 50}\n",
            "          \\label{fig:1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 1000 Hidden Dimensions: 8 Max. Trajectory Length: 50}\n",
            "          \\label{fig:1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 1000 Hidden Dimensions: 8 Max. Trajectory Length: 70}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Metrics for Trajectories: 1000 Hidden Dimensions: 8 Max. Trajectory Length: 70}\n",
            "          \\label{fig:1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 1000 Hidden Dimensions: 8 Max. Trajectory Length: 70}\n",
            "          \\label{fig:1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 1000 Hidden Dimensions: 8 Max. Trajectory Length: 100}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Metrics for Trajectories: 1000 Hidden Dimensions: 8 Max. Trajectory Length: 100}\n",
            "          \\label{fig:1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 1000 Hidden Dimensions: 8 Max. Trajectory Length: 100}\n",
            "          \\label{fig:1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 1000 Hidden Dimensions: 32 Max. Trajectory Length: 30}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Metrics for Trajectories: 1000 Hidden Dimensions: 32 Max. Trajectory Length: 30}\n",
            "          \\label{fig:1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 1000 Hidden Dimensions: 32 Max. Trajectory Length: 30}\n",
            "          \\label{fig:1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 1000 Hidden Dimensions: 32 Max. Trajectory Length: 50}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Metrics for Trajectories: 1000 Hidden Dimensions: 32 Max. Trajectory Length: 50}\n",
            "          \\label{fig:1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 1000 Hidden Dimensions: 32 Max. Trajectory Length: 50}\n",
            "          \\label{fig:1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 1000 Hidden Dimensions: 32 Max. Trajectory Length: 70}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Metrics for Trajectories: 1000 Hidden Dimensions: 32 Max. Trajectory Length: 70}\n",
            "          \\label{fig:1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 1000 Hidden Dimensions: 32 Max. Trajectory Length: 70}\n",
            "          \\label{fig:1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 1000 Hidden Dimensions: 32 Max. Trajectory Length: 100}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Metrics for Trajectories: 1000 Hidden Dimensions: 32 Max. Trajectory Length: 100}\n",
            "          \\label{fig:1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 1000 Hidden Dimensions: 32 Max. Trajectory Length: 100}\n",
            "          \\label{fig:1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the varying trajectory lengths\n",
        "num_trajectories_list = [200, 400, 600, 800, 1000]\n",
        "# Define hidden_dims\n",
        "hidden_dimens = [[8],[8,8],[32]]\n",
        "# Define trajectory lengths\n",
        "trajectory_length = [30, 50, 70, 100]\n",
        "\n",
        "for dims in hidden_dimens:\n",
        "  # params = base_params_test.copy()  # Make a copy to avoid modifying the base parameters\n",
        "  params[\"hidden_dims\"] = dims\n",
        "  for len in trajectory_length:\n",
        "    params[\"max_length\"] = len\n",
        "    for num in num_trajectories_list:\n",
        "      params[\"num_trajectories\"] = num  # Update the number of trajectories\n",
        "      # Create an instance of SCOPE_experiment with modified parameters\n",
        "      test_experiment = SCOPE_experiment(**params)\n",
        "      # test_experiment.run_experiment()\n",
        "      test_load = existing_experiments(test_experiment)\n",
        "      # test_load.plot_metrics_save(save = True)\n",
        "      # print(test_load.experiment_instance.generate_file_name())\n",
        "      filename = test_load.experiment_instance.generate_file_name()\n",
        "\n",
        "      num_trajectories = str(test_experiment.num_trajectories)\n",
        "      hidden_dims = str(test_experiment.hidden_dims[0])\n",
        "      max_length = str(test_experiment.max_length)\n",
        "\n",
        "      latex_template = r\"\"\"\n",
        "      \\subsection*{Experiment with Trajectories: %s Hidden Dimensions: %s Max. Trajectory Length: %s}\n",
        "\n",
        "      \\begin{figure}[H]\n",
        "          \\centering\n",
        "          \\includegraphics[width=\\textwidth]{plt_plots/%s.png}\n",
        "          \\caption{Metrics for Trajectories: %s Hidden Dimensions: %s Max. Trajectory Length: %s}\n",
        "          \\label{fig:%s}\n",
        "      \\end{figure}\n",
        "\n",
        "      \\begin{figure}[h]\n",
        "          \\centering\n",
        "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_%s.png}\n",
        "          \\caption{Shaping prediction heatmap for with Trajectories: %s Hidden Dimensions: %s Max. Trajectory Length: %s}\n",
        "          \\label{fig:%s}\n",
        "      \\end{figure}\n",
        "      \"\"\"\n",
        "      latex_code = latex_template % (num_trajectories, hidden_dims, max_length,filename, num_trajectories, hidden_dims, max_length,filename, filename, num_trajectories, hidden_dims, max_length,filename )\n",
        "      print(latex_code)\n",
        "\n",
        "      # test_load.get_heatmap()\n",
        "      # test_load.save_heatmap()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLWiZlTiLUXW",
        "outputId": "91850eeb-031a-4f33-adb5-14f16fe1cc14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      \\subsection*{Experiment with Trajectories: 200 Hidden Dimensions: 8 Max. Trajectory Length: 30}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Metrics for Trajectories: 200 Hidden Dimensions: 8 Max. Trajectory Length: 30}\n",
            "          \\label{fig:200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 200 Hidden Dimensions: 8 Max. Trajectory Length: 30}\n",
            "          \\label{fig:200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 400 Hidden Dimensions: 8 Max. Trajectory Length: 30}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Metrics for Trajectories: 400 Hidden Dimensions: 8 Max. Trajectory Length: 30}\n",
            "          \\label{fig:400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 400 Hidden Dimensions: 8 Max. Trajectory Length: 30}\n",
            "          \\label{fig:400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 600 Hidden Dimensions: 8 Max. Trajectory Length: 30}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Metrics for Trajectories: 600 Hidden Dimensions: 8 Max. Trajectory Length: 30}\n",
            "          \\label{fig:600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 600 Hidden Dimensions: 8 Max. Trajectory Length: 30}\n",
            "          \\label{fig:600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 800 Hidden Dimensions: 8 Max. Trajectory Length: 30}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Metrics for Trajectories: 800 Hidden Dimensions: 8 Max. Trajectory Length: 30}\n",
            "          \\label{fig:800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 800 Hidden Dimensions: 8 Max. Trajectory Length: 30}\n",
            "          \\label{fig:800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 1000 Hidden Dimensions: 8 Max. Trajectory Length: 30}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Metrics for Trajectories: 1000 Hidden Dimensions: 8 Max. Trajectory Length: 30}\n",
            "          \\label{fig:1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 1000 Hidden Dimensions: 8 Max. Trajectory Length: 30}\n",
            "          \\label{fig:1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "      \n",
            "Experiment does not exist in the specified folder.\n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 1 Hidden Dimensions: 8 Max. Trajectory Length: 50}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/1_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Metrics for Trajectories: 1 Hidden Dimensions: 8 Max. Trajectory Length: 50}\n",
            "          \\label{fig:1_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_1_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 1 Hidden Dimensions: 8 Max. Trajectory Length: 50}\n",
            "          \\label{fig:1_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "      \n",
            "Experiment does not exist in the specified folder.\n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 0 Hidden Dimensions: 8 Max. Trajectory Length: 50}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/0_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Metrics for Trajectories: 0 Hidden Dimensions: 8 Max. Trajectory Length: 50}\n",
            "          \\label{fig:0_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_0_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 0 Hidden Dimensions: 8 Max. Trajectory Length: 50}\n",
            "          \\label{fig:0_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "      \n",
            "Experiment does not exist in the specified folder.\n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 0 Hidden Dimensions: 8 Max. Trajectory Length: 50}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/0_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Metrics for Trajectories: 0 Hidden Dimensions: 8 Max. Trajectory Length: 50}\n",
            "          \\label{fig:0_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_0_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 0 Hidden Dimensions: 8 Max. Trajectory Length: 50}\n",
            "          \\label{fig:0_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "      \n",
            "Experiment does not exist in the specified folder.\n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 0 Hidden Dimensions: 8 Max. Trajectory Length: 50}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/0_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Metrics for Trajectories: 0 Hidden Dimensions: 8 Max. Trajectory Length: 50}\n",
            "          \\label{fig:0_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_0_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 0 Hidden Dimensions: 8 Max. Trajectory Length: 50}\n",
            "          \\label{fig:0_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "      \n",
            "Experiment does not exist in the specified folder.\n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 0 Hidden Dimensions: 8 Max. Trajectory Length: 70}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/0_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Metrics for Trajectories: 0 Hidden Dimensions: 8 Max. Trajectory Length: 70}\n",
            "          \\label{fig:0_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_0_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 0 Hidden Dimensions: 8 Max. Trajectory Length: 70}\n",
            "          \\label{fig:0_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "      \n",
            "Experiment does not exist in the specified folder.\n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 0 Hidden Dimensions: 8 Max. Trajectory Length: 100}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/0_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Metrics for Trajectories: 0 Hidden Dimensions: 8 Max. Trajectory Length: 100}\n",
            "          \\label{fig:0_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_0_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 0 Hidden Dimensions: 8 Max. Trajectory Length: 100}\n",
            "          \\label{fig:0_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "      \n",
            "Experiment does not exist in the specified folder.\n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 0 Hidden Dimensions: 8 Max. Trajectory Length: 30}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/0_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Metrics for Trajectories: 0 Hidden Dimensions: 8 Max. Trajectory Length: 30}\n",
            "          \\label{fig:0_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_0_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 0 Hidden Dimensions: 8 Max. Trajectory Length: 30}\n",
            "          \\label{fig:0_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "      \n",
            "Experiment does not exist in the specified folder.\n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 0 Hidden Dimensions: 8 Max. Trajectory Length: 50}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/0_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Metrics for Trajectories: 0 Hidden Dimensions: 8 Max. Trajectory Length: 50}\n",
            "          \\label{fig:0_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_0_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 0 Hidden Dimensions: 8 Max. Trajectory Length: 50}\n",
            "          \\label{fig:0_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "      \n",
            "Experiment does not exist in the specified folder.\n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 0 Hidden Dimensions: 8 Max. Trajectory Length: 70}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/0_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Metrics for Trajectories: 0 Hidden Dimensions: 8 Max. Trajectory Length: 70}\n",
            "          \\label{fig:0_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_0_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 0 Hidden Dimensions: 8 Max. Trajectory Length: 70}\n",
            "          \\label{fig:0_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "      \n",
            "Experiment does not exist in the specified folder.\n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 0 Hidden Dimensions: 8 Max. Trajectory Length: 100}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/0_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Metrics for Trajectories: 0 Hidden Dimensions: 8 Max. Trajectory Length: 100}\n",
            "          \\label{fig:0_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_0_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 0 Hidden Dimensions: 8 Max. Trajectory Length: 100}\n",
            "          \\label{fig:0_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "      \n",
            "Experiment does not exist in the specified folder.\n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 0 Hidden Dimensions: 32 Max. Trajectory Length: 30}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/0_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Metrics for Trajectories: 0 Hidden Dimensions: 32 Max. Trajectory Length: 30}\n",
            "          \\label{fig:0_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_0_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 0 Hidden Dimensions: 32 Max. Trajectory Length: 30}\n",
            "          \\label{fig:0_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "      \n",
            "Experiment does not exist in the specified folder.\n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 0 Hidden Dimensions: 32 Max. Trajectory Length: 50}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/0_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Metrics for Trajectories: 0 Hidden Dimensions: 32 Max. Trajectory Length: 50}\n",
            "          \\label{fig:0_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_0_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 0 Hidden Dimensions: 32 Max. Trajectory Length: 50}\n",
            "          \\label{fig:0_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "      \n",
            "Experiment does not exist in the specified folder.\n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 0 Hidden Dimensions: 32 Max. Trajectory Length: 70}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/0_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Metrics for Trajectories: 0 Hidden Dimensions: 32 Max. Trajectory Length: 70}\n",
            "          \\label{fig:0_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_0_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 0 Hidden Dimensions: 32 Max. Trajectory Length: 70}\n",
            "          \\label{fig:0_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "      \n",
            "Experiment does not exist in the specified folder.\n",
            "\n",
            "      \\subsection*{Experiment with Trajectories: 0 Hidden Dimensions: 32 Max. Trajectory Length: 100}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/0_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Metrics for Trajectories: 0 Hidden Dimensions: 32 Max. Trajectory Length: 100}\n",
            "          \\label{fig:0_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[h]\n",
            "          \\centering\n",
            "          \\includegraphics[width=\\textwidth]{plt_plots/shaping_heatmap_predictions_0_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 0 Hidden Dimensions: 32 Max. Trajectory Length: 100}\n",
            "          \\label{fig:0_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for num in num_trajectories:\n",
        "      params[\"num_trajectories\"] = num\n",
        "      print(params[\"num_trajectories\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUvFq3O9L7Xn",
        "outputId": "408a060f-c570-4dfd-adc4-3bcdbc690720"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_trajectories"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ViBhpbdkL_eU",
        "outputId": "ae0383cc-2f93-43dc-a446-6315f3412fe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the varying trajectory lengths\n",
        "num_trajectories_list = [200, 400, 600, 800, 1000]\n",
        "# Define hidden_dims\n",
        "hidden_dimens = [[8],[8,8],[32]]\n",
        "# Define trajectory lengths\n",
        "trajectory_length = [30, 50, 70, 100]\n",
        "\n",
        "# for num in num_trajectories:\n",
        "for dims in hidden_dimens:\n",
        "  # Modify the base parameters for each experiment\n",
        "  # params = base_params_test.copy()  # Make a copy to avoid modifying the base parameters\n",
        "  # params[\"num_trajectories\"] = num  # Update the number of trajectories\n",
        "  params[\"hidden_dims\"] = dims\n",
        "  # for dims in hidden_dimens:\n",
        "  for len in trajectory_length:\n",
        "    # params = base_params_test.copy()  # Make a copy to avoid modifying the base parameters\n",
        "    # params[\"hidden_dims\"] = dims\n",
        "    params['max_length'] = len\n",
        "\n",
        "    # for len in trajectory_length:\n",
        "    latex_subsection = r\"\"\"\n",
        "    \\subsection*{Experiment set with Hidden Dimensions: %s Max. Trajectory Length: %s}\n",
        "    \"\"\"\n",
        "    # latex_sub =\n",
        "    latex_sub = latex_subsection % (str(dims), str(len))\n",
        "    print(latex_sub)\n",
        "    for num in num_trajectories_list:\n",
        "      # params[\"max_length\"] = len\n",
        "      params[\"num_trajectories\"] = num\n",
        "\n",
        "      # Create an instance of SCOPE_experiment with modified parameters\n",
        "      test_experiment = SCOPE_experiment(**params)\n",
        "      # test_experiment.run_experiment()\n",
        "      test_load = existing_experiments(test_experiment)\n",
        "      # test_load.plot_metrics_save(save = True)\n",
        "      # print(test_load.experiment_instance.generate_file_name())\n",
        "      filename = test_load.experiment_instance.generate_file_name()\n",
        "\n",
        "      num_trajectories = str(test_experiment.num_trajectories)\n",
        "      # print(num)\n",
        "      # print(num_trajectories)\n",
        "      hidden_dims = str(test_experiment.hidden_dims)\n",
        "      max_length = str(test_experiment.max_length)\n",
        "\n",
        "      latex_template = r\"\"\"\n",
        "      \\subsubsection*{Experiment with Trajectories: %s Hidden Dimensions: %s Max. Trajectory Length: %s}\n",
        "\n",
        "      \\begin{figure}[H]\n",
        "          \\centering\n",
        "          \\includegraphics[width=0.55\\textwidth]{plt_plots/%s.png}\n",
        "          \\caption{Metrics for Trajectories: %s Hidden Dimensions: %s Max. Trajectory Length: %s}\n",
        "          \\label{fig:%s}\n",
        "      \\end{figure}\n",
        "\n",
        "      \\begin{figure}[H]\n",
        "          \\centering\n",
        "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_%s.png}\n",
        "          \\caption{Shaping prediction heatmap for with Trajectories: %s Hidden Dimensions: %s Max. Trajectory Length: %s}\n",
        "          \\label{fig:%s}\n",
        "      \\end{figure}\n",
        "      \"\"\"\n",
        "      latex_code = latex_template % (num_trajectories, hidden_dims, max_length,filename, num_trajectories, hidden_dims, max_length,filename, filename, num_trajectories, hidden_dims, max_length,filename )\n",
        "      print(latex_code)\n",
        "\n",
        "      # test_load.get_heatmap()\n",
        "      # test_load.save_heatmap()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e1Dq138K_aQ",
        "outputId": "f61e3672-7682-4aec-fd10-4a6c2f13e82a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    \\subsection*{Experiment set with Hidden Dimensions: [8] Max. Trajectory Length: 30}\n",
            "    \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 200 Hidden Dimensions: [8] Max. Trajectory Length: 30}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Metrics for Trajectories: 200 Hidden Dimensions: [8] Max. Trajectory Length: 30}\n",
            "          \\label{fig:200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 200 Hidden Dimensions: [8] Max. Trajectory Length: 30}\n",
            "          \\label{fig:200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "      \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 400 Hidden Dimensions: [8] Max. Trajectory Length: 30}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Metrics for Trajectories: 400 Hidden Dimensions: [8] Max. Trajectory Length: 30}\n",
            "          \\label{fig:400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 400 Hidden Dimensions: [8] Max. Trajectory Length: 30}\n",
            "          \\label{fig:400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "      \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 600 Hidden Dimensions: [8] Max. Trajectory Length: 30}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Metrics for Trajectories: 600 Hidden Dimensions: [8] Max. Trajectory Length: 30}\n",
            "          \\label{fig:600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 600 Hidden Dimensions: [8] Max. Trajectory Length: 30}\n",
            "          \\label{fig:600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "      \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 800 Hidden Dimensions: [8] Max. Trajectory Length: 30}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Metrics for Trajectories: 800 Hidden Dimensions: [8] Max. Trajectory Length: 30}\n",
            "          \\label{fig:800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 800 Hidden Dimensions: [8] Max. Trajectory Length: 30}\n",
            "          \\label{fig:800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "      \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 1000 Hidden Dimensions: [8] Max. Trajectory Length: 30}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Metrics for Trajectories: 1000 Hidden Dimensions: [8] Max. Trajectory Length: 30}\n",
            "          \\label{fig:1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 1000 Hidden Dimensions: [8] Max. Trajectory Length: 30}\n",
            "          \\label{fig:1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "    \\subsection*{Experiment set with Hidden Dimensions: [8] Max. Trajectory Length: 50}\n",
            "    \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 200 Hidden Dimensions: [8] Max. Trajectory Length: 50}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Metrics for Trajectories: 200 Hidden Dimensions: [8] Max. Trajectory Length: 50}\n",
            "          \\label{fig:200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 200 Hidden Dimensions: [8] Max. Trajectory Length: 50}\n",
            "          \\label{fig:200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "      \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 400 Hidden Dimensions: [8] Max. Trajectory Length: 50}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Metrics for Trajectories: 400 Hidden Dimensions: [8] Max. Trajectory Length: 50}\n",
            "          \\label{fig:400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 400 Hidden Dimensions: [8] Max. Trajectory Length: 50}\n",
            "          \\label{fig:400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "      \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 600 Hidden Dimensions: [8] Max. Trajectory Length: 50}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Metrics for Trajectories: 600 Hidden Dimensions: [8] Max. Trajectory Length: 50}\n",
            "          \\label{fig:600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 600 Hidden Dimensions: [8] Max. Trajectory Length: 50}\n",
            "          \\label{fig:600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "      \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 800 Hidden Dimensions: [8] Max. Trajectory Length: 50}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Metrics for Trajectories: 800 Hidden Dimensions: [8] Max. Trajectory Length: 50}\n",
            "          \\label{fig:800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 800 Hidden Dimensions: [8] Max. Trajectory Length: 50}\n",
            "          \\label{fig:800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "      \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 1000 Hidden Dimensions: [8] Max. Trajectory Length: 50}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Metrics for Trajectories: 1000 Hidden Dimensions: [8] Max. Trajectory Length: 50}\n",
            "          \\label{fig:1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 1000 Hidden Dimensions: [8] Max. Trajectory Length: 50}\n",
            "          \\label{fig:1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "    \\subsection*{Experiment set with Hidden Dimensions: [8] Max. Trajectory Length: 70}\n",
            "    \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 200 Hidden Dimensions: [8] Max. Trajectory Length: 70}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Metrics for Trajectories: 200 Hidden Dimensions: [8] Max. Trajectory Length: 70}\n",
            "          \\label{fig:200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 200 Hidden Dimensions: [8] Max. Trajectory Length: 70}\n",
            "          \\label{fig:200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "      \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 400 Hidden Dimensions: [8] Max. Trajectory Length: 70}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Metrics for Trajectories: 400 Hidden Dimensions: [8] Max. Trajectory Length: 70}\n",
            "          \\label{fig:400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 400 Hidden Dimensions: [8] Max. Trajectory Length: 70}\n",
            "          \\label{fig:400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "      \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 600 Hidden Dimensions: [8] Max. Trajectory Length: 70}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Metrics for Trajectories: 600 Hidden Dimensions: [8] Max. Trajectory Length: 70}\n",
            "          \\label{fig:600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 600 Hidden Dimensions: [8] Max. Trajectory Length: 70}\n",
            "          \\label{fig:600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "      \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 800 Hidden Dimensions: [8] Max. Trajectory Length: 70}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Metrics for Trajectories: 800 Hidden Dimensions: [8] Max. Trajectory Length: 70}\n",
            "          \\label{fig:800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 800 Hidden Dimensions: [8] Max. Trajectory Length: 70}\n",
            "          \\label{fig:800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "      \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 1000 Hidden Dimensions: [8] Max. Trajectory Length: 70}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Metrics for Trajectories: 1000 Hidden Dimensions: [8] Max. Trajectory Length: 70}\n",
            "          \\label{fig:1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 1000 Hidden Dimensions: [8] Max. Trajectory Length: 70}\n",
            "          \\label{fig:1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "    \\subsection*{Experiment set with Hidden Dimensions: [8] Max. Trajectory Length: 100}\n",
            "    \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 200 Hidden Dimensions: [8] Max. Trajectory Length: 100}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Metrics for Trajectories: 200 Hidden Dimensions: [8] Max. Trajectory Length: 100}\n",
            "          \\label{fig:200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 200 Hidden Dimensions: [8] Max. Trajectory Length: 100}\n",
            "          \\label{fig:200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "      \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 400 Hidden Dimensions: [8] Max. Trajectory Length: 100}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Metrics for Trajectories: 400 Hidden Dimensions: [8] Max. Trajectory Length: 100}\n",
            "          \\label{fig:400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 400 Hidden Dimensions: [8] Max. Trajectory Length: 100}\n",
            "          \\label{fig:400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "      \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 600 Hidden Dimensions: [8] Max. Trajectory Length: 100}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Metrics for Trajectories: 600 Hidden Dimensions: [8] Max. Trajectory Length: 100}\n",
            "          \\label{fig:600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 600 Hidden Dimensions: [8] Max. Trajectory Length: 100}\n",
            "          \\label{fig:600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "      \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 800 Hidden Dimensions: [8] Max. Trajectory Length: 100}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Metrics for Trajectories: 800 Hidden Dimensions: [8] Max. Trajectory Length: 100}\n",
            "          \\label{fig:800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 800 Hidden Dimensions: [8] Max. Trajectory Length: 100}\n",
            "          \\label{fig:800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "      \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 1000 Hidden Dimensions: [8] Max. Trajectory Length: 100}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Metrics for Trajectories: 1000 Hidden Dimensions: [8] Max. Trajectory Length: 100}\n",
            "          \\label{fig:1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 1000 Hidden Dimensions: [8] Max. Trajectory Length: 100}\n",
            "          \\label{fig:1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "    \\subsection*{Experiment set with Hidden Dimensions: [8, 8] Max. Trajectory Length: 30}\n",
            "    \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 200 Hidden Dimensions: [8, 8] Max. Trajectory Length: 30}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Metrics for Trajectories: 200 Hidden Dimensions: [8, 8] Max. Trajectory Length: 30}\n",
            "          \\label{fig:200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 200 Hidden Dimensions: [8, 8] Max. Trajectory Length: 30}\n",
            "          \\label{fig:200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "      \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 400 Hidden Dimensions: [8, 8] Max. Trajectory Length: 30}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Metrics for Trajectories: 400 Hidden Dimensions: [8, 8] Max. Trajectory Length: 30}\n",
            "          \\label{fig:400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 400 Hidden Dimensions: [8, 8] Max. Trajectory Length: 30}\n",
            "          \\label{fig:400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "      \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 600 Hidden Dimensions: [8, 8] Max. Trajectory Length: 30}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Metrics for Trajectories: 600 Hidden Dimensions: [8, 8] Max. Trajectory Length: 30}\n",
            "          \\label{fig:600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 600 Hidden Dimensions: [8, 8] Max. Trajectory Length: 30}\n",
            "          \\label{fig:600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "      \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 800 Hidden Dimensions: [8, 8] Max. Trajectory Length: 30}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Metrics for Trajectories: 800 Hidden Dimensions: [8, 8] Max. Trajectory Length: 30}\n",
            "          \\label{fig:800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 800 Hidden Dimensions: [8, 8] Max. Trajectory Length: 30}\n",
            "          \\label{fig:800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "      \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 1000 Hidden Dimensions: [8, 8] Max. Trajectory Length: 30}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Metrics for Trajectories: 1000 Hidden Dimensions: [8, 8] Max. Trajectory Length: 30}\n",
            "          \\label{fig:1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 1000 Hidden Dimensions: [8, 8] Max. Trajectory Length: 30}\n",
            "          \\label{fig:1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "    \\subsection*{Experiment set with Hidden Dimensions: [8, 8] Max. Trajectory Length: 50}\n",
            "    \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 200 Hidden Dimensions: [8, 8] Max. Trajectory Length: 50}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Metrics for Trajectories: 200 Hidden Dimensions: [8, 8] Max. Trajectory Length: 50}\n",
            "          \\label{fig:200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 200 Hidden Dimensions: [8, 8] Max. Trajectory Length: 50}\n",
            "          \\label{fig:200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "      \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 400 Hidden Dimensions: [8, 8] Max. Trajectory Length: 50}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Metrics for Trajectories: 400 Hidden Dimensions: [8, 8] Max. Trajectory Length: 50}\n",
            "          \\label{fig:400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 400 Hidden Dimensions: [8, 8] Max. Trajectory Length: 50}\n",
            "          \\label{fig:400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "      \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 600 Hidden Dimensions: [8, 8] Max. Trajectory Length: 50}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Metrics for Trajectories: 600 Hidden Dimensions: [8, 8] Max. Trajectory Length: 50}\n",
            "          \\label{fig:600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 600 Hidden Dimensions: [8, 8] Max. Trajectory Length: 50}\n",
            "          \\label{fig:600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "      \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 800 Hidden Dimensions: [8, 8] Max. Trajectory Length: 50}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Metrics for Trajectories: 800 Hidden Dimensions: [8, 8] Max. Trajectory Length: 50}\n",
            "          \\label{fig:800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 800 Hidden Dimensions: [8, 8] Max. Trajectory Length: 50}\n",
            "          \\label{fig:800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "      \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 1000 Hidden Dimensions: [8, 8] Max. Trajectory Length: 50}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Metrics for Trajectories: 1000 Hidden Dimensions: [8, 8] Max. Trajectory Length: 50}\n",
            "          \\label{fig:1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 1000 Hidden Dimensions: [8, 8] Max. Trajectory Length: 50}\n",
            "          \\label{fig:1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "    \\subsection*{Experiment set with Hidden Dimensions: [8, 8] Max. Trajectory Length: 70}\n",
            "    \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 200 Hidden Dimensions: [8, 8] Max. Trajectory Length: 70}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Metrics for Trajectories: 200 Hidden Dimensions: [8, 8] Max. Trajectory Length: 70}\n",
            "          \\label{fig:200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 200 Hidden Dimensions: [8, 8] Max. Trajectory Length: 70}\n",
            "          \\label{fig:200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "      \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 400 Hidden Dimensions: [8, 8] Max. Trajectory Length: 70}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Metrics for Trajectories: 400 Hidden Dimensions: [8, 8] Max. Trajectory Length: 70}\n",
            "          \\label{fig:400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 400 Hidden Dimensions: [8, 8] Max. Trajectory Length: 70}\n",
            "          \\label{fig:400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "      \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 600 Hidden Dimensions: [8, 8] Max. Trajectory Length: 70}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Metrics for Trajectories: 600 Hidden Dimensions: [8, 8] Max. Trajectory Length: 70}\n",
            "          \\label{fig:600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 600 Hidden Dimensions: [8, 8] Max. Trajectory Length: 70}\n",
            "          \\label{fig:600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "      \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 800 Hidden Dimensions: [8, 8] Max. Trajectory Length: 70}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Metrics for Trajectories: 800 Hidden Dimensions: [8, 8] Max. Trajectory Length: 70}\n",
            "          \\label{fig:800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 800 Hidden Dimensions: [8, 8] Max. Trajectory Length: 70}\n",
            "          \\label{fig:800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "      \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 1000 Hidden Dimensions: [8, 8] Max. Trajectory Length: 70}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Metrics for Trajectories: 1000 Hidden Dimensions: [8, 8] Max. Trajectory Length: 70}\n",
            "          \\label{fig:1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 1000 Hidden Dimensions: [8, 8] Max. Trajectory Length: 70}\n",
            "          \\label{fig:1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "    \\subsection*{Experiment set with Hidden Dimensions: [8, 8] Max. Trajectory Length: 100}\n",
            "    \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 200 Hidden Dimensions: [8, 8] Max. Trajectory Length: 100}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Metrics for Trajectories: 200 Hidden Dimensions: [8, 8] Max. Trajectory Length: 100}\n",
            "          \\label{fig:200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 200 Hidden Dimensions: [8, 8] Max. Trajectory Length: 100}\n",
            "          \\label{fig:200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "      \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 400 Hidden Dimensions: [8, 8] Max. Trajectory Length: 100}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Metrics for Trajectories: 400 Hidden Dimensions: [8, 8] Max. Trajectory Length: 100}\n",
            "          \\label{fig:400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 400 Hidden Dimensions: [8, 8] Max. Trajectory Length: 100}\n",
            "          \\label{fig:400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "      \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 600 Hidden Dimensions: [8, 8] Max. Trajectory Length: 100}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Metrics for Trajectories: 600 Hidden Dimensions: [8, 8] Max. Trajectory Length: 100}\n",
            "          \\label{fig:600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 600 Hidden Dimensions: [8, 8] Max. Trajectory Length: 100}\n",
            "          \\label{fig:600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "      \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 800 Hidden Dimensions: [8, 8] Max. Trajectory Length: 100}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Metrics for Trajectories: 800 Hidden Dimensions: [8, 8] Max. Trajectory Length: 100}\n",
            "          \\label{fig:800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 800 Hidden Dimensions: [8, 8] Max. Trajectory Length: 100}\n",
            "          \\label{fig:800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "      \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 1000 Hidden Dimensions: [8, 8] Max. Trajectory Length: 100}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Metrics for Trajectories: 1000 Hidden Dimensions: [8, 8] Max. Trajectory Length: 100}\n",
            "          \\label{fig:1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 1000 Hidden Dimensions: [8, 8] Max. Trajectory Length: 100}\n",
            "          \\label{fig:1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_8_8_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "    \\subsection*{Experiment set with Hidden Dimensions: [32] Max. Trajectory Length: 30}\n",
            "    \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 200 Hidden Dimensions: [32] Max. Trajectory Length: 30}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Metrics for Trajectories: 200 Hidden Dimensions: [32] Max. Trajectory Length: 30}\n",
            "          \\label{fig:200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 200 Hidden Dimensions: [32] Max. Trajectory Length: 30}\n",
            "          \\label{fig:200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "      \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 400 Hidden Dimensions: [32] Max. Trajectory Length: 30}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Metrics for Trajectories: 400 Hidden Dimensions: [32] Max. Trajectory Length: 30}\n",
            "          \\label{fig:400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 400 Hidden Dimensions: [32] Max. Trajectory Length: 30}\n",
            "          \\label{fig:400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "      \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 600 Hidden Dimensions: [32] Max. Trajectory Length: 30}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Metrics for Trajectories: 600 Hidden Dimensions: [32] Max. Trajectory Length: 30}\n",
            "          \\label{fig:600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 600 Hidden Dimensions: [32] Max. Trajectory Length: 30}\n",
            "          \\label{fig:600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "      \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 800 Hidden Dimensions: [32] Max. Trajectory Length: 30}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Metrics for Trajectories: 800 Hidden Dimensions: [32] Max. Trajectory Length: 30}\n",
            "          \\label{fig:800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 800 Hidden Dimensions: [32] Max. Trajectory Length: 30}\n",
            "          \\label{fig:800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "      \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 1000 Hidden Dimensions: [32] Max. Trajectory Length: 30}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Metrics for Trajectories: 1000 Hidden Dimensions: [32] Max. Trajectory Length: 30}\n",
            "          \\label{fig:1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_30.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 1000 Hidden Dimensions: [32] Max. Trajectory Length: 30}\n",
            "          \\label{fig:1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_30}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "    \\subsection*{Experiment set with Hidden Dimensions: [32] Max. Trajectory Length: 50}\n",
            "    \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 200 Hidden Dimensions: [32] Max. Trajectory Length: 50}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Metrics for Trajectories: 200 Hidden Dimensions: [32] Max. Trajectory Length: 50}\n",
            "          \\label{fig:200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 200 Hidden Dimensions: [32] Max. Trajectory Length: 50}\n",
            "          \\label{fig:200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "      \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 400 Hidden Dimensions: [32] Max. Trajectory Length: 50}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Metrics for Trajectories: 400 Hidden Dimensions: [32] Max. Trajectory Length: 50}\n",
            "          \\label{fig:400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 400 Hidden Dimensions: [32] Max. Trajectory Length: 50}\n",
            "          \\label{fig:400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "      \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 600 Hidden Dimensions: [32] Max. Trajectory Length: 50}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Metrics for Trajectories: 600 Hidden Dimensions: [32] Max. Trajectory Length: 50}\n",
            "          \\label{fig:600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 600 Hidden Dimensions: [32] Max. Trajectory Length: 50}\n",
            "          \\label{fig:600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "      \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 800 Hidden Dimensions: [32] Max. Trajectory Length: 50}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Metrics for Trajectories: 800 Hidden Dimensions: [32] Max. Trajectory Length: 50}\n",
            "          \\label{fig:800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 800 Hidden Dimensions: [32] Max. Trajectory Length: 50}\n",
            "          \\label{fig:800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "      \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 1000 Hidden Dimensions: [32] Max. Trajectory Length: 50}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Metrics for Trajectories: 1000 Hidden Dimensions: [32] Max. Trajectory Length: 50}\n",
            "          \\label{fig:1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_50.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 1000 Hidden Dimensions: [32] Max. Trajectory Length: 50}\n",
            "          \\label{fig:1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_50}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "    \\subsection*{Experiment set with Hidden Dimensions: [32] Max. Trajectory Length: 70}\n",
            "    \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 200 Hidden Dimensions: [32] Max. Trajectory Length: 70}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Metrics for Trajectories: 200 Hidden Dimensions: [32] Max. Trajectory Length: 70}\n",
            "          \\label{fig:200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 200 Hidden Dimensions: [32] Max. Trajectory Length: 70}\n",
            "          \\label{fig:200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "      \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 400 Hidden Dimensions: [32] Max. Trajectory Length: 70}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Metrics for Trajectories: 400 Hidden Dimensions: [32] Max. Trajectory Length: 70}\n",
            "          \\label{fig:400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 400 Hidden Dimensions: [32] Max. Trajectory Length: 70}\n",
            "          \\label{fig:400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "      \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 600 Hidden Dimensions: [32] Max. Trajectory Length: 70}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Metrics for Trajectories: 600 Hidden Dimensions: [32] Max. Trajectory Length: 70}\n",
            "          \\label{fig:600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 600 Hidden Dimensions: [32] Max. Trajectory Length: 70}\n",
            "          \\label{fig:600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "      \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 800 Hidden Dimensions: [32] Max. Trajectory Length: 70}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Metrics for Trajectories: 800 Hidden Dimensions: [32] Max. Trajectory Length: 70}\n",
            "          \\label{fig:800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 800 Hidden Dimensions: [32] Max. Trajectory Length: 70}\n",
            "          \\label{fig:800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "      \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 1000 Hidden Dimensions: [32] Max. Trajectory Length: 70}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Metrics for Trajectories: 1000 Hidden Dimensions: [32] Max. Trajectory Length: 70}\n",
            "          \\label{fig:1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_70.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 1000 Hidden Dimensions: [32] Max. Trajectory Length: 70}\n",
            "          \\label{fig:1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_70}\n",
            "      \\end{figure}\n",
            "      \n",
            "\n",
            "    \\subsection*{Experiment set with Hidden Dimensions: [32] Max. Trajectory Length: 100}\n",
            "    \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 200 Hidden Dimensions: [32] Max. Trajectory Length: 100}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Metrics for Trajectories: 200 Hidden Dimensions: [32] Max. Trajectory Length: 100}\n",
            "          \\label{fig:200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 200 Hidden Dimensions: [32] Max. Trajectory Length: 100}\n",
            "          \\label{fig:200_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "      \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 400 Hidden Dimensions: [32] Max. Trajectory Length: 100}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Metrics for Trajectories: 400 Hidden Dimensions: [32] Max. Trajectory Length: 100}\n",
            "          \\label{fig:400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 400 Hidden Dimensions: [32] Max. Trajectory Length: 100}\n",
            "          \\label{fig:400_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "      \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 600 Hidden Dimensions: [32] Max. Trajectory Length: 100}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Metrics for Trajectories: 600 Hidden Dimensions: [32] Max. Trajectory Length: 100}\n",
            "          \\label{fig:600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 600 Hidden Dimensions: [32] Max. Trajectory Length: 100}\n",
            "          \\label{fig:600_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "      \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 800 Hidden Dimensions: [32] Max. Trajectory Length: 100}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Metrics for Trajectories: 800 Hidden Dimensions: [32] Max. Trajectory Length: 100}\n",
            "          \\label{fig:800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 800 Hidden Dimensions: [32] Max. Trajectory Length: 100}\n",
            "          \\label{fig:800_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "      \n",
            "      \n",
            "      \\subsubsection*{Experiment with Trajectories: 1000 Hidden Dimensions: [32] Max. Trajectory Length: 100}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Metrics for Trajectories: 1000 Hidden Dimensions: [32] Max. Trajectory Length: 100}\n",
            "          \\label{fig:1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "\n",
            "      \\begin{figure}[H]\n",
            "          \\centering\n",
            "          \\includegraphics[width=0.55\\textwidth]{plt_plots/shaping_heatmap_predictions_1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_100.png}\n",
            "          \\caption{Shaping prediction heatmap for with Trajectories: 1000 Hidden Dimensions: [32] Max. Trajectory Length: 100}\n",
            "          \\label{fig:1000_0.99_0.3_bottleneck_four_regions_k_p9_a_1_0.1_32_0.2_0.001_1e-05_1e-05_1_1_100}\n",
            "      \\end{figure}\n",
            "      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "str([8,8])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Uvm3s5kWOC_k",
        "outputId": "3ab7e84a-d80a-4cfe-c5be-ef02bcd2973c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[8, 8]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJztffS2I-aZ",
        "outputId": "d30385a1-6862-4780-d0e8-044f4d816ea2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'pi_b_top_k': 1,\n",
              " 'pi_b_epsilon': 0.4,\n",
              " 'pi_e_top_k': 1,\n",
              " 'pi_e_epsilon': 0.05,\n",
              " 'q_table': array([[[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00]],\n",
              " \n",
              "        [[ 3.01458116e-04,  8.58632941e-03,  4.27874848e-02,\n",
              "           3.59981903e-04,  1.06963459e-02],\n",
              "         [ 5.75933419e-02,  6.02922328e-02,  6.99403286e-01,\n",
              "           1.77725665e-02,  7.43218437e-02],\n",
              "         [ 7.34193981e-01,  6.99822962e-01,  8.77173007e-01,\n",
              "           5.91608703e-01,  7.46506393e-01],\n",
              "         [ 9.01541948e-01,  9.03474629e-01,  8.87099385e-01,\n",
              "           8.83283734e-01,  9.10344481e-01],\n",
              "         [ 9.13268805e-01,  9.12957370e-01,  8.80335510e-01,\n",
              "           9.08076465e-01,  9.24511015e-01],\n",
              "         [ 8.85746300e-01,  9.42133784e-01,  8.08581293e-01,\n",
              "           8.81675839e-01,  8.28410685e-01],\n",
              "         [ 7.39615679e-01,  8.39131653e-01,  5.90266645e-01,\n",
              "           7.96507776e-01,  5.89306116e-01],\n",
              "         [ 3.61727566e-01,  5.91513038e-01,  1.42657563e-01,\n",
              "           4.59852248e-01, -3.39613147e-02],\n",
              "         [-4.08169627e-01, -9.95582759e-01, -5.59949636e-01,\n",
              "          -1.28358766e-01, -9.99417245e-01],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00]],\n",
              " \n",
              "        [[ 4.26960737e-02,  1.22040976e-02,  7.07565606e-01,\n",
              "           8.84096175e-02,  1.17400363e-01],\n",
              "         [ 6.01490557e-01,  4.70571637e-01,  8.42462778e-01,\n",
              "           5.66953540e-01,  7.04761624e-01],\n",
              "         [ 8.66542578e-01,  8.66744399e-01,  8.55047166e-01,\n",
              "           8.46370876e-01,  8.74681056e-01],\n",
              "         [ 8.63981664e-01,  8.83431971e-01,  8.32310975e-01,\n",
              "           8.59307945e-01,  8.52212548e-01],\n",
              "         [ 8.26075554e-01,  8.59658003e-01,  7.70196736e-01,\n",
              "           8.41882527e-01,  7.83637881e-01],\n",
              "         [ 7.07998335e-01,  7.87045181e-01,  6.27991319e-01,\n",
              "           7.34956205e-01,  5.96307874e-01],\n",
              "         [ 4.56813365e-01,  6.25618875e-01,  3.52304190e-01,\n",
              "           5.74512064e-01,  2.70009160e-01],\n",
              "         [ 4.87219132e-02,  2.35472977e-01, -1.16110891e-02,\n",
              "           3.00192118e-01, -2.29841053e-01],\n",
              "         [-5.58922887e-01, -4.02525246e-01, -6.02935672e-01,\n",
              "          -2.27366418e-01, -9.93875921e-01],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00]],\n",
              " \n",
              "        [[ 7.76757777e-01,  6.46644056e-01,  8.11647177e-01,\n",
              "           7.83762932e-01,  7.91211307e-01],\n",
              "         [ 8.31790090e-01,  8.31706643e-01,  8.19305420e-01,\n",
              "           8.15395832e-01,  8.36970747e-01],\n",
              "         [ 8.31669986e-01,  8.47131312e-01,  8.06822538e-01,\n",
              "           8.27015460e-01,  8.20448041e-01],\n",
              "         [ 7.97939062e-01,  8.23913813e-01,  7.52867877e-01,\n",
              "           8.04754972e-01,  7.62283444e-01],\n",
              "         [ 7.16844916e-01,  7.60662556e-01,  6.44945443e-01,\n",
              "           7.42989361e-01,  6.41311884e-01],\n",
              "         [ 5.61837733e-01,  6.40596867e-01,  4.68805015e-01,\n",
              "           5.96788645e-01,  4.25397903e-01],\n",
              "         [ 3.17319512e-01,  3.85975540e-01,  2.46852994e-01,\n",
              "           4.19501513e-01,  1.29352391e-01],\n",
              "         [-3.83496881e-02,  2.76816217e-03, -9.26085562e-02,\n",
              "           1.05878554e-01, -3.10729265e-01],\n",
              "         [-5.68435550e-01, -5.47269166e-01, -6.31152153e-01,\n",
              "          -3.58182192e-01, -9.89775419e-01],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00]],\n",
              " \n",
              "        [[ 8.03347290e-01,  8.03987980e-01,  7.97309637e-01,\n",
              "           8.03754866e-01,  8.06786597e-01],\n",
              "         [ 8.04274738e-01,  8.14129531e-01,  8.04016948e-01,\n",
              "           7.98337936e-01,  7.95290053e-01],\n",
              "         [ 7.75013089e-01,  8.03576708e-01,  7.74309099e-01,\n",
              "           7.83236504e-01,  7.47934282e-01],\n",
              "         [ 7.06801116e-01,  7.53064156e-01,  7.04900742e-01,\n",
              "           7.26948202e-01,  6.47932708e-01],\n",
              "         [ 5.98613977e-01,  6.53655648e-01,  5.89529991e-01,\n",
              "           6.43420935e-01,  5.06872594e-01],\n",
              "         [ 4.27482456e-01,  5.06077111e-01,  2.18852516e-02,\n",
              "           5.10043323e-01,  3.05412292e-01],\n",
              "         [ 1.95719317e-01,  2.52024084e-01, -3.76119137e-01,\n",
              "           3.19020212e-01,  3.12695391e-02],\n",
              "         [-1.42510399e-01, -1.25696927e-01, -6.40404999e-01,\n",
              "           6.93832263e-02, -3.89573246e-01],\n",
              "         [-6.16155744e-01, -5.83669901e-01, -9.14503813e-01,\n",
              "          -3.95892829e-01, -9.62614059e-01],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00]],\n",
              " \n",
              "        [[ 7.87583292e-01,  7.93893993e-01,  7.35095620e-01,\n",
              "           7.88040876e-01,  7.87722766e-01],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [-2.97964811e-01, -2.97235817e-01, -2.98528314e-01,\n",
              "          -2.96230882e-01, -2.95614064e-01],\n",
              "         [-6.69492424e-01, -6.68205738e-01, -6.67580426e-01,\n",
              "          -6.66414618e-01, -6.68061376e-01],\n",
              "         [-8.86965275e-01, -8.86626363e-01, -8.86276484e-01,\n",
              "          -8.86178255e-01, -8.86678576e-01],\n",
              "         [-9.79844928e-01, -9.79811490e-01, -9.79866564e-01,\n",
              "          -9.79757965e-01, -9.79948938e-01],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00]],\n",
              " \n",
              "        [[ 6.20627761e-01,  6.95579708e-01,  5.68124533e-01,\n",
              "           6.27064943e-01,  5.40536582e-01],\n",
              "         [ 4.47503597e-01,  4.62527961e-01,  4.13305730e-01,\n",
              "           5.65253913e-01,  3.46164078e-01],\n",
              "         [ 2.43780926e-01,  2.36258805e-01,  1.96950376e-01,\n",
              "           3.76319587e-01,  7.35066012e-02],\n",
              "         [-9.91613120e-02, -1.12530075e-01, -1.26859203e-01,\n",
              "           7.29341805e-02, -3.53678554e-01],\n",
              "         [-5.77467859e-01, -6.14735723e-01, -5.76468170e-01,\n",
              "          -3.61737192e-01, -9.42735255e-01],\n",
              "         [-9.52133298e-01, -9.51536894e-01, -9.52732682e-01,\n",
              "          -9.53122199e-01, -9.53324258e-01],\n",
              "         [-9.65967476e-01, -9.67929304e-01, -9.67234969e-01,\n",
              "          -9.67667997e-01, -9.68022764e-01],\n",
              "         [-9.82173681e-01, -9.82192874e-01, -9.82513547e-01,\n",
              "          -9.82198179e-01, -9.82171416e-01],\n",
              "         [-9.96439934e-01, -9.95249748e-01, -9.96555328e-01,\n",
              "          -9.96478081e-01, -9.96708989e-01],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00]],\n",
              " \n",
              "        [[ 5.34046054e-01,  5.94694138e-01,  4.84974623e-01,\n",
              "           5.34990370e-01,  4.58612800e-01],\n",
              "         [ 3.78343493e-01,  4.41976160e-01,  3.37427229e-01,\n",
              "           4.78509337e-01,  2.70618826e-01],\n",
              "         [ 1.75689697e-01,  1.93058521e-01,  1.22156583e-01,\n",
              "           2.79015154e-01, -6.34363561e-04],\n",
              "         [-1.51716277e-01, -1.32227838e-01, -1.88690513e-01,\n",
              "           6.44603511e-03, -4.08399671e-01],\n",
              "         [-6.01225376e-01, -5.74674726e-01, -5.96032977e-01,\n",
              "          -4.30384666e-01, -9.43769991e-01],\n",
              "         [-9.53934371e-01, -9.53492165e-01, -9.53504980e-01,\n",
              "          -9.53996897e-01, -9.54029441e-01],\n",
              "         [-9.68029499e-01, -9.68184471e-01, -9.67247367e-01,\n",
              "          -9.67679977e-01, -9.67700839e-01],\n",
              "         [-9.81046379e-01, -9.81963813e-01, -9.82086897e-01,\n",
              "          -9.82034802e-01, -9.82345939e-01],\n",
              "         [-9.96139109e-01, -9.96357501e-01, -9.95756745e-01,\n",
              "          -9.95213270e-01, -9.96062934e-01],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00]],\n",
              " \n",
              "        [[ 4.54495490e-01,  5.03036320e-01,  4.05172586e-01,\n",
              "           4.53364670e-01,  3.83510530e-01],\n",
              "         [ 3.14470321e-01,  3.71679455e-01,  2.75614172e-01,\n",
              "           3.71530771e-01,  2.20512554e-01],\n",
              "         [ 1.10673852e-01,  1.54534027e-01,  8.37569386e-02,\n",
              "           2.21284449e-01, -2.02698391e-02],\n",
              "         [-1.77205712e-01, -1.53582498e-01, -1.87302649e-01,\n",
              "          -1.64497644e-03, -3.90040785e-01],\n",
              "         [-5.91077209e-01, -6.12238467e-01, -6.48980141e-01,\n",
              "          -3.53197545e-01, -9.43539560e-01],\n",
              "         [-9.53668594e-01, -9.53802943e-01, -9.53901052e-01,\n",
              "          -9.53992724e-01, -9.52796817e-01],\n",
              "         [-9.67261255e-01, -9.67643082e-01, -9.68016326e-01,\n",
              "          -9.67541993e-01, -9.65447724e-01],\n",
              "         [-9.81641114e-01, -9.80132520e-01, -9.81524050e-01,\n",
              "          -9.81054425e-01, -9.81759787e-01],\n",
              "         [-9.96500134e-01, -9.95860994e-01, -9.95348155e-01,\n",
              "          -9.95945632e-01, -9.96349275e-01],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00]],\n",
              " \n",
              "        [[ 3.82001519e-01,  4.29919422e-01,  3.81996095e-01,\n",
              "           3.76303107e-01,  3.12185019e-01],\n",
              "         [ 2.48819113e-01,  2.85849273e-01,  2.55668253e-01,\n",
              "           3.18613708e-01,  1.55175820e-01],\n",
              "         [ 6.69126809e-02,  1.02018878e-01,  5.38834631e-02,\n",
              "           1.75553754e-01, -8.15205947e-02],\n",
              "         [-2.24359870e-01, -1.72365353e-01, -2.03656361e-01,\n",
              "          -8.09799209e-02, -4.24898863e-01],\n",
              "         [-6.22137249e-01, -5.65495312e-01, -6.51820362e-01,\n",
              "          -4.86206621e-01, -9.43249345e-01],\n",
              "         [-9.53823447e-01, -9.53712940e-01, -9.53664899e-01,\n",
              "          -9.53794241e-01, -9.53277051e-01],\n",
              "         [-9.67401803e-01, -9.67875481e-01, -9.68209565e-01,\n",
              "          -9.67946470e-01, -9.68456686e-01],\n",
              "         [-9.80477750e-01, -9.81244147e-01, -9.81424451e-01,\n",
              "          -9.81877804e-01, -9.81393218e-01],\n",
              "         [-9.94938016e-01, -9.96083200e-01, -9.96059060e-01,\n",
              "          -9.96754050e-01, -9.96289313e-01],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00]]]),\n",
              " 'gamma': 0.99,\n",
              " 'num_trajectories': '0',\n",
              " 'num_bootstraps': 10000,\n",
              " 'percent_to_estimate_phi': 0.3,\n",
              " 'shaping_feature': <function shaping_features.bottleneck_four_regions_k_p9_a_1(current_state, env, k=0.9, a=1)>,\n",
              " 'shaping_coefficient': 0.1,\n",
              " 'hidden_dims': [32],\n",
              " 'learning_rate': 0.001,\n",
              " 'dropout_prob': 0.2,\n",
              " 'l1_reg': 1e-05,\n",
              " 'l2_reg': 1e-05,\n",
              " 'scope_weight': 1,\n",
              " 'mse_weight': 1,\n",
              " 'num_epochs': 300,\n",
              " 'max_length': 100,\n",
              " 'death_drag': 0.0,\n",
              " 'dtype': torch.float64,\n",
              " 'experiment_type': 'test',\n",
              " 'folder_path': '/content/drive/MyDrive/Lifegate_experiments'}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the varying trajectory lengths\n",
        "num_trajectories = [200, 400, 600, 800, 1000]\n",
        "# Define hidden_dims\n",
        "hidden_dimens = [[8], [8, 8], [32]]\n",
        "# Define trajectory lengths\n",
        "trajectory_length = [30, 50, 70, 100]\n",
        "\n",
        "# Base parameters (assuming base_params_test is defined somewhere in your code)\n",
        "base_params_test = {}\n",
        "\n",
        "# Placeholder for the LaTeX content\n",
        "latex_content = r\"\"\"\n",
        "\\documentclass{article}\n",
        "\\usepackage{graphicx}\n",
        "\\begin{document}\n",
        "\"\"\"\n",
        "\n",
        "# Loop through the parameter combinations\n",
        "for section_idx, num in enumerate(num_trajectories, start=1):\n",
        "    # params = base_params_test.copy()  # Make a copy to avoid modifying the base parameters\n",
        "    params[\"num_trajectories\"] = num  # Update the number of trajectories\n",
        "\n",
        "    for dims in hidden_dimens:\n",
        "        params[\"hidden_dims\"] = dims\n",
        "\n",
        "        for length in trajectory_length:\n",
        "            params[\"max_length\"] = length\n",
        "\n",
        "            # Create an instance of SCOPE_experiment with modified parameters\n",
        "            test_experiment = SCOPE_experiment(**params)\n",
        "            # test_experiment.run_experiment()\n",
        "            test_load = existing_experiments(test_experiment)\n",
        "            # test_load.plot_metrics_save(save=True)\n",
        "\n",
        "            # Generate file name from the experiment instance\n",
        "            file_name = test_load.experiment_instance.generate_file_name()\n",
        "\n",
        "            # Convert parameters to string\n",
        "            num_trajectories_str = str(test_experiment.num_trajectories)\n",
        "            hidden_dims_str = '-'.join(map(str, test_experiment.hidden_dims))\n",
        "            max_length_str = str(test_experiment.max_length)\n",
        "\n",
        "            # Format the LaTeX code\n",
        "            latex_code = r\"\"\"\n",
        "\\subsection*{Section %d: Trajectories=%s, HiddenDims=%s, MaxLength=%s}\n",
        "\n",
        "\\begin{figure}[h]\n",
        "    \\centering\n",
        "    \\includegraphics[width=\\textwidth]{%s.png}\n",
        "    \\caption{Metrics for Trajectories=%s, HiddenDims=%s, MaxLength=%s}\n",
        "    \\label{fig:%s}\n",
        "\\end{figure}\n",
        "\n",
        "\\begin{figure}[h]\n",
        "    \\centering\n",
        "    \\includegraphics[width=\\textwidth]{shaping_heatmap_predictions_%s.png}\n",
        "    \\caption{Shaping prediction heatmap for Trajectories=%s, HiddenDims=%s, MaxLength=%s}\n",
        "    \\label{fig:shaping_%s}\n",
        "\\end{figure}\n",
        "\"\"\" % (section_idx, num_trajectories_str, hidden_dims_str, max_length_str,\n",
        "       file_name, num_trajectories_str, hidden_dims_str, max_length_str, file_name,\n",
        "       num_trajectories_str, hidden_dims_str, max_length_str, num_trajectories_str)\n",
        "\n",
        "            # Print the LaTeX code for the current iteration\n",
        "            print(latex_code)\n",
        "\n",
        "            # Append the LaTeX code to the content\n",
        "            latex_content += latex_code\n",
        "\n",
        "            # Generate and save the heatmap\n",
        "            test_load.save_heatmap()\n",
        "\n",
        "# End of LaTeX document content\n",
        "latex_content += r\"\"\"\n",
        "\\end{document}\n",
        "\"\"\"\n",
        "\n",
        "# Print the complete LaTeX document content\n",
        "print(latex_content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "xUdCcuQ1_mRm",
        "outputId": "0fb41aaa-012a-48e2-9fb4-cddfbd29b34b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "not enough arguments for format string",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-6ae41fc34bd1>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;31m# Format the LaTeX code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             latex_code = r\"\"\"\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;31m\\\u001b[0m\u001b[0msubsection\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mSection\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrajectories\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHiddenDims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaxLength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: not enough arguments for format string"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "str(test_experiment.max_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "v-PcwLA88Zv8",
        "outputId": "8b1a9793-0468-48d3-9d8f-c7794ac4fc94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'100'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clean Loading"
      ],
      "metadata": {
        "id": "6d9muwMezClb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading metrics\n"
      ],
      "metadata": {
        "id": "kFvlJkDuqnEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiments Run:\n",
        "\n",
        "### Define the varying trajectory lengths\n",
        "num_trajectories = [200, 400, 600, 800, 1000]\n",
        "### Define hidden_dims\n",
        "hidden_dimens = [[8],[8,8],[32]]\n",
        "### Define trajectory lengths\n",
        "trajectory_length = [30, 50, 70, 100]\n",
        "\n"
      ],
      "metadata": {
        "id": "1oBVHJcnHUSQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_params_load = {\n",
        "    # Parameters related to policy generation\n",
        "    \"pi_b_top_k\": 1,\n",
        "    \"pi_b_epsilon\": 0.4,\n",
        "    \"pi_e_top_k\": 1,\n",
        "    \"pi_e_epsilon\": 0.05,\n",
        "    \"q_table\": q_table,\n",
        "    \"gamma\": 0.99,\n",
        "    \"num_trajectories\": 200,\n",
        "    \"num_bootstraps\": 10000,\n",
        "    \"percent_to_estimate_phi\": 0.3,\n",
        "\n",
        "    # Parameters related to shaping\n",
        "    \"shaping_feature\": smallest_distance_to_deadend,\n",
        "    \"shaping_coefficient\": 0.1,\n",
        "\n",
        "    # Parameters related to neural network architecture and training\n",
        "    \"hidden_dims\": [8],\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"dropout_prob\": 0.2,\n",
        "    \"l1_reg\": 0.00001,\n",
        "    \"l2_reg\": 0.00001,\n",
        "    \"scope_weight\": 1,\n",
        "    \"mse_weight\": 1,\n",
        "    \"num_epochs\": 300,\n",
        "\n",
        "    # Parameters related to environment\n",
        "    \"max_length\": 50,\n",
        "    \"death_drag\": 0.0,\n",
        "    # Other general parameters\n",
        "    \"dtype\": torch.float64,\n",
        "    \"experiment_type\": \"test\",\n",
        "    \"folder_path\": \"/content/drive/MyDrive/Lifegate_experiments\"\n",
        "    # \"folder_path\": \"/content\"\n",
        "}"
      ],
      "metadata": {
        "id": "Gb7UJDmHzFtf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Individual experiments"
      ],
      "metadata": {
        "id": "K9jHvrH3zvpL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_experiment = SCOPE_experiment(**base_params_load)\n",
        "test_load = existing_experiments(test_experiment)"
      ],
      "metadata": {
        "id": "S-2YrWmqzxzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U kaleido"
      ],
      "metadata": {
        "id": "vUNxRZxl1oUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kaleido\n"
      ],
      "metadata": {
        "id": "OQ5tGhKO2ToC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_load.plot_metrics_save(save = True)"
      ],
      "metadata": {
        "id": "990QGBHi029U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install psutil\n"
      ],
      "metadata": {
        "id": "SEVLh8QP3C1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "import os\n",
        "\n",
        "# Create a simple plot\n",
        "fig = go.Figure(data=go.Bar(y=[2, 3, 1]))\n",
        "\n",
        "# Define a save path (ensure the directory exists and is writable)\n",
        "# save_path = os.path.join(os.getcwd(), \"simple_plot.png\")\n",
        "\n",
        "# Save the figure using orca\n",
        "try:\n",
        "    fig.write_image(\"simple_plot.png\", engine=\"orca\")\n",
        "    # print(f\"Image saved successfully at {save_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving image: {e}\")\n",
        "\n",
        "# Display the figure\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "KjHb7qV52oy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_load.plot_metrics_save(save = True)"
      ],
      "metadata": {
        "id": "wW3oHWrQYt4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_load.plot_metrics()"
      ],
      "metadata": {
        "id": "MrnZNzP70lAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_load.experiment_instance.generate_file_name())"
      ],
      "metadata": {
        "id": "tKdSdkSdBUID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_test = test_load.experiment_instance.generate_file_name()"
      ],
      "metadata": {
        "id": "O7FYc0CVnhoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_test"
      ],
      "metadata": {
        "id": "4kPXdf47nwDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"over_trajectories_\" + file_test.split('_', 1)[1]"
      ],
      "metadata": {
        "id": "nj_PuX-_nolG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_trajectories = [200, 400, 600, 800, 1000]\n",
        "\n",
        "for i in num_trajectories:\n",
        "  print(\"-\"*100)\n",
        "  print(f\"{i} trajectories: \")\n",
        "  print(\"-\"*100)\n",
        "  params = base_params_load.copy()\n",
        "  params[\"num_trajectories\"] = i\n",
        "  test_experiment = SCOPE_experiment(**params)\n",
        "  test_load = existing_experiments(test_experiment)\n",
        "  test_load.plot_metrics_save(save = True)\n",
        "  # test_load.plot_metrics()\n",
        "  # print(test_load.experiment_instance.generate_file_name())\n",
        "\n"
      ],
      "metadata": {
        "id": "3uZFRIzmM4Qi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_load.get_state_visitation_heatmap()"
      ],
      "metadata": {
        "id": "kL7lWeCV0qY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_load.get_heatmap()"
      ],
      "metadata": {
        "id": "6Hw1Wdkj1NVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multiple experiments"
      ],
      "metadata": {
        "id": "sDSPF3dL2Uu4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_params_load = {\n",
        "    # Parameters related to policy generation\n",
        "    \"pi_b_top_k\": 1,\n",
        "    \"pi_b_epsilon\": 0.4,\n",
        "    \"pi_e_top_k\": 1,\n",
        "    \"pi_e_epsilon\": 0.05,\n",
        "    \"q_table\": q_table,\n",
        "    \"gamma\": 0.99,\n",
        "    \"num_trajectories\": 1000,\n",
        "    \"num_bootstraps\": 10000,\n",
        "    \"percent_to_estimate_phi\": 0.3,\n",
        "\n",
        "    # Parameters related to shaping\n",
        "    \"shaping_feature\": smallest_distance_to_deadend,\n",
        "    \"shaping_coefficient\": 0.1,\n",
        "\n",
        "    # Parameters related to neural network architecture and training\n",
        "    \"hidden_dims\": [8],\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"dropout_prob\": 0.2,\n",
        "    \"l1_reg\": 0.00001,\n",
        "    \"l2_reg\": 0.00001,\n",
        "    \"scope_weight\": 1,\n",
        "    \"mse_weight\": 1,\n",
        "    \"num_epochs\": 300,\n",
        "\n",
        "    # Parameters related to environment\n",
        "    \"max_length\": 100,\n",
        "    \"death_drag\": 0.0,\n",
        "    # Other general parameters\n",
        "    \"dtype\": torch.float64,\n",
        "    \"experiment_type\": \"test\",\n",
        "    \"folder_path\": \"/content/drive/MyDrive/Lifegate_experiments\"\n",
        "    # \"folder_path\": \"/content\"\n",
        "}"
      ],
      "metadata": {
        "id": "2Fig8IjZIg9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Over num trajectories"
      ],
      "metadata": {
        "id": "Vf7dv3Gv2ZBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "PF2vhQ4hoid4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_trajectories = [200, 400, 600, 800, 1000]\n",
        "viz_over_num_trajectories_save(base_params_load, num_trajectories)"
      ],
      "metadata": {
        "id": "k8rLBNyo2gZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Over train set size"
      ],
      "metadata": {
        "id": "Z_Wr6gxa2cad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set_sizes = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
        "viz_over_train_set(base_params_load, train_set_sizes)"
      ],
      "metadata": {
        "id": "_Zwhi2xB2f6W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}